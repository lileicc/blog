<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.1" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://lileicc.github.io/blog/dl4mt/2021/lut/"><meta property="og:site_name" content="Li-Lab Blog"><meta property="og:title" content="Break the Limitation of Training Data — A Better Encoder Enhanced by BERT for Speech Translation"><meta property="og:description" content="Speech translation (ST) has increasing demand in our daily life and work. Applications like travel assistant, simultaneous conference translation and movie subtitling can highly reduce translation costs. Building a ST system that can understand and directly translate acoustic speech signals into text in a target language is challenging. For example, people do not always premeditate what they are going to say. Not like text translation, ST lacks completed organization sometimes. Another part is that the parallel corpus for ST is not enough, compared to the MT task. Especially, most ST methods are limited by the amount of parallel corpus."><meta property="og:type" content="article"><meta property="og:image" content="https://lileicc.github.io/blog/"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2022-09-13T03:45:15.000Z"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image:alt" content="Break the Limitation of Training Data — A Better Encoder Enhanced by BERT for Speech Translation"><meta property="article:author" content="Zichen Chen"><meta property="article:tag" content="Speech Translation"><meta property="article:tag" content="BERT"><meta property="article:published_time" content="2021-11-30T00:00:00.000Z"><meta property="article:modified_time" content="2022-09-13T03:45:15.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Break the Limitation of Training Data — A Better Encoder Enhanced by BERT for Speech Translation","image":["https://lileicc.github.io/blog/"],"datePublished":"2021-11-30T00:00:00.000Z","dateModified":"2022-09-13T03:45:15.000Z","author":[{"@type":"Person","name":"Zichen Chen"}]}</script><title>Break the Limitation of Training Data — A Better Encoder Enhanced by BERT for Speech Translation | Li-Lab Blog</title><meta name="description" content="Speech translation (ST) has increasing demand in our daily life and work. Applications like travel assistant, simultaneous conference translation and movie subtitling can highly reduce translation costs. Building a ST system that can understand and directly translate acoustic speech signals into text in a target language is challenging. For example, people do not always premeditate what they are going to say. Not like text translation, ST lacks completed organization sometimes. Another part is that the parallel corpus for ST is not enough, compared to the MT task. Especially, most ST methods are limited by the amount of parallel corpus.">
    <link rel="preload" href="/blog/assets/style-e7wIrRON.css" as="style"><link rel="stylesheet" href="/blog/assets/style-e7wIrRON.css">
    <link rel="modulepreload" href="/blog/assets/app-TCeo_ajs.js"><link rel="modulepreload" href="/blog/assets/index.html-YsvHpHbM.js"><link rel="modulepreload" href="/blog/assets/index.html-w1429E4w.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-x3n3nnut.js">
    <link rel="prefetch" href="/blog/assets/index.html-uWfE6SbM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nE6gO_7K.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rddA2LN3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wZ8zj1zx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-PlQK4o96.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Xh1KOjV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VxJu2QC1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-U1VQl2Eb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gq5IQW34.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Eum09ixv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-k_z2qdXd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nDgcuDE0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-n_sa__IF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-02N2Cr31.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-aOh-NUrG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SwXHc6hE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-hkym9iFT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qCUSFaKS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--SW4lVd9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ejNKoiVJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ezBeMfjC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Z1t3jQDg.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-RYhmq5TF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oWDVHkT8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ROvhtggM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JUJ-rlbb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Ptx4qWCt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-umnWKYQq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rP7ssLIy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pXPA5v4g.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vstHpLDr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7boXnOP-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-E_bwP14Y.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-II3fUI6m.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CQrB_jON.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mLIoTvBR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-n7XOGv9Z.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zfNzFZSH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-i3ALVI_i.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0sOpWKpl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1cll9k9d.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7HN2H0UB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZDqg7rQw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pdN0LDKr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eNcYnvl4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-t2PsU7-4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-G00w86XT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-U5Qrn136.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bcJG7kH0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-IKJ4tLEW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BL0MJvIF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8Z5PG7OQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-V5Y8hLj3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cRwt7pxi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qsNk41eE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GOpL5FJN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_duZqh60.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-OrLT7NEC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lJG6txrw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oLHMXl4g.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-EMVGsE7D.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-vv4O3-5x.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-be7D4hpM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BT0eMqel.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SLiRoZsw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1NcWQ1JA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ekyShiFQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-sgk1m2_n.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-kb8GfeRD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xXnQV_mG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-INKfADYC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZCH3VU2M.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_hKQG08R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-bNOG1auN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-mePQ6M8X.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_TMm0KxD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-gx5foYfd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5Mhhvs5z.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-95M6igPl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jk41IluR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m9EbEEr8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-k7_BPpe1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Ex4rTbEQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-XXOQbmSB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x11OWh_8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5jEY1mB9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HKCgalpW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-PxIjFQ4M.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Slp92PgS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QXd7khlA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zWDW-dE0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-62MXtNkc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Tbf_mkls.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-hJ-E417x.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FuZtKTKb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Tv61iqe7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZeEjo3Po.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cw-4yGRl.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-bKNj4RYx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iYZB-JbA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-RKPNe-DY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pSPa82Ht.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-h4ofnM77.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-o5XIGgxU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-1KgcEp7d.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rgDmtxzC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-zptFsrns.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-L_Vpusdt.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oFmu9Riz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-C-F0YMcE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ePYWVr43.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VGTCbEKH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-m613z7qy.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-K3vd68-z.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Pe24msDw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GA1jJEr_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7tVkGo2o.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-h4DrqiSa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-oLGgogi3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FuPET0ka.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-3ImcXxNM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-fAiBxV-C.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wfv4V-9y.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0NhC4spl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-hubfQiTd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-SaTzCUQS.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4fMtu3Sn.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nzkrpgLA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GKUqQ3rT.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yDhhzzRG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html--p6oz0Q4.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jqd-2qdZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Q2YhSatR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-UY4YFkOl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xcmj5LbI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7I0SQuFR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TsTfjUqR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TvPj7CxK.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-uxnPR0Lp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-NcCekipx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-HL1RCy7q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JvCUhiEm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-wfqH0YcV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9bvCn9s_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Z3xS8x1W.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-reiNbN8M.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jbYZ4as8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WR6QlAin.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-WaFgOK5R.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-VUvPSPw2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-0b-Nw4qY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FSdd7GgV.js" as="script"><link rel="prefetch" href="/blog/assets/giscus-unEZQsJ0.js" as="script"><link rel="prefetch" href="/blog/assets/auto-HRhNfH8L.js" as="script"><link rel="prefetch" href="/blog/assets/index-rBp-GJb9.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-i2ohwMnJ.js" as="script"><link rel="prefetch" href="/blog/assets/SearchResult-qkUJdFfb.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/blog/"><img class="vp-nav-logo" src="/blog/logo.svg" alt="Li-Lab Blog"><!----><span class="vp-site-name hide-in-pad">Li-Lab Blog</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Blog Home" class="vp-link nav-link nav-link" href="/blog/"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon>Blog Home<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Category" class="vp-link nav-link nav-link" href="/blog/category/"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="baseline-category" width="1em" height="1em"></iconify-icon>Category<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Tags" class="vp-link nav-link nav-link" href="/blog/tag/"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="tag" width="1em" height="1em"></iconify-icon>Tags<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Timeline" class="vp-link nav-link nav-link" href="/blog/timeline/"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="time" width="1em" height="1em"></iconify-icon>Timeline<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/lileicc/blog" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" class="outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="search-pro-button" role="search" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Break the Limitation of Training Data — A Better Encoder Enhanced by BERT for Speech Translation</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Zichen Chen</span></span><span property="author" content="Zichen Chen"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2021-11-30T00:00:00.000Z"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category5 clickable" role="navigation">ST</span><span class="page-category-item category1 clickable" role="navigation">DL4MT</span><!--]--><meta property="articleSection" content="ST,DL4MT"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag5 clickable" role="navigation">Speech Translation</span><span class="page-tag-item tag3 clickable" role="navigation">BERT</span><!--]--><meta property="keywords" content="Speech Translation,BERT"></span><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 5 min</span><meta property="timeRequired" content="PT5M"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#end-to-end-st">End-to-end ST</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#inspired-by-human-—-lut">Inspired by Human — LUT</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#evaluation-of-the-lut">Evaluation of the LUT</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#semantic-analysis">Semantic Analysis</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#lut-vs-cascaded-model">LUT vs Cascaded Model</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><p>Speech translation (ST) has increasing demand in our daily life and work. Applications like travel assistant, simultaneous conference translation and movie subtitling can highly reduce translation costs. Building a ST system that can understand and directly translate acoustic speech signals into text in a target language is challenging. For example, people do not always premeditate what they are going to say. Not like text translation, ST lacks completed organization sometimes. Another part is that the parallel corpus for ST is not enough, compared to the MT task. Especially, most ST methods are limited by the amount of parallel corpus.</p><!-- more --><p>Such demanded applications stir interest within the research community. Over its decades history, speech translation has experienced several shifts in its primary research themes. The traditional way is coupled cascades of speech recognition and machine translation. Then, researchers emerged the exploration of tight coupling. Recently, end-to-end models have attracted much attention. To achieve end-to-end speech translation, our research community has made a lot of efforts. Today, we are going to introduce an interesting paper that helps us to break the limitations of the amount of parallel corpus.</p><h2 id="end-to-end-st" tabindex="-1"><a class="header-anchor" href="#end-to-end-st" aria-hidden="true">#</a> End-to-end ST</h2><p>Generally, we use Cascaded ST systems to achieve ST, which extracts acoustic features and source-text semantic features before translating them to the target text.</p><p><img src="/blog/assets/1-fED187Qr.png" alt="Figure 1: The process of Cascaded ST systems"></p><p>Figure 1: The process of Cascaded ST systems</p><p>However, such intermediate stages meet challenges in real cases: no sufficient supervision to guide the encoder-decoder to process the audio properly, and the amount of parallel ST training corpus is small. It may generate errors when processing the audio inputs, and then influence the quality of MT.</p><p>Therefore, end-to-end ST has been proposed to solve these issues. Methods like pre-training and multi-task learning can significantly improve performance. However, the performance of end-to-end ST is not as good as Cascaded ST for a very long time, since the ST data is insufficient to build a high-quality model.</p><p>How to utilize the best of existing ST data to improve the end-to-end ST performance? <em>Listen, Understand and Translate (LUT): Triple Supervision Decouples End-to-end Speech-to-text Translation</em> introduces a human-inspired method to complete ST tasks via understanding acoustic information at the semantic level as much as possible, just like humans. It can guide the acoustic encoder to extract information from the auditory input. Additionally, it utilizes a pre-trained BERT model to enforce the upper encoder to produce as much semantic information as possible, without extra data.</p><h2 id="inspired-by-human-—-lut" tabindex="-1"><a class="header-anchor" href="#inspired-by-human-—-lut" aria-hidden="true">#</a> Inspired by Human — LUT</h2><p>Let&#39;s take a look at the human&#39;s translation process. For example, when we want to translate Chinese audio to English, we need to listen to the audio first and try to understand the meaning of audio. After processing it in our brain, we can get the outputs.</p><p><img src="/blog/assets/2-9s91EV3z.png" alt="Figure 2: The process of how humans translate."></p><p>Figure 2: The process of how humans translate.</p><p>Currently, end-to-end models are built with an encoder-decoder architecture that can directly translate speech without using explicitly generated intermediate ASR output. Methods like multi-task training and pre-training are used to incorporate additional ASR and MT data and reduce dependency on scarce end-to-end data. However, these techniques were not able to exploit ASR and MT data as effectively as Cascade methods, to get comparable translation quality.</p><p>What if we make the machine to imitate human behaviour in translation? Can we improve the quality of speech translation? The answer is yes. The significant part of LUT is it adds the &quot;understand&quot; function in ST.</p><p>LUT uses an <strong>acoustic encoder</strong> to &quot;Listen&quot;, a <strong>semantic encoder</strong> to &quot;Understand&quot;, and a <strong>translation decoder</strong> to &quot;Translate&quot;, to imitate the intermediate steps for effective end-to-end speech translation.</p><p><img src="/blog/assets/3-tnY-RBFc.png" alt="Figure 3: The architecture of LUT. "></p><p>Figure 3: The architecture of LUT.</p><p>Specifically, LUT consists of three modules:</p><ul><li><strong>Acoustic encoder</strong> network that encodes the audio input sequence into hidden features corresponding to the source text;</li><li><strong>Semantic encoder</strong> network that extracts hidden semantic representation for translation, which behaves like a normal machine translation encoder;</li><li><strong>Translation decoder</strong> network that outputs sentence tokens in the target language.</li></ul><p>The most interesting feature of LUT is utilizing Connectionist Temporal Classification (CTC) + distance Loss to optimize the encoders, and break the limitation of insufficient parallel ST data within BERT. This is particularly interesting because it is hard to train an end-to-end ST model well with a small number of data (compared to MT). This strategy helps LUT to learn semantic features, meanwhile, it can predict recognition results while predicting translation results. Thus, we can diagnose whether the wrong prediction for translation is caused by the wrong acoustic modelling.</p><h2 id="evaluation-of-the-lut" tabindex="-1"><a class="header-anchor" href="#evaluation-of-the-lut" aria-hidden="true">#</a> <strong>Evaluation of the LUT</strong></h2><p>To test the effectiveness of LUT, the paper includes Augmented Librispeech English-French, IWSLT2018 English-German, and TED English-Chinese test.LUT achieves all the best performance. Compared to the Cascaded model, LUT is lighter (fewer parameters), which can perform a faster translation.</p><h3 id="semantic-analysis" tabindex="-1"><a class="header-anchor" href="#semantic-analysis" aria-hidden="true">#</a> Semantic Analysis</h3><p>LUT compares the acoustic encoder and semantic encoder in this paper. Figure 3 shows the attention for different module layers. It is interesting that the acoustic encoder focuses on the local features, while the semantic encoder can capture more global features.</p><p><img src="/blog/assets/4-FZprD6Zb.png" alt="Figure 4: The visualization of attention for different module layers. (a), (b) visualize the attention of the last layer of the acoustic encoder and the first layer of semantic encoder respectively. "></p><p>Figure 4: The visualization of attention for different module layers. (a), (b) visualize the attention of the last layer of the acoustic encoder and the first layer of semantic encoder respectively.</p><p>It also compares the acoustic encoder and semantic encoder on the Fluent Speech Commands dataset, to test SpeakerVer (identify the speaker) and IntentIde (intention recognition). In Table 1, the semantic encoder only gets 46.3 accuracy on the SpeakerVer task, showing that the semantic encoder can focus on the translation task.</p><table><thead><tr><th></th><th>SpeakerVer</th><th>IntentIde</th></tr></thead><tbody><tr><td>Acoustic Encoder</td><td>97.6</td><td>91.0</td></tr><tr><td>Semantic Encoder</td><td>46.3</td><td>93.1</td></tr></tbody></table><p>Table 1: Classification accuracy on speaker verification and intent identification.</p><p>It finds acoustic information is modelled at low-level layers and semantic information is captured at high-level layers.</p><h3 id="lut-vs-cascaded-model" tabindex="-1"><a class="header-anchor" href="#lut-vs-cascaded-model" aria-hidden="true">#</a> LUT vs Cascaded Model</h3><table><thead><tr><th>Transcription</th><th>LUT</th></tr></thead><tbody><tr><td>reference</td><td>it was mister jack maldon</td></tr><tr><td>hypothesis</td><td>it was mister jack mal</td></tr><tr><td>Translation</td><td></td></tr><tr><td>reference</td><td>c&#39;était m. jack maldon</td></tr><tr><td>hypothesis</td><td>c&#39;était m. jack maldon</td></tr></tbody></table><table><thead><tr><th>Transcription</th><th>Cascaded</th></tr></thead><tbody><tr><td>reference</td><td>it was mister jack maldon</td></tr><tr><td>hypothesis</td><td>it was mister jack mal</td></tr><tr><td>Translation</td><td></td></tr><tr><td>reference</td><td>c&#39;était m. jack maldon</td></tr><tr><td>hypothesis</td><td>c&#39;était m. jack mal</td></tr></tbody></table><p>Here is an example of transcription and translation on En-Fr test set generated by the LUT and Cascaded model. It has a recognition error in the transcription stage (mal). LUT can translate correctly, ignoring the mistake that happened in transcription, while Cascaded Model can not correct the error and continue to pass the incorrect signal.</p><p>LUT not only can directly translate to the target language within the original audio information, but also is fault-tolerant during the acoustic modelling.</p><h1 id="summary" tabindex="-1"><a class="header-anchor" href="#summary" aria-hidden="true">#</a> Summary</h1><p>LUT is a unified training framework to decouple the end-to-end speech translation task, under the supervision of the acoustic, semantic, linguistic level. It is effective and utilizes existing data to solve the problem of insufficient ST data.</p><p>The code can be found at: <a href="https://github.com/dqqcasia/st" target="_blank" rel="noopener noreferrer">https://github.com/dqqcasia/st<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p><a href="https://github.com/dqqcasia/st" target="_blank" rel="noopener noreferrer">GitHub - dqqcasia/st: End-to-end Speech Translation<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>Paper: <a href="https://arxiv.org/pdf/2009.09704.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2009.09704.pdf<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h1 id="reference" tabindex="-1"><a class="header-anchor" href="#reference" aria-hidden="true">#</a> Reference</h1><ol><li><p>Dong Q, Ye R, Wang M, et al. &quot; Listen, Understand and Translate&quot;: Triple Supervision Decouples End-to-end Speech-to-text Translation[J]. AAAI 2021.</p></li><li><p>Sperber M, Paulik M. Speech Translation and the End-to-End Promise: Taking Stock of Where We Are[C]//Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020: 7409-7421.</p></li><li><p>Stoian M C, Bansal S, Goldwater S. Analyzing ASR pretraining for low-resource speech-to-text translation[C]//ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020: 7909-7913</p></li><li><p>Weiss R J, Chorowski J, Jaitly N, et al. Sequence-to-sequence models can directly translate foreign speech[J]. arXiv preprint arXiv:1703.08581, 2017.</p></li></ol><h1 id="supplemental-materials" tabindex="-1"><a class="header-anchor" href="#supplemental-materials" aria-hidden="true">#</a> Supplemental Materials</h1><ol><li><p>Baevski A, Zhou H, Mohamed A, et al. wav2vec 2.0: A framework for self-supervised learning of speech representations[J]. arXiv preprint arXiv:2006.11477, 2020.</p></li><li><p>Han C, Wang M, Ji H, et al. Learning Shared Semantic Space for Speech-to-Text Translation[J]. arXiv preprint arXiv:2105.03095, 2021.</p></li><li><p>Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in neural information processing systems. 2017: 5998-6008.</p></li></ol></div><!--[--><!----><!--]--><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/lileicc/blog/edit/main/dl4mt/2021/lut/README.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><div class="update-time"><span class="label">Last update: </span><!----></div><div class="contributors"><span class="label">Contributors: </span><!--[--><!--[--><span class="contributor" title="email: lileicc@gmail.com">Lei Li</span><!--]--><!--]--></div></div></footer><!----><div id="comment" class="giscus-wrapper input-top" style="display:block;"><div class="loading-icon-wrapper" style="display:flex;align-items:center;justify-content:center;height:96px"><svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" preserveAspectRatio="xMidYMid" viewBox="25 25 50 50"><animateTransform attributeName="transform" type="rotate" dur="2s" keyTimes="0;1" repeatCount="indefinite" values="0;360"></animateTransform><circle cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="4" stroke-linecap="round"><animate attributeName="stroke-dasharray" dur="1.5s" keyTimes="0;0.5;1" repeatCount="indefinite" values="1,200;90,200;1,200"></animate><animate attributeName="stroke-dashoffset" dur="1.5s" keyTimes="0;0.5;1" repeatCount="indefinite" values="0;-35px;-125px"></animate></circle></svg></div></div><!--[--><!----><!--]--><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Li Lab</div><div class="vp-copyright">Copyright © 2023 Zichen Chen</div></footer></div><!--]--><!----><!----><!--]--></div>
    <script type="module" src="/blog/assets/app-TCeo_ajs.js" defer></script>
  </body>
</html>

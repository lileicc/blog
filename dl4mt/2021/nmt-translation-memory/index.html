<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.11" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.43" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://lileicc.github.io/blog/dl4mt/2021/nmt-translation-memory/"><meta property="og:site_name" content="Li-Lab Blog"><meta property="og:title" content="Neural Machine Translation with Monolingual Translation Memory"><meta property="og:description" content="Hello fellow readers! In this post, I would like to share a recent advance in the field of Machine Translation. Specifically, I will be presenting the paper Neural Machine Trans..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2024-05-25T23:17:24.000Z"><meta property="article:author" content="Rajan Saini"><meta property="article:tag" content="Translation Memory"><meta property="article:published_time" content="2021-12-08T00:00:00.000Z"><meta property="article:modified_time" content="2024-05-25T23:17:24.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Neural Machine Translation with Monolingual Translation Memory","image":[""],"datePublished":"2021-12-08T00:00:00.000Z","dateModified":"2024-05-25T23:17:24.000Z","author":[{"@type":"Person","name":"Rajan Saini"}]}</script><title>Neural Machine Translation with Monolingual Translation Memory | Li-Lab Blog</title><meta name="description" content="Hello fellow readers! In this post, I would like to share a recent advance in the field of Machine Translation. Specifically, I will be presenting the paper Neural Machine Trans...">
    <link rel="preload" href="/blog/assets/style-Cq8eyGeZ.css" as="style"><link rel="stylesheet" href="/blog/assets/style-Cq8eyGeZ.css">
    <link rel="modulepreload" href="/blog/assets/app-DiCjo-Va.js"><link rel="modulepreload" href="/blog/assets/index.html-rdxcuHG-.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/blog/assets/index.html-n7qbu3dk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DsZ03cqp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-r3wL3lYW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BTmZnjzu.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B3lBlHt5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DkOZIlpg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CFyAOJxa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Dy--DCvM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BGcY7GRM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CnEewnS_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B-7kV_Pa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Dxt46wjr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ailBi3IV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CLkHMPSR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BcxjbFyQ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B5tQQqUs.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7GEx1xL_.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-X1I--pzi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Cqxm4VEw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-dZRpMDcp.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B0QaSsCk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lbmWsbm6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BL20rJEw.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-DwhX0xCD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-eyD8xvL-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-4T5RsOJr.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-C4oYB-TX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DT0Vw-X1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ChpH1XCa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CG4zWerc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cDcguak7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BLmhJl3H.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BUnffEMv.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-K8vN4nvk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-izeVRWR8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-p4XBto_y.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-l1eZfZeq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DggTdQeV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BqVwiDmI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ChpRCIc8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5hhedaTR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CIWPrBfh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BYBCTXZh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DWU1ODhk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BbKNZ18w.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BkwXzOb3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-jhqGT4dL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CS6gUaSX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CGvZjib9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DkRkbNQ6.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Ic0xQiYz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Bi8bMppE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DPfrum7j.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BYsu2jJc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-chNhRanf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BXwcVWaJ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B6PjGDAO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-nmkosgT0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-C-1PzENR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BaWZvSMh.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-iCm852ld.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BDc3S-C2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CoxTWtqI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BW3VPrzj.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DLbZgarF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DZPCdxOC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CvBuB7g8.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BQK4OLG0.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-fRbI1bsI.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Byllwfsd.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DNApUOep.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BHiIQnkE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BuHhtC_q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DW1rLQdB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CFKdo3WH.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B8BC64BL.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-xb2wQrjg.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B6uJhqIN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DrA_NyPl.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-C7_gn4qD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DPhNyCil.js" as="script"><link rel="prefetch" href="/blog/assets/giscus--_FS5kYt.js" as="script"><link rel="prefetch" href="/blog/assets/auto-CAdRPfCH.js" as="script"><link rel="prefetch" href="/blog/assets/index-wZ-hXvzw.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-SzV8tJDW.js" as="script"><link rel="prefetch" href="/blog/assets/SearchResult-75TAtN8b.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container no-sidebar external-link-icon has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/blog/"><img class="vp-nav-logo" src="/blog/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">Li-Lab Blog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link vp-link" href="/blog/" aria-label="Blog Home"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon>Blog Home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link vp-link" href="/blog/category/" aria-label="Category"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="baseline-category" width="1em" height="1em"></iconify-icon>Category<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link vp-link" href="/blog/tag/" aria-label="Tags"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="tag" width="1em" height="1em"></iconify-icon>Tags<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link vp-link" href="/blog/timeline/" aria-label="Timeline"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="time" width="1em" height="1em"></iconify-icon>Timeline<!----></a></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/lileicc/blog" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Neural Machine Translation with Monolingual Translation Memory</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Rajan Saini</span></span><span property="author" content="Rajan Saini"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2021-12-08T00:00:00.000Z"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color0 clickable" role="navigation">MT</span><span class="page-category-item color0 clickable" role="navigation">DL4MT</span><!--]--><meta property="articleSection" content="MT,DL4MT"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2 clickable" role="navigation">Translation Memory</span><!--]--><meta property="keywords" content="Translation Memory"></span><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 8 min</span><meta property="timeRequired" content="PT8M"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#so-what-is-machine-translation">So... what is Machine Translation?</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#data-is-key">Data is Key</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#monolingual-data">Monolingual Data</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#translation-memory">Translation Memory</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#end-of-intro">End of Intro</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#monolingual-translation-memory">Monolingual Translation Memory</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#intuition">Intuition</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#parallel-encoders">Parallel Encoders</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#main-translation-model">Main Translation Model</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#done-at-last">Done! At last</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#references">References</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content"><p>Hello fellow readers! In this post, I would like to share a recent advance in the field of Machine Translation. Specifically, I will be presenting the paper <em>Neural Machine Translation with Monolingual Translation Memory</em> by Cai et al, which received one of the six distinguished paper awards from ACL 2021.</p><p>Paper: <a href="https://aclanthology.org/2021.acl-long.567/" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2021.acl-long.567/</a> Code: <a href="https://github.com/jcyk/copyisallyouneed" target="_blank" rel="noopener noreferrer">https://github.com/jcyk/copyisallyouneed</a></p><h2 id="so-what-is-machine-translation" tabindex="-1"><a class="header-anchor" href="#so-what-is-machine-translation"><span>So... what is Machine Translation?</span></a></h2><p>You can probably guess from the name: over the last few decades, researchers have tried to get computers (a.k.a. <strong>machines</strong>) to <strong>translate</strong> between human languages. Their hard work has resulted in a plethora of products, like Google Translate and Microsoft Translator. I&#39;m sure all of you have played with these tools before (if not, <a href="https://translate.google.com/" target="_blank" rel="noopener noreferrer">there&#39;s no time like the present</a>) and have tried inputting various kinds of sentences. Their translation quality is quite impressive, and you can get near-native translations in many contexts (e.g. simple sentences between widely-spoken languages). However, you also may have noticed that some languages have better performance than others. This difference is due to the amount of usable translation data available (we&#39;ll go over what this means below). One of the key challenges being worked on today is to bridge this gap between <em>low-resource</em> and <em>high-resource</em> languages.</p><figure><img src="/blog/assets/english-spanish-0KJmPfDD.png"><img src="/blog/assets/english-xhosa-BHOd_x7E.png"><figcaption align="center" style="font-size:1vh;">The Spanish output seems to be accurate, but it might be possible to improve the Xhosa translation (disclaimer - I do not speak Xhosa). The word &quot;recurrent&quot; is being translated into &quot;oluqhubekayo&quot;, which means &quot;ongoing&quot;. In order to better capture the spirit of recurrent neural networks, however, a word closer to &quot;self-referencing&quot; might be more appropriate. This example is intended to illustrate the need for better low-resource language performance in jargon-heavy contexts. </figcaption></figure><h3 id="data-is-key" tabindex="-1"><a class="header-anchor" href="#data-is-key"><span>Data is Key</span></a></h3><p>In order to understand what translation data is and why it is crucial for a good machine translation (MT) system, we first need to understand how these systems work. All of the current state-of-the-art use special kinds of programs called <em>neural networks</em>, which are infamous for being able to approximate <em>any</em> mathematical function by looking at examples.</p><figure><img src="/blog/assets/neural-network-j52JBvzs.png"><figcaption align="center" style="font-size:1vh;">In this case, the network is learning to approximate f(x) = x + 1 just by looking at set of examples. The end goal to make correct guesses for unseen inputs, like passing 1.5 and getting 2.5. </figcaption></figure><p>If we can convert an English sentence into a list of numbers, and if we can do the same for a Spanish sentence, then in theory, it should be possible for the network to learn how to convert the numbers from one form into the other. And if we can train it on a large number of sentence pairs, it just might learn the grammatical rules well enough to provide good translations for unseen inputs.</p><figure><img src="/blog/assets/neural-machine-translation-CuikXaN_.png"><figcaption align="center" style="font-size:1vh;">Instead of a single number, the network is learning to map between entire sequences of numbers. This is still possible, and there are special network architectures optimized for &quot;sequence to sequence&quot; tasks. </figcaption></figure><p>Generally, hundreds-of-thousands or millions of parallel sentences are needed for good performance. However, it is hard to obtain pure, parallel datasets of this size for low-resource languages.</p><h3 id="monolingual-data" tabindex="-1"><a class="header-anchor" href="#monolingual-data"><span>Monolingual Data</span></a></h3><p>Even though low-resource languages like Xhosa may lack large amounts of parallel data, they still have vast amounts of untranslated text. If incorporated creatively, this <em>monolingual</em> (i.e. untranslated) text can also be used to help the network learn. Many strategies exist:</p><ul><li><em>Back-translation</em> uses an okay-performing, reversed translation model to turn each sentence from the monolingual data into a synthetic (fake) parallel pair. We can then train the main model on this new parallel data to hopefully expose it to a wider variety of sentences.</li><li>One could also use this data to <em>pre-train</em> the model before training on the parallel data. During the pre-training, all one has to do is delete random words from the monolingual corpus (e.g. a Xhosa book) and train the model to fill in the blanks. If the model does this task successfully and then trains on the parallel data, it may make better translations (at least, according to results published in <em>Multilingual Denoising Pre-training for Neural Machine Translation</em>).</li></ul><p>However, the main advance I will be sharing with you presents an entirely new way of using monolingual data. Specifically, it combines monolingual data with a mechanism called <em>Translation Memory</em>.</p><h3 id="translation-memory" tabindex="-1"><a class="header-anchor" href="#translation-memory"><span>Translation Memory</span></a></h3><p>Before getting into what <em>Translation Memory</em> actually is, let me first motivate it a little. Intuitively, a good-performing translation program should be able to perform well in a wide variety of contexts. Specifically, it should be able to translate sentences from speeches, news articles, folk tales, research papers, tweets, random blog posts on machine translation, etc. However, if you want a generic, jack-of-all-trades model to make passable translations in all of these areas, you inevitably have to make some sacrifices. This is where the <em>infrequent words</em> problem comes in: words that are infrequently-encountered by the model during training get discarded as noise, reducing performance in specialized domains. For example, it could forget the word &quot;chromosome&quot; and translate a biology textbook incorrectly. This happens to humans too. If you&#39;re trying to become an expert at 10 topics in a short timespan, you may easily forget technical words crucial to each of the 10 topics. If one of those topics is the <em>Medieval History of Mathematics</em>, you may easily forget who <em>al-Khawarizmi</em> was, causing you to mis-attribute his discoveries. (It&#39;s even harder for a neural network, as it could never exploit the mnemonic connection between <em>algorithm</em> and <em>al-Khawarizmi</em> 😄).</p><p>However, the good news is that computers can look things up extremely quickly, far more quickly than humans. Imagine if you were tested on the <em>Medieval History of Mathematics</em>, but you had the textbook&#39;s glossary with you. All of a sudden, if you were asked about <em>al-Khawarizmi</em>, you could provide the correct answer in the time that it takes you to look him up. <em>Translation Memory</em> essentially imbues the neural network with this same capability.</p><p>Essentially, each time the network is asked to generate a word, it can reference the translation memory (a bilingual dictionary mapping words between the source and target languages) to provide a more nuanced translation. The original researchers who proposed this concept came up with a two-component model architecture. One component consists of a neural network that generates its own &quot;guess&quot; for the translation word-by-word. The other component, called a memory component, retrieves the translations for each source word from a large dictionary. These two proposals are then combined, so that the one with higher confidence is used in the final translation.</p><p>(Note that everything in this section comes from <em>Memory-augmented Neural Machine Translation</em> [2]. If you want to learn more, go read their paper! I promise you, it&#39;s very interesting).</p><h3 id="end-of-intro" tabindex="-1"><a class="header-anchor" href="#end-of-intro"><span>End of Intro</span></a></h3><p>Thank you so much for bearing with me through the introduction. I did my best to put these topics into understandable words, but I may have accidentally glossed over something without explaining. If you have any questions or feedback, please don&#39;t hesitate to reach out to me at rajansaini@ucsb.edu.</p><h2 id="monolingual-translation-memory" tabindex="-1"><a class="header-anchor" href="#monolingual-translation-memory"><span>Monolingual Translation Memory</span></a></h2><p>Now, the moment we have all been waiting for has finally arrived. We can finally talk about what Monolingual Translation Memory is, how it exploits monolingual data, and what its implications are.</p><h3 id="intuition" tabindex="-1"><a class="header-anchor" href="#intuition"><span>Intuition</span></a></h3><p>The original Translation Memory introduced above is quite powerful, but it has a few limitations:</p><ul><li>The first is that it requires a parallel, bilingual dictionary. This means that when trying to come up with a translation for an unknown word, the model will try to translate it <em>directly</em> rather than use the entire sentence&#39;s context.</li><li>In addition, it is impossible for the retrieval mechanism itself to adapt as the model trains (a dictionary cannot change, even though other words might be more relevant).</li></ul><p>The new Monolingual Translation Memory is designed to solve both of these issues by:</p><ul><li>Using entire aligned sentences instead of a word-to-word dictionary. Such a sentence-sentence dictionary would be prohibitively long for humans to read through, but a clever retrieval mechanism would make it usable for a computer program. Furthermore, they use another neural network called a &quot;parallel encoder&quot; to determine whether two sentences are translations of each other. This allows them to associate monolingual sentences with existing translations, exploding the number of possibilities! (If you&#39;re confused by this, don&#39;t worry; this will be explained in more detail in a section below)</li><li>Making the retrieval mechanism <em>learnable</em>. This means that as the model trains on a parallel corpus, the retrieval mechanism should also be able to adapt itself. Specifically, it should learn to provide the most relevant translations from a large set of sentences (including sentences outside the original sentence-sentence dictionary).</li></ul><h3 id="parallel-encoders" tabindex="-1"><a class="header-anchor" href="#parallel-encoders"><span>Parallel Encoders</span></a></h3><p>The main secret behind this advance is its usage of <em>parallel encoders</em>. These are neural networks (i.e. mathematical functions) that map sentences to their meaning. More precisely, they map sentence embeddings (the original sentence converted to numbers, see &quot;Data is Key&quot;) to an <em>encoding vector</em>. The hope is for sentences with the <em>same meaning</em> to have the <em>same encoding</em>, even if they are expressed differently. For example, a good encoder would give &quot;I find recurrent neural networks fascinating&quot; and &quot;recurrent neural networks are fascinating to me&quot; similar encodings.</p><figure><img src="/blog/assets/siamese-network-diagram-D2OxlYxs.jpg"><figcaption align="center" style="font-size:1vh;">This concept being illustrated is also known as a Siamese network. They have been used successfully outside of machine translation, for tasks like handwritten signature verifiction and facial recognition. </figcaption></figure><p>We can also extend this idea across languages! We can have an encoder for each language that converts their sentences into a shared &quot;meaning space&quot;. More precisely, two sentences from different languages that share the same meaning should get mapped to similar encoding vectors:</p><p><img src="/blog/assets/training-translation-memory-DAAAKLsY.png" alt=""></p><p>Before we train our main neural network, we first train the target and source encoders on parallel text. The goal is for them to output identical encodings when they have the same meaning and different encodings when their meaning is different. This is called the &quot;alignment step&quot;. Then we can run the target encoder over a large untranslated corpus to encode each sentence. Then, every time the user wants a new sentence translated, we can find the target sentence with closest meaning by comparing the encodings:</p><p><img src="/blog/assets/monolingual-translation-memory-8YhwKEaU.jpg" alt=""></p><p>Through this method, every sentence ever written in the target language can now be retrieved (at least in theory). The researchers that proposed this process found that searching for the most-similar encoding is equivalent to performing a Maximum Inner Product Search (MIPS). Fast algorithms that solve MIPS have already been discovered, so they can also be used for a speedy retrieval.</p><h3 id="main-translation-model" tabindex="-1"><a class="header-anchor" href="#main-translation-model"><span>Main Translation Model</span></a></h3><p>The retrieval model described above will give native translations, since it searches through text originally written by humans. However, what about completely new inputs for which direct translations have never existed? In that case, we would still want to use a larger neural network to create novel translations. If we could somehow allow that network to have access to some of the best-matched sentences found by the retrieval model, this should give us the best of both worlds. In highly domain-specific cases, the retrieval model could pull up relevant words or context that the network can use. The network could then produce a translation that matches the source sentence while taking advantage of these technical words.</p><figure><img src="/blog/assets/mtm-architecture-B7obNB3t.png"><figcaption align="center" style="font-size:1vh;">This figure was taken from the original paper. The retrieval model is expected to output a list of sentence encodings (z1, z2, ...) and their similarities to the original input sentence (f(x,z1), f(x,z2), ...). This information is then fed into the main network (the Translation Model), along with the source sentence&#39;s encoding. </figcaption></figure><p>In order to pass the encodings and retrieved sentences to the translation model, we can use a memory encoder and an attention mechanism. The memory encoder is a simple learnable matrix that maps each sentence to a new vector space (this section is a little more advanced, but &quot;learnable&quot; means that the matrix&#39;s weights will get adjusted during training) . I would guess that this is done so that the source sentence and retrieved sentences get mapped to the same vector space. This way, they can be meaningfully compared with and added to each other. After the retrieved sentences get transformed into memory embeddings, an attention mechanism combines them with the source sentences (scaled back by their confidences). I will not explain the full details behind how the attention mechanism works (<a href="https://towardsdatascience.com/the-intuition-behind-transformers-attention-is-all-you-need-393b5cfb4ada" target="_blank" rel="noopener noreferrer">this article</a> has a great explanation), but the intuitive idea is that it highlights the relevant items from the memory encoder based on the source embeddings. After that, a decoder network converts the attention scores into the final translation, word-by-word.</p><h2 id="done-at-last" tabindex="-1"><a class="header-anchor" href="#done-at-last"><span>Done! At last</span></a></h2><p>Whew! That was a lot! Anyway, this is my possibly-confusing attempt at sharing one of the latest advances in Machine Translation. If you need any clarification (especially with the translation model above), definitely feel free to reach out! Otherwise, thank you so much for your patience to have made it this far.</p><h2 id="references" tabindex="-1"><a class="header-anchor" href="#references"><span>References</span></a></h2><p>[1] Deng Cai, Yan Wang, Huayang Li, Wai Lam, Lemao Liu. Neural Machine Translation with Monolingual Translation Memory. ACL 2021.</p><p>[2] Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, Andrew Abel. Memory-augmented Neural Machine Translation. EMNLP 2017.</p><p>[3] Victor Zhou. “Neural Networks from Scratch.” <em>Victor Zhou</em>, Victor Zhou, 9 Feb. 2020, https://victorzhou.com/series/neural-networks-from-scratch/.</p></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="vp-link vp-external-link-icon vp-meta-label" href="https://github.com/lileicc/blog/edit/main/dl4mt/2021/nmt-translation-memory/README.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last update: </span><!----></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: lileicc@gmail.com">Lei Li</span><!--]--><!--]--></div></div></footer><!----><div id="vp-comment" class="giscus-wrapper input-top" style="display:block;"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" preserveAspectRatio="xMidYMid" viewBox="0 0 100 100"><circle cx="28" cy="75" r="11" fill="currentColor"><animate attributeName="fill-opacity" begin="0s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></circle><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 47a28 28 0 0 1 28 28"><animate attributeName="stroke-opacity" begin="0.1s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 25a50 50 0 0 1 50 50"><animate attributeName="stroke-opacity" begin="0.2s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path></svg></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Li Lab</div><div class="vp-copyright">Copyright © 2024 Rajan Saini </div></footer></div><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/blog/assets/app-DiCjo-Va.js" defer></script>
  </body>
</html>

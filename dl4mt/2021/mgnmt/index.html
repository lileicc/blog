<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.11" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.43" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://lileicc.github.io/blog/dl4mt/2021/mgnmt/"><meta property="og:site_name" content="Li-Lab Blog"><meta property="og:title" content="Mirror-Generative Neural Machine Translation"><meta property="og:description" content="In general, neural machine translation (NMT) requires a large amount of parallel data (e.g., EN->CN). However, it is not easy to collect enough high-quality parallelly-paired se..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2024-05-25T23:06:05.000Z"><meta property="article:author" content="Tsu-Jui Fu"><meta property="article:tag" content="Variational Inference"><meta property="article:tag" content="Latent Variable Model"><meta property="article:tag" content="Semi-supervised Learning"><meta property="article:published_time" content="2021-11-25T00:00:00.000Z"><meta property="article:modified_time" content="2024-05-25T23:06:05.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Mirror-Generative Neural Machine Translation","image":[""],"datePublished":"2021-11-25T00:00:00.000Z","dateModified":"2024-05-25T23:06:05.000Z","author":[{"@type":"Person","name":"Tsu-Jui Fu"}]}</script><title>Mirror-Generative Neural Machine Translation | Li-Lab Blog</title><meta name="description" content="In general, neural machine translation (NMT) requires a large amount of parallel data (e.g., EN->CN). However, it is not easy to collect enough high-quality parallelly-paired se...">
    <link rel="preload" href="/blog/assets/style-BEIjLUpX.css" as="style"><link rel="stylesheet" href="/blog/assets/style-BEIjLUpX.css">
    <link rel="modulepreload" href="/blog/assets/app-DvxBpnKI.js"><link rel="modulepreload" href="/blog/assets/index.html-nXBkKbPa.js"><link rel="modulepreload" href="/blog/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/blog/assets/index.html-BroJAVs1.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DqRRrdxN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-geg8hdaA.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-T38F122l.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BU0zenT9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DRY_Rg1V.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-yeU1vgED.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DWy6xs1J.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-pCrE8yHf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BJ_AghC5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-k3b_T-SP.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-5PV3NlK2.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CbDJmTDz.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-rqHrn9XR.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DXKear5F.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DDGXC_ws.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DQsqSk5b.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ZWqMQjDf.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BmkCcctU.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CO-pLJt9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DpYleMCC.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Dc1M0ATi.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CauSBX8J.js" as="script"><link rel="prefetch" href="/blog/assets/404.html-Cw-U9o5J.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B_ynrIRb.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-QtilJd5B.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BNCIUQPO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DdBHs2Us.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DOSYHKuw.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-qalJTdOm.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Chsz9oWa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ChJmO1W9.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B4SXWPkk.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Brw2XJ0u.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DkfNdZ8V.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CSREm_rq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-8X7fVq8Q.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-lG0YXER3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Dx4J44pa.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-T9BHFuQN.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Y-i8XmH5.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DK7Fp7xG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CRTjq6AW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CoiG0KoW.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DRJCQVaX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-TJWQZwkM.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-_9uD0-ss.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Bo--ZP-D.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-9Zna8f0T.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DF9aEpdE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DVXDgIxX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-FdwJo6wG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-tsChVsQB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DLTaczOx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-COn1v7J7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-cFqiIE9S.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DkU8CzUY.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-AfrCKcc-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BiQLQhAV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BPrRjTfB.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Y_uyyvMq.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-JDfCOuVV.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CCFENeZX.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DYUMSDb3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CPfa70U7.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DQUwiUh-.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-GAJuCCKc.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-B3hZ6uy3.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CqQ0-pfF.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-7yOzg9-j.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-v8rZf8KZ.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-ukHX_v8t.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BFYa-2at.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BOt7aLMO.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DJKc1PBD.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-BPUrixrx.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-Dnwk3GJG.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-CxLTGcig.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-DyAaHm9G.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-D5yXusUE.js" as="script"><link rel="prefetch" href="/blog/assets/index.html-x5aSH1Ah.js" as="script"><link rel="prefetch" href="/blog/assets/giscus--_FS5kYt.js" as="script"><link rel="prefetch" href="/blog/assets/auto-CAdRPfCH.js" as="script"><link rel="prefetch" href="/blog/assets/index-wZ-hXvzw.js" as="script"><link rel="prefetch" href="/blog/assets/photoswipe.esm-SzV8tJDW.js" as="script"><link rel="prefetch" href="/blog/assets/SearchResult-Rjd_xNPH.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container no-sidebar external-link-icon has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/blog/"><img class="vp-nav-logo" src="/blog/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">Li-Lab Blog</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link vp-link" href="/blog/" aria-label="Blog Home"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="home" width="1em" height="1em"></iconify-icon>Blog Home<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link vp-link" href="/blog/category/" aria-label="Category"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="baseline-category" width="1em" height="1em"></iconify-icon>Category<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link vp-link" href="/blog/tag/" aria-label="Tags"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="tag" width="1em" height="1em"></iconify-icon>Tags<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link vp-link" href="/blog/timeline/" aria-label="Timeline"><iconify-icon class="font-icon icon" style="" mode="style" inline icon="time" width="1em" height="1em"></iconify-icon>Timeline<!----></a></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/lileicc/blog" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon" name="search"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Mirror-Generative Neural Machine Translation</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Tsu-Jui Fu</span></span><span property="author" content="Tsu-Jui Fu"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2021-11-25T00:00:00.000Z"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color0 clickable" role="navigation">MT</span><span class="page-category-item color0 clickable" role="navigation">DL4MT</span><!--]--><meta property="articleSection" content="MT,DL4MT"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color6 clickable" role="navigation">Variational Inference</span><span class="page-tag-item color6 clickable" role="navigation">Latent Variable Model</span><span class="page-tag-item color7 clickable" role="navigation">Semi-supervised Learning</span><!--]--><meta property="keywords" content="Variational Inference,Latent Variable Model,Semi-supervised Learning"></span><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 4 min</span><meta property="timeRequired" content="PT4M"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#background-back-translation">Background (Back Translation)</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#mgnmt">MGNMT</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#overview">Overview</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#parallel-training">Parallel Training</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#non-parallel-training">Non-parallel Training</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#decoding">Decoding</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#exeperiments">Exeperiments</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#dataset">Dataset</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#quantitative-results">Quantitative Results</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#ablation-study">Ablation Study</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#qualitative-examples">Qualitative Examples</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#conclusion">Conclusion</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#reference">Reference</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content"><p>In general, neural machine translation (NMT) requires a large amount of parallel data (e.g., EN-&gt;CN). However, it is not easy to collect enough high-quality parallelly-paired sentences for training the translation model. On the other hand, we can capture enormous plain text from Wikipedia or news articles for each specific language. In this paper, MGNMT tries to make good use of non-parallel data and boost the performance of NMT.</p><p><a href="https://openreview.net/pdf?id=HkxQRTNYPH" target="_blank" rel="noopener noreferrer">Paper</a></p><p><a href="https://github.com/zhengzx-nlp/MGNMT" target="_blank" rel="noopener noreferrer">Code</a></p><h2 id="background-back-translation" tabindex="-1"><a class="header-anchor" href="#background-back-translation"><span>Background (Back Translation)</span></a></h2><p>Back Translation (BT) is a technique to boost translation performance by incorporating pseudo-inverse pairs as parallel sentences. Assuming that we are translating English (EN) into Chinese (CN), our translation goal is TM<sub>EN-CN</sub>. BT considers another TM<sub>CN-EN</sub> that translates Chinese sentences back to English. With the back-translated English sentences, BT treats the additional EN-CH sentences to further train TM<sub>EN-CN</sub>. By alternative training TM<sub>EN-CN</sub> and TM<sub>CN-EN</sub>, we can improve TM<sub>EN-CN</sub> by pseudo-parallel pairs. Although BT increases translation performance, both TM<sub>EN-CN</sub> and TM<sub>CN-EN</sub> are updated independently, which limits the effectiveness of using non-parallel sentences.</p><img src="https://i.imgur.com/rpj2IFj.png" width="30%"><h2 id="mgnmt" tabindex="-1"><a class="header-anchor" href="#mgnmt"><span>MGNMT</span></a></h2><h3 id="overview" tabindex="-1"><a class="header-anchor" href="#overview"><span>Overview</span></a></h3><p>MGNMT is a unified NMT framework that considers both source-target and target-source translation models (TM) with their respective language models (LM). Both TM and LM share the semantic space, making it more efficient when learning from the non-parallel corpus. In addition, LM can further improve the text quality during the decoding step of TM. Inspired by generative NMT (GNMT), MGNMT introduces a latent semantic variable z and adopts symmetry of mirror-image properties to decompose the conditional joint probability p(x, y | z):</p><img src="https://i.imgur.com/zXfL7CY.png" width="60%"><ul><li>(x, y): source-target language pair;</li><li>Θ: trainable model parameters for TM and LM;</li><li>D_xy: parallel source-target corpus;</li><li>D_x and D_y: non-parallel monolingual corpus.</li></ul><h3 id="parallel-training" tabindex="-1"><a class="header-anchor" href="#parallel-training"><span>Parallel Training</span></a></h3><p>Given a parallel corpus (x, y), MGNMT adopts stochastic gradient variational Bayes (SGVB) to obtain an approximate maximum likelihood estimate of log p(x, y):</p><img src="https://i.imgur.com/RvtbmWh.png" width="60%"><p>and the Evidence Lower Bound (ELBO) can be derived as:</p><img src="https://i.imgur.com/kH82Wt1.png" width="60%"><p>Through reparameterization, we can jointly train the entire MGNMT via gradient-based optimizations for parallel-corpus training.</p><img src="https://i.imgur.com/XzRf5Uz.png" width="30%"><h3 id="non-parallel-training" tabindex="-1"><a class="header-anchor" href="#non-parallel-training"><span>Non-parallel Training</span></a></h3><p>To utilize non-parallel corpus, MGNMT designs an interactive training method by back translation (BT). Given a sentence x<sub>s</sub> in the source language and y<sub>t</sub> in the target language, MGNMT aims at maximizing the lower bounds of their marginal distribution likelihood:</p><img src="https://i.imgur.com/Vy7RI5F.png" width="60%"><p>As BT, for example, MGNMT samples x from p(x | y<sub>t</sub>) as the translation result of y<sub>t</sub>, and a pseudo-parallel pair (x, y<sub>t</sub>) is produced:</p><img src="https://i.imgur.com/6XvCgKa.png" width="60%"><p>With the pseudo-parallel corpus from two directions, they can combine to train MGNMT:</p><img src="https://i.imgur.com/XJMC9YW.png" width="60%"><p>Since the latent variable comes from the shared posterior q(z | x, y; Θ), it serves as a communication bridge that boosts the BT performance in MGNMT.</p><h3 id="decoding" tabindex="-1"><a class="header-anchor" href="#decoding"><span>Decoding</span></a></h3><p>MGNMT considers pre-trained LM to help obtain smoother and higher-quality translation results during decoding.</p><img src="https://i.imgur.com/o0RpZF5.png" width="60%"><p>Take the source-to-target translation as an example:</p><ol><li>Sample an initialized latent variable z from the standard Gaussian prior distribution, and receives a translation result y from argmax<sub>y</sub> p(y | x, z);</li><li>Keep re-decoding with beam search to maximize ELBO:</li></ol><img src="https://i.imgur.com/DgsYMmF.png" width="60%"><p>Each decoding score is determined by the x-to-y translation and the LM<sub>y</sub>, making the translated results more similar to the target language. Moreover, the reconstructed score is obtained from the y-to-x translation and LM<sub>x</sub>, further improving the translation effect upon the idea of BT.</p><h2 id="exeperiments" tabindex="-1"><a class="header-anchor" href="#exeperiments"><span>Exeperiments</span></a></h2><h3 id="dataset" tabindex="-1"><a class="header-anchor" href="#dataset"><span>Dataset</span></a></h3><table><thead><tr><th style="text-align:center;">Dataset</th><th style="text-align:center;">WMT14<sub>EN-DE</sub></th><th style="text-align:center;">NIST<sub>EN-ZH</sub></th><th style="text-align:center;">WMT16<sub>EN-RO</sub></th><th style="text-align:center;">IWSLT16<sub>EN-DE</sub></th></tr></thead><tbody><tr><td style="text-align:center;">Paralel</td><td style="text-align:center;">4.50M</td><td style="text-align:center;">1.34M</td><td style="text-align:center;">0.62M</td><td style="text-align:center;">0.20M (TED)</td></tr><tr><td style="text-align:center;">Non-parallel</td><td style="text-align:center;">5.00M</td><td style="text-align:center;">1.00M</td><td style="text-align:center;">1.00M</td><td style="text-align:center;">0.20M (NEWS)</td></tr></tbody></table><p>MGNMT considers WMT16<sub>EN-RO</sub> as low-resource translation and IWSLT16<sub>EN-DE</sub> of TED talk for cross-domain translation. Both WMT14<sub>EN-DE</sub> and NIST<sub>EN-ZH</sub> are for the general resource-rich evaluation. Specifically, all models are trained using parallel data from TED and non-parallel data from NEWS for cross-domain translation.</p><h3 id="quantitative-results" tabindex="-1"><a class="header-anchor" href="#quantitative-results"><span>Quantitative Results</span></a></h3><img src="https://i.imgur.com/bqJFmCn.png" width="60%"><p><b>Resource-low Translation.</b> Firstly, as for the resource-low scenario (WMT16<sub>EN-RO</sub> and IWSLT16<sub>EN-DE</sub>), MGNMT slightly surpasses the competitive baselines (<i>e.g.,</i> 33.9 BLEU on WMT16<sub>RO-EN</sub> and 33.6 BLEU on TED<sub>DE-EN</sub>). If incorporating non-parallel data, MGNMT gains a significant improvement (<i>e.g.,</i> +5.2% BLEU on TED<sub>EN-DE</sub> and +5.9% on NEWS<sub>DE-EN</sub>), which outperforms all other baselines that also use non-parallel corpus.</p><img src="https://i.imgur.com/JntnTEI.png" width="60%"><p><b>Resource-rich Translation.</b> Similar results can be found in resource-rich scenarios. MGNMT performs better than GNMT with only the parallel corpus (<i>e.g.,</i> 31.4 BLEU on WMT14<sub>DE-EN</sub> and 40.42 BLEU on NIST<sub>EN-ZH</sub>) and further boosts the translation quality with the aid of non-parallel data (<i>e.g.,</i> 30.3 BLEU on WMT14<sub>EN-DE</sub> and 49.05 BLEU on NIST<sub>ZH-EN</sub>).</p><h3 id="ablation-study" tabindex="-1"><a class="header-anchor" href="#ablation-study"><span>Ablation Study</span></a></h3><img src="https://i.imgur.com/tzEeu7u.png" width="30%"><p><b>Effectiveness of Language Model during Decoding.</b> Incorporating a pre-trained language model (LM) during decoding is an intuitive method to improve decoding quality. However, such simple interpolation (LM-FUSION) over NMT and external LM only brings out mild effects. In contrast, a natural integration adopted in MGNMT is essential to address the unrelated probabilistic modeling issue.</p><img src="https://i.imgur.com/tzEeu7u.png" width="30%"><p><b>Impact of #Non-parallel Data.</b> The plot shows that with more non-parallel data involved, the translation performance keeps increasing, which demonstrates the benefit of MGNMT from data scales. Surprisingly, one monolingual side data, English, can also improve EN-GN translation under the MGNMT framework.</p><h3 id="qualitative-examples" tabindex="-1"><a class="header-anchor" href="#qualitative-examples"><span>Qualitative Examples</span></a></h3><p><img src="https://i.imgur.com/vPGJ7Wo.png" width="30%"><img src="https://i.imgur.com/VQil8lK.png" width="30%"></p><p>Without non-parallel in-domain data (NEWS), the baseline (RNMT) results in an obvious style mismatches phenomenon. Among all enhanced methods that attempt to alleviate this domain inconsistency issue, MGNMT leads to the best in-domain-related translation results.</p><h2 id="conclusion" tabindex="-1"><a class="header-anchor" href="#conclusion"><span>Conclusion</span></a></h2><p>This paper presents a mirror generative NMT, MGNMT, that utilizes non-parallel corpus efficiently. MGNMT adopts a shared bilingual semantic space to jointly learn their goal and back-translated models. Moreover, MGNMT considers the learned language model during decoding, which directly improves the translation quality. One future research direction is to integrate MGNMT for fully unsupervised NMT.</p><h2 id="reference" tabindex="-1"><a class="header-anchor" href="#reference"><span>Reference</span></a></h2><ul><li>Zaixiang Zheng, Hao Zhou, Shujian Huang, Lei Li, Xin-Yu Dai, and Jiajun Chen. Mirror-Generative Neural Machine Translation. ICLR 2020.</li></ul></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="vp-link vp-external-link-icon vp-meta-label" href="https://github.com/lileicc/blog/edit/main/dl4mt/2021/mgnmt/README.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last update: </span><!----></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: lileicc@gmail.com">Lei Li</span><!--]--><!--]--></div></div></footer><!----><div id="vp-comment" class="giscus-wrapper input-top" style="display:block;"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" preserveAspectRatio="xMidYMid" viewBox="0 0 100 100"><circle cx="28" cy="75" r="11" fill="currentColor"><animate attributeName="fill-opacity" begin="0s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></circle><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 47a28 28 0 0 1 28 28"><animate attributeName="stroke-opacity" begin="0.1s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path><path fill="none" stroke="#88baf0" stroke-width="10" d="M28 25a50 50 0 0 1 50 50"><animate attributeName="stroke-opacity" begin="0.2s" dur="1s" keyTimes="0;0.2;1" repeatCount="indefinite" values="0;1;1"></animate></path></svg></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">Li Lab</div><div class="vp-copyright">Copyright © 2024 Tsu-Jui Fu </div></footer></div><!--]--><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/blog/assets/app-DvxBpnKI.js" defer></script>
  </body>
</html>

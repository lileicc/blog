const nt="ENTRIES",V="KEYS",T="VALUES",F="";class D{set;_type;_path;constructor(t,s){const n=t._tree,u=Array.from(n.keys());this.set=t,this._type=s,this._path=u.length>0?[{node:n,keys:u}]:[]}next(){const t=this.dive();return this.backtrack(),t}dive(){if(this._path.length===0)return{done:!0,value:void 0};const{node:t,keys:s}=E(this._path);if(E(s)===F)return{done:!1,value:this.result()};const n=t.get(E(s));return this._path.push({node:n,keys:Array.from(n.keys())}),this.dive()}backtrack(){if(this._path.length===0)return;const t=E(this._path).keys;t.pop(),!(t.length>0)&&(this._path.pop(),this.backtrack())}key(){return this.set._prefix+this._path.map(({keys:t})=>E(t)).filter(t=>t!==F).join("")}value(){return E(this._path).node.get(F)}result(){switch(this._type){case T:return this.value();case V:return this.key();default:return[this.key(),this.value()]}}[Symbol.iterator](){return this}}const E=e=>e[e.length-1],ut=(e,t,s)=>{const n=new Map;if(t===void 0)return n;const u=t.length+1,o=u+s,i=new Uint8Array(o*u).fill(s+1);for(let r=0;r<u;++r)i[r]=r;for(let r=1;r<o;++r)i[r*u]=r;return R(e,t,s,n,i,1,u,""),n},R=(e,t,s,n,u,o,i,r)=>{const d=o*i;t:for(const l of e.keys())if(l===F){const a=u[d-1];a<=s&&n.set(r,[e.get(l),a])}else{let a=o;for(let h=0;h<l.length;++h,++a){const m=l[h],p=i*a,f=p-i;let c=u[p];const g=Math.max(0,a-s-1),_=Math.min(i-1,a+s);for(let y=g;y<_;++y){const b=m!==t[y],z=u[f+y]+ +b,A=u[f+y+1]+1,w=u[p+y]+1,L=u[p+y+1]=Math.min(z,A,w);L<c&&(c=L)}if(c>s)continue t}R(e.get(l),t,s,n,u,a,i,r+l)}};class C{_tree;_prefix;_size=void 0;constructor(t=new Map,s=""){this._tree=t,this._prefix=s}atPrefix(t){if(!t.startsWith(this._prefix))throw new Error("Mismatched prefix");const[s,n]=x(this._tree,t.slice(this._prefix.length));if(s===void 0){const[u,o]=M(n);for(const i of u.keys())if(i!==F&&i.startsWith(o)){const r=new Map;return r.set(i.slice(o.length),u.get(i)),new C(r,t)}}return new C(s,t)}clear(){this._size=void 0,this._tree.clear()}delete(t){return this._size=void 0,ot(this._tree,t)}entries(){return new D(this,nt)}forEach(t){for(const[s,n]of this)t(s,n,this)}fuzzyGet(t,s){return ut(this._tree,t,s)}get(t){const s=I(this._tree,t);return s!==void 0?s.get(F):void 0}has(t){const s=I(this._tree,t);return s!==void 0&&s.has(F)}keys(){return new D(this,V)}set(t,s){if(typeof t!="string")throw new Error("key must be a string");return this._size=void 0,O(this._tree,t).set(F,s),this}get size(){if(this._size)return this._size;this._size=0;const t=this.entries();for(;!t.next().done;)this._size+=1;return this._size}update(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=O(this._tree,t);return n.set(F,s(n.get(F))),this}fetch(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=O(this._tree,t);let u=n.get(F);return u===void 0&&n.set(F,u=s()),u}values(){return new D(this,T)}[Symbol.iterator](){return this.entries()}static from(t){const s=new C;for(const[n,u]of t)s.set(n,u);return s}static fromObject(t){return C.from(Object.entries(t))}}const x=(e,t,s=[])=>{if(t.length===0||e==null)return[e,s];for(const n of e.keys())if(n!==F&&t.startsWith(n))return s.push([e,n]),x(e.get(n),t.slice(n.length),s);return s.push([e,t]),x(void 0,"",s)},I=(e,t)=>{if(t.length===0||e==null)return e;for(const s of e.keys())if(s!==F&&t.startsWith(s))return I(e.get(s),t.slice(s.length))},O=(e,t)=>{const s=t.length;t:for(let n=0;e&&n<s;){for(const o of e.keys())if(o!==F&&t[n]===o[0]){const i=Math.min(s-n,o.length);let r=1;for(;r<i&&t[n+r]===o[r];)++r;const d=e.get(o);if(r===o.length)e=d;else{const l=new Map;l.set(o.slice(r),d),e.set(t.slice(n,n+r),l),e.delete(o),e=l}n+=r;continue t}const u=new Map;return e.set(t.slice(n),u),u}return e},ot=(e,t)=>{const[s,n]=x(e,t);if(s!==void 0){if(s.delete(F),s.size===0)W(n);else if(s.size===1){const[u,o]=s.entries().next().value;q(n,u,o)}}},W=e=>{if(e.length===0)return;const[t,s]=M(e);if(t.delete(s),t.size===0)W(e.slice(0,-1));else if(t.size===1){const[n,u]=t.entries().next().value;n!==F&&q(e.slice(0,-1),n,u)}},q=(e,t,s)=>{if(e.length===0)return;const[n,u]=M(e);n.set(u+t,s),n.delete(u)},M=e=>e[e.length-1],it=(e,t)=>{const s=e._idToShortId.get(t);if(s!=null)return e._storedFields.get(s)},rt=/[\n\r -#%-*,-/:;?@[-\]_{}\u00A0\u00A1\u00A7\u00AB\u00B6\u00B7\u00BB\u00BF\u037E\u0387\u055A-\u055F\u0589\u058A\u05BE\u05C0\u05C3\u05C6\u05F3\u05F4\u0609\u060A\u060C\u060D\u061B\u061E\u061F\u066A-\u066D\u06D4\u0700-\u070D\u07F7-\u07F9\u0830-\u083E\u085E\u0964\u0965\u0970\u09FD\u0A76\u0AF0\u0C77\u0C84\u0DF4\u0E4F\u0E5A\u0E5B\u0F04-\u0F12\u0F14\u0F3A-\u0F3D\u0F85\u0FD0-\u0FD4\u0FD9\u0FDA\u104A-\u104F\u10FB\u1360-\u1368\u1400\u166E\u1680\u169B\u169C\u16EB-\u16ED\u1735\u1736\u17D4-\u17D6\u17D8-\u17DA\u1800-\u180A\u1944\u1945\u1A1E\u1A1F\u1AA0-\u1AA6\u1AA8-\u1AAD\u1B5A-\u1B60\u1BFC-\u1BFF\u1C3B-\u1C3F\u1C7E\u1C7F\u1CC0-\u1CC7\u1CD3\u2000-\u200A\u2010-\u2029\u202F-\u2043\u2045-\u2051\u2053-\u205F\u207D\u207E\u208D\u208E\u2308-\u230B\u2329\u232A\u2768-\u2775\u27C5\u27C6\u27E6-\u27EF\u2983-\u2998\u29D8-\u29DB\u29FC\u29FD\u2CF9-\u2CFC\u2CFE\u2CFF\u2D70\u2E00-\u2E2E\u2E30-\u2E4F\u3000-\u3003\u3008-\u3011\u3014-\u301F\u3030\u303D\u30A0\u30FB\uA4FE\uA4FF\uA60D-\uA60F\uA673\uA67E\uA6F2-\uA6F7\uA874-\uA877\uA8CE\uA8CF\uA8F8-\uA8FA\uA8FC\uA92E\uA92F\uA95F\uA9C1-\uA9CD\uA9DE\uA9DF\uAA5C-\uAA5F\uAADE\uAADF\uAAF0\uAAF1\uABEB\uFD3E\uFD3F\uFE10-\uFE19\uFE30-\uFE52\uFE54-\uFE61\uFE63\uFE68\uFE6A\uFE6B\uFF01-\uFF03\uFF05-\uFF0A\uFF0C-\uFF0F\uFF1A\uFF1B\uFF1F\uFF20\uFF3B-\uFF3D\uFF3F\uFF5B\uFF5D\uFF5F-\uFF65]+/u,S="or",$="and",ct="and_not",lt=(e,t)=>{e.includes(t)||e.push(t)},P=(e,t)=>{for(const s of t)e.includes(s)||e.push(s)},N=({score:e},{score:t})=>t-e,ht=()=>new Map,k=e=>{const t=new Map;for(const s of Object.keys(e))t.set(parseInt(s,10),e[s]);return t},G=(e,t)=>Object.prototype.hasOwnProperty.call(e,t)?e[t]:void 0,dt={[S]:(e,t)=>{for(const s of t.keys()){const n=e.get(s);if(n==null)e.set(s,t.get(s));else{const{score:u,terms:o,match:i}=t.get(s);n.score=n.score+u,n.match=Object.assign(n.match,i),P(n.terms,o)}}return e},[$]:(e,t)=>{const s=new Map;for(const n of t.keys()){const u=e.get(n);if(u==null)continue;const{score:o,terms:i,match:r}=t.get(n);P(u.terms,i),s.set(n,{score:u.score+o,terms:u.terms,match:Object.assign(u.match,r)})}return s},[ct]:(e,t)=>{for(const s of t.keys())e.delete(s);return e}},at=(e,t,s,n,u,o)=>{const{k:i,b:r,d}=o;return Math.log(1+(s-t+.5)/(t+.5))*(d+e*(i+1)/(e+i*(1-r+r*n/u)))},ft=e=>(t,s,n)=>{const u=typeof e.fuzzy=="function"?e.fuzzy(t,s,n):e.fuzzy||!1,o=typeof e.prefix=="function"?e.prefix(t,s,n):e.prefix===!0;return{term:t,fuzzy:u,prefix:o}},H=(e,t,s,n)=>{for(const u of Object.keys(e._fieldIds))if(e._fieldIds[u]===s){e._options.logger("warn",`SlimSearch: document with ID ${e._documentIds.get(t)} has changed before removal: term "${n}" was not present in field "${u}". Removing a document after it has changed can corrupt the index!`,"version_conflict");return}},gt=(e,t,s,n)=>{if(!e._index.has(n)){H(e,s,t,n);return}const u=e._index.fetch(n,ht),o=u.get(t);o==null||o.get(s)==null?H(e,s,t,n):o.get(s)<=1?o.size<=1?u.delete(t):o.delete(s):o.set(s,o.get(s)-1),e._index.get(n).size===0&&e._index.delete(n)},mt={k:1.2,b:.7,d:.5},pt={idField:"id",extractField:(e,t)=>e[t],tokenize:e=>e.split(rt),processTerm:e=>e.toLowerCase(),fields:void 0,searchOptions:void 0,storeFields:[],logger:(e,t)=>{typeof console?.[e]=="function"&&console[e](t)},autoVacuum:!0},J={combineWith:S,prefix:!1,fuzzy:!1,maxFuzzy:6,boost:{},weights:{fuzzy:.45,prefix:.375},bm25:mt},Ft={combineWith:$,prefix:(e,t,s)=>t===s.length-1},_t={batchSize:1e3,batchWait:10},U={minDirtFactor:.1,minDirtCount:20},yt={..._t,...U},Y=(e,t=S)=>{if(e.length===0)return new Map;const s=t.toLowerCase();return e.reduce(dt[s])||new Map},B=(e,t,s,n,u,o,i,r,d=new Map)=>{if(u==null)return d;for(const l of Object.keys(o)){const a=o[l],h=e._fieldIds[l],m=u.get(h);if(m==null)continue;let p=m.size;const f=e._avgFieldLength[h];for(const c of m.keys()){if(!e._documentIds.has(c)){gt(e,h,c,s),p-=1;continue}const g=i?i(e._documentIds.get(c),s,e._storedFields.get(c)):1;if(!g)continue;const _=m.get(c),y=e._fieldLength.get(c)[h],b=at(_,p,e._documentCount,y,f,r),z=n*a*g*b,A=d.get(c);if(A){A.score+=z,lt(A.terms,t);const w=G(A.match,s);w?w.push(l):A.match[s]=[l]}else d.set(c,{score:z,terms:[t],match:{[s]:[l]}})}}return d},At=(e,t,s)=>{const n={...e._options.searchOptions,...s},u=(n.fields||e._options.fields).reduce((c,g)=>({...c,[g]:G(n.boost,g)||1}),{}),{boostDocument:o,weights:i,maxFuzzy:r,bm25:d}=n,{fuzzy:l,prefix:a}={...J.weights,...i},h=e._index.get(t.term),m=B(e,t.term,t.term,1,h,u,o,d);let p,f;if(t.prefix&&(p=e._index.atPrefix(t.term)),t.fuzzy){const c=t.fuzzy===!0?.2:t.fuzzy,g=c<1?Math.min(r,Math.round(t.term.length*c)):c;g&&(f=e._index.fuzzyGet(t.term,g))}if(p)for(const[c,g]of p){const _=c.length-t.term.length;if(!_)continue;f?.delete(c);const y=a*c.length/(c.length+.3*_);B(e,t.term,c,y,g,u,o,d,m)}if(f)for(const c of f.keys()){const[g,_]=f.get(c);if(!_)continue;const y=l*c.length/(c.length+_);B(e,t.term,c,y,g,u,o,d,m)}return m},X=(e,t,s={})=>{if(typeof t!="string"){const a={...s,...t,queries:void 0},h=t.queries.map(m=>X(e,m,a));return Y(h,a.combineWith)}const{tokenize:n,processTerm:u,searchOptions:o}=e._options,i={tokenize:n,processTerm:u,...o,...s},{tokenize:r,processTerm:d}=i,l=r(t).flatMap(a=>d(a)).filter(a=>!!a).map(ft(i)).map(a=>At(e,a,i));return Y(l,i.combineWith)},K=(e,t,s={})=>{const n=X(e,t,s),u=[];for(const[o,{score:i,terms:r,match:d}]of n){const l=r.length,a={id:e._documentIds.get(o),score:i*l,terms:Object.keys(d),match:d};Object.assign(a,e._storedFields.get(o)),(s.filter==null||s.filter(a))&&u.push(a)}return u.sort(N),u},Ct=(e,t,s={})=>{s={...e._options.autoSuggestOptions,...s};const n=new Map;for(const{score:o,terms:i}of K(e,t,s)){const r=i.join(" "),d=n.get(r);d!=null?(d.score+=o,d.count+=1):n.set(r,{score:o,terms:i,count:1})}const u=[];for(const[o,{score:i,terms:r,count:d}]of n)u.push({suggestion:o,terms:r,score:i/d});return u.sort(N),u};class Et{_options;_index;_documentCount;_documentIds;_idToShortId;_fieldIds;_fieldLength;_avgFieldLength;_nextId;_storedFields;_dirtCount;_currentVacuum;_enqueuedVacuum;_enqueuedVacuumConditions;constructor(t){if(t?.fields==null)throw new Error('SlimSearch: option "fields" must be provided');const s=t.autoVacuum==null||t.autoVacuum===!0?yt:t.autoVacuum;this._options={...pt,...t,autoVacuum:s,searchOptions:{...J,...t.searchOptions||{}},autoSuggestOptions:{...Ft,...t.autoSuggestOptions||{}}},this._index=new C,this._documentCount=0,this._documentIds=new Map,this._idToShortId=new Map,this._fieldIds={},this._fieldLength=new Map,this._avgFieldLength=[],this._nextId=0,this._storedFields=new Map,this._dirtCount=0,this._currentVacuum=null,this._enqueuedVacuum=null,this._enqueuedVacuumConditions=U,this.addFields(this._options.fields)}get isVacuuming(){return this._currentVacuum!=null}get dirtCount(){return this._dirtCount}get dirtFactor(){return this._dirtCount/(1+this._documentCount+this._dirtCount)}get documentCount(){return this._documentCount}get termCount(){return this._index.size}toJSON(){const t=[];for(const[s,n]of this._index){const u={};for(const[o,i]of n)u[o]=Object.fromEntries(i);t.push([s,u])}return{documentCount:this._documentCount,nextId:this._nextId,documentIds:Object.fromEntries(this._documentIds),fieldIds:this._fieldIds,fieldLength:Object.fromEntries(this._fieldLength),averageFieldLength:this._avgFieldLength,storedFields:Object.fromEntries(this._storedFields),dirtCount:this._dirtCount,index:t,serializationVersion:2}}addFields(t){for(let s=0;s<t.length;s++)this._fieldIds[t[s]]=s}}const zt=({index:e,documentCount:t,nextId:s,documentIds:n,fieldIds:u,fieldLength:o,averageFieldLength:i,storedFields:r,dirtCount:d,serializationVersion:l},a)=>{if(l!==1&&l!==2)throw new Error("SlimSearch: cannot deserialize an index created with an incompatible version");const h=new Et(a);h._documentCount=t,h._nextId=s,h._documentIds=k(n),h._idToShortId=new Map,h._fieldIds=u,h._fieldLength=k(o),h._avgFieldLength=i,h._storedFields=k(r),h._dirtCount=d||0,h._index=new C;for(const[m,p]of h._documentIds)h._idToShortId.set(p,m);for(const[m,p]of e){const f=new Map;for(const c of Object.keys(p)){let g=p[c];l===1&&(g=g.ds),f.set(parseInt(c,10),k(g))}h._index.set(m,f)}return h},Q=Object.entries,wt=Object.fromEntries,j=(e,t)=>{const s=e.toLowerCase(),n=t.toLowerCase(),u=[];let o=0,i=0;const r=(l,a=!1)=>{let h="";i===0?h=l.length>20?`… ${l.slice(-20)}`:l:a?h=l.length+i>100?`${l.slice(0,100-i)}… `:l:h=l.length>20?`${l.slice(0,20)} … ${l.slice(-20)}`:l,h&&u.push(h),i+=h.length,a||(u.push(["mark",t]),i+=t.length,i>=100&&u.push(" …"))};let d=s.indexOf(n,o);if(d===-1)return null;for(;d>=0;){const l=d+n.length;if(r(e.slice(o,d)),o=l,i>100)break;d=s.indexOf(n,o)}return i<100&&r(e.slice(o),!0),u},Z=/[\u4e00-\u9fa5]/g,tt=(e={})=>({fuzzy:.2,prefix:!0,processTerm:t=>{const s=t.match(Z)||[],n=t.replace(Z,"").toLowerCase();return n?[n,...s]:[...s]},...e}),xt=(e,t)=>t.contents.reduce((s,[,n])=>s+n,0)-e.contents.reduce((s,[,n])=>s+n,0),kt=(e,t)=>Math.max(...t.contents.map(([,s])=>s))-Math.max(...e.contents.map(([,s])=>s)),et=(e,t,s={})=>{const n={};return K(t,e,tt({boost:{h:2,t:1,c:4},...s})).forEach(u=>{const{id:o,terms:i,score:r}=u,d=o.includes("@"),l=o.includes("#"),[a,h]=o.split(/[#@]/),m=i.sort((f,c)=>f.length-c.length).filter((f,c)=>i.slice(c+1).every(g=>!g.includes(f))),{contents:p}=n[a]??={title:"",contents:[]};if(d)p.push([{type:"customField",key:a,index:h,display:m.map(f=>u.c.map(c=>j(c,f))).flat().filter(f=>f!==null)},r]);else{const f=m.map(c=>j(u.h,c)).filter(c=>c!==null);if(f.length&&p.push([{type:l?"heading":"title",key:a,...l&&{anchor:h},display:f},r]),"t"in u)for(const c of u.t){const g=m.map(_=>j(c,_)).filter(_=>_!==null);g.length&&p.push([{type:"text",key:a,...l&&{anchor:h},display:g},r])}}}),Q(n).sort(([,u],[,o])=>"max"==="total"?xt(u,o):kt(u,o)).map(([u,{title:o,contents:i}])=>{if(!o){const r=it(t,u);r&&(o=r.h)}return{title:o,contents:i.map(([r])=>r)}})},st=(e,t,s={})=>Ct(t,e,tt(s)).map(({suggestion:n})=>n),v=wt(Q(JSON.parse("{\"/\":{\"documentCount\":278,\"nextId\":278,\"documentIds\":{\"0\":\"v-5ef099df\",\"1\":\"v-5ef099df#introduction\",\"2\":\"v-5ef099df#issues-with-current-tokenization-models\",\"3\":\"v-5ef099df#techniques-of-volt\",\"4\":\"v-5ef099df#effectiveness-of-volt\",\"5\":\"v-5ef099df#_1-overall-better-performance-than-widely-used-vocabularies\",\"6\":\"v-5ef099df#_2-low-resource-consumption\",\"7\":\"v-5ef099df#_3-versatile-better-on-a-large-array-of-languages\",\"8\":\"v-5ef099df#summary\",\"9\":\"v-5ef099df#references\",\"10\":\"v-5ef099df@0\",\"11\":\"v-5ef099df@1\",\"12\":\"v-d12a3a8c\",\"13\":\"v-d12a3a8c#预训练技术在机器翻译领域存在的挑战—-灾难性遗忘\",\"14\":\"v-d12a3a8c#渐进式学习策略-缓解灾难性遗忘问题\",\"15\":\"v-d12a3a8c#梯度控制\",\"16\":\"v-d12a3a8c#基于门控制的融合\",\"17\":\"v-d12a3a8c#渐进蒸馏策略\",\"18\":\"v-d12a3a8c#实验效果和未来方向\",\"19\":\"v-d12a3a8c@0\",\"20\":\"v-d12a3a8c@1\",\"21\":\"v-af4d51b6\",\"22\":\"v-af4d51b6#introduction\",\"23\":\"v-af4d51b6#challenges-in-machine-translation-pre-training\",\"24\":\"v-af4d51b6#motivation-and-techniques-of-mrasp\",\"25\":\"v-af4d51b6#effectiveness-of-mrasp\",\"26\":\"v-af4d51b6#_1-en-de-and-en-fr-benchmarks\",\"27\":\"v-af4d51b6#_2-extend-to-language-not-seen-during-the-pre-training-phase\",\"28\":\"v-af4d51b6#_3-case-study\",\"29\":\"v-af4d51b6#french-chinese-fr-zh\",\"30\":\"v-af4d51b6#dutch-portuguese-nl-pt\",\"31\":\"v-af4d51b6#english-french-en-fr\",\"32\":\"v-af4d51b6#english-chinese-en-zh\",\"33\":\"v-af4d51b6#findings-from-mrasp-trained-model\",\"34\":\"v-af4d51b6#_1-mrasp-draws-word-level-vector-representation-of-different-language-closer\",\"35\":\"v-af4d51b6#_2-mrasp-draws-sentence-level-vector-representation-of-different-language-closer\",\"36\":\"v-af4d51b6#summary\",\"37\":\"v-af4d51b6#references\",\"38\":\"v-af4d51b6@0\",\"39\":\"v-af4d51b6@1\",\"40\":\"v-e73f2188\",\"41\":\"v-e73f2188#introduction\",\"42\":\"v-e73f2188#drw-overview\",\"43\":\"v-e73f2188#experiments\",\"44\":\"v-e73f2188#limitations\",\"45\":\"v-e73f2188#summary\",\"46\":\"v-e73f2188#references\",\"47\":\"v-e73f2188@0\",\"48\":\"v-e73f2188@1\",\"49\":\"v-0060584c\",\"50\":\"v-0060584c#challenges\",\"51\":\"v-0060584c#our-proposed-model-gain\",\"52\":\"v-0060584c#experiments\",\"53\":\"v-0060584c#dataset\",\"54\":\"v-0060584c#main-results\",\"55\":\"v-0060584c#ablation-study\",\"56\":\"v-0060584c#further-analysis\",\"57\":\"v-0060584c#cross-sentence-relation-extraction\",\"58\":\"v-0060584c#logical-reasoning-for-relation-extraction\",\"59\":\"v-0060584c#case-study\",\"60\":\"v-0060584c#conclusion\",\"61\":\"v-0060584c#reference\",\"62\":\"v-0060584c@0\",\"63\":\"v-0060584c@1\",\"64\":\"v-037c250d\",\"65\":\"v-037c250d#introduction\",\"66\":\"v-037c250d#loren-s-architecture\",\"67\":\"v-037c250d#decomposition-of-the-claim\",\"68\":\"v-037c250d#probing-questions-generation-evidences-retrieval-and-local-premises-construction\",\"69\":\"v-037c250d#latent-model-construction\",\"70\":\"v-037c250d#experiment\",\"71\":\"v-037c250d#experiment-metrics-for-the-performance-of-the-model\",\"72\":\"v-037c250d#future-improvements\",\"73\":\"v-037c250d#conclusion\",\"74\":\"v-037c250d#references\",\"75\":\"v-037c250d@0\",\"76\":\"v-037c250d@1\",\"77\":\"v-291e7daf\",\"78\":\"v-291e7daf#background\",\"79\":\"v-291e7daf#major-questions\",\"80\":\"v-291e7daf#our-findings\",\"81\":\"v-291e7daf#the-anisotropic-embedding-space-of-bert\",\"82\":\"v-291e7daf#word-frequency-biases-the-embedding-space\",\"83\":\"v-291e7daf#low-frequency-words-disperse-sparsely\",\"84\":\"v-291e7daf#proposed-method-bert-flow\",\"85\":\"v-291e7daf#experiments\",\"86\":\"v-291e7daf#results-w-o-nli-supervision\",\"87\":\"v-291e7daf#results-w-nli-supervision\",\"88\":\"v-291e7daf#conclusion\",\"89\":\"v-291e7daf#reference\",\"90\":\"v-291e7daf@0\",\"91\":\"v-291e7daf@1\",\"92\":\"v-75a8c0a1\",\"93\":\"v-75a8c0a1#introduction\",\"94\":\"v-75a8c0a1#challenges-in-speech-translation\",\"95\":\"v-75a8c0a1#motivation-and-techniques-of-chimera\",\"96\":\"v-75a8c0a1#shared-semantic-memory\",\"97\":\"v-75a8c0a1#dataset-and-preprocessing\",\"98\":\"v-75a8c0a1#effectiveness-of-chimera\",\"99\":\"v-75a8c0a1#_1-benchmark-experiments\",\"100\":\"v-75a8c0a1#_2-visualizations\",\"101\":\"v-75a8c0a1#summary\",\"102\":\"v-75a8c0a1#references\",\"103\":\"v-75a8c0a1@0\",\"104\":\"v-75a8c0a1@1\",\"105\":\"v-4e089efc\",\"106\":\"v-4e089efc@0\",\"107\":\"v-4e089efc@1\",\"108\":\"v-4e141a4b\",\"109\":\"v-4e141a4b#introduction\",\"110\":\"v-4e141a4b#preliminary\",\"111\":\"v-4e141a4b#core-idea-contextual-parameter-generator\",\"112\":\"v-4e141a4b#dive-deeper-the-design-of-cpg\",\"113\":\"v-4e141a4b#experiment-and-performance\",\"114\":\"v-4e141a4b#language-embeddings\",\"115\":\"v-4e141a4b#summary\",\"116\":\"v-4e141a4b#reference\",\"117\":\"v-4e141a4b@0\",\"118\":\"v-4e141a4b@1\",\"119\":\"v-60c9a2e1\",\"120\":\"v-60c9a2e1#novelty\",\"121\":\"v-60c9a2e1#evaluation-on-various-tasks\",\"122\":\"v-60c9a2e1#translation\",\"123\":\"v-60c9a2e1#word-prediction-and-text-generation\",\"124\":\"v-60c9a2e1#comprehension\",\"125\":\"v-60c9a2e1#case-study\",\"126\":\"v-60c9a2e1#conclusion\",\"127\":\"v-60c9a2e1#references\",\"128\":\"v-60c9a2e1@0\",\"129\":\"v-60c9a2e1@1\",\"130\":\"v-a6614676\",\"131\":\"v-a6614676#_1-background\",\"132\":\"v-a6614676#_1-1-challenge\",\"133\":\"v-a6614676#_1-2-motivation\",\"134\":\"v-a6614676#_2-methodology\",\"135\":\"v-a6614676#_2-1-problem-definition\",\"136\":\"v-a6614676#_2-2-overview\",\"137\":\"v-a6614676#components\",\"138\":\"v-a6614676#_3-experiments\",\"139\":\"v-a6614676#_3-1-datasets\",\"140\":\"v-a6614676#_3-2-configuration\",\"141\":\"v-a6614676#_3-1-results\",\"142\":\"v-a6614676#_4-conclusion-and-discussin\",\"143\":\"v-a6614676#reference\",\"144\":\"v-a6614676@0\",\"145\":\"v-a6614676@1\",\"146\":\"v-8eab3c46\",\"147\":\"v-8eab3c46@0\",\"148\":\"v-8eab3c46@1\",\"149\":\"v-6c37a1e9\",\"150\":\"v-6c37a1e9#_1-what-is-lightseq\",\"151\":\"v-6c37a1e9#_1-1-nlp-models\",\"152\":\"v-6c37a1e9#_1-2-motivation\",\"153\":\"v-6c37a1e9#_1-3-lightseq\",\"154\":\"v-6c37a1e9#_2-technique-details\",\"155\":\"v-6c37a1e9#_2-1-operation-fusion\",\"156\":\"v-6c37a1e9#_2-2-hierarchical-auto-regressive-search\",\"157\":\"v-6c37a1e9#_2-3-dynamic-gpu-memory-reuse\",\"158\":\"v-6c37a1e9#_3-using-lightseq\",\"159\":\"v-6c37a1e9#_3-1-installation\",\"160\":\"v-6c37a1e9#_3-2-training-examples-using-lightseq\",\"161\":\"v-6c37a1e9#_3-3-inference-examples-using-lightseq\",\"162\":\"v-6c37a1e9#_4-performance\",\"163\":\"v-6c37a1e9#_4-1-training-performance\",\"164\":\"v-6c37a1e9#_4-2-inference-performance\",\"165\":\"v-6c37a1e9#_4-3-more-inference-performance-on-nvidia-p4-and-t4\",\"166\":\"v-6c37a1e9#_4-4-real-world-cloud-computing-delay-test-on-gpt\",\"167\":\"v-6c37a1e9#_5-reference\",\"168\":\"v-6c37a1e9@0\",\"169\":\"v-6c37a1e9@1\",\"170\":\"v-60cbfb81\",\"171\":\"v-60cbfb81#end-to-end-st\",\"172\":\"v-60cbfb81#inspired-by-human-—-lut\",\"173\":\"v-60cbfb81#evaluation-of-the-lut\",\"174\":\"v-60cbfb81#semantic-analysis\",\"175\":\"v-60cbfb81#lut-vs-cascaded-model\",\"176\":\"v-60cbfb81@0\",\"177\":\"v-60cbfb81@1\",\"178\":\"v-5ea8eb91\",\"179\":\"v-5ea8eb91#background-back-translation\",\"180\":\"v-5ea8eb91#mgnmt\",\"181\":\"v-5ea8eb91#overview\",\"182\":\"v-5ea8eb91#parallel-training\",\"183\":\"v-5ea8eb91#non-parallel-training\",\"184\":\"v-5ea8eb91#decoding\",\"185\":\"v-5ea8eb91#exeperiments\",\"186\":\"v-5ea8eb91#dataset\",\"187\":\"v-5ea8eb91#quantitative-results\",\"188\":\"v-5ea8eb91#ablation-study\",\"189\":\"v-5ea8eb91#qualitative-examples\",\"190\":\"v-5ea8eb91#conclusion\",\"191\":\"v-5ea8eb91#reference\",\"192\":\"v-5ea8eb91@0\",\"193\":\"v-5ea8eb91@1\",\"194\":\"v-eef560ce\",\"195\":\"v-eef560ce#baseline\",\"196\":\"v-eef560ce#multilingual-contrastive-learning\",\"197\":\"v-eef560ce#aligned-augmentation\",\"198\":\"v-eef560ce#datasets\",\"199\":\"v-eef560ce#supervised-direction\",\"200\":\"v-eef560ce#unsupervised-direction\",\"201\":\"v-eef560ce#zero-shot-non-english-translation\",\"202\":\"v-eef560ce#what-is-the-importance-of-each-contribution\",\"203\":\"v-eef560ce#how-is-the-alignment-of-different-languages-in-visualization\",\"204\":\"v-eef560ce@0\",\"205\":\"v-eef560ce@1\",\"206\":\"v-a1211dca\",\"207\":\"v-a1211dca#a-brief-history-of-mt-evaluation-metrics\",\"208\":\"v-a1211dca#human-evaluation\",\"209\":\"v-a1211dca#automatic-evaluation\",\"210\":\"v-a1211dca#bertscore\",\"211\":\"v-a1211dca#motivation\",\"212\":\"v-a1211dca#technique\",\"213\":\"v-a1211dca#effectiveness\",\"214\":\"v-a1211dca#comet\",\"215\":\"v-a1211dca#motivation-1\",\"216\":\"v-a1211dca#technique-1\",\"217\":\"v-a1211dca#effectiveness-1\",\"218\":\"v-a1211dca#case-study\",\"219\":\"v-a1211dca#conclusion\",\"220\":\"v-a1211dca#code\",\"221\":\"v-a1211dca#reference\",\"222\":\"v-a1211dca@0\",\"223\":\"v-a1211dca@1\",\"224\":\"v-7cb553dd\",\"225\":\"v-7cb553dd#so-what-is-machine-translation\",\"226\":\"v-7cb553dd#data-is-key\",\"227\":\"v-7cb553dd#monolingual-data\",\"228\":\"v-7cb553dd#translation-memory\",\"229\":\"v-7cb553dd#end-of-intro\",\"230\":\"v-7cb553dd#monolingual-translation-memory\",\"231\":\"v-7cb553dd#intuition\",\"232\":\"v-7cb553dd#parallel-encoders\",\"233\":\"v-7cb553dd#main-translation-model\",\"234\":\"v-7cb553dd#done-at-last\",\"235\":\"v-7cb553dd#references\",\"236\":\"v-7cb553dd@0\",\"237\":\"v-7cb553dd@1\",\"238\":\"v-5b1d4715\",\"239\":\"v-5b1d4715#introduction\",\"240\":\"v-5b1d4715#multi-head-attention-module\",\"241\":\"v-5b1d4715#problem-associated-with-the-self-attention\",\"242\":\"v-5b1d4715#ran-recurrent-attention\",\"243\":\"v-5b1d4715#effectiveness-and-analysis-of-the-ran\",\"244\":\"v-5b1d4715#_1-main-results\",\"245\":\"v-5b1d4715#_2-analysis\",\"246\":\"v-5b1d4715#summary\",\"247\":\"v-5b1d4715#references\",\"248\":\"v-5b1d4715@0\",\"249\":\"v-5b1d4715@1\",\"250\":\"v-e648c9de\",\"251\":\"v-e648c9de#_1-introduction\",\"252\":\"v-e648c9de#_2-case-study-on-machine-translation\",\"253\":\"v-e648c9de#_3-the-secret-behind-self-training\",\"254\":\"v-e648c9de#_4-the-proposed-method-noisy-self-training\",\"255\":\"v-e648c9de#_5-experiments\",\"256\":\"v-e648c9de#machine-translation\",\"257\":\"v-e648c9de#comparison-with-back-translation\",\"258\":\"v-e648c9de#analysis\",\"259\":\"v-e648c9de#summary\",\"260\":\"v-e648c9de#references\",\"261\":\"v-e648c9de@0\",\"262\":\"v-e648c9de@1\",\"263\":\"v-3d2c52a4\",\"264\":\"v-3d2c52a4#motivations-and-overview\",\"265\":\"v-3d2c52a4#methods\",\"266\":\"v-3d2c52a4#reconstruction-loss\",\"267\":\"v-3d2c52a4#cross-domain-loss\",\"268\":\"v-3d2c52a4#generative-and-discriminative-loss\",\"269\":\"v-3d2c52a4#experiments-and-case-study\",\"270\":\"v-3d2c52a4#conclusion\",\"271\":\"v-3d2c52a4#reference\",\"272\":\"v-3d2c52a4@0\",\"273\":\"v-3d2c52a4@1\",\"274\":\"v-2d0aa5cf\",\"275\":\"v-744a7276\",\"276\":\"v-0f29a47d\",\"277\":\"v-7a4ce775\"},\"fieldIds\":{\"h\":0,\"t\":1,\"c\":2},\"fieldLength\":{\"0\":[9,56],\"1\":[1,315],\"2\":[5,194],\"3\":[3,246],\"4\":[3,52],\"5\":[8,80],\"6\":[4,95],\"7\":[9,50],\"8\":[1,121],\"9\":[1,64],\"10\":[null,null,1],\"11\":[null,null,6],\"12\":[3,29],\"13\":[2,31],\"14\":[2,21],\"15\":[1,35],\"16\":[1,19],\"17\":[1,19],\"18\":[1,86],\"19\":[null,null,1],\"20\":[null,null,5],\"21\":[10,104],\"22\":[1,222],\"23\":[6,208],\"24\":[5,259],\"25\":[3,162],\"26\":[6,70],\"27\":[11,130],\"28\":[3,19],\"29\":[5,79],\"30\":[5,108],\"31\":[5,69],\"32\":[5,19],\"33\":[5,70],\"34\":[11,41],\"35\":[11,114],\"36\":[1,121],\"37\":[1,146],\"38\":[null,null,1],\"39\":[null,null,11],\"40\":[6,12],\"41\":[1,187],\"42\":[2,182],\"43\":[1,190],\"44\":[1,61],\"45\":[1,63],\"46\":[1,26],\"47\":[null,null,1],\"48\":[null,null,2],\"49\":[4,78],\"50\":[1,59],\"51\":[4,199],\"52\":[1],\"53\":[1,79],\"54\":[2,154],\"55\":[2,36],\"56\":[2],\"57\":[4,55],\"58\":[5,52],\"59\":[2,64],\"60\":[1,83],\"61\":[1,48],\"62\":[null,null,1],\"63\":[null,null,2],\"64\":[6,38],\"65\":[1,141],\"66\":[3,120],\"67\":[4,62],\"68\":[9,120],\"69\":[3,98],\"70\":[1,42],\"71\":[8,324],\"72\":[2,109],\"73\":[1,35],\"74\":[1,45],\"75\":[null,null,1],\"76\":[null,null,7],\"77\":[13,46],\"78\":[1,91],\"79\":[2,60],\"80\":[2,47],\"81\":[6,68],\"82\":[6,78],\"83\":[5,40],\"84\":[4,101],\"85\":[1,28],\"86\":[5,52],\"87\":[4,27],\"88\":[1,30],\"89\":[1,87],\"90\":[null,null,1],\"91\":[null,null,4],\"92\":[9,47],\"93\":[1,359],\"94\":[4,198],\"95\":[5,242],\"96\":[3,142],\"97\":[3,159],\"98\":[3,120],\"99\":[3,29],\"100\":[2,142],\"101\":[1,136],\"102\":[1,118],\"103\":[null,null,2],\"104\":[null,null,6],\"105\":[6,355],\"106\":[null,null,2],\"107\":[null,null,4],\"108\":[8],\"109\":[1,173],\"110\":[1,96],\"111\":[5,144],\"112\":[6,154],\"113\":[3,166],\"114\":[2,95],\"115\":[1,73],\"116\":[1,46],\"117\":[null,null,2],\"118\":[null,null,2],\"119\":[6,139],\"120\":[1,161],\"121\":[4,73],\"122\":[1,118],\"123\":[5,119],\"124\":[1,234],\"125\":[2,267],\"126\":[1,190],\"127\":[1,14],\"128\":[null,null,2],\"129\":[null,null,4],\"130\":[7,183],\"131\":[2,64],\"132\":[2,68],\"133\":[3,47],\"134\":[2,53],\"135\":[4,45],\"136\":[2,37],\"137\":[1,113],\"138\":[2],\"139\":[3,39],\"140\":[3,40],\"141\":[3,60],\"142\":[4,71],\"143\":[1,19],\"144\":[null,null,2],\"145\":[null,null,5],\"146\":[7,442],\"147\":[null,null,2],\"148\":[null,null,8],\"149\":[9,14],\"150\":[5],\"151\":[3,69],\"152\":[3,91],\"153\":[3,104],\"154\":[3,27],\"155\":[4,70],\"156\":[5,88],\"157\":[6,48],\"158\":[3,8],\"159\":[3,29],\"160\":[6,26],\"161\":[5,27],\"162\":[2],\"163\":[4,35],\"164\":[4,31],\"165\":[10,24],\"166\":[9,35],\"167\":[2,100],\"168\":[null,null,2],\"169\":[null,null,4],\"170\":[15,128],\"171\":[4,136],\"172\":[4,190],\"173\":[4,36],\"174\":[2,87],\"175\":[4,215],\"176\":[null,null,2],\"177\":[null,null,3],\"178\":[5,64],\"179\":[4,62],\"180\":[1],\"181\":[1,78],\"182\":[2,45],\"183\":[3,76],\"184\":[1,71],\"185\":[1],\"186\":[1,49],\"187\":[2,84],\"188\":[2,83],\"189\":[2,33],\"190\":[1,51],\"191\":[1,22],\"192\":[null,null,2],\"193\":[null,null,8],\"194\":[10,111],\"195\":[1,64],\"196\":[3,121],\"197\":[2,96],\"198\":[1,59],\"199\":[2,50],\"200\":[2,111],\"201\":[5,90],\"202\":[8,96],\"203\":[10,172],\"204\":[null,null,2],\"205\":[null,null,11],\"206\":[5,30],\"207\":[7],\"208\":[2,106],\"209\":[2,103],\"210\":[1,69],\"211\":[1,151],\"212\":[1,225],\"213\":[1,99],\"214\":[1,68],\"215\":[1,98],\"216\":[1,209],\"217\":[1,112],\"218\":[2,323],\"219\":[1,123],\"220\":[1,9],\"221\":[1,214],\"222\":[null,null,2],\"223\":[null,null,5],\"224\":[6,54],\"225\":[6,154],\"226\":[3,144],\"227\":[2,126],\"228\":[2,234],\"229\":[3,47],\"230\":[3,31],\"231\":[1,142],\"232\":[2,174],\"233\":[3,184],\"234\":[3,50],\"235\":[1,48],\"236\":[null,null,2],\"237\":[null,null,2],\"238\":[6,66],\"239\":[1,132],\"240\":[4,143],\"241\":[6,53],\"242\":[3,118],\"243\":[7],\"244\":[3,186],\"245\":[2,111],\"246\":[1,45],\"247\":[1,87],\"248\":[null,null,2],\"249\":[null,null,3],\"250\":[7,79],\"251\":[2,133],\"252\":[6,146],\"253\":[6,134],\"254\":[7,119],\"255\":[2],\"256\":[2,71],\"257\":[4,42],\"258\":[1,78],\"259\":[1,61],\"260\":[1,19],\"261\":[null,null,2],\"262\":[null,null,2],\"263\":[7,148],\"264\":[3,121],\"265\":[1,69],\"266\":[2,143],\"267\":[3,82],\"268\":[4,83],\"269\":[4,175],\"270\":[1,54],\"271\":[1,49],\"272\":[null,null,2],\"273\":[null,null,3],\"274\":[1],\"275\":[1],\"276\":[1],\"277\":[1]},\"averageFieldLength\":[3.3749911362719125,100.47206999742647,1.5646157597806365],\"storedFields\":{\"0\":{\"h\":\"Learning Optimal Vocabularies for Machine Translation with only CPU\",\"t\":[\"Constructing a vocabulary is a fisrt step for any NLP tasks. How can we efficiently learn an optimal vocabulary for machine translation? In this blog, I will explain the VOLT algorithm from the paper Vocabulary Leaning via Optimal Transport for Neural Machine Translation, which was awarded the Best Paper at ACL 2021.\",\"Paper: https://arxiv.org/pdf/2012.15671.pdf\",\"Code: https://github.com/Jingjing-NLP/VOLT\"]},\"1\":{\"h\":\"Introduction\",\"t\":[\"At its core, the paper aims to find a way to reduce resource consumption and computational times of machine translation's vocabulary building algorithms. The method we will explore today could result in machine translation models running much faster on machines with much less computational power than what is required now. A key part of translating between one language and another is taking the text in the original language and breaking it down into tokens to make the translation process much simpler by using the tokens as a foundation of words or characters to use in the translation. Tokens are just key elements of the text, they can be words, characters, or even sub-words. A sub-word is just a part of a word. For instance, a sub-word for both the words \\\"lower\\\" and \\\"lowly\\\" could be \\\"low\\\". The set of tokens that get produced from a piece of text is called a token vocabulary. Here is an example of a sentence and some possible token vocabularies from that sentence.\",\"Which one of these generated token vocabularies is better? The word level vocabulary has the advantage of the smallest size, but it runs into the following issue. If there is a word or character we cannot construct with our token vocabulary, we denote this as an unknown or out of vocabulary token and label it as [UNK] or [OOV]. Obviously, the goal is to have as few [UNK] tokens as possible. With word vocabularies, there is a higher chance of [UNK] tokens since any word not in our training corpus will not be constructable with our generated vocabulary. On the opposite end of the spectrum, the character level token will have very few [UNK] tokens as we can construct most tokens with characters in our vocabulary. However, the size of the token vocabulary, as can be seen from the example above, is quite large. Sub-word vocabularies are a good mix between word and character level vocabularies as they can construct tokens that would otherwise be [UNK] and have a manageable size compared to character level vocabularies. Even though we now know that sub-word vocabularies are the preferred type, we still do not know what vocabulary we should choose from given all the possible sub-word vocabularies. For instance, going back to the previous example we can have many sub-word vocabularies generated.\",\"These 3 generated vocabularies are all sub-word vocabularies with different sizes and abilities to construct words. Just by looking at it, there is no way to tell which of these vocabularies is the best. Hence, we must construct a systematic way to find which vocabulary is better. This is where VOLT comes in. VOLT aims to find the best possible token vocabulary that can be generated from a piece of text in an efficient manner. VOLT and other vocabulary generation algorithms use the concept of entropy. Entropy just means the amount of information present in each token. If a certain word or character occurs a lot in a piece of text, then each time we add it as a token we add a relatively small amount of information since its already widely present in the text. However, if a word occurs only once then adding it to our vocabulary would be quite valuable as we only add it that one time. Words or character that occur often have a higher entropy than low occurring words or characters. Intuitively, a vocabulary with the lowest possible entropy would be optimal as it holds a lot of information per token. The main objective of VOLT is to find the best vocabulary in terms of both optimizing size and entropy. As we’ll see later, this often results in much smaller vocabulary sizes than vocabularies generated by other algorithms.\",\"VOLT has other advantages other than reducing the vocabulary size. Firstly, VOLT does not only reduce size but produces an overall better vocabulary than current methods. We will see performance metrics later that show this off. Secondly, VOLT works well on multilingual MT settings. This means that VOLT performs better on a more diverse range of languages than other methods such as Byte-Pair Encoding (BPE) [1]. Lastly, VOLT uses less resources and computational time than current prevailing methods. For instance, on English to German translation, VOLT uses 30 GPU hours while conventional methods such as BPE-Search take 384 GPU hours. This is because VOLT does not require trail training when it comes to computing the optimal vocabulary. Trail training just means having to iterate through all possible vocabulary sizes to find the best vocabulary at the best size, this methodology is extremely inefficient and so its use is avoided in VOLT.\",\"The question to now be asked is why is VOLT necessary. Why do we need to reduce vocabulary size in the first place? In this next section, we will discuss the current issues with other tokenization methods and why VOLT is necessary.\"]},\"2\":{\"h\":\"Issues with current tokenization models\",\"t\":[\"Most current translation models use word-level vocabularies. As discussed above, sub-word vocabularies tend to be overall better. Using a sub-word level encoding can help decrease the sparsity of tokens and increase the shared feature of similar words. My previous example of taking “low” from “lowly” and “lower” previews how we can have these shared features between words. Furthermore, sub-level vocabularies tend to have shorter sentence lengths and no rare words compares to character level vocabularies.\",\"Sub-word vocabularies seem great, but the issue lies with the methods the use them. Here is an example of an analysis on piece of text done by BPE.\",\"BPE works by merging frequent character sequences to make sub-words for the token vocabulary. In the above image. A hyphen is placed in every position there is a possible merge of multiple characters into a sub-word. Nonetheless, our concern here is not how BPE works but the fact that its analysis focuses on how often a character sequence occurs and merges frequent character sequences together. However, BPE does not consider any of the features, namely size, of the resulting vocabulary.\",\"The question here becomes, if the problem with BPE is size why not just run BPE for all possible sizes and pick the best one. To do this, we would have to run BPE-1K, BPE-2K, BPE-3K, … all the way up to BPE-60K. For each one we would have to train the model on a collection of text and then conduct tests to retrieve BLEU score for each model, which is a performance metric, and then pick the vocabulary with the highest score. It is not difficult to see that this would take extremely long to produce the best vocabulary. Just running BPE on 12 different sizes and getting the best vocabulary takes 384 computing hours on the GPU as we will see later. Therefore, VOLT is needed, it allows us to find a vocabulary without having to iterate through every possible vocabulary size to find the optimal one. In the next section, we will discuss how VOLT manages to achieve this.\"]},\"3\":{\"h\":\"Techniques of VOLT\",\"t\":[\"To attempt to optimize both entropy and size, we will use the idea of Marginal Utility. In economics, marginal utility is the amount of satisfaction a consumer attains from consuming a unit of a product. It is used to balance between the benefit and the cost. Let’s look at the following example to make things clear. A high school is buying laptops in bulk for its students, it needs to find the optimal amount and price to buy these laptops at. Here are some of its options\",\"While it may seem like an easy choice for the school to just buy 400 laptops. 400 laptops might be too much, meaning laptops would go unused and the school would have wasted money. Hence, the optimal choice would be choosing 200 laptops which would fit the school’s needs at a good price. This is the concept of marginal utility. We apply this same concept in the paper by using vocabulary size as the cost and the value is the information per character, which as defined before is entropy. We define a new concept, the Marginal Utility of Vocabularization (MUV), which finds the best trade-off between size and entropy. For VOLT to find the optimal vocabulary, it needs to find the vocabulary with the highest MUV.\",\"Intuitively, the equation for MUV is the derivation of entropy with respect to size as we want to know how much we are sacrificing in terms of a larger vocabulary size with every drop in vocabulary entropy. Now that MUV is defined, we can view VOLT as an optimal transport problem. There have been algorithms developed to efficiently solve optimal transport problems such as the Sinkhorn algorithm which is used here to find the vocabulary with the highest MUV, which is the optimal vocabulary.\",\"Our initial goal was to find the vocabulary with the highest BLEU score, this was then simplified to the vocabulary with the highest MUV. With an equation for MUV as defined above, we further reduced this to an optimal transport problem which already has well known solution. Lets take a look at how effective the usage of MUV is.\",\"Initial results show that the usage of MUV has a correlation with two-thirds of tasks performed. Let’s now look at a few figures to clarify the points being made here.\",\"Firstly, it’s helpful to understand that BLEU and Spearman score are just two performance metrics and not knowing the details of how they work does not affect one’s ability to understand these figures. In the first model, we have entropy on the y-axis and size on the x-axis. Notice the roughly inversely proportional relationship between them. The BLEU score is also graphed, and a star is placed at the vocabulary with highest MUV. Notice that the starred vocabulary is the one corresponding to the vocabulary with the highest BLEU score, meaning it is the best performing vocabulary.\",\"For the second figure, experiments were conducted on 45 language pairs and the spearman score between MUV and BLEU were recorded for each pair. Spearman score here is just a correlation score where the higher the correlation between MUV and performance, the higher the spearman score. The figure shows the results with the spearman score on the x-axis and the number of generated vocabularies that correspond to a certain spearman score range on the y-axis. The results show that for two-thirds of the generated vocabularies there is a positive spearman score indicating a correlation between MUV and performance.\"]},\"4\":{\"h\":\"Effectiveness of VOLT\",\"t\":[\"The experiments shown here are conducted from one of the three following datasets. The WMT-14 English-German dataset which has 4.5 M English-German sentence pairs. The TED bilingual dataset where we chose 12 different language pairs that had the most training data. Lastly, the TED multilingual dataset where we chose 52 language pairs on a many-to English setting. Here are some of the main advantages of VOLT:\"]},\"5\":{\"h\":\"1. Overall better performance than widely used vocabularies\",\"t\":[\"In a paper by Shuoyang Ding [2], it was found that among the 42 papers accepted for the Conference of Machine Translation(WMT), the most common size was 30K-40K. Hence, we compare VOLT’s BLEU (performance) scores with a popular method such as Byte Pair Encoding with a 30K vocabulary size. Here are the results:\",\"In all of these examples, not only does VOLT produce a vocabulary that is almost 10x smaller than that of BPE-30K, but it also actually outperforms it as well in terms of BLEU score. Out of the 24 some language to English translation, VOLT outperformed BPE-30K on 23 of them.\"]},\"6\":{\"h\":\"2. Low Resource Consumption\",\"t\":[\"To explore VOLT’s resource consumption in respect to other methods, we will first run BPE-1K, BPE-2K, BPE-3K, BPE-4K, BPE-5K, BPE-6K, BPE-7K, BPE-8K, BPE-9K, BPE-10K, BPE-20K, and BPE 30K and select the best performing vocabulary out of those produced by these runs. We will cause this method of running several BPE’s and selecting the best one BPE-Search. We will compare BPE-Search with VOLT to get the following results:\",\"In the figure above, GH and CH are GPU Hours and CPU Hours respectively. The results seem to indicate that the performance score of both is extremely similar. However, VOLT seems to be a better option as it produces a vocabulary in 300+ less computing hours than BPE-Search, making it a much more efficient algorithm.\"]},\"7\":{\"h\":\"3. Versatile, better on a large array of languages\",\"t\":[\"To test how good VOLT is across as many languages as possible. We conduct experiments to compare VOLT to BPE-60K as that it the most popular size setting for multi-lingual translation tasks. Here are the results:\",\"The figure shows results for BPE-60K and VOLT on 20 different languages to English translation tasks. VOLT performs better than BPE-60K on 18 of those languages which shows how versatile VOLT is.\"]},\"8\":{\"h\":\"Summary\",\"t\":[\"A key part of machine translation is the process of vocabulary building and tokenization. For one language to be translated to another, we must extract all the key elements of the source language text such as words and characters and use those to translate the text to another language. Traditionally, tokenization methods tend to focus on how frequently a word or character pair occurs to decide whether to make it a token. However, these methods do not consider how big the token set is going to end up being, which also affects the performance of the resulting token set on translation tasks. The method introduced in this paper, VOLT, considers both word frequency and size to produce better performing token sets. In addition, VOLT does not iterate through all possible sizes to find the best one; instead, it treats the problem as an optimal transport problem. This means it applies constraints on the possible optimal sizes and utilizes transport matrices to come up with the optimal size. VOLT is an important method when it comes future machine translation models as it could result in faster training times and better performance all in less computing hours.\"]},\"9\":{\"h\":\"References\",\"t\":[\"[1] Sennrich, Haddow, et al. “Neural machine translation of rare words with subword units.” In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers. The Association for Computer Linguistics\",\"[2] Ding, Renduchintala, et al.  “A call for prudent choice of subword merge operations in neural machine translation.” In Proceedings of Machine Translation Summit XVII Volume 1: Research Track, MTSummit 2019, Dublin, Ireland, August 19-23, 2019, pages 204– 213. European Association for Machine Translation.\"]},\"10\":{\"c\":[\"MT\"]},\"11\":{\"c\":[\"Multilingual MT\",\"Vocabulary Learning\",\"Optimal Transport\"]},\"12\":{\"h\":\"机器翻译中的 BERT 应用\",\"t\":[\"​ 预训练技术，比如 BERT等，在自然语言处理领域，尤其是自然语言理解任务取得了巨大的成功。然而目前预训练技术在文本生成领域，比如机器翻译领域，能够取得什么样的效果，还是一个开放问题。CTNMT 这篇论文，从三个方面介绍这个问题：\",\"预训练技术，比如 BERT或者 GPT 在机器翻译中的应用存在什么挑战？\",\"针对这些调整，需要怎么最大程度利用预训练知识？\",\"预训练和机器翻译的融合还有什么潜力？\",\"阅读时间大概 10 分钟。论文链接：https://arxiv.org/abs/1908.05672\"]},\"13\":{\"h\":\"预训练技术在机器翻译领域存在的挑战—-灾难性遗忘\",\"t\":[\"​ 机器翻译和传统自然语言处理很大的一个差异点在于有海量训练数据。很多自然语言处理任务，比如 SRL、POS等任务，训练数据一般只有3-10 万句规模，但是机器翻译任务的数据量一般都是千万级别，比如 WMT En-Fr 有 4000 万平行数据。如此大的数据量就给预训练模式带来了挑战。因为一般预训练模式，都是在较大的训练数据上预训练模型，接下来再一个小数据上进行微调模型，这样模型保留了大数据的知识，又可以适应小模型的数据，因而会有不错的表现。但是，对于机器翻译来说，下游任务的微调需要更多步骤，和更久的时间，一个直接影响就是灾难性遗忘，也就是模型随着不断微调逐渐忘记了预训练的知识，那么预训练模型的威力就很难在下游任务中得到体现。\"]},\"14\":{\"h\":\"渐进式学习策略--缓解灾难性遗忘问题\",\"t\":[\"​ 基于对灾难性遗忘的假设，CTNMT 提出了三种策略来逐步缓解问题。\",\"最简单的也是最直接的通过学习率来控制，有效但是实际操作需要比较仔细的参数控制策略。\",\"动态的基于门控制策略，由模型来决定预训练模型参数和机器翻译模型参数的贡献比例。\",\"continues learning 中最常见的策略，通过知识蒸馏来保持预训练模型的知识在下游微调中不要被忘记。\",\"这篇工作最重要的贡献并不是提出了这三种 technical 策略，更有趣的地方在于指出了机器翻译预训练微调框架中存在的问题，以及提出了几个简单的方法，验证了假设，并且在机器翻译benchmark 任务中观察到了显著提升。\"]},\"15\":{\"h\":\"梯度控制\",\"t\":[\"​ 最简单的策略是在下游任务更新的时候，控制BERT 的学习率，将 BERT 的学习控制在一个比较小的范围。不同于其它 NLP 任务，对于机器翻译来说，BERT 作为 Encoder 只占了整体参数中一半的参数量，还有另外一半没有被初始化，如果一开始所有参数一起调整，随机初始化的参数传递的梯度会有大量噪音，这部分噪音会很大程度影响 BERT 的参数，因此最优的策略应该是一开始固定 BERT 参数，先更新随机初始化部分的参数，当这部分参数更新差不多的时候，再打开 BERT 参数，然后一起更新着两部分参数，更新一定步骤之后，再将 BERT 参数固定下来，只更新 MT 部分的参数，这样就可以很大程度上避免了灾难性遗忘的问题，而且也可以让参数更好的适应下游任务，最大程度利用到预训练知识。\"]},\"16\":{\"h\":\"基于门控制的融合\",\"t\":[\"​ 梯度控制简单有效，但是很大的一个问题在于需要超参来控制 BERT 参数更新的开始和结束，因此 CTNMT 又引入了门机制来更自动的控制这种更新。简单说门机制引入一个可学习的参数控制 BERT 和 MT Encoder 贡献的比例，实际上这个参数也可以反过来控制更新的程度，有了这种自动控制机制，模型就可以将机器翻译和 BERT 有机结合起来，也可以很好的避免灾难性遗忘问题。\"]},\"17\":{\"h\":\"渐进蒸馏策略\",\"t\":[\"​ 持续学习中一个重要的方法就是蒸馏策略，也就是学生不断学习老师的知识，这样学生网络在不断更新的情况下，也可以保持不忘记老师的知识，在这个工作中，我们将 BERT 看作老师，将 MT Encoder看作学生。 这样就可以同时保持机器翻译参数的灵活性和保留 BERT 知识，最重要的是，这种方法只需要更改模型训练，对于模型解码不需要有任何更改，非常实用。\"]},\"18\":{\"h\":\"实验效果和未来方向\",\"t\":[\"​ CTNMT 在主流的 En-Fr、En-De 和 Zh-En 三个 WMT 语种上都做了实验，这三个数据也是业界比较公认的 Benchmark，通过下图的实验可以发现，三个单独的策略都起到了很明显的作用，更有趣的是，这三个方法加在一起还可以进一步提升模型效果。在英德方向上，最后实验得到了 30.1 的 BLEU score，相比 baseline 提升了接近三个点。\",\"​ 接下来 CTNMT 分析了数据量和效果之间的关系，可以发现在数据量比较少的时候，普通的 fine-tuning 和CTNMT 的方法差异非常小，这个原因主要是数据量少的时候灾难性遗忘的问题不是很严重，直接做 fine-tuning 就可以了。但是数据量增大的时候，可以发现，fine-tuning 的提升 gap 就会相对下降，这是由于随着数据量的增大，灾难性遗忘引起的问题越来越显著。但是 CTNMT 可以很好的避免这种遗忘，因而保持了稳定的提升。\",\"​ 此外，也简单做了一些关于 GPT 和 BERT 的模型选择实验，发现简单的再 encoder 和 decoder 使用 GPT 或者 BERT 效果并不是一样好，总结来说：\",\"Encoder 采用 BERT 初始化效果最好\",\"Decoder采用 BERT 或者 GPT 初始化，效果不明显\",\"​\\t直觉上讲，Decoder 对于机器翻译也起到了非常重要的作用，目前只初始化 Decoder，可能分布不一样，并且 Decoder 和 Encoder 之间有 attention，这部分也没有办法初始化，所以局部的 pre-training 还有很大的提升空间。因此，未来如何研究更好的将 Decoder 预训练和 Encoder预训练结合起来，得到进一步提升，是非常有潜力的方向。\"]},\"19\":{\"c\":[\"MT\"]},\"20\":{\"c\":[\"BERT\",\"Pre-training\",\"Catastrophic Forgetting\"]},\"21\":{\"h\":\"What is proper Pre-training for Multilingual Machine Translation?\",\"t\":[\"​ In 1920, the great philosopher Bertrand Russell visited China, accompanied by Yuen Ren Chao, a Chinese-American linguist. Mr. Chao was a naturally gifted polyglot. At that time, he could already speak Baoding dialect, Wu dialect, Fuzhou dialect, Nanjing dialect, and English. He accompanied Russell from Shanghai to Changsha by ship. During the trip, he was learning Changsha dialect from Yang Ruiliu, an economist on the same ship. When the ship docked in Changsha, Yuen Ren Chao was already able to translate Russell's speeches and slang into Changsha dialect. Can our neural network become a model like \\\"Yuen Ren Chao\\\" on machine translation? That is, to create a unified model with multilingual abilities, and when encountering new languages, the model could quickly adapt to translating new ones after training with a small amount of data.\",\"Paper：https://arxiv.org/abs/2010.03142\",\"Github: https://github.com/linzehui/mRASP\"]},\"22\":{\"h\":\"Introduction\",\"t\":[\"A recent work mRASP, which appeared at the 2020 Conference of Empirical Methods in Natural Language Processing, aims to provide a Yuen Ren Chao polyglot model for machine translation [1]. The key idea is to pre-train a model with multilingual capability, and yield any specific translation model by fine-tuning on the corresponding parallel corpus. The model trained with mRASP technique in 32 languages has achieved a comprehensive and significant improvement in 47 translation test sets.\",\"Unlike previous translation models, mRASP has established a successful paradigm of pre-training and fine-tuning for machine translation. This is similar to BERT's role on NLU tasks. There were already pretrained models for natural language generation (GPT). However, they are limited in extending their capabilities on multilingual machine translation tasks. The central problem that mRASP wants to solve is, can we develop a unified pre-trained translation model and extend it by fine-tuning on a small amount of parallel corpus on any specific language pair to obtain any-language translation model?\",\"mRASP is designed for machine translation tasks. It has three advantages. First, the translation quality can be consistently improved regardless of the amount of parallel bilingual corpus. In rich-resource directions, such as the standard English-French wmt2014 translation task, which already has 40 million parallel sentence pairs for training, mRASP can still significantly improve the quality, reaching a BLEU score of 44.3. In low-resource directions, mRASP performs surprisingly well. In extreme cases, when we have only 10,000 training data for fine-tuning, a reasonable translation model can be obtained through 10-minute fine-tuning. Second, It breaks the limit on languages, for any direction, the mRASP can be directly used to fine-tune to get a single-directional translation model. Finally, it is resource-efficient. Some other pre-training paradigms are trained on hundreds of GPUs for a couple of weeks. By contrast, mRASP only needs 8 GPUs for a week. In short, mRASP can be understood as a lightweight BERT in the field of machine translation. When you need a machine translation model, you should try it, it may surprise you! The authors also said that this technology has been used on the Volctrans system developed by ByteDance and has been tested in actual business practice. The authors have kindly published the research data, codes and pre-trained models.\",\"Next, we will introduce and analyze mRASP from three aspects: 1) the challenges of machine translation pre-training; 2) the motivation and methods of mRASP; 3) the performance and analysis of mRASP.\"]},\"23\":{\"h\":\"Challenges in machine translation pre-training\",\"t\":[\"At present, the vast majority of AI tasks are basically statistical learning based on data, and the performance of the model depends on the quality and quantity of data to a large extent. It has become a new successful paradigm for NLP to use a large amount of cheap data to pre-train the model, then fine-tune with a small amount of annotation data in specific scenarios. For example, pre-trained on large-scale unlabeled text, BERT[2] can achieve good results on 11 NLU tasks after fine-tuning on limited annotation data. However, in multilingual machine translation, the paradigm of pre-training and fine-tuning has not yet achieved general success. The training objectives of previous NLP pre-training methods such as BERT and GPT[5] have a large gap with machine translation, thus are not easy to use directly. mRASP proposed a new idea: it uses massive bilingual parallel corpus accumulated in multiple languages to jointly train a unified model, and then fine-tune based on it. Therefore the pre-training and fine-tuning objectives are as close as possible, so as to give greater play to the role of the pre-training model.\",\"The above figure compares and analyzes the limitations of the previous NLP pre-training paradigms in machine translation scenarios. BERT and GPT respectively correspond to the pre-training of the Transformer[6] encoder part and the decoder part, while machine translation uses the whole sequence-to-sequence model. Only part of the parameters of the translation model are initialized due the inconsistency in model structure. Therefore it will be difficult to effectively play the role of pre-training. As a result, it requires a lot of special skills to be improved [10].\",\"Researchers soon proposed frameworks such as MASS [7] and BART [8] to extend pre-training to sequence-to-sequence tasks. They use auto-encoder for self-learning and have achieved significant results in many downstream NLG tasks. However, there are still two important problems when applying them in machine translation: 1) They brings no improvement in rich-resource languages (such as English, German, English and French). 2) There is no way to extend to multilingual translation tasks. This limitation is largely due to the fact that autocoding is a relatively simple task so it is difficult to learn a deeper representation. By contrast, machine translation requires a more complex semantic transformation. The training objective discrepancy between pre-training and fine-tuning makes it difficult for the model to make the best use of training data. It has become an important challenge to overcome the two problems for the application of pre-training paradigms in the field of machine translation.\"]},\"24\":{\"h\":\"Motivation and Techniques of mRASP\",\"t\":[\"​For language learners, a very interesting phenomenon is that after learning three or four languages, the speed of learning a new language will accelerate. For example, if an English native speaker learns German and French separately, he/she may take one year each. However, if he learns German first and then learns French, he/she may only take one year and three months to learn it. If he/she learns Spanish subsequently, the speed may be faster [3]. The same is true for learning programming languages. Learning C ++ may take one year. Learning Java, Python subsequently may only take one month. A simple explanation is that in the process of multilingual learning, human beings will spontaneously summarize the abstract commonalities among languages and focus on learning the characteristics of new languages. Therefore, in order to improve personal language learning ability, it is often necessary to learn more languages, to have a more accurate grasp of language commonalities, instead of desperately learning one language. By the same token, for machine translation, it has become a very interesting question whether the translation ability can be transferred to different languages so that the information between different languages can be utilized for each other.\",\"The design goal of mRASP is based on such considerations: design a general pre-trained model to learn the commonalities of transformation between languages, and then it will be easier to migrate to the new translation direction. Just like language learners, after learning two languages, the third language becomes easier. The design of mRASP follows two basic principles: first, the training objective of pre-training is the same as machine translation, and it is necessary to learn the transformation ability between languages; second, learn the universal representation of the language as much as possible, if the semantics of cross-lingual sentences or words are close, the representation should also be close.\",\"mRASP follows a common pre-training-fine-tuning framework. In the pre-training stage, unlike the traditional pre-training model in which massive unsupervised monolingual data are used, mRASP takes a different approach: it puts multilingual parallel data into the same model for joint training. The Transformer architecture is adopted, plus a language identifier (Language token) to identify the source language and the target language. In order to ensure that sentences and words in different languages could be embedded in the neighbor space, sentences with the same meaning, random alignment substitution (RAS) is introduced to create a richer context.\",\"There is a certain probability that \\\"爱\\\"(Chinese) in a Chinese sentence \\\"我 爱 北京 天安门\\\" will be replaced by \\\"aime\\\" (French), and \\\"北京\\\"(Chinese) will also be replaced by \\\"Pékin\\\" (French), so the original sentence becomes \\\"I aime Pékin Tiananmen.\\\" A pair of parallel sentence pairs in the training set can be expanded into two pairs (even three pairs, four pairs,......)\",\"我 爱 北京 天安门 ==> I love Beijing Tiananmen Square 我 aime Pékin 天安门 ==> I love Beijing Tiananmen Square \",\"For the model, by learning from abundant parallel corpus, it will naturally learn the correspondence between synonyms across different languages according to this \\\"artificially created context\\\". In fact, RAS based on parallel dictionaries has bridge the representation gap of synonyms across different languages. In the above example, the word vector expectations calculated by \\\"爱\\\"('love' in Chinese) and \\\"aime\\\"('love' in French) are as close as possible.\",\"In the fine-tuning stage, we initialize the parameters with mRASP, and then we adopt the same training method as the traditional single-directional machine translation. Therefore, using mRASP does not require any additional skills. For a detailed introduction, please refer to the paper[1].\"]},\"25\":{\"h\":\"Effectiveness of mRASP\",\"t\":[\"mRASP uses parallel corpus of 32 languages to-and-from English for pre-training. When we only use parallel corpus of English to French wmt14 for fine-tuning, it achieves 44.3 BLEU without laborious Back Translation of massive monolingual corpus. Moreover, when applied to a new translation direction Dutch (Nl) to Portuguese (Pt), with only 12,000 parallel sentence pairs for fine-tuning, mRASP gets a reasonable (BLEU 10 +) model in ten minutes. By contrast, training any usable MT model from scratch using the equivalent parallel sentence pairs is impossible (BLEU is close to 0).\",\"In summary, mRASP has the following advantages:\",\"Easy to reproduce\",\"The pre-training of mRASP only requires a total of 110 million parallel sentence pairs (the same pair of parallel sentence is applicable to both directions, resulting in a total of 220 million training samples), and the vocabulary only has 64k bpe subword tokens. Compared with other pre-training methods, in which tens of billions of data and dozens of layers are frequently used, the training process is less difficult. We can complete the pre-training process on 32 languages in less than a week using 8 GPUs. By the way, support for more languages can also be simply expanded.\",\"Highly Versatile\",\"Compared with the single-directional machine translation models, mRASP brings a consistent improvement in rich, medium and low-resource scenarios. Even for English to French direction where we have the largest parallel corpus, the translation quality is further improved by 1.1 BLEU. More surprisingly, for Dutch to Portuguese direction that have never been seen in the pre-training data, a significant improvement of 10 + BLEU has also been achieved.\",\"Here are some representative experimental results:\"]},\"26\":{\"h\":\"1. En-De and En-Fr Benchmarks\",\"t\":[\"The following figure compares the effect of mRASP on En-De and En-Fr with several concurrent cross-lingual pre-training models. It can be seen that mRASP has certain advantages: it reaches 30.3 (tokenized BLEU) on En->De wmt 2016 test set, 44.3 (tokenized BLEU) on En->Fr wmt 2014 test set. CTNMT uses BERT pre-training. MASS introduces large-scale monolingual data. mBERT is a multilingual BERT model. mBART is another pre-training method that is proposed concurrently, it uses massive multilingual monolingual data, and is trained on 256 GPUs for 20 days.\"]},\"27\":{\"h\":\"2. Extend to language not seen during the pre-training phase\",\"t\":[\"Directions that are not included in parallel pairs during the pre-training stage, are also referred as \\\"Exotic Directions\\\". Whether mRASP is effective on Exotic Directions, determines whether mRASP has good generalization capabilities.\",\"The Exotic Directions are divided into four situations in the paper:\",\"Exotic Pair: Both the source language and the target language have been individually pre-trained, but the model has not yet seen the bilingual pairs of them\",\"Exotic Source: The model has only seen the target language in the pre-training stage, and the source language has not been seen at all\",\"Exotic Target: The model has only seen the source language in the pre-training stage, and the target language has not been seen at all\",\"Exotic Full: The model has not seen the source language or the target language at all in the pre-training stage\",\"It is difficult to train machine translation under the circumstances. Of course, the most difficult one is the last one, which is equivalent to requiring people who have never learned Latin and Hindi to read a few sentences in Latin and Hindi then translate between them.\",\"Category\",\"Source language seen during pre-training?\",\"Target language seen during pre-training?\",\"Language pair seen during pre-training?\",\"Exotic Pair\",\"✔\",\"✔\",\"X\",\"Exotic Source\",\"X\",\"✔\",\"X\",\"Exotic Target\",\"✔\",\"X\",\"X\",\"Exotic Full\",\"X\",\"X\",\"X\",\"It is worth noting that both sides of Fr-Zh have appeared separately, but they have not appeared as parallel pairs. mRASP achieves a 20 + BLEU score after fine-tuning on 20K parallel corpus.\",\"For Exotic Full scenario, such as Dutch to Portuguese (Nl-Pt), only 12,000 parallel corpora are used, and after about 10 minutes of training, you can achieve a 10+ BLEU score.\"]},\"28\":{\"h\":\"3. Case study\",\"t\":[\"In order to understand the effect of mRASP more intuitively, the authors also make a case study in the paper.\"]},\"29\":{\"h\":\"French-Chinese(Fr-Zh)\",\"t\":[\"Exotic Pair, 20k Parallel Sentence Pair\",\"Direct (0.7 BLEU) is much weaker than mRASP (25.8 BLEU)\",\"The Direct system does not work at all, while the mRASP system translates well.\",\"Original Text\",\"Translation in English\",\"source\",\"Ordre du jour provisoire de la 7424e séance ( privée ) du Conseil\",\"Provisional agenda for the 7424th (closed) meeting of the Council\",\"target\",\"安全 理事会 第 7424 次 ( 闭门 ) 会议 临时 议程\",\"Security Council, 7424th (closed) meeting, provisional, agenda\",\"Direct\",\"事实上 ， 国际 货币 基金 组织 的 国际 货币 基金 组织 （ IMF ）\",\"In fact, international, monetary, fund, organization, international, monetary, fund, organization (IMF)\",\"mRASP\",\"安理会 第 7424 次 （ 非 公开 ） 会议 临时 议程\",\"Council, 7424th (closed) meeting, provisional, agenda\"]},\"30\":{\"h\":\"Dutch-Portuguese (Nl-Pt)\",\"t\":[\"Exotic Full, 12,000 parallel sentence pairs\",\"Direct 0 BLEU vs mRASP 14.1 BLEU\",\"We find that the translation system obtained by mRASP can not successfully translate every detail, but it can grasp the key information of the original text. For example, in the following example (1) date (2) minutes of the meeting <-> news of meeting (3) circulated <-> shared.\",\"Original Text\",\"Translation in English\",\"source\",\"de notulen van de vergadering van donderdag 21 september zijn rondgedeeld.\",\"The minutes of the meeting on Thursday, 21 September have been circulated.\",\"target\",\"a acta da sessão de quinta feira , 21 de setembro de 2000 , já foi distribuída.\",\"The minutes of the meeting on Thursday, 21 September 2000 have now been distributed.\",\"Direct\",\"Os governos, os líderes mundiais dos seus próprios.\",\"Governments, their own world leaders.\",\"mRASP\",\"As notícias da reunião do dia 21 de Setembro foram partilhadas.\",\"News of the September 21 meeting has been shared.\"]},\"31\":{\"h\":\"English-French (En-Fr)\",\"t\":[\"We found that one of the advantages of the model trained by the mRASP method over the Direct method is that the Direct system tends to ignore meaningless words (such as articles, deixis, etc.), while the mRASP maintains the consistency of articles and deixis.\",\"Text\",\"source\",\"An investigation is under way to find the cause of the fire .\",\"target\",\"Une enquête est en cours pour trouver la cause de cet incendie .\",\"Direct\",\"enquête est en cours pour déterminer la cause de l' incendie .\",\"mRASP\",\"Une enquête est en cours pour trouver la cause de l' incendie .\",\"Text\",\"source\",\"After Broadway and London , Paris is finally finding its voice .\",\"target\",\"Après Broadway et Londres , Paris trouve enfin sa voix .\",\"Direct\",\"Broadway et Londres , Paris trouve enfin sa voix .\",\"mRASP\",\"Après Broadway et Londres , Paris trouve enfin sa voix .\"]},\"32\":{\"h\":\"English-Chinese (En-Zh)\",\"t\":[\"Original Text\",\"Translation in English\",\"source\",\"and for the middle class.\",\"target\",\"对中产阶级而言。\",\"For the middle class.\",\"Direct\",\"还有中产阶级。\",\"And the middle class.\",\"mRASP\",\"对中产阶级而言。\",\"For the middle class.\"]},\"33\":{\"h\":\"Findings from mRASP trained model\",\"t\":[\"As a general pre-training model, where does the improvements of mRASP for downstream MT tasks come from?\",\"The author believes that its improvements mainly comes from two aspects:\",\"mRASP narrows the gap between the vector representation of synonyms across different languages\",\"mRASP narrows the gap between the vector representation of synonymous sentences across different languages\",\"The narrowing of the gap between word-level and sentence-level representations means that after learning parallel sentence pairs in a large number of languages in the pre-training stage, mRASP implicitly \\\"mastered\\\" the language-independent representation, which can be migrated to any language, so mRASP can generally improve the effect of downstream machine translation tasks.\"]},\"34\":{\"h\":\"1. mRASP draws word-level vector representation of different language closer\",\"t\":[\"RAS is introduced by making the same context shared between synonyms across different languages. Since the word vector is determined by the context, RAS further draws the representation of synonyms across different languages closer.\",\"Up: w/o RAS, Down: w/ RAS\",\"It can be seen that with the RAS method, the embedding distribution between different languages is drawn closer (the angle becomes smaller).\"]},\"35\":{\"h\":\"2. mRASP draws sentence-level vector representation of different language closer\",\"t\":[\"mRASP narrows the gap between the representation of synonyms, as well as the vector representation of semantics.\",\"We use the encoder output vector as the representation of the sentence (L2 normalized averaged-pooled encoded output). From the TED parallel test set (filtered 15-way parallel test set, a total of 2284), we match the nearest sentence based on similarity score (cosine similarity), then calculate the Top-1 accuracy (sentence retrieval accuracy).\",\"Figure 1: The accuracy of mRASP minus the accuracy of mBART [9]. Note that Dutch (Nl) has never appeared in the mRASP pre-training data, and the accuracy in other directions is much higher than that of mBART.\",\"The average accuracy of mRASP retrieval reached 76%\",\"Figure 2: Accuracy of mRASP minus the accuracy of mRASP w/o RAS. It can be seen that RAS has obvious benefits on languages (Nl) that did not appear in the pre-training stage.\",\"Figure 3: After removing the language identifier (Language token) at the beginning of the sentence, the accuracy of Nl can be further improved, at a sacrifice that the accuracy of other languages is greatly reduced.\",\"It can be seen that RAS does further draws closer the semantic vector representation, and synonymous sentences will be closely represented after mRASP.\"]},\"36\":{\"h\":\"Summary\",\"t\":[\"Back to the beginning of the article, Mr. Chao, a language genius, has mastered 33 dialects plus 7 foreign languages in his life. From Baoding in the north China to Fuzhou in the south, from the upper reaches to the lower reaches of the Yangtze River, from Berkeley in the United States to Paris in France, he can speak local languages with a local accent. And the establishment of a unified multilingual and cross-domain translation model is one of the ultimate goals of machine translation research. mRASP, which is in line with the language genius Yuen Ren Chao, has established a successful path from multilingual pre-training to fine-tuning to multiple machine translation models, which will also become a new paradigm of machine translation. ByteDance has applied this technology to the Volctrans system and you can try it in the web page attached at the end of the text. We are looking forward to the continuous emergence of new methods in this direction, making great strides towards the ultimate machine translation goal. In the next few years, the progress of machine translation can help everyone in dozens of countries become \\\"Yuen Ren Chao\\\" and truly communicate without language barriers.\"]},\"37\":{\"h\":\"References\",\"t\":[\"[1] Lin, Zehui, et al. \\\"Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information.\\\" In the Conference on Empirical Methods in Natural Language Processing (2020).\",\"[2] Devlin, Jacob, et al. \\\"Bert: Pre-training of deep bidirectional transformers for language understanding.\\\" NAACL-HLT (1) 2019: 4171-4186.\",\"[3] Thomas, Reed, and Callie Mady. \\\"Teaching for transfer: Insights from theory and practices in primary-level French-second-language classrooms.\\\" McGill Journal of Education/Revue des sciences de l'éducation de McGill 49.2 (2014): 399-416.\",\"[4] Johnson, Melvin, et al. \\\"Google’s multilingual neural machine translation system: Enabling zero-shot translation.\\\" Transactions of the Association for Computational Linguistics 5 (2017): 339-351.\",\"[5] Radford, Alec, et al. \\\"Improving language understanding by generative pre-training.\\\" (2018): 12.\",\"[6] Vaswani, Ashish, et al. \\\"Attention is all you need.\\\" Advances in neural information processing systems. 2017.\",\"[7] Song, Kaitao, et al. \\\"MASS: Masked Sequence to Sequence Pre-training for Language Generation.\\\" ICML. 2019.\",\"[8] Lewis, Mike, et al. \\\"Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.\\\" ACL 2020: 7871-7880\",\"[9] Liu, Yinhan, et al. \\\"Multilingual denoising pre-training for neural machine translation.\\\" TACL.2020\",\"[10] Yang, et al. \\\"Towards Making the Most of BERT in Neural Machine Translation\\\"  AAAI.2020\"]},\"38\":{\"c\":[\"MT\"]},\"39\":{\"c\":[\"Multilingual MT\",\"Pre-training\",\"Random Aligned Substitution\",\"Zero-shot Translation\",\"mRASP\"]},\"40\":{\"h\":\"Protecting Intellectual Property of NLP Models\",\"t\":[\"How to protect AI models from malicious use or being stolen?\"]},\"41\":{\"h\":\"Introduction\",\"t\":[\"Natural language processing (NLP) is the branch of artificial intelligence that aims to bridge the language barrier between humans and computers by allowing computers to interpret and produce human language. Many NLP tasks, such as machine translation, summarization, text classification, and sequence labeling involve the use of neural networks, which take in large amounts of training data to statistically learn how to perform these tasks. Neural networks that have been trained on a specific task can be deployed as web services with pay-per-query APIs, allowing businesses to make use of them without undertaking the task of training the developing the model themselves.\",\"Although these deployed NLP models provide a useful service to customers and businesses, there are significant challenges in providing the intellectual property of the creators of these models. Clients can use a process known as distillation to steal the parameters of the model to use for themselves. In this process, the attacker sends carefully designed queries to the API, specifically to learn the parameters of the model for malicious uses. Past attempts to prevent these attacks have involved the use of watermarking, in which a secret logo or signature is embedded in the model. In the event of a possible theft, a model owner can detect the watermark in the stolen model to establish ownership. However, these watermarks typically do not apply to NLP models, and they are invasive and fragile within their models.\",\"Recently Zhao et al presents the protection method of NLP models from distillation through Distillation-Resistant Watermarking (DRW), in a [paper][1] published at EMNLP 2022. DRW allows for training independence, flexibility, effectiveness, and scalability. This paper explains the technique behind DRW, as well as four tasks the researchers performed in order to evaluate its effectiveness.\",\"Paper: https://arxiv.org/abs/2210.03312 Code: https://github.com/xuandongzhao/drw\"]},\"42\":{\"h\":\"DRW Overview\",\"t\":[\"In DRW, a perturbation is introduced to the output of the proprietary model. In the case of a distillation attack, this perturbation will be transferred onto the suspect model, allowing the suspect model to be identified as stolen from the proprietary model. This is outlined in figure 1.\",\" Figure 1: Model extraction and watermark detection\",\"Proprietary models have two possible types of output: soft labels (real values such as probabilities) and hard labels. An adversary can query the model, obtain a pseudo-labeled dataset from the results, and train a new model with this dataset in order to create the stolen model. Adversaries can distill a proprietary model with hard labels by minimizing the cross-entropy loss or distill a proprietary model with soft labels by minimizing the Kullback-Liebler divergence loss. With DRW, a watermark is dynamically embedded in query responses for theft detection. The following variables represent a key K:\",\"Taken together, these variables define a periodic signal function:\",\"where g is a hash function that projects a text representation to a scalar.\",\"Next, the periodic signal for the victim output is given by\",\"where ϵ is the watermark level for the periodic signal and pc​ is the proprietary model’s prediction prior to watermarking. For soft labels, the proprietary model generates the output directly, while for hard labels, the proprietary model generates a one-hot label with probability for each class. In the case of hard labels, the watermark is retained through the expectation of the probabilities.\",\"In order to detect the watermark in a suspect model, the Lomb-Scargle periodogram method for detecting period signals is used. It yields an estimate of the Fourier power spectrum at a given frequency, after which signal strength is evaluated by calculating the signal-to-noise ratio:\",\"A higher signal-to-noise ratio indicates a higher peak in the frequency domain, which can be used as evidence of theft.\",\"The paper presents theoretical guarantees for DRW as well. In the soft label setting, if the water mark level is small, DRW does not have a large effect on accuracy. Furthermore, researchers derive an equation for the lower bound of accuracy in the hard label setting, allowing them to control the level to which watermarking affects the accuracy in that case as well.\"]},\"43\":{\"h\":\"Experiments\",\"t\":[\"The researchers evaluated DRW using four different tasks: Part-Of-Speech (POS) Tagging, Named Entity Recognition (NER), SST-2, and MRPC. BERT was used as the model backbone for each task. For each task, the protected proprietary model was trained to perform well on the validation set until it had comparable performance to BERT. Training data was split into two parts for soft and hard label distillation.\",\"The existing state-of-the-art method, DeepJudge, quantitatively tests similarities between a proprietary model and suspect model. DeepJudge was modified by the researchers for use in texts and was used as the basis of comparison for DRW. For each task, researchers trained 10 extracted models from watermarked models, 10 extracted models from unwatermarked models, and 10 models from scratch. The method was evaluated with both distillation with soft labels and distillation with hard labels. DeepJudge performed well in detecting extracted models on SST-2 and MRPC tasks, but it could not do so for POS Tagging or NER. DRW successfully detected extraction across all tasks. DRW did cause a slight performance drop of within 5% of the proprietary model, with soft labels exhibiting less of a performance drop than hard labels.\",\"The researchers additionally evaluated the watermark level necessary to ensure detection while minimizing the effect on accuracy. They did so by varying the watermark level in the SST-2 task and evaluating model accuracy and watermark detection. As expected, a higher watermark level leads to better detection but a lower model accuracy. The results are given in the graphs below:\",\" Model accuracy on SST-2 task after watermark.\",\" Detection rate with DRW.\",\"In another experiment, researchers designed 10 sets of ranking tasks, building 10 positive and 20 negative samples with a watermark level from 0.02 to 0.2. At a watermark level below 0.12, DRW could not perfectly detect positive and negative suspects.\",\"Researchers also evaluated whether categories affect watermark protection. Watermarks were added to four different categories, and extracted models were trained using soft distillation and hard distillation. Results, shown below, indicate that the watermark has a greater effect when a category involves more samples.\",\"One final aspect of this model that researchers evaluated is how much of the proprietary model output should be watermarked. The researchers performed tasks while modifying the ratio of watermarked data. Similar to the watermark level, results (show below) show that model accuracy is negatively affected by a higher ratio, but watermark detection is improved.\"]},\"44\":{\"h\":\"Limitations\",\"t\":[\"This work has some limitations. Watermark detection does not work well when the watermarked data is only a small proportion of the training data set for the extracted model, and the method does not work well when the attacker only makes a few queries to the proprietary model. These limitations are both the result of limited watermark embedding in the extracted model, which prevents the detection of that watermark. Finally, if a proprietary model outputs soft labels, an adversary can get around watermarks by using the argmax operation to erase the watermark.\"]},\"45\":{\"h\":\"Summary\",\"t\":[\"DRW presents a promising method of preventing the theft of intellectual property in NLP models. The use of a watermark in the output of NLP models will cause that watermark to be detectable in stolen models, given owners of the original model evidence in a potential legal case regarding the theft of their model. Although there are some limitations to this method, this paper demonstrates that it is an effective method of theft detection. This will help alleviate potential ethical concerns in deploying NLP models for use commercially, and it will help protect companies that distribute NLP web services.\"]},\"46\":{\"h\":\"References\",\"t\":[\"[1] Zhao, Xuandong, Li, Lei, Wang, Yu-Xiang. (2022). Distillation-Resistant Watermarking for Model Protection in NLP. EMNLP-Findings 2022, https://arxiv.org/abs/2210.03312\"]},\"47\":{\"c\":[\"NLP\"]},\"48\":{\"c\":[\"Model Protection\"]},\"49\":{\"h\":\"Document-level Relation Extraction\",\"t\":[\"The task of identifying semantic relations between entities from text, namely relation extraction (RE), plays a crucial role in a variety of knowledge-based applications. Previous methods focus on sentence-level RE, which predicts relations among entities in a single sentence. However, sentence-level RE models suffer from an inevitable limitation – they fail to recognize relations between entities across sentences. Hence, extracting relations at the document-level is necessary for a holistic understanding of knowledge in text. This blog describes a recent work on document-level relation extraction by Zeng et al. EMNLP 2020.\",\"Paper: https://arxiv.org/abs/2009.13752 Code: https://github.com/DreamInvoker/GAIN\"]},\"50\":{\"h\":\"Challenges\",\"t\":[\"There are several major challenges in effective relation extraction at the document-level. The figure below shows an example.\",\"The subject and object entities involved in a relation may appear in different sentences, e.g., the relation between Baltimore and U.S., as well as Eldersburg and U.S.\",\"The same entity may be mentioned multiple times in different sentences.\",\"The identification of many relations requires techniques of logical reasoning, e.g., Eldersburg belongs to U.S. because Eldersburg is located in Maryland, and Maryland belongs to U.S..\"]},\"51\":{\"h\":\"Our proposed Model: GAIN\",\"t\":[\"To tackle the challenges, we propose Graph Aggregation-and-Inference Network (GAIN). GAIN consists of double graph, i.e., mention-level graph and entity-level graph. Our intuitions are that: 1) Mention-level graph can model the interactions among mentions across sentences, so that global context can be better captured. 2) Entity-level graph can conduct logical reasoning for certain entity pairs over entities.\",\"Our model contains the following four modules.\",\"Encoding module. Tokens of the document is represented as the concatenation of word embedding, entity type embedding, and entity id embedding. Then they are fed into the encoder (e.g., LSTM or BERT) to obtain the contextualized representation.\",\"Mention-level Graph Aggregation Module. To model the document-level information and interactions among mentions, a heterogeneous mention-level graph is constructed followed by graph convolution network. The graph has two kinds of nodes: 1) Mention node, which refers to one specific entity mention in the document; 2) Document node, which aims to model the overall document information and serves as a pivot for interactions among different mentions. Three types of edges are leveraged to connect these nodes:\",\"Intra-Entity Edge: Mentions referring to the same entity are fully connected with intra-entity edges. In this way, the interaction among different mentions of the same entity could be modeled.\",\"Inter-Entity Edge: Two mentions of different entities are connected with an inter-entity edge if they co-occur in a single sentence. In this way, interactions among entities could be modeled by co-occurrences of their mentions.\",\"Document Edge: All mentions are connected to the document node with the document edge. With such connections, the document node can attend to all the mentions and enable interactions between document and mentions. Besides, the distance between two mention nodes is at most two with the document node as a pivot. Therefore long-distance dependency can be better modeled.\",\"Entity-level Graph Inference Module. To explicitly capture the logic reasoning chain of entity pairs over all the entities, we constuct an entity-level graph by merging mention nodes referring to the same entity in the mention-level graph into an entity node. Concretely, to model the logical chain between a certain entity pair, we find out all the two-hop paths between them, in which a path is represented as the concatenation of both forward and backward edges. Then we levelrage attention mechanism to aggregate multiple paths into a reasoning-aware path representation.\",\"Classification Module. Since a pair of entities may contain multiple relations, we formulate the task as a multi-label classification. Concretely, we first concatenate the entity, document, and path representations. Then we feed it into a MLP and use sigmoid function to predict the score for all possible relations.\"]},\"52\":{\"h\":\"Experiments\"},\"53\":{\"h\":\"Dataset\",\"t\":[\"We evaluate our model on DocRED (Yao et al., 2019), a large-scale human-annotated dataset for document-level RE constructed from Wikipedia and Wikidata. DocRED has 96 relations types, 132, 275 entities, and 56, 354 relational facts in total. Documents in DocRED contain about 8 sentences on average, and more than 40.7% relation facts can only be extracted from multiple sentences. Moreover, 61.1% relation instances require various inference skills such as logical inference (Yao et al., 2019). we follow the standard split of the dataset, 3, 053 documents for training, 1, 000 for development and 1, 000 for test.\"]},\"54\":{\"h\":\"Main Results\",\"t\":[\"We compare the performance among the following models:\",\"CNN, LSTM, BiLSTM, Context-Aware, BERT-RE, RoBERTa-RE, CorefBERT-RE, CorefRoBERTa-RE: Using different encoding mechanisms to simply encode the whole document and extract relations.\",\"HIN-Glove, HIN-BERT: Extracting relations through a hierarchical interaction network with either Glove embedding or BERT.\",\"GAT, GCNN, EOG, AGGCN, LSR-Glove, LSR-BERT: Previous graph-based methods, while our graph construction is totally different from theirs and they conduct logical reasoning only based on GCN.\",\"GAIN-Glove, GAIN-BERT: Our proposed model with either Glove embedding or BERT.\",\"The evaluation metrics we use are F1/AUC and Ign-F1/Ign-AUC. The latter means we do not consider the triples (i.e., head-relation-tail) that are already contained in the training set.\",\"The key observations are:\",\"Among the models not using BERT or BERT variants, GAIN-GloVe consistently outperforms all sequential-based and graph-based strong baselines by 0.9∼12.82 F1 score on the test set.\",\"Among the models using BERT or BERT variants, GAIN-BERT base yields a great improvement of F1/Ign F1 on dev and test set by 2.22/6.71 and 2.19/2.03, respectively, in comparison with the strong baseline LSR-BERT base. GAIN-BERT large also improves 2.85/2.63 F1/Ign F1 on test set compared with previous state-of-the-art method, CorefRoBERTaRElarge.\",\"GAIN can better utilize powerful BERT representation. LSR-BERT base improves F1 by 3.83 and 4.87 on dev and test set with GloVe embedding replaced with BERTbase while our GAIN-BERT base yields an improvement by 5.93 and 6.16.\"]},\"55\":{\"h\":\"Ablation Study\",\"t\":[\"We conduct ablation study by removing the mention-level graph, entity-level graph inference module, and the document node in the mention-level graph. The F1 scores on test set significantly decrease by 2.02~2.34/1.61~1.90 for GAIN-Glove/GAIN-BERT.\"]},\"56\":{\"h\":\"Further Analysis\"},\"57\":{\"h\":\"Cross-sentence Relation Extraction\",\"t\":[\"We evaluate GAIN on relations within a single sentence (Intra-F1) and those involving multiple sentences (Inter-F1), respectively. GAIN outperforms other baselines not only in Intra-F1 but also Inter-F1. The removal of Mention-level Graph (hMG) leads to a more considerable decrease in Inter-F1 than Intra-F1, which indicates our hMG do help interactions among mentions, especially those distributed in different sentences with long-distance dependency.\"]},\"58\":{\"h\":\"Logical Reasoning for Relation Extraction\",\"t\":[\"We evaluate GAIN on relations requiring logical reasoning (Infer-F1), and the experimental results show GAIN can better handle relational inference. For example, GAIN-BERT base improves 5.11 Infer-F1 compared with RoBERTa-RE base. The inference module also plays an important role in capturing potential inference chains between entities, without which GAIN-BERT base would drop by 1.78 Infer-F1.\"]},\"59\":{\"h\":\"Case Study\",\"t\":[\"The figure above shows the case study of our proposed model GAIN, in comparison with other baselines. As is shown, BiLSTM can only identify two relations within the first sentence. Both BERT-RE base and GAIN-BERT base can successfully predict Without Me is part of The Eminem Show. But only GAIN-BERT base is able to deduce the performer and publication date of Without Me are the same as those of The Eminem Show, namely Eminem and May 26, 2002, where it requires logical inference across sentences.\"]},\"60\":{\"h\":\"Conclusion\",\"t\":[\"Extracting inter-sentence relations and conducting relational reasoning are challenging in document-level relation extraction. In this paper, we introduce Graph Aggregationand-Inference Network (GAIN) to better cope with document-level relation extraction, which features double graphs in different granularity. GAIN utilizes a heterogeneous Mention-level Graph to model the interaction among different mentions across the document and capture document-aware features. It also uses an Entity-level Graph with a proposed path reasoning mechanism to infer relations more explicitly. Experimental results on the large-scale human annotated dataset, DocRED, show GAIN outperforms previous methods, especially in inter-sentence and inferential relations scenarios. The ablation study also confirms the effectiveness of different modules in our model.\"]},\"61\":{\"h\":\"Reference\",\"t\":[\"Shuang Zeng, Runxin Xu, Baobao Chang, Lei Li. Double Graph Based Reasoning for Document-level Relation Extraction. EMNLP 2020.\",\"Yuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, Maosong Sun. 2019. DocRED: A Large-Scale Document-Level Relation Extraction Dataset. In Proceedings of ACL.\"]},\"62\":{\"c\":[\"IE\"]},\"63\":{\"c\":[\"Relation Extraction\"]},\"64\":{\"h\":\"Automatic Verification of Natural Language Claims\",\"t\":[\"How to develop a model to verify a natural language statement while explaining its rationale?\",\"Reading Time: About 10 minutes.\",\"Paper：https://arxiv.org/abs/2012.13577\",\"Code: https://github.com/jiangjiechen/LOREN\",\"Demo: https://huggingface.co/spaces/Jiangjie/loren-fact-checking\"]},\"65\":{\"h\":\"Introduction\",\"t\":[\"Contemporarily, the widespread use of the internet leads people to be more relying on it as an information source for news or life tips. However, though the information we get can be reliable the majority of the time, it's still inevitable to have some rumors spreading across the internet. For instance, on Feb.7, an article published by the Washington Free Beacon claimed that \\\"Biden Admin To Fund Crack Pipe Distribution To Advance ‘Racial Equity \\\" [1] while the truth is quite opposite --- Biden didn't fund for crack pipes. How to have models to detect the truthfulness of these claims? Some studies have developed models on fact verification, but these models only give you the result of prediction and ignore the importance of providing reasons for that result. Nonetheless, we should not disregard the essentials of providing rationales for the fact verification result in order to convince audiences. Aim to solve this issue, the recent paper LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification [2] introduced the LOREN method that can predict the veracity of a claim while generating rationales for the result.\",\"In this article, I will introduce the model, LOREN, in three aspects:\",\"Explain the LOREN'S architecture.\",\"Analyze the performance of LOREN.\",\"Possible improvements and potentials of LOREN.\"]},\"66\":{\"h\":\"LOREN'S architecture\",\"t\":[\"Overall, LOREN's claim verification process is composed of these steps:\",\"It decomposes a natural language statement into different phrase units.\",\"For each phrase, LOREN generates a probing question and use it to retrieve relevant evidences, and then it establishes a local premise for that phrase.\",\"Given the probing questions, evidences, and local premises, LOREN uses a latent model to aggregate the veracity of each phrase using three-valued soft logic, and it finally calculates the probability of the claim being supportive (SUP), refuted (REF), or not enough information (NEI).\",\"The purpose of the first two steps is to look for the evidence that supports the phrase-level veracity, and by the means of soft logic, which I will introduce later in the article, we can verify the claim and provide reasoning behind it. Here is an example from the original paper that better illustrated the overall idea:\",\" Note that $c_1'$ in the above figure is supposed to be \\\"Joe Biden won the 2020 election\\\". This is the problem in evidence retrival part of LOREN, which I will address it later in the third session. \"]},\"67\":{\"h\":\"Decomposition of the claim\",\"t\":[\"The above figure shows an example how LOREN decomposes the claim into phrases. The idea behind the claim decomposition is straightforward: We extract verbs, adjective phrases, noun phrases, and name entities from the claim. To ensure the accuracy of the decomposition, LOREN leverage a part-of-speech (POS) tagger for identifying verbs and a constituency parser to identify noun phrases [2] as presented by step 1 in the above example. To decompose these noun phrases into fine-grained phrases, it further uses POS tagger and name entity recognizer to extract adjective phrases, name entities, and fine-grained noun phrases from the original noun phrases (Step 2).\"]},\"68\":{\"h\":\"Probing questions generation, evidences retrieval, and local premises construction\",\"t\":[\"Local premises are the collection of information to verify the veracity of each claim. [2] To construct local premises, we need probing questions and evidence as input. Regarding the probing questions, they consist of two sub-questions: one is the cloze question and another is the interrogative question. The cloze question is generated by masking out the phrase in the original claim and the interrogative question is generated by the off-the-shelf question generating model based on the T5 base. To better illustrate how LOREN generates probing questions, here is an example: For the phrase \\\"Smriti Mandhana\\\" in the claim \\\"Smriti Mandhana is an Indian woman\\\", the cloze question is \\\"[MASK] is an Indian woman\\\" and the iterrogative question is \\\"Who is an Indian woman\\\".\",\"For the evidence retrieval part, we will assume it's done by an off-the-shelf technique, whose evidence source is Wikipedia, because the primary focus of LOREN is the fact verification (This results in a drawback of LOREN's lack of common sense knowledge, which I will address it later in the article). With probing questions and evidence, LOREN adopted the generative machine reading comprehension(MRC) model as a sequence-to-sequence model [3]. MRC model is self-supervised and based on evidence given for each phrase, it will generate answers for that phrase by answering its corresponding probing questions. Then it will replace the original phrase in the claim with answers to generate our local premises.\"]},\"69\":{\"h\":\"Latent model construction\",\"t\":[\"Before we dive into the detail of latent model, let me introduce the logic constraints that LOREN developed for predicting claim veracity based on the veracity of each phrase.\",\"A claim is supportive(SUP) iff all phrases are supportive(SUP)\",\"A claim is refuted(REF) iff there's at least one phrase that is refuted(REF)\",\"A claim is non-enough-information(NEI) iff neither above.\",\"Following the above logic rules, loren further soften these rules into a probability distribution.\",\"qϕT​(yz​=SUP)=∑i=1∣z∣​qϕ​(z=SUP)\",\"qϕT​(yz​=REF)=1−∑i=1∣z∣​(1−qϕ​(z=SUP))\",\"qϕT​(yz​=NEI)=1−qϕT​(yz​=SUP)−qϕT​(yz​=REF)\",\"where\",\"y∈SUP,REF,NEI, which is the veracity of a claim.\",\"zi​∈SUP,REF,NEI, which is the latent variable represents the veracity of a phrase.\",\"yz​, which is the logic aggregation of the latent variable z, meaning that yz​ is a categorical distribution over three labels SUP,REF,NEI.\",\"The above aggregation of the soft logic serves to distill the knowldge to pθ​(y∣z,x) (Probability of the claim label given the phrase-level label and input x), which is the probability we eventually want to optimize.\"]},\"70\":{\"h\":\"Experiment\",\"t\":[\"The model is trained on BERT and RoBERTa, and eventually it is evaluated on the dataset FEVER 1.0 shared task that is split into training, development and blind test set. Before we analyze the experiment result, I will summarize the experiment metrics they used to evaluate the performance[2]:\"]},\"71\":{\"h\":\"Experiment metrics for the performance of the model:\",\"t\":[\"Label Accuracy (LA): The accuracy of predicted label for claim regardless of retrieved evidence.\",\"FEVER score (FEV): The accuracy of both predicted label and retrieved evidence.\",\"Let's look at the above overall performance of LOREN. We can see from the result that LOREN is either outperforming or comparable with other baseline method except for LisT5. This is mainly because the PLM for LisT5, which is T5, is larger than BERT and RoBERTa. However, LOREN still outperforms LisT5 on the FEVER score of the development set (dev). To summarize, the performance of LOREN is decent and it has the potential to achieve a better result.\",\"Here is a bar chart that can visualize LOREN's comparable test FEV score with other models:\",\"In addition, we will dive into the most important part of the experiment: a case study of the LOREN's interpretability. For claim one in the above figure, LOREN can detect which phrase is the culprit in the claim, and it's also providing the reasoning that why that phrase is causing the mistake, i.e., replacing the false phrase \\\"the number three\\\" with \\\"the number one\\\". In the third claim, LOREN shows its ability to detect multiple culprit phrases in the claim. However, for the second claim, the predicted result should be NEI. LOREN made this mistake mainly because of the evidence retrieval module and MRC module. First, the evidence retrieval module did not draw the correct evidence, and then the MRC module still replaced the original phrase even though there's no direct evidence given. Here's some examples that indicates a drawback of LOREN:\",\"For the phrase \\\"a tree\\\" in the claim, even though LOREN generates the correct local premise based on the evidence, it still considers the label of this phrase as supported. It is because LOREN does not possess commonsense knowledge, and we can see the probability of SUP and REF are very close, indicating that LOREN fails to distinguish \\\"tree\\\" and \\\"edible fruit produced\\\" as two completely different objects.\",\"Here's another interesting example of LOREN's output. For the claim \\\"Alaska was Russian territory long ago\\\", though LOREN found the correct evidence, but it predicted the claim as REFUTES. It is confusing because the United States purchased Alaska on 1867, and before that time, Alaska is Russian territory. How did LOREN make this mistake? LOREN even has the evidence:\\\"The Russian Empire was the first actively colonize the area beginning in the 18th century\\\". In here I guess the reason's that LOREN does not consider Russian Empire is the same as Russian in the context of the claim, so I make another experiment by replacing \\\"Russian\\\" to \\\"Russian Empire's\\\":\",\"The result illustrated that LOREN knows Alaska was the territory of the Russian Empire since 1867. The former claim verification failed because LOREN can only predict based on the current evidence retrieved. In the last claim, LOREN does not have the evidence showing Russia is Russian Empire, so it eventually believes the claim is false. However, as humans, we always consider the Russian empire as Russia because it's the history of that country. But for LOREN in this case, it does not know about how a country is related to its history without enough evidence. The main cause of this result is also the immaturity of evidence retrieval. In the next step, I will show the potential problems within LOREN's MRC mode.\",\"Here I provide a successful prediction outcome, and as we can see, LOREN's evidence retrival and MRC model work well in this prediction except that it fails to predict the first local premises to be refuted. However, when I change \\\"is\\\" to \\\"is not\\\", a more weird thing happens: LOREN's MRC model does not change the origin local premises in the last example:\",\"As we can see for the second phrase \\\"Mexico\\\", LOREN still replaces the phrase with \\\"the United States\\\" and even calculates a higher probability of refutes than supports. For now I'm not certain why LOREN behaves like this, but I have an assumption: LOREN's MRC model does not successfully interpret the claim. To be more specific, the prediction of the first phrase in these two examples are contradicting with each other, indicating that LOREN fails to interpret the difference between \\\"is\\\" and \\\"is not\\\", although its probability of supported and refuted are close to each other in the second example. Back to the local premises construction (MRC) for the second phrase, LOREN again fails to differentiate the meaning of \\\"is\\\" and \\\"is not\\\", so it has the same prediction for the veracity of second phrase as REF.\",\"Despite some issues in evidence retrieval and MRC, LOREN can verify most claims given Wikipedia as the knowledge source. The above claim \\\"Eminem is a rapper, but he also starred in a film\\\" is a typical example where LOREN grabs the correct evidence and successfully verifies the claim as SUP. We know that Eminem is an influential rapper in the US, but lots of people do not know he is also an actor. In this case, for the phrase \\\"a film\\\" and \\\"starred\\\", LOREN retrieve the correct evidence, which is the first and third one. Then, LOREN's local premises construction for these two phrases also performs well: \\\"Eminem is a rapper, but he also starred in Funny People\\\" and \\\"Eminem is a rapper, but he also appeared in a film\\\", which results in the high probability of support. Eventually, LOREN considers this claim is SUP.\"]},\"72\":{\"h\":\"Future improvements\",\"t\":[\"Since LOREN primarily focused on fact verification, so the evidence retrieval module in the model is immature. For the evidence retrieval part, LOREN directly adopts the retrieved results of KGAT which relies on the entity linking: sentence ranking pipeline. In other words, LOREN searches the name entity on Wikipedia and selects related sentences (evidence) based on a neural sentence ranking. Since evidence retrieved from Wikipedia is rich in encyclopedic knowledge but poor in commonsense knowledge, LOREN is biased toward this knowledge. Thus, how to train LOREN to understand common sense knowledge is worth exploring in the future. On the other hand, LOREN does not possess the power to verify the first-order logic claims, such as \\\"All spiders are poisonous\\\" or \\\"There exists an apple that is not edible\\\". Since in this case, if the evidence does not directly imply the correctness of the claim, LOREN may not be able (and it's also computationally inefficient) to search for all spiders to check if there exist some spiders that are not poisonous.\"]},\"73\":{\"h\":\"Conclusion\",\"t\":[\"To verify the veracity of a claim, LOREN first computes the probability of the veracity of each phrase in the claim, and with the soft logics, it further aggregates the corresponding probabilities to predict the correctness of the claim. This method does well in verifying correctness of a claim and providing the related rationales.\"]},\"74\":{\"h\":\"References\",\"t\":[\"[1] Patrick Hauf \\\"Biden Admin To Fund Crack Pipe Distribution To Advance ‘Racial Equity’\\\" the Washington Free Beacon, 2022.\",\"[2] Jiangjie Chen, Qiaoben Bao, Changzhi Sun, Xinbo Zhang, Jiaze Chen, Hao Zhou, Yanghua Xiao, and Lei Li.\\n\\\"LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification\\\", AAAI, 2022\"]},\"75\":{\"c\":[\"NLP\"]},\"76\":{\"c\":[\"Fact Verafication\",\"Reasoning\",\"Logic-regularized neural network\"]},\"77\":{\"h\":\"What is the problem with BERT embeddings and how to fix them?\",\"t\":[\"This blog presents an easy fix to the sentence embeddings learned by pre-trained language models. It is based on the paper: On the Sentence Embeddings from Pre-trained Language Models by Li et al EMNLP 2020.\",\"Paper: https://arxiv.org/abs/2011.05864 Code: https://github.com/bohanli/BERT-flow\"]},\"78\":{\"h\":\"Background\",\"t\":[\"Recently, pre-trained language models and its variants like BERT have been widely used as representations of natural language.\",\"Photo credit to https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/\",\"Despite their great success on many NLP tasks through fine-tuning, the sentence embeddings from BERT without finetuning are significantly inferior in terms of semantic textual similarity (Reimers and Gurevych, 2019) – for example, they even underperform the GloVe embeddings which are not contextualized and trained with a much simpler model. Such issues hinder applying BERT sentence embeddings directly to many real-world scenarios where collecting labeled data is highlycosting or even intractable.\"]},\"79\":{\"h\":\"Major Questions\",\"t\":[\"In this paper, we aim to answer two major questions:\",\"(1) why do the BERT-induced sentence embeddings perform poorly to retrieve semantically similar sentences? Do they carry too little semantic information, or just because the semantic meanings in these embeddings are not exploited properly?\",\"(2) If the BERT embeddings capture enough semantic information that is hard to be directly utilized, how can we make it easier without external supervision?\"]},\"80\":{\"h\":\"Our Findings\",\"t\":[\"We argue that the semantic information in the BERT embeddings is not fully exploited. We first reveal the theoretical connection between the masked language model pre-training objective and the semantic similarity task theoretically, and then analyze the BERT sentence embeddings empirically. We find that BERT always induces a non-smooth anisotropic semantic space of sentences, which harms its performance of semantic similarity.\"]},\"81\":{\"h\":\"The Anisotropic Embedding Space of BERT\",\"t\":[\"Gao et al. (2019) and Wang et al. (2020) have pointed out that, for language modeling, the maximum likelihood training with Equation 1 usually produces an anisotropic word embedding space. “Anisotropic” means word embeddings occupy a narrow cone in the vector space. This phenomenon is also observed in the pretrained Transformers like BERT, GPT-2, etc (Ethayarajh, 2019).\",\"Tips\",\"The BERT word embedding space. The 2D-scatterplot is achieved via SVD-based dimension reduction. The embeddings are colored according to their associated word frequency.\"]},\"82\":{\"h\":\"Word Frequency Biases the Embedding Space\",\"t\":[\"However, as discussed by Gao et al. (2019), anisotropy is highly relevant to the imbalance of word frequency. We observe that high-frequency words are all close to the origin, while low-frequency words are far away from the origin.\",\"This phenomenon can be explained through the softmax formulation of (masked) language models. Note that there is a word-frequency term in the decomposition of the dot product between context and word embeddings. Nevertheless, the PMI term is still highly associated with semantic similarity.\",\"Remark\",\"We expect the embedding induced similarity to be consistent to semantic similarity. If embeddings are distributed in different regions according to frequency statistics, the induced similarity is not useful any more.\"]},\"83\":{\"h\":\"Low-Frequency Words Disperse Sparsely\",\"t\":[\"We also observe that, in the learned anisotropic embedding space, high-frequency words concentrates densely to their k-nearest neighbors and low-frequency words disperse sparsely.\",\"Remark\",\"Due to the sparsity, many “holes” could be formed around the low-frequency words in the embedding space, where the semantic meaning can be poorly defined.\"]},\"84\":{\"h\":\"Proposed Method: BERT-flow\",\"t\":[\"To address these issues, we propose to transform the anisotropic sentence embedding distribution to a smooth and isotropic Gaussian distribution through normalizing flows that are learned with an unsupervised objective.\",\"A standard Gaussian latent space may have favorable properties which can help with our problem.\",\"First, standard Gaussian satisfies isotropy. By fitting a mapping to an isotropic distribution, the singular spectrum of the embedding space can be flattened. In this way, the word frequency-related singular directions, which are the dominating ones, can be suppressed.\",\"Second, the probabilistic density of Gaussian is well defined over the entire real space. This means there are no “hole” areas, which are poorly defined in terms of probability. The helpfulness of Gaussian prior for mitigating the “hole” problem has been widely observed in existing literature of deep latent variable models (e.g., variational auto-encoders).\"]},\"85\":{\"h\":\"Experiments\",\"t\":[\"Experimental results show that our proposed BERT-flow method obtains significant performance gains over the state-of-the-art sentence embeddings on a variety of semantic textual similarity tasks.\"]},\"86\":{\"h\":\"Results w/o NLI Supervision\",\"t\":[\"We perform extensive experiments on 7 standard semantic textual similarity benchmarks without using any downstream supervision. Our empirical results demonstrate that the flow transformation is able to consistently improve BERT by up to 12.70 points with an average of 8.16 points in terms of Spearman correlation between cosine embedding similarity and human annotated similarity.\"]},\"87\":{\"h\":\"Results w/ NLI Supervision\",\"t\":[\"When combined with external supervision from NLI tasks, our method outperforms the sentence-BERT embeddings (Reimers and Gurevych, 2019), leading to new state-of-theart performance.\"]},\"88\":{\"h\":\"Conclusion\",\"t\":[\"We investigate the deficiency of the BERT sentence embeddings on semantic textual similarity. We propose a flow-based calibration which can effectively improve the performance. BERT-flow obtains significant performance gains over the SoTA sentence embeddings on a variety of semantic textual similarity tasks.\"]},\"89\":{\"h\":\"Reference\",\"t\":[\"Bohan Li, Hao Zhou, Junxian He, Mingxuan Wang, Yiming Yang, Lei Li. On the Sentence Embeddings from Pre-trained Language Models. EMNLP 2020.\",\"Nils Reimers and Iryna Gurevych. 2019. SentenceBERT: Sentence embeddings using siamese BERT networks. In Proceedings of EMNLP-IJCNLP.\",\"Jun Gao, Di He, Xu Tan, Tao Qin, Liwei Wang, and TieYan Liu. 2019. Representation degeneration problem in training natural language generation models. In Proceedings of ICLR.\",\"Lingxiao Wang, Jing Huang, Kevin Huang, Ziniu Hu, Guangtao Wang, and Quanquan Gu. 2020. Improving neural language generation with spectrum control. In Proceedings of ICLR.\",\"Kawin Ethayarajh. 2019. How contextual are contextualized word representations? comparing the geometry of bert, elmo, and gpt-2 embeddings. In Proceedings of EMNLP-IJCNLP.\"]},\"90\":{\"c\":[\"NLP\"]},\"91\":{\"c\":[\"Pre-training\",\"BERT\",\"Embedding\"]},\"92\":{\"h\":\"Learning Shared Semantic Space for Speech-to-Text Translation\",\"t\":[\"How to develop a translation model that can take both speech and text as input and translate to target language? Can we borrow inspiration from human brain study to improve the speech translation models?\",\"Reading Time: About 15 minutes.\",\"Paper：https://arxiv.org/pdf/2105.03095.pdf\",\"Github: https://github.com/Glaciohound/Chimera-ST\"]},\"93\":{\"h\":\"Introduction\",\"t\":[\"Although it seems difficult for normal people to acquire more than two languages, according to the Wikipedia there are many polyglots who can speak tens of languages. For example, Ziad Fazah, speaking a total of 59 world languages, is believed to be the world’s greatest living polyglot. However, compared with others in the history his record does not stand out. It was recorded that Cardinal Giuseppe Caspar Mezzofanti, who was born in 1774, could speak 38 languages and 40 dialects. Meanwhile, the 10th-century Muslim polymath Al-Farabi was claimed to know 70 languages. The German Hans Conon von der Gabelentz, born in 1807, researched and published books about grammars for 80 languages. The highest record probably belongs to Sir John Bowring, Governor of Hong Kong from 1854 to 1859, who was said to know 200 languages, and capable of speaking 100. But it turns out extremely difficult for machine to learn natural languages like humans, in particular, despite its huge potential applications, speech translation has always been a challenge for machine. One common advantage is that those polyglots all benefit from not only text, but also audio corpus. However, how to utilize both audio and text information to help machine speech translation has not been fully exploited. The challenge comes from the intrinsic difference of modality between audio and text.\",\"A recent work Chimera from ByteDance AI Lab and UIUC aims to draw strengths from both modalities for speech translation [1]. Their key idea is to represent text and audio inputs differently, then fuse them together by projecting audio and text features into a common semantic representation to boost the ST performance.\",\"There are two main advantages for including audio and text data together for training one ST model. First, humans learn languages simultaneously from audio, text and videos rather than pure text. Inspired by this observation, it is believed that text knowledge can provide additional insights for ST. Second, since MT corpus is much larger compared with small corpus of ST, which is also expensive to create, incorporating MT text provides much fruitful training data and is expected to yield improvements on ST when bridging the modality gap properly.\",\"Taking those benefits into consideration, the Chimera model showed significant improvements by unifying MT and ST tasks on the benchmark ST datasets containing more than ten languages pairs.\",\"Unlike previous translation models, Chimera has established a successful paradigm of bridging the modality gap between text and audio for speech translation. This is similar to multi-modality MT, in which images can improve the text translation quality. Considering the pixel level information in images is accurately described, the audio is even noisier and leads to more challenges.\",\"Chimera is designed for an end-to-end speech-to-text translation task. It has two advantages. First, the translation quality can be consistently improved by leveraging a large amount of external machine translation data. In rich-resource directions, such as the largest speech translation dataset MuST-C, which already contains translations from English to eight languages with each pair consisting of at least 385 hours of audio recordings, Chimera can still significantly improve the quality, reaching a new State-Of-The-Art(SOTA) BLEU score on all language pairs. In low-resource directions, such as LibriSpeech dataset containing only 100 hours of training data, Chimera also performs surprisingly well and consistently outperforms the previous best results. Finally, they verified the common knowledge conveyed between these audio and text tasks indeed comes from the shared semantic space and thus paves a new way for augmenting training resources across modalities.\",\"Chimera can be thought of as a multimodal in the field of speech translation in general. When you need to develop a speech translation model but don't have enough audio data, you may consider using Chimera, and it can turn out to be better than your expectation! The research data, codes and resources are also kindly published by the authors.\",\"Next, we will introduce and analyze Chimera from three aspects: 1) the challenges of bridging the gap between audio and text for speech translation; 2) the motivation and methods of Chimera; 3) the performance and analysis of Chimera.\"]},\"94\":{\"h\":\"Challenges in speech translation\",\"t\":[\"The current paradigm of artificial intelligence highly depends on training on a large dataset, and thus make predictions on a small test set. However, different modalities of data have been labeled for various tasks but seldom been utilized together due to the modality gap of data representations. For example, billions of parallel MT corpora have been ignored as additional training data for SP for a long time. At the meanwhile, the data of ST is always in the dearth due to the difficulty of collection and high cost. Looking at the relatively smaller amount of parallel data for ST compared with MT, it is natural to have the idea of combining them together. Unfortunately, although they both encode human languages, they are dissimilar in both coding attributes(pitch, volume, and intonation versus words, suffixes, and punctuation) and length(thousands of time frames versus tens of words). Therefore, it has always been a challenge to unify representations from audio and text. The recent evidence from functional neuroimaging identifies certain regions in brain that the processing stream for speech sounds and visual text correlates positively with the subjects' reading ability. This finding provides the intuition for developing a multi-modality converged representation of audio and text in language activities. But only little previous research explored this direction possibly due to the difficulties of modality fusion and marginal improvements. Surprisingly, Chimera establishes a new bridge to fill the modality gap between speech and text and can serve as a new foundation in this area.\",\"In the above figure[2], the color represents relative contribution of unimodal visual (green), unimodal auditory (red), and similar contribution of visual and auditory predictors (yellow) to explaining signal variance. The lateral and inferior occipital-temporal cortex were active by unimodal presentation of letters, while Heschl's gyrus (primary auditory cortex) and portions of the superotemporal cortex were activated by unimodal presentation of speech sounds. This neuroimaging evidence convinces the connection of audio and text in human brain, serving as theoretical foundation of modality fusion.\"]},\"95\":{\"h\":\"Motivation and Techniques of Chimera\",\"t\":[\"​For language learners, a very interesting phenomenon is that they learn better by audio and text together rather than text only. The aforementioned famous polyglots also stated that their success originated from various interactions with native speakers in other languages, such as listening, reading, and speaking. Nowadays, many people also learn new languages by watching movies, in which they will be immersed in audio and subtitles. In particular, the above figure is Ioannis Ikonomou, who was born in Greek and now works as translator for European Union. Ikonomou can speak 32 languages and could also translate those languages to each other in daily work. According to his interview, he was born in a famous tourism city, where people from all over tha world visit there every day. Under the influence of different tourists, he learned English at 5 years old, German at 7 years old, Italian at 10 years old, Russian at 13 years old, East African Swahili at the age of 14, and Turkish at the age of 16. He said \\\"Learning Polish can make Polish dumplings better. Learning Russian is to understand Dostoyevsky, Persian is to appreciate ancient Persian poetry, and Hungarian is to understand Hungarian folk songs. For German, it is to understand the veteran show \\\"Mirror of the World\\\" every Sunday evening.\\\"[3]. It is worthy to point that he learned most languages when he was still a child, demonstrating strong language ability of human children.\",\"The above figure shows the developmental milestones of human children learners. Children first learns how to speak from their family and thus how to speak fluently, read and write formally at school.\",\"All those evidence demonstrates that combining audio and text could help humans learn a new language. A natural next step is to apply this idea in speech machine translation.\",\"The design goal of Chimera is based on such considerations: design a general framework to learn the combination of audio and text from languages, and then it will benefit from this combined pre-training when migrating to the new speech translation direction. Just like language learners, after learning two modalities, the one modality becomes easier. The design of Chimera follows three basic principles: first, learn the shared semantic memory module to bridge the gap between the representation of audio and text; Second, the training objective of pre-training comes from three parts: 1) the speech-to-text translation training, 2) the text machine translation training, and 3) Bi-modal contrastive training; Third, train on external MT corpora and then apply the model in ST task.\"]},\"96\":{\"h\":\"Shared semantic memory\",\"t\":[\" Chimera follows a transformer based encoder-decoder framework and above is an overview. Word embedding for text input and the Wav2vec2[4] sub-module for speech input are both included in the Encoder Module. The shared semantic projection Module generates semantic memory with fixed-size representation from contextual features using its memory query. The Decoder Module decodes semantic memory translation.\",\"Since the encoder and decoder are actually standard modules based on transformer[5], which have been proven to be the SOTA design in many natural language processing tasks, the shared semantic memory module is the key to success of Chimera. So here we will mainly discuss the fantastic design of this shared module. Among this framework, the module relies heavily on shared semantic projection. In fact, contextual elements of speech and text can have a wide range of distributions and lengths. The shared semantic projection should, in theory, compute a fixed number of semantic features as output semantic memories. This module takes the contextual information extracted from the encoding module as input and outputs semantic memories with a set length of m. It is made up of n layers of attention. It stores a tuple of m trainable input-dependent memory queries as the initial \\\"memories\\\" to represent the categories of required semantic information. Attention \\\"keys\\\" and \\\"values\\\" are provided by unimodal contextual features, but attention \\\"queries\\\" are provided by memories. Memories are fed into the n shared semantic projection layers in an iterative fashion, with each layer's output being used as input to the next layer. The semantic memory is created from the final output.\"]},\"97\":{\"h\":\"Dataset and preprocessing\",\"t\":[\"Two datasets were used for conducting experiments to verify the effectiveness of Chimera. One is called MuST-C, the largest ST corpus, which contains translations from English(EN) to 8 languages: Dutch (NL), French (FR), German (DE), Italian (IT), Portuguese (PT), Romanian(RO), Russian (RU), and Spanish (ES). With each pair consisting of at least 385 hours of audio recordings. Another popular one is Augmented LibriSpeech Dataset (En-Fr), which is composed of aligned e-books in French and their human reading in English of 100 hours. They also incorporate data from WMT, OpenSubtitles and OPUS100 translation tasks as pretraining corpora.\",\"In practice, speech input, the 16-bit raw wave sequences are normalized by a factor of 215 to the range of [-1, 1), which uses the Wav2Vec2 Module following the base configuration in [4]. The shared Transformer encoder consists of 6 layers. The memory queries are 64 512- dimensional vectors. The parameters of shared semantic projection resemble a 3-layer Transformer encoder. The Transformer decoder has 6 layers. Each of these Transformer layers, except for those in the Wav2Vec2 module, has an embedding dimension of 512, a hidden dimension of 512, and 8 attention heads.\",\"Chimera contains around 165M parameters. The whole training process for one trial on 8 Nvidia Tesla-V100 GPUs generally takes 20 –40 hours according to the translation direction.\"]},\"98\":{\"h\":\"Effectiveness of Chimera\",\"t\":[\"In summary, Chimera has the following advantages:\",\"New state-of-the-art performance on all language pairs\",\"Even though they did not use Google Translate results on Augmented Librispeech as most baselines, Chimera obtains state-of-the-art performance on all language pairs. Chimera's EN-DE results use WMT14+OpenSubtitles for MT pretraining, whereas the original paper also contains a full ablation research on the effect of MT data. It's worth noting that the improvement in EN-PT isn't as dramatic as it is in EN-DE and EN-FR. This is due to a mismatch in data between OPUS100 and MuST-C. OPUS100 has a high amount of sentences from movie subtitles, which are more informal, feature repeated lines, and address issues that are not covered in MuST-C public speeches.\",\"Successfully share knowledge across tasks\",\"Additional trial findings corroborate their design of auxiliary tasks by demonstrating its ability to acquire a well-structured shared semantic space as well as successfully exchange learned knowledge between MT and ST.\",\"Here are some representative experimental results:\"]},\"99\":{\"h\":\"1. Benchmark Experiments\",\"t\":[\"The below two tables demonstrate the main results on tst-COMMON subset on all 8 languages in MuST-C dataset amd on LibriSpeech English-French dataset.\",\"Table 1: Main results on tst-COMMON subset on all 8 languages in MuST-C dataset.\",\"Table 2: Results on LibriSpeech English-French dataset.\"]},\"100\":{\"h\":\"2. Visualizations\",\"t\":[\"Regardless of the input modality, the shared semantic projection is designed to extract only the semantic categories of information required for decoding. To validate this hypothesis, a 2-dimensional PCA projection was performed in the semantic memories across different samples.\",\"In the above figure, each colored cluster (circled out) represents a semantic memory element. A '.' corresponds to a speech semantic memory, and a “+” marks a text one. It is obvious that semantic memories are strongly clustered, with each individual learning a specific region. The model's capacity to overlook representation disparities and bridge the modality gap is demonstrated by the close distance of speech and text representations inside the same region.\",\"One randomly selected semantic memory subspace was analyzed by PCA to its related cluster to get a better look at the structure of each semantic memory subspace.\",\"The above figure is the visualization of one specific semantic memory with no different samples or modalities. \\\"+\\\" denotes text representations, while \\\".\\\" denotes speech representations. Marks of the same color are linked by dashed lines and come from the same speech-transcript pair. Some speech-transcript pairs have been circled and their transcripts have been annotated. Three different fonts denote three different sets of transcripts with similar patterns. As can be seen from the circles, the matched speech and transcript inputs are indeed close to each other. Such results provide strong evidence of the efficacy of the semantic memory module, especially when considering audio and text represent different modalities.\"]},\"101\":{\"h\":\"Summary\",\"t\":[\"Going back to the polyglots, who successfully learn new languages through various kinds of interactions with the environments such as speaking, reading and writing, Chimera makes one important step towards drawing strength from text machine translation to advance speech translation. In general, Chimera unites MT and ST tasks by projecting audio and text data to a shared semantic representation, boosting performance on ST benchmarks MuST-C and Augmented Librispeech to a new state-of-the-art. Further visualizations show that the shared semantic space does indeed convey common knowledge between these two tasks, paving the path for novel ways to supplement training materials across modalities.\",\"In the future, we are looking forward to more advanced techniques to solve two additional problems: 1) how to tightly align speech and text representations and 2) how to make the workflows of MT and ST fully shared. Since ST is an exciting new area, there are a lot of interesting research and progress almost every week. In the near future, we believe a beautiful new world, where the real time speech translation comes true and the language barriers among countries and nations are broken, is waiting fo us.\"]},\"102\":{\"h\":\"References\",\"t\":[\"[1] Han, Chi, Mingxuan Wang, Heng Ji, and Lei Li. \\\"Learning Shared Semantic Space for Speech-to-Text Translation.\\\" ACL 2021.\",\"[2] Van Atteveldt, Nienke, Elia Formisano, Rainer Goebel, and Leo Blomert. \\\"Integration of letters and speech sounds in the human brain.\\\" Neuron 43, no. 2 (2004): 271-282.\",\"[3] https://en.wikipedia.org/wiki/Ioannis_Ikonomou\",\"[4] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020. wav2vec 2.0: A framework for self-supervised learning of speech representations. In Advances in Neural Information Processing Systems, volume 33, pages 12449–12460. Curran Associates, Inc.\",\"[5] Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. \\\"Attention is all you need.\\\" In Advances in neural information processing systems, pp. 5998-6008. 2017.\"]},\"103\":{\"c\":[\"ST\",\"DL4MT\"]},\"104\":{\"c\":[\"Speech Translation\",\"Shared Semantic Memory\",\"Chimera\"]},\"105\":{\"h\":\"Automatic Machine Translation Evaluation - COMET Explained\",\"t\":[\"While the advance in deep learning has dramatically improved the machine translation quality, there is little development in the evaluation of machine translation models. The most widely-used metrics like BLEU [Papineni et al., 2002] and METEOR [Lavie and Denkowski, 2009] simply match the n-gram between the hypothesis text and reference text, which is too rigid without considering the variance in ground-truth translations and fail to differentiate the current highest performance machine translation models. They also cannot be accurately correlated with human judgment for a piece of text.\",\"Recently, model-based evaluation metrics have been proposed. Some matrics like METEOR-VECTOR [Servan et al., 2016], BLEU2VEC [T¨attar and Fishel, 2017], YISI-1 [Lo, 2019], MOVERSCORE [Zhao et al., 2019], and BERTSCORE [Zhang et al., 2020] are based on the pre-trained word embeddings like word2vec and BERT, to capture the semantic level similarity between hypotheses and references. Others like BLEURT [Sellam et al., 2020] aim to directly optimize the correlation with human judgment by training a machine learning model to learn the appropriate metric. There is also another kind of evaluation metrics called Quality Estimation that does not require reference text. COMET is built upon this category of metrics.\",\"COMET predict human evaluation based on a cross-lingual pre-trained language model (e.g. multilingual BERT [Devlin et al., 2019], XLM [Conneau and Lample, 2019] or XLM-RoBERTa [Conneau et al., 2019]) to make use of both the reference and source sentences. Authors propose two different architectures for COMET: The Estimator model which directly regresses the human evaluation score (e.g. DA, MQM, and HTER), and the Translation Ranking model which is trained to rank the hypotheses according to human evaluation.\",\"First, they produce a sentence embedding using the pre-trained language model. For Estimator model, they aggregate the embeddings of the source sentence, hypothesis sentence, and reference sentence together the regress using a feed-forward layer. For Translation Ranking model, they pair two hypotheses per source/reference, such that one reference ranks higher than the other in terms of human evaluation. Then they apply the triplet margin loss to both the source-hypothesis triplet and the reference-hypothesis triplet and add them together. The results show that the Translation Ranking model performs better than the Estimator model and many state-of-the-art baseline metrics in terms of consistency with human evaluation.\",\"Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.\",\"Alon Lavie and Michael Denkowski. 2009. The meteor metric for automatic evaluation of machine translation. Machine Translation, 23:105–115.\",\"Christophe Servan, Alexandre B´erard, Zied Elloumi, Herv´e Blanchon, and Laurent Besacier. 2016. Word2Vec vs DBnary: Augmenting METEOR using vector representations or lexical resources? In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 1159–1168, Osaka, Japan. The COLING 2016 Organizing Committee. \",\"Andre T¨attar and Mark Fishel. 2017. bleu2vec: the painfully familiar metric on continuous vector space steroids. In Proceedings of the Second Conference on Machine Translation, pages 619–622, Copenhagen, Denmark. Association for Computational Linguistics.\",\"Chi-kiu Lo. 2019. YiSi - a unified semantic MT quality evaluation and estimation metric for languages with different levels of available resources. In Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1), pages 507–513, Florence, Italy. Association for Computational Linguistics.\",\"Wei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Christian M. Meyer, and Steffen Eger. 2019. MoverScore: Text generation evaluating with contextualized embeddings and earth mover distance. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 563–578\",\"Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations.\",\"Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. BLEURT: Learning robust metrics for text generation. In Proceedings ofthe 58th Annual Meeting ofthe Association for Computational Linguistics, pages 7881–7892, Online. Association for Computational Linguistics.\"]},\"106\":{\"c\":[\"MT\",\"DL4MT\"]},\"107\":{\"c\":[\"MT Evaluation\",\"Pre-training\"]},\"108\":{\"h\":\"Contextual Parameter Generation for Universal Neural Machine Translation\"},\"109\":{\"h\":\"Introduction\",\"t\":[\"A typical neural machine translation (NMT) system needs to support the translation among various languages, that is, a multilingual(many-to-many) NMT system rather than only support the translation between two languages. However, to support the multilingual translation is still a challenge. One direct idea is to use a separate model to translation one language to another language, which is very easy to implement but brings high costs: To support the translation among N languages, we need train N(N-1)/2 separate models. Such a method does not allow the sharing of information across languages, which can result in overparameterization and sub-optimal in performance. We denote this method as per-language NMT\",\"Another method is called universal NMT, which use a single model for all language pairs. Compared to the previous method, it shares the parameters among all languages which can avoid overparameterization. However, the universal NMT lacks any language-specific parameterization, which makes it oversimplified. Also, since all languages use the same model, the vocabulary will be very large which makes it hard to scale. How to find a balance between per-language NMT and universal NMT to get a better solution to support the multilingual translation task is still a challenge.\",\"Here we make a quick comparison between different methods for the multilingual translation system. Assume that we need to support the translation among N languages.\",\"Model\",\"Model Num\",\"Information accross Language\",\"Language-specific Parameterization\",\"Others\",\"Per-language NMT\",\"N(N−1)/2\",\"False\",\"True\",\"Overparameterization\",\"Universal NMT\",\"1\",\"True\",\"False\",\"Oversimplification\",\"CPG NMT\",\"1\",\"True\",\"True\",\"-\",\"To solve this problem, this paper propose a very novel and neat idea: to design a universal neural machine translation. For all language pairs, the model is the same. But a parameter generator will generate bias to the parameters of the model according to the source language and target language. Since the bias is generated according to the type of the language pair, the generation process is called Contextual Parameter Generation (CPG). The method is not only effective in machine translation but can also be adapted to other fields, for example, domain adapatation. As a result, it is of great significance to read and discuss the method of this paper and the insight behind it.\"]},\"110\":{\"h\":\"Preliminary\",\"t\":[\"To make our demonstration clearer, we first make some basic denotations. Assume that we have a set of source languages S and a set of target language T, then the total number of langauge pairs will be ∣S∣∗∣T∣. We denote the total number of languages as L=∣S∪T∣. Assume we also have a set of C≤∣S∣∗∣T∣ pairwise paralleled corpora {P1​,…,PC​}, each of which contains a set of sentence pairs for a single source-target language conbination. The goal of multilingual NMT is to build a model that, when trained using the provided parallel corpora, can learn to translation well between any pair of languages in S×T.\",\"In this paper, the authors use a seq2seq model for the multilingual translation. We denote the paramter of the encoder, fenc​, as θenc​ and that of the decoder, fdec​, as θdec​. The encoder will encode the source sentences and produce an intermediate representation that can later be used by the decoder to generate sentences in the target language.\"]},\"111\":{\"h\":\"Core Idea: Contextual Parameter Generator\",\"t\":[\"Till now, all modules defined above is under the basic NMT framework and should be relatively easy to understand. In this part, we will introduce the core idea of this paper called parameter generator. For a overall description, we can denote the multilingual translation model proposed by this paper as:\",\"Vanilla Seq2seq architecture+Parameter Generator→Multilingual translation system\",\"This formular reflects that the proposed parameter generator is model-free, which means it can be combined with any other models(RNN-based, Transformer-based, etc.) and even other tasks. The basic idea can be describe as follows: Except the backbone model fenc​ and fdec​ with their parameter θenc​ and θdec​, we also have a new model, the parameter generator model G with parameter θG​, which will incluence the parameter of fenc​ and fdec​ according to the source and target language. Denote the source language as Ls​ and the target language as Lt​, we can express the idea as:\",\"θenc∗​=θenc∗​⊕G(Ls​),θdec∗​=θdec∗​⊕G(Lt​)\",\"where G will output the \\\"influence\\\" to the parameter of the encoder/decoder given the source/target language (for example, Chinese, English, German, etc.), and the ⊕ means the way we apply the \\\"influence\\\" to the parameters of the encoder/decoder.\",\"Now based on this, we can imagine how we utilize this idea to design a multilingual translation system. We use only one seq2seq model with the same paramters for all language pairs. Given a language pair, the parameter generator G will first generate the \\\"influence\\\" to the encoder and decoder and then modify their parameters to get θenc∗​ and θdec∗​. After that, we use the encoder/decoder with new parameters to conduct training or testing. Note that the gradient can be backpropagated to the seq2seq model and the parameter generator, thus updating the two models to conduct training.\"]},\"112\":{\"h\":\"Dive deeper: the design of CPG\",\"t\":[\"Now we ellaborate the detailed design of CPG. For the encoder side and decoder side, we have two separate paramter generators denoted as Genc​​ and Gdec​​. The parameter generator does not rely on the specific neural network architecture. For simplification, in this paper the authors define the generators with linear transforms. For each language, we initialize it with an embedding ls​​ and lt​​, where s​ and t​ refer to the encoder side and the decoder side. Then the parameter generation process can be represented as:\",\"θenc∗​=θenc∗​+Wenc​ls​\",\"θdec∗​=θdec∗​+Wdec​lt​\",\"where ls​,lt​∈RM,Wenc​∈RPenc​×M,Wdec​∈RPdec​timesM, M is the language embedding size, Penc​ is the number of paramters of the encoder, and Pdec​ is the number of parameters of the decoder.\",\"One problem of this method can be the number of the parameters of the dense layer (that is, the linear transformation of Wenc​​ and Wdec​​). For example, assume that the number of paramters of the encoder/decoder is 100M (The size of the pre-traiend BART-base model is 139M with 12-layer Transformer encoder/decoder). In this case, if the dimension of the language embedding is 128, the number of the parameters of encoder/decoder will be 12.8B respectively, which can cause a high memory and computational cost. As a result, similar to the trick in ALBERT[1/], the authors propose to use the following method:\",\"θenc​=Wenc​Penc​ls​\",\"where Wenc​∈RPenc​×M′,Penc​∈RM′×M​. By selecting M′​​ as a small value, we can lower down the parameter size of the parameter generator. We can find that to support a multilingual machine translation system, the CPG method uses much fewer parameters than the per-language method. Compared to the universal method, although introduce more parameters, the CPG method allows incorporated the language-specific information, thus bringing better performance.\"]},\"113\":{\"h\":\"Experiment and Performance\",\"t\":[\"In this section, we talk about the experiment performance of CPG on multilingual translation tasks. The authors use a two-layer LSTM encoder-decoder model with attention to train the MT model and test the performance on three settings: 1. Supervised: Use the full corpora to train the CPG model. During training, they first sample a language pair uniformly and then sample a batch of data for that language pair. The authors train two models: one which does not use auto-encoding of monolingual data during training(CPG∗) and one which does (CPG) 2. Low-resource. Low-resource setting is similar to the supervised setting, except that the size of the paralleled corpora is limited. Note that for CPG and GMT the full monolingual corpora is used for training. 3. Zero-shot. Under zero-shot setting, the goal is to evaluate how well a model can learn to translate between language pairs that is has not seen while training. For example, a model trained using the paralleled corpora English-German and English-French will be evaluated in translating between German and French. For the plain pairwise NMT models(PNMT), this can be achiveved by pivoting. That means, in the previous example, we would first translate from German to English and then translate from English to French. In comparison, the proposed CPG method in this paper support zero-shot learning inherently and requires no pivoting. For the datasets, the authors select IWSLT-15/17. Using a langauge embedding size of 8, the result on IWSLT-15 dataset is shown below: \",\"The performance is quite impressive, especially considing the result of CPG is achieved with only one model with much less paramters. It consistently outperforms the baselines in all settings including supervised and low-resource. Another experiment is on IWSLT-17 dataset. On this dataset, the authors also conduct ablation study on the language embedding size M and M′. We can find that except M′=1, all the CPG models outperforms the baselines. \"]},\"114\":{\"h\":\"Language embeddings\",\"t\":[\"Since the CPG model learns the language embeddings during training, we can explore them to find if the model captures the relations among languages. The figure below shows the result. There are some interesting patterns that indicate that the learned language embeddings are reasonable. For example, German(De) and Dutch (Nl) are most similar on the IWSLT-17 dataseta and Italian(It) and Romanian (Ro) coming second. The authors claim that these relationships agree with linguistic knowledge about these languages and the families they belong to. The embedding similarity can also help discover relationships between languages that were previously unknown. For example, on IWLST-15 dataset, French (Fr) is significantly similar to Vietnamese (Vi), which may caused by the occupation of Vietnam by France during the 19th to 20th centuries. \"]},\"115\":{\"h\":\"Summary\",\"t\":[\"In this blog, we introduce the basic idea of CPG-based multilingual machine translation model as well as its impressive performance. What's more, such an idea can not only be applied to machine translation but can also be used in other domains. It is very meaningful to put this work to public, which can improve the performance of machine learning models and help promote the low-carbon action since it reduce the parameters of the model and the training cost. We are very excited to incorporate it into our current research to improve the performance of zero-shot learning performance on other tasks.\"]},\"116\":{\"h\":\"Reference\",\"t\":[\"[1]Lan Z, Chen M, Goodman S, et al. Albert: A lite bert for self-supervised learning of language representations[J]. arXiv preprint arXiv:1909.11942, 2019.\\n[2] Emmanouil Antonios Platanios, Mrinmaya Sachan, Graham Neubig, Tom Mitchell. Contextual Parameter Generation for Universal Neural Machine Translation. EMNLP 2018.\"]},\"117\":{\"c\":[\"MT\",\"DL4MT\"]},\"118\":{\"c\":[\"Multilingual MT\"]},\"119\":{\"h\":\"Generative Pre-trained Transformer (GPT)\",\"t\":[\"In the past couple years, we have seen the rise of Transformer architectures in Natural Language Processing. Transformers revolutionized the speed and accuracy of machine translation systems, and alleviated the need for Recurrent Neural Networks and LSTMs to derive context and meaning for sequence to sequence modeling. Since the Attention Is All You Need paper was published in 2017, there have been many experimental application and fine-tuning improvements made upon the original model. The latest such improvement is the Generative Pre-Trained Transformer 3, or GPT-3.\",\"GPT-3 is the third generation of the autoregressive language modeling GPT-n series created by OpenAI. Its architecture is exactly the same as the previous generation, GPT-2, with the exception of using alternating dense and locally banded sparce attention patterns. For this generation, OpenAI trained 8 different models with a variable number of parameters, layers, dimensions, learning rates, and batch sizes. Furthermore, unlike the GPT-2 which was trained on the WebText dataset, GPT-3 was trained on Common Crawl, which consists of nearly a trillion words. However, because this dataset is so large and unfiltered, various techniques had to be used to prevent overfitting the model and data contaimination.\"]},\"120\":{\"h\":\"Novelty\",\"t\":[\"Aside from the changes made above to the new model, the novelty of GPT-3 stems from its ability to use one-shot and few-shot demonstrations — it is not limited to zero-shot like GPT-2. To be more specific, this means that before actually testing GPT-3 on a specific task, the model can take a certain amount of examples K of the desired task as a form of conditioning before letting the model perform testing and inference on its own. For one-shot demonstrations, K is 1, and for few-shot demonstrations, K can be anywhere between 10 and 100 demonstrations of the task. This may sounds similar to fine-tuning a model, but there is one key difference: for these n-shot demonstrations, the model is NOT allowed to update its weights whereas for fine-tuning, the model is supposed to update its weights. This novel approach of providing demonstrations before actual testing was specifically chosen because it best simulates human learning and behavior. Typically, when people are told to complete a task, they are usually offered one or more examples before having to attempt the task on their own. The table below illustrates the advantages and disadvantages of each of the different types of n-shots for GPT-3.\",\"Type\",\"Advantages\",\"Disadvantages\",\"Fine Tuning\",\"Strong performance on a specific task\",\"The need for an new, large dataset for the specific task\",\"Few-Shot\",\"Major reduction in the need for task specific data and examples\",\"Potential for much worse performance than state-of-the-art fine tuned models\",\"One-Shot\",\"Most closely related to the way tasks are communicated to humans\",\"Performs worse than Few-Shot\",\"Zero-Shot\",\"Most convenient and no need for additional data\",\"Most challenging setting, humans cannot even perform some tasks without examples\"]},\"121\":{\"h\":\"Evaluation on Various Tasks\",\"t\":[\"With these new types of testing and inference methods, GPT-3 was evaluated on a variety of NLP tasks that include text translation, generation, prediction, and comprehension. This fact alone — that one single model is able to be evaluated on a range of tasks — shows how powerful and exciting GPT-3 is. Prior to GTP-3, models had to be explicitly trained to do a specific task. In the following subsections, when describing the evaluations and accuracy for the different use cases, you will see that GPT-3 is powerful enough to match or even outperform some state-of-the-art models for NLP tasks.\"]},\"122\":{\"h\":\"Translation\",\"t\":[\"One of the tasks GPT-3 was tested on was its ability to perform sequence to sequence translation. The Common Crawl dataset OpenAI used to train their model contained English words 93% of the time and words from foreign languages 7% of the time. The words from the foreign natural languages were seamlessly blended together with the English text on a word, sentence, and document level. This allowed for the model to extract meaning and context from the foreign words, and be able to accurately translate them when asked to do so. From this translation test, GPT-3 resulted in a similar BLEU score compared to prior unsupervised NMT work. While zero-shot underperformed compared to prior works, one-shot improved the BLEU score by 4 and few-shot improved the BLEU score by 11. BLEU score improvement was especially noticed when translating phrases into English as opposed to translating sentence from English. In fact, some translations from English even outperform the best supervised results. The table and graph below shows the comparison of BLEU scores for each of the different n-shots and other NMT models, and how BLEU score changes with model size.\"]},\"123\":{\"h\":\"Word Prediction and Text Generation\",\"t\":[\"Another task GPT-3 was tested on was predicting the next word given a few sentences or a passage. A demonstration along the lines of Alice was friends with Bob. Alice went to visit her friend __. → Bob was given to the model as an example along with a task description. From examples like these, the largest GPT-3 model (with 175 billion parameters) outperformed the current state-of-the-art model by 20%, predicting the next word correctly 86.4% of the time. Even if a model was trained on this specific task and outperformed a state-of-the-art model by 20%, it would still be extraordinary.\",\"Another simliar test using GPT-3 was news article generation. The model was given a number of news articles written by humans as conditioning, and asked to generate a news article itself. Because this task is difficult to measure quantitatively, they measured the performance of the task based on whether or not a human could distinguish GPT-3 generated articles from human written one. As expected, as the size of the model increased, the ability for humans to distinguish the difference between a generated article and a human written one decreased. Astoundingly though, the mean human accuracy for detecting generated articles for the largest GPT-3 model was just slightly above chance at 52%.\"]},\"124\":{\"h\":\"Comprehension\",\"t\":[\"One of the most extensive tasks GPT-3 was trained on was its ability to comprehend and extract meaning from text. This was tested in a varitey of ways including utilizing new words, answering questions based on prompts and facts, and general reasoning.\",\"To evaluate the model's ability to utilize new words, the OpenAI team came up with some made up words and provided its definition to the model. From this information, the model was tasked to use the word in a sentence. Since there is no quantitative metric to measure how well a made-up word is used in a sentence, they again used a qualitative human evaluation. In most cases, the GPT-3 generated sentences that included the made-up word seemed to be proficient at using the novel word correctly. A similar test with a quantitative metric had to do with recognizing novel patterns by using SAT analogies. The model was provided SAT style analogy questions and tasked to determine which pair of words in the answer choices had the same relationship as the words in the question. In this task, GPT-3 was correct 65.2% of the time in the few-shot setting. While this may not seem too accurate, take into account that the average college applicant was correct only 57% of the time.\",\"Another comprehension task GPT-3 was tested on was knowledge-based question answering. The model was given the PhysicalQA dataset which contains a set of common sense questions about how the world works. In this experiment, GPT-3 achieved an accuracy of 82.8% in the few-shot setting on the easy questions. Compared to a previous fine-tuned state-of-the-art model RoBERTa, GPT-3's accuracy was 3.4% higher, again showcasing its ability to outperform fine-tuned models.\",\"The last comprehension test I wanted to mention had to do with relationships between sentences and pronoun references. GPT-3 was tested to see if it could determine which subject a pronoun was referring to. This Winograd Style task is a baseline task in natural language processing, where pronoun references are very clear to humans but ambiguous in grammatical context. Fine-tuned models designed for this task achieve almost perfect accuracy now, but GPT-3 still only falls a few points below state-of-the-art models at 88.6%. A similar task has to do with natural language inference between two sentences. Here, the model was tested to understand the relationship between two sentences. Usually, this involves determining whether or not a sentence can logically follow a given sentence. This task was evaluated on SuperGLUE's RTE dataset, where GPT-3's accuracy performed just slightly above random at 56%. I mention this test to show that while GPT-3 is a very powerful model, it cannot be generalized to every aspect of natural language processing.\"]},\"125\":{\"h\":\"Case Study\",\"t\":[\"As an experiment, I decided to test the BLEU score when translating a few phrases from Slovak, my native language, into English. Since Slovak isn't a particularly highly studied language in terms of machine translation, I thought it would be interesting to see if GPT-3 could accurately translate Slovak into English. In order to test this, I came up with a set of phrases in Slovak and their respective translations into English using Google Translate. From this set of translations, I took the Slovak phrases, fed them through the GPT-3 model completion task with a few-shot prompt, and did a BLEU score evaluation from the output of the GPT-3 model and the Google Translate reference text. One of the things I noticed throughout this experiment was that the model sometimes generates different translated sentences for the same input. Nevertheless, the BLEU score still hovers around the same values. The prompt and results are shown below. The average BLEU score between GPT-3's translation and Google Translate for the ten translations was 0.7196.\",\"Case Study Code\",\"Prompt: Slovak: Dobré ráno!\",\"English: Good morning!\",\"Slovak: Ako sa máš?\",\"English: How are you?\",\"Slovak: Odkiaľ si?\",\"English: Where are you from?\",\"Slovak:\",\"Slovak (Input)\",\"Reference (Google Translate)\",\"Candidate (GPT-3)\",\"BLEU Score\",\"Dnes si môžeme ísť kúpiť oblečenie do nákupného centra, ale nebudeme sa tam môcť najesť\",\"Today we can go to the mall to buy clothes, but we will not be able to eat there\",\"Today we can go to the mall to buy clothes, but we cannot eat there\",\"0.6313\",\"O druhej poobede budem doma na obed\",\"I will be home for lunch at two in the afternoon\",\"I'll be home for lunch at 2 o'clock\",\"0.3553\",\"Môžete mi poslať e-mail s dátumom a časom stretnutia?\",\"Can you send me an email with the date and time of the meeting?\",\"Can you send me an email with the date and time of our meeting?\",\"0.8555\",\"Keď sa skončí hokej, mali by sme ísť hrať hokej\",\"When hockey is over, we should go play hockey\",\"When hockey ends we should go play hockey\",\"0.5247\",\"Kúpim chladničku za sto dolárov\",\"I'll buy a refrigerator for a hundred dollars\",\"I want to buy a refrigerator for $100\",\"0.3457\",\"Musím sa učiť na test z biológie\",\"I have to study for a biology test\",\"I have to study for a biology test\",\"1.0\",\"Poďme do parku a zahrajme si futbal\",\"Let's go to the park and play football\",\"Let's go to the park and play football\",\"1.0\",\"Môžeme mať na večeru kuracie mäso?\",\"Can we have chicken for dinner?\",\"Can we have chicken for dinner?\",\"1.0\",\"Tento víkend som išiel do domu svojich priateľov a hral videohry\",\"This weekend I went to my friends' house and played video games\",\"This weekend I went to my friends' house and played video games\",\"1.0\",\"Veľmi sa teším, keď ich zajtra uvidím hrať na koncerte\",\"I'm very happy to see them play at the concert tomorrow\",\"I'm very looking forward to seeing them play at the concert tomorrow\",\"0.4833\"]},\"126\":{\"h\":\"Conclusion\",\"t\":[\"From this blog, we see that GPT-3 is extremely powerful and can perform better on some NLP tasks than even the state-of-the-art fine-tuned models. GPT-3 is not trained to do anything specific task; rather, it is pretrained on a massive dataset consisting of over a trillion words. When used for a specific task, the model is able to take zero, one, or a few demonstrations of the task depending on the type of experiment you want to conduct. This is ultimately what gives it the flexiblity to be applied to a variety of different domains within NLP.\",\"For language translation specifically, it achieved BLEU scores slightly below that of some supervised NMT models. This is incredible, given it is not fine-tuned or trained for machine tranlation. When increasing from zero-shot to one-shot to few-shot, GPT-3 performed significantly better and better in translating between languages. It performed best when translating to English because the CommonCrawl dataset used to train GPT-3 contained English words 93% of the time, and foreign words 7% of the time. In my specific case study of translating Slovak into English, the model achieved an average BLEU score of 0.7196 using a few-shot setting.\",\"In my opinion, even though GPT-3 is the latest and greatest language model to date, there is still room for improvement for these novel large-scale models. While GPT-3 proved that one pre-trained model can perform many NLP tasks and generate impressive results, it still lacks the ability to extract meaning and comprehension from text. Its synthesis techniques are gramatically sound and readable, but its contextual meaning is often repetitive, incoherent, and occasionaly contradictory. There are hypotheses that bidirectional encoder models could solve these sort of comprehension issues and create another incredible model, but until we figure out a way to truly extract meaning and generate long text that gives us coherent information, I believe GPT-3 will remain the status qou for generative language models.\"]},\"127\":{\"h\":\"References\",\"t\":[\"[1] Language Models are Few-Shot Learners \",\"[2] Attention Is All You Need \"]},\"128\":{\"c\":[\"NLG\",\"DL4MT\"]},\"129\":{\"c\":[\"Pre-training\",\"Language Modelling\"]},\"130\":{\"h\":\"Can Visual Imagination Help Machine Translation?\",\"t\":[\"Machine translation has helped people daily life, and is also an important research topic especially in computer science community. It expands from one language translate to another language, speech translate to text, etc. Today, I'm going to talk about a paper \\\"Generative Imagination Elevates Machine Translation\\\". I'll cover the background, challenge and motivation behind this paper. Then I'll go through some technical details of this paper as well as some in-depth analysis of their experimental settings and results. Finally, we will discuss about the potential extension of this work. Hopefully, this would give you a better understanding of this area, and point out to a promising research direction.\",\"Below is an example of multimodal machine translation, which is try to caption the image in two language and use them as paired translation. Everything sounds like a very straightforward application of ideas that are around for quite a while, but it has a secrete ingredient that makes it work efficiently. It is the way they represent the image that they call “Visual-Semantic Embedding”. They run an object detector for the images and represent each object by the penultimate layer of the object detection network. Then, they learn a projection of the object representations such that hidden states of the text encoder can be expressed as a linear combination of the projected object representations. Compared to the standard unsupervised translation that relies on iterative back-translation, this way of training improves the translation quality quite a lot. On the other hand, the standard unsupervised methods are designed to work with much larger datasets and these data come from a quite narrow domain. When they integrate this training machinery into a supervised learning setup in addition to standard training examples, they reach the state-of-the-art results.\"]},\"131\":{\"h\":\"1. Background\",\"t\":[\"Multimodal translation has benn explored for a while after the successful deep learning applcation for both natural language processing and computer vision. As you can see in below images from the paper, is the problem setup of their proposed ImagiT. It is different from existing multimodal NMT, as they only takes sentence in the source language as the usual NMT task. They are trying to generating an image and utilize the internal visual information to help machine translation task. \"]},\"132\":{\"h\":\"1.1 Challenge\",\"t\":[\"Current state-of-the-art methods are built upon solely textual information, which is not consistent with how human try to implement the tasks. Most of the time, human would leverage some understanding or memory from visual information to help translation process. How to leverage such visual information to improve NMT task might help it bridge the gap with human performance in multiple domains of machine translation. But this is a really challenging task, given that the paired images of texts are scarce and synthesized images from textural input are of low quality.\"]},\"133\":{\"h\":\"1.2 Motivation\",\"t\":[\"Existing multi modal NMT need the paired image as the input, which limit its development, since such bilingual parallel corpora annotated by images are not always available. And the cost of manual annotation is pretty high. This paper try to avoid the need of paired image by synthesizing it, thus address the bottlenecks mentioned above.\"]},\"134\":{\"h\":\"2. Methodology\",\"t\":[\"ImagiT is composed of roughly three key components, including imagination, visual representation module and common natural language translation model. The imagination are usually generated by some GAN techniques, and the visual representation are either extracted from the hidden states of GAN or by extracting features with computer vision SOTA backbones over the generated images. Then the visual and textual informatoin are fused together for the next step natural language translation task.\"]},\"135\":{\"h\":\"2.1 Problem Definition\",\"t\":[\"The problem here is given a source language, we want to translate it into a target language in textual modal. In the meantime, instead of gathering paired images, we synthesize the imagination from textual input. Then the imagination is leveraged as the external knowledge, which contains some spatial correspondence to help further NMT task.\"]},\"136\":{\"h\":\"2.2 Overview\",\"t\":[\"ImagiT embodies the encoder-decoder structure for end-to-end machine translation. Between the encoder and the decoder, there is an imagination step to generate semanticequivalent visual representation. Technically, the model is composed of following modules: source text encoder, generative imagination network, image captioning, multimodal aggregation and decoder for translation. \"]},\"137\":{\"h\":\"Components\",\"t\":[\"For source text encoder, they utilize the state-of-art Transformer-based machine translation framework. For generativ imagination network, they follow previous common practice of using the conditioning augmentation to enhance robustness to small perturbations along the conditioning text manifold and improve the diversity of generated samples with Generative Adversarial Network. For an imagined image, its semantic meaning is equivalent to the source sentence. They leverage the image captioning to translate the imagined visual representation back to the source language. Such symmetric structure can make the imagined visual feature act like a mirror, which effectively enhancing the semantic consistency of the imagined visual feature and precisely reflect the underlying semantics. Then comes to the aggregation part, to finally get the imagined visual textual representation, we have to fuse the representation from both modalities. By inducing the hidden representation under the guide of image-aware attention and graph persepctive of Transformer would ben elegant method to integrate visual feature. To train the whole network end-to-end, they leverage adversarial training to alternatively train the generator and the discriminator.\"]},\"138\":{\"h\":\"3. Experiments\"},\"139\":{\"h\":\"3.1 Datasets\",\"t\":[\"They evaluate the proposed ImagiT model on two datasets, Multi30K and Ambiguous COCO. To show its ability to train with external out-of-domain datasets, they adopt MS COCO in the next analyzing section. And the baseline is the conventional text-only Transformer.\"]},\"140\":{\"h\":\"3.2 Configuration\",\"t\":[\"For the imagination network, the noise vector’s dimension is 100, and the generated visual feature is 128 × 128. The upsampling and residual block in visual feature transformers consist of 3×3 stride 1 convolution, batch normalization, and ReLU activation. For detailed experimental settings, please refer to the paper.\"]},\"141\":{\"h\":\"3.1 Results\",\"t\":[\" As can be seen from above table, the main result from the Test2016, Test2017 for the En⇒De and En⇒Fr MNMT task is reported. The first category (Multimodal Neural Machine Translation Systems) collects the existing MNMT systems, which take both source sentences and paired images as input. The second category illustrates the systems that do not require images as input. Since our method falls into the second group, the baselines are the text-only Transformer and the aforementioned works.\"]},\"142\":{\"h\":\"4. Conclusion and Discussin\",\"t\":[\"Generally, this paper proposed a novel method to generate semantic-consistent visual representations for imagination-guided translation without any anootated images. But ImagiT is not applicable to larger-scale text-only NMT tasks, such as WMT'14, as they are not easy to be visualized, containing fewer objects and visually depictable entities. Besides, it largely depends on the quantity and quality of annotated images. Future work might be combining with knowledge based imagination for more complex and abstract textual information.\"]},\"143\":{\"h\":\"Reference\",\"t\":[\"Quanyu Long, Mingxuan Wang, Lei Li. Generative Imagination Elevates Machine Translation. NAACL 2021. https://arxiv.org/abs/2009.09654\"]},\"144\":{\"c\":[\"MT\",\"DL4MT\"]},\"145\":{\"c\":[\"Imagination\",\"Visual Machine Translation\",\"ImagiT\"]},\"146\":{\"h\":\"Exploiting Capacity for Multilingual Neural Machine Translation\",\"t\":[\"Multiligual machine translation aims at learning a single tanslation model for multiple languages. However, high resource language often suffers from performance degradation. In this blog, we present a method LaSS proposed in a recent ACL paper on multilingual neural machine translation. The LaSS is an approach to jointly train a single unified multilingual MT model and learns language-specific subnetwork for each language pair. Authors conducted experiments on IWSLT and WMT datasets with various Transformer architectures. The experimental results demonstrates average 1.2 BLEU improvements on 36 language pairs. LaSS shows strong generalization capabilty and demonstrates strong performance in zero-shot translation. Specifically, LaSS achieves 8.3 BLEU on 30 language pairs.\",\"Recent research has forcused on the efficicacy of multilingual NMT, which supports translation from multiple source languages into multiple target languages with a single unified network. The parameter sharing of multilingual Machine Translation model encourages or enforce the parameter sharing between different languages. To demonstrate an extreme case - direct translation between a language pair never seen during the training.\",\"The main challenge for the many-to-many multilingual machine translation is the insufficient model capacity. Since all the translation directions need to be learned in a single model, the model is forced to split out for different language pairs. In this case, rich resource language especially will suffer from the performance degradation. One may consider to enhance the model size to solve the issue. However, larger model size will accompany to the enlargement of dataset. To stay with the same model parameters, an alternatvie solution is to design language-aware components, for example, language-dependent hidden cells and language-aware layer normalization etc.\",\"Therefore, to achieve a parameter-efficient network, without external trainable parameters for language-specific features, authors propose a Language Specific Subnetwork for multilingual NMT (LaSS). Each language pair in LaSS contains both language universal and language specific parameters. The network is trained to decide the sharing strategy. In particular, LaSS can model the language specific and language universal features for each language direction without interference.\",\"Overall idea for LaSS is to find sub-networks corresponding to each language pair and only updates the parameters of those sub-networks during the joint training (See Figure 1 for illustration). Authors adopt the multilingual Transformer as the backbone network. They train an initial multilingual MT model with the following loss:\",\"<x, y> is a language pair from s to t. theta is the model parameter.\",\"Start from multilingual base, authors try to find a sub-network which is specific to each language pair. Specific algorithm to find the language specific mask is following:\",\"Start with a multilingual MT model jointly trained on {Dsi->ti} from i=1 to i=N.\",\"Fine-tunning theta on specific language pair si to ti will amplify the magnitude of the important weights and diminish the unimportant weights.\",\"Rank the weights in fine-tuned model and prune the lowest alpha percent. The mask Msi->ti is obtained by setting the remaining indices of parameters to be 1.\",\"After getting masks for all the language pairs, authors create random batches of bilingual sentence pairs where each batch contains only samples from one pair. Specifically, a batch Bsi->ti is randomly drawn from the language-specific data Dsi->ti. During the backpropogation step, authors only update the parameters in theta belonging to the subnetworks, which are the Msi->ti obtaiend from the step 3. The parameters are iteratively updated until convergence.\",\"During the inference, model parameters are used along with the mask Msi->ti. For every given input sentence in language s and a target language t, model only uses parameter theta with 1s indicated by mask Msi->ti to produce the final inference result.\",\"The experiments are conducted on IWSLT and WMT benchmarks. For IWSLT, we collect 8 English-centric language pairs from IWSLT2014. They apply byte pair encoding (BPE) to preprocess multilingual sentences, resulting in a vocabulary size of 30k for IWSLT and 64k for WMT.\",\"LaSS consistently outperforms the multilingual baseline on all language pairs, confirming that using LaSS to alleviate parameter interference can help boost performance. Similarly, LaSS obtains consistent gains over multilingual baseline on WMT for both Transformer-base and Transformer-big. For Transformer-base, LaSS achieves an average improvement of 1.2 BLEU on 36 language pairs. For Transformer-large, LaSS obtains 0.6 BLEU improvement. Authors have three key observations: 1) As dataset scale increases, the improvement of BLEU and WR becomes larger, suggesting that the language pairs with large scale benefits more from LaSS. 2) Transformer-base gains more from the Transformer-big. This verfies the idea that more severe parameter interference for smaller models. 3) Authors also tested on random initialized masks, which is underperformed compared to the baselines. LaSS performance in IWLST and WMT compared to baseline and random initialized masks are included in Table 1 and Table 2, respectively.\",\"In this work, authors also demonstrate that LaSS can easily adapt to new unseen languages without dramatic drops for other existing languages. They distribute a new sub-network to each new language pair and train the sub-network with the specific language pair for fixed steps. In this way, the new language pair will only update the corresponding parameters and it can alleviate the interference and catastrophic forgetting to other language pairs. As demonstrated in the figure 2, LaSS hardly drops on other language pairs, while the multilingual baseline model dramatically drops by a large margin. LaSS also demonstrates its strong performance in zero-shot machine translation. Since LaSS strengthens its language specific parameters, apart from the language indicator, to the model to translate into the target language.\",\"In the end, authors further analysized on the mask similarity and language family. They observed that for both En->X and X->En, the mask similarity is positively correlated to the language family similarity. Moreover, authors observed that on both the encoder and decoder side, the model tends to distribute more language specific components on the top and bottom layers rather than the middle ones. For fully-connected layer, the model tends to distribute more language specific capacity on the middle layers for the encoder, while distribute more language specific capacity in the decoder for the top layers. They also invertigate on how mask can improve zero-shot performance. They observed that replacing the encoder mask with other languages causes only littler performance drop, while replacing the decoder mask causes dramatic performance drop. Therefore, decoder mask is essential of performance improvement. Lastly, they found out for larger dataset, like WMT, a smaller pruning rate is better to keep the model capacity.\",\"In this work, authors proposed a framework to learn Language-Specific Sub-network (LaSS) for multilingual NMT. The consistent improvements are observed in both IWSLT and WMT datasets, which prove that LaSS is able to alleviate parameter interference and boost performance. They further demonstrated improved performance in new language pair, zero-shot machine translation. In the end, they included detailed analysis on mask-language family relations, language specific capacity, improved performance of mask over zero-shot MT and parameter choice of pruning parameter.\",\"Code: https://github.com/NLP-Playground/LaSS\",\"Zehui Lin, Liwei Wu, Mingxuan Wang, Lei Li. Learning Language Specific Sub-network for Multilingual Machine Translation. ACL 2021. https://arxiv.org/abs/2105.09259\"]},\"147\":{\"c\":[\"MT\",\"DL4MT\"]},\"148\":{\"c\":[\"Multilingual MT\",\"Model Capacity\",\"Language-specific Sub-network\"]},\"149\":{\"h\":\"Accelerating the Computation on GPUs for Natural Language Processing\",\"t\":[\"A high performance open-source library for NLP Transformer model training and inferencing.\"]},\"150\":{\"h\":\"1. What is LightSeq?\"},\"151\":{\"h\":\"1.1 NLP models\",\"t\":[\"Transformers[1], BERT[2], or GPT[3] models are state-of-art models on natural language processing tasks. They are heavily used and breaking multiple records on sequence-to-sequence (Seq2Seq) tasks including machine translation, text summarization, and text generation, or even computer vision tasks by Vision Transformers (an image is just a sequence of pixels). However, those models are huge in size that needs large-scale training and inference. This makes it computationally expensive, so serving these models is a challenge for real industrial applications.\"]},\"152\":{\"h\":\"1.2 Motivation\",\"t\":[\"Due to the high complexity and large parameter size of transformer models, the latency for both training and inference is high. Here are the three comparisons between the current inference systems and LightSeq, and the reasons why they are not able to perform well for online tasks.\",\"Popular deep learning frameworks. Since those models have flexible model structures, both TensorFlow and PyTorch need additional memory allocation and extra overhead for training. Thus, they do not make full use of the hardware resource.\",\"Inference optimization frameworks. Optimization frameworks like TensorFlow XLA, TVM, and TensorRT are not suitable for variable-length inputs, which require dynamic memory allocation that does not perform well for transformer models.\",\"Similar acceleration frameworks. Faster-Transformer and TurboTransformers are similar to LightSeq. However, they do not have all components or features compared to LightSeq (Table 1).\"]},\"153\":{\"h\":\"1.3 Lightseq\",\"t\":[\"LightSeq[4], is a high-performance open-source library for both training and inference that is directly built on top of CUDA official libraries (cuBLAS, Thrust, CUB). It supports models in the Transformer family including BERT, GPT, and full encoder-decoder. It introduces new transformer encoders and decoders components after fusing and optimizing the existing models.\",\"The applications of LightSeq include Machine Translation, Text Generation, Dialog, Language Modelling, Sentiment Analysis, and other related tasks with sequence data, which can be easily deployed to commercial products.\",\"LightSeq improves the speed for both training and inference stages. Models like DeepSpeed[5] only accelerate the training, and tools like TensorRT, FasterTransformer, or TurboTransformers only support optimizing the inference. Here are the comparison tables on different features between LightSeq and other models.\",\"Table 1. The tables above are from the official Github repository.\"]},\"154\":{\"h\":\"2. Technique Details\",\"t\":[\"There are three main methods that LightSeq uses to optimize the model, training speed, and inference speed. The image below shows the architecture of a sequence-to-sequence model using transformers.\"]},\"155\":{\"h\":\"2.1 Operation Fusion\",\"t\":[\"Transformers model implemented by popular deep learning frameworks like Pytorch or Tensorflow just combine multiple fine-grained kernel functions for one layer. In this way, it needs to launch more kernel functions and uses lots of memory I/O that costs extra time for training and inference.\",\"LightSeq uses general matrix multiply (GEMM) and custom kernel functions, so here are only six custom kernel functions and six GEMM in a Transformer encoder layer for LightSeq models. The right image shows the model structure of the LightSeq transformer encoder layer.\",\"Need to add more intuitive description here\"]},\"156\":{\"h\":\"2.2 Hierarchical Auto-Regressive Search\",\"t\":[\"Searching usually happens in the last step of a transformer model. Redundant calculations often exist in output layers since we only need a few labels/tokens with the highest probability instead of all of them.\",\"LightSeq optimizes this process by using a Hierarchical Auto Regressive Search method to erase redundant calculations and perform parallel computing illustrated as below (using beam search as an example).\",\"the following steps happen for each beam.\",\"Randomly divide logits into k groups\",\"Calculate the maximum of group i, denoted as mi​\",\"Calculate the minimum of mi​, denoted as R, which can be regarded as a rough top-k value of logits.\",\"Select logits larger than R and write them into GPU memory.\"]},\"157\":{\"h\":\"2.3 Dynamic GPU Memory Reuse\",\"t\":[\"LightSeq pre-defines the maximum of dynamic shapes, such as the maximal sequence length, to avoid memory allocation time and save GPU memory occupancy. Also, GPU memory is shared for non-dependent intermediate results to reduce the memory usage.\",\"By using LightSeq, users are able to 8 Transformer big models simultaneously on a NVIDIA Tesla T4 GPU.\"]},\"158\":{\"h\":\"3. Using LightSeq\",\"t\":[\"Running LightSeq requires one or more GPUs.\"]},\"159\":{\"h\":\"3.1 Installation\",\"t\":[\"LightSeq installation from PyPI only supports python 3.6 to 3.8 on Linux for now. Consider compiling from source if you have other environments.\",\"pip install lightseq fairseq sacremoses transformers\"]},\"160\":{\"h\":\"3.2 Training examples using LightSeq\",\"t\":[\"Training a translation task on wmt14 en2de dataset by running the following command.\",\"sh examples/training/fairseq/ls_fairseq_wmt14en2de.sh\",\"If you want to run the training using FairSeq, run the following command.\",\"sh examples/training/fairseq/fairseq_wmt14en2de.sh\"]},\"161\":{\"h\":\"3.3 Inference examples Using LightSeq\",\"t\":[\"pip install torch tensorflow transformers lightseq\",\"cd examples/inference/python\",\"python export/hf_bart_export.py\",\"python test/ls_bart.py\",\"Here is a guide on using LightSeq for training and inference.\"]},\"162\":{\"h\":\"4. Performance\"},\"163\":{\"h\":\"4.1 Training Performance\",\"t\":[\"The plots below are the experiment results on WMT14 English to German translation tasks using Transformer-Big models. In all plots, FairSeq+LightSeq models are able to improve the performance to 3.5X maximum.\",\"The image above is from the official Github repository.\"]},\"164\":{\"h\":\"4.2 Inference Performance\",\"t\":[\"Here are the inference results using LightSeq, TensorFlow, PyTorch, and FasterTransformer on neural machine translation using Transformer-base models with beam search methods.\",\"The image above is from the official Github repository.\"]},\"165\":{\"h\":\"4.3 More Inference Performance on Nvidia P4 and T4\",\"t\":[\"The three images below are from the Volctrans Blog on segmentfault.com.\",\"X-axes are the Batch size and sequence length pairs, and Y-axes are the acceleration rates.\"]},\"166\":{\"h\":\"4.4 Real-world Cloud Computing Delay Test on GPT\",\"t\":[\"This plot shows the performance of deploying a GPT model to cloud computing. At 11:00, the delay performance decreased from 360 ms to 80 ms when LightSeq is turned on.\",\"The image above is from the Volctrans Blog on segmentfault.com.\"]},\"167\":{\"h\":\"5. Reference\",\"t\":[\"[1] Vaswani, Ashish, et al. \\\"Attention is all you need.\\\" Advances in neural information processing systems. 2017.\",\"[2] Devlin, Jacob, et al. \\\"Bert: Pre-training of deep bidirectional transformers for language understanding.\\\" arXiv preprint arXiv:1810.04805 (2018).\",\"[3] Brown, Tom B., et al. \\\"Language models are few-shot learners.\\\" arXiv preprint arXiv:2005.14165 (2020).\",\"[4] Wang, Xiaohui, et al. \\\"LightSeq: A High Performance Inference Library for Transformers.\\\" arXiv preprint arXiv:2010.13887 (2020).\",\"[5] Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. (2020) DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD '20, Tutorial).\"]},\"168\":{\"c\":[\"NLP\",\"DL4MT\"]},\"169\":{\"c\":[\"Transformer\",\"GPU Acceleration\",\"CUDA\"]},\"170\":{\"h\":\"Break the Limitation of Training Data — A Better Encoder Enhanced by BERT for Speech Translation\",\"t\":[\"Speech translation (ST) has increasing demand in our daily life and work. Applications like travel assistant, simultaneous conference translation and movie subtitling can highly reduce translation costs. Building a ST system that can understand and directly translate acoustic speech signals into text in a target language is challenging. For example, people do not always premeditate what they are going to say. Not like text translation, ST lacks completed organization sometimes. Another part is that the parallel corpus for ST is not enough, compared to the MT task. Especially, most ST methods are limited by the amount of parallel corpus.\",\"Such demanded applications stir interest within the research community. Over its decades history, speech translation has experienced several shifts in its primary research themes. The traditional way is coupled cascades of speech recognition and machine translation. Then, researchers emerged the exploration of tight coupling. Recently, end-to-end models have attracted much attention. To achieve end-to-end speech translation, our research community has made a lot of efforts. Today, we are going to introduce an interesting paper that helps us to break the limitations of the amount of parallel corpus.\"]},\"171\":{\"h\":\"End-to-end ST\",\"t\":[\"Generally, we use Cascaded ST systems to achieve ST, which extracts acoustic features and source-text semantic features before translating them to the target text.\",\"Figure 1: The process of Cascaded ST systems\",\"However, such intermediate stages meet challenges in real cases: no sufficient supervision to guide the encoder-decoder to process the audio properly, and the amount of parallel ST training corpus is small. It may generate errors when processing the audio inputs, and then influence the quality of MT.\",\"Therefore, end-to-end ST has been proposed to solve these issues. Methods like pre-training and multi-task learning can significantly improve performance. However, the performance of end-to-end ST is not as good as Cascaded ST for a very long time, since the ST data is insufficient to build a high-quality model.\",\"How to utilize the best of existing ST data to improve the end-to-end ST performance? Listen, Understand and Translate (LUT): Triple Supervision Decouples End-to-end Speech-to-text Translation introduces a human-inspired method to complete ST tasks via understanding acoustic information at the semantic level as much as possible, just like humans. It can guide the acoustic encoder to extract information from the auditory input. Additionally, it utilizes a pre-trained BERT model to enforce the upper encoder to produce as much semantic information as possible, without extra data.\"]},\"172\":{\"h\":\"Inspired by Human — LUT\",\"t\":[\"Let's take a look at the human's translation process. For example, when we want to translate Chinese audio to English, we need to listen to the audio first and try to understand the meaning of audio. After processing it in our brain, we can get the outputs.\",\"Figure 2: The process of how humans translate.\",\"Currently, end-to-end models are built with an encoder-decoder architecture that can directly translate speech without using explicitly generated intermediate ASR output. Methods like multi-task training and pre-training are used to incorporate additional ASR and MT data and reduce dependency on scarce end-to-end data. However, these techniques were not able to exploit ASR and MT data as effectively as Cascade methods, to get comparable translation quality.\",\"What if we make the machine to imitate human behaviour in translation? Can we improve the quality of speech translation? The answer is yes. The significant part of LUT is it adds the \\\"understand\\\" function in ST.\",\"LUT uses an acoustic encoder to \\\"Listen\\\", a semantic encoder to \\\"Understand\\\", and a translation decoder to \\\"Translate\\\", to imitate the intermediate steps for effective end-to-end speech translation.\",\"Figure 3: The architecture of LUT.\",\"Specifically, LUT consists of three modules:\",\"Acoustic encoder network that encodes the audio input sequence into hidden features corresponding to the source text;\",\"Semantic encoder network that extracts hidden semantic representation for translation, which behaves like a normal machine translation encoder;\",\"Translation decoder network that outputs sentence tokens in the target language.\",\"The most interesting feature of LUT is utilizing Connectionist Temporal Classification (CTC) + distance Loss to optimize the encoders, and break the limitation of insufficient parallel ST data within BERT. This is particularly interesting because it is hard to train an end-to-end ST model well with a small number of data (compared to MT). This strategy helps LUT to learn semantic features, meanwhile, it can predict recognition results while predicting translation results. Thus, we can diagnose whether the wrong prediction for translation is caused by the wrong acoustic modelling.\"]},\"173\":{\"h\":\"Evaluation of the LUT\",\"t\":[\"To test the effectiveness of LUT, the paper includes Augmented Librispeech English-French, IWSLT2018 English-German, and TED English-Chinese test.LUT achieves all the best performance. Compared to the Cascaded model, LUT is lighter (fewer parameters), which can perform a faster translation.\"]},\"174\":{\"h\":\"Semantic Analysis\",\"t\":[\"LUT compares the acoustic encoder and semantic encoder in this paper. Figure 3 shows the attention for different module layers. It is interesting that the acoustic encoder focuses on the local features, while the semantic encoder can capture more global features.\",\"Figure 4: The visualization of attention for different module layers. (a), (b) visualize the attention of the last layer of the acoustic encoder and the first layer of semantic encoder respectively.\",\"It also compares the acoustic encoder and semantic encoder on the Fluent Speech Commands dataset, to test SpeakerVer (identify the speaker) and IntentIde (intention recognition). In Table 1, the semantic encoder only gets 46.3 accuracy on the SpeakerVer task, showing that the semantic encoder can focus on the translation task.\",\"SpeakerVer\",\"IntentIde\",\"Acoustic Encoder\",\"97.6\",\"91.0\",\"Semantic Encoder\",\"46.3\",\"93.1\",\"Table 1: Classification accuracy on speaker verification and intent identification.\",\"It finds acoustic information is modelled at low-level layers and semantic information is captured at high-level layers.\"]},\"175\":{\"h\":\"LUT vs Cascaded Model\",\"t\":[\"Transcription\",\"LUT\",\"reference\",\"it was mister jack maldon\",\"hypothesis\",\"it was mister jack mal\",\"Translation\",\"reference\",\"c'était m. jack maldon\",\"hypothesis\",\"c'était m. jack maldon\",\"Transcription\",\"Cascaded\",\"reference\",\"it was mister jack maldon\",\"hypothesis\",\"it was mister jack mal\",\"Translation\",\"reference\",\"c'était m. jack maldon\",\"hypothesis\",\"c'était m. jack mal\",\"Here is an example of transcription and translation on En-Fr test set generated by the LUT and Cascaded model. It has a recognition error in the transcription stage (mal). LUT can translate correctly, ignoring the mistake that happened in transcription, while Cascaded Model can not correct the error and continue to pass the incorrect signal.\",\"LUT not only can directly translate to the target language within the original audio information, but also is fault-tolerant during the acoustic modelling.\",\"LUT is a unified training framework to decouple the end-to-end speech translation task, under the supervision of the acoustic, semantic, linguistic level. It is effective and utilizes existing data to solve the problem of insufficient ST data.\",\"The code can be found at: https://github.com/dqqcasia/st\",\"GitHub - dqqcasia/st: End-to-end Speech Translation\",\"Paper: https://arxiv.org/pdf/2009.09704.pdf\",\"Dong Q, Ye R, Wang M, et al. \\\" Listen, Understand and Translate\\\": Triple Supervision Decouples End-to-end Speech-to-text Translation[J]. AAAI 2021.\",\"Sperber M, Paulik M. Speech Translation and the End-to-End Promise: Taking Stock of Where We Are[C]//Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020: 7409-7421.\",\"Stoian M C, Bansal S, Goldwater S. Analyzing ASR pretraining for low-resource speech-to-text translation[C]//ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020: 7909-7913\",\"Weiss R J, Chorowski J, Jaitly N, et al. Sequence-to-sequence models can directly translate foreign speech[J]. arXiv preprint arXiv:1703.08581, 2017.\",\"Baevski A, Zhou H, Mohamed A, et al. wav2vec 2.0: A framework for self-supervised learning of speech representations[J]. arXiv preprint arXiv:2006.11477, 2020.\",\"Han C, Wang M, Ji H, et al. Learning Shared Semantic Space for Speech-to-Text Translation[J]. arXiv preprint arXiv:2105.03095, 2021.\",\"Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in neural information processing systems. 2017: 5998-6008.\"]},\"176\":{\"c\":[\"ST\",\"DL4MT\"]},\"177\":{\"c\":[\"Speech Translation\",\"BERT\"]},\"178\":{\"h\":\"Mirror-Generative Neural Machine Translation\",\"t\":[\"In general, neural machine translation (NMT) requires a large amount of parallel data (e.g., EN->CN). However, it is not easy to collect enough high-quality parallelly-paired sentences for training the translation model. On the other hand, we can capture enormous plain text from Wikipedia or news articles for each specific language. In this paper, MGNMT tries to make good use of non-parallel data and boost the performance of NMT.\",\"Paper\",\"Code\"]},\"179\":{\"h\":\"Background (Back Translation)\",\"t\":[\"Back Translation (BT) is a technique to boost translation performance by incorporating pseudo-inverse pairs as parallel sentences. Assuming that we are translating English (EN) into Chinese (CN), our translation goal is TMEN-CN. BT considers another TMCN-EN that translates Chinese sentences back to English. With the back-translated English sentences, BT treats the additional EN-CH sentences to further train TMEN-CN. By alternative training TMEN-CN and TMCN-EN, we can improve TMEN-CN by pseudo-parallel pairs. Although BT increases translation performance, both TMEN-CN and TMCN-EN are updated independently, which limits the effectiveness of using non-parallel sentences.\"]},\"180\":{\"h\":\"MGNMT\"},\"181\":{\"h\":\"Overview\",\"t\":[\"MGNMT is a unified NMT framework that considers both source-target and target-source translation models (TM) with their respective language models (LM). Both TM and LM share the semantic space, making it more efficient when learning from the non-parallel corpus. In addition, LM can further improve the text quality during the decoding step of TM. Inspired by generative NMT (GNMT), MGNMT introduces a latent semantic variable z and adopts symmetry of mirror-image properties to decompose the conditional joint probability p(x, y | z):\",\"(x, y): source-target language pair;\",\"Θ: trainable model parameters for TM and LM;\",\"D_xy: parallel source-target corpus;\",\"D_x and D_y: non-parallel monolingual corpus.\"]},\"182\":{\"h\":\"Parallel Training\",\"t\":[\"Given a parallel corpus (x, y), MGNMT adopts stochastic gradient variational Bayes (SGVB) to obtain an approximate maximum likelihood estimate of log p(x, y):\",\"and the Evidence Lower Bound (ELBO) can be derived as:\",\"Through reparameterization, we can jointly train the entire MGNMT via gradient-based optimizations for parallel-corpus training.\"]},\"183\":{\"h\":\"Non-parallel Training\",\"t\":[\"To utilize non-parallel corpus, MGNMT designs an interactive training method by back translation (BT). Given a sentence xs in the source language and yt in the target language, MGNMT aims at maximizing the lower bounds of their marginal distribution likelihood:\",\"As BT, for example, MGNMT samples x from p(x | yt) as the translation result of yt, and a pseudo-parallel pair (x, yt) is produced:\",\"With the pseudo-parallel corpus from two directions, they can combine to train MGNMT:\",\"Since the latent variable comes from the shared posterior q(z | x, y; Θ), it serves as a communication bridge that boosts the BT performance in MGNMT.\"]},\"184\":{\"h\":\"Decoding\",\"t\":[\"MGNMT considers pre-trained LM to help obtain smoother and higher-quality translation results during decoding.\",\"Take the source-to-target translation as an example:\",\"Sample an initialized latent variable z from the standard Gaussian prior distribution, and receives a translation result y from argmaxy p(y | x, z);\",\"Keep re-decoding with beam search to maximize ELBO:\",\"Each decoding score is determined by the x-to-y translation and the LMy, making the translated results more similar to the target language. Moreover, the reconstructed score is obtained from the y-to-x translation and LMx, further improving the translation effect upon the idea of BT.\"]},\"185\":{\"h\":\"Exeperiments\"},\"186\":{\"h\":\"Dataset\",\"t\":[\"Dataset\",\"WMT14EN-DE\",\"NISTEN-ZH\",\"WMT16EN-RO\",\"IWSLT16EN-DE\",\"Paralel\",\"4.50M\",\"1.34M\",\"0.62M\",\"0.20M (TED)\",\"Non-parallel\",\"5.00M\",\"1.00M\",\"1.00M\",\"0.20M (NEWS)\",\"MGNMT considers WMT16EN-RO as low-resource translation and IWSLT16EN-DE of TED talk for cross-domain translation. Both WMT14EN-DE and NISTEN-ZH are for the general resource-rich evaluation. Specifically, all models are trained using parallel data from TED and non-parallel data from NEWS for cross-domain translation.\"]},\"187\":{\"h\":\"Quantitative Results\",\"t\":[\"Resource-low Translation. Firstly, as for the resource-low scenario (WMT16EN-RO and IWSLT16EN-DE), MGNMT slightly surpasses the competitive baselines (e.g., 33.9 BLEU on WMT16RO-EN and 33.6 BLEU on TEDDE-EN). If incorporating non-parallel data, MGNMT gains a significant improvement (e.g., +5.2% BLEU on TEDEN-DE and +5.9% on NEWSDE-EN), which outperforms all other baselines that also use non-parallel corpus.\",\"Resource-rich Translation. Similar results can be found in resource-rich scenarios. MGNMT performs better than GNMT with only the parallel corpus (e.g., 31.4 BLEU on WMT14DE-EN and 40.42 BLEU on NISTEN-ZH) and further boosts the translation quality with the aid of non-parallel data (e.g., 30.3 BLEU on WMT14EN-DE and 49.05 BLEU on NISTZH-EN).\"]},\"188\":{\"h\":\"Ablation Study\",\"t\":[\"Effectiveness of Language Model during Decoding. Incorporating a pre-trained language model (LM) during decoding is an intuitive method to improve decoding quality. However, such simple interpolation (LM-FUSION) over NMT and external LM only brings out mild effects. In contrast, a natural integration adopted in MGNMT is essential to address the unrelated probabilistic modeling issue.\",\"Impact of #Non-parallel Data. The plot shows that with more non-parallel data involved, the translation performance keeps increasing, which demonstrates the benefit of MGNMT from data scales. Surprisingly, one monolingual side data, English, can also improve EN-GN translation under the MGNMT framework.\"]},\"189\":{\"h\":\"Qualitative Examples\",\"t\":[\"Without non-parallel in-domain data (NEWS), the baseline (RNMT) results in an obvious style mismatches phenomenon. Among all enhanced methods that attempt to alleviate this domain inconsistency issue, MGNMT leads to the best in-domain-related translation results.\"]},\"190\":{\"h\":\"Conclusion\",\"t\":[\"This paper presents a mirror generative NMT, MGNMT, that utilizes non-parallel corpus efficiently. MGNMT adopts a shared bilingual semantic space to jointly learn their goal and back-translated models. Moreover, MGNMT considers the learned language model during decoding, which directly improves the translation quality. One future research direction is to integrate MGNMT for fully unsupervised NMT.\"]},\"191\":{\"h\":\"Reference\",\"t\":[\"Zaixiang Zheng, Hao Zhou, Shujian Huang, Lei Li, Xin-Yu Dai, and Jiajun Chen. Mirror-Generative Neural Machine Translation. ICLR 2020.\"]},\"192\":{\"c\":[\"MT\",\"DL4MT\"]},\"193\":{\"c\":[\"Variational Inference\",\"Latent Variable Model\",\"Semi-supervised Learning\"]},\"194\":{\"h\":\"Contrastive Learning for Many-to-many Multilingual Neural Machine Translation\",\"t\":[\"How to develop a single unified model to translate from any language to any language? This work proposes a many-to-many translation system with emphasis on both English-centric and non-English directions. Many recent works have focused on proposing a single unified model for multiligual translation. These models are favorable because they are efficient and easy for deployment. However, most of these works focus on improving English-centric directions, which means that translation between two arbitrary languages may not be well supported. Therefore, in this paper, they propose a training method called mRASP2, including contrastive learning and alignment augmentation (AA) to train a unified multilingual translation system. They also contribute a monolingual dataset called MC24. By making use of monolingual and bilingual language copora, the system is able to learn language-agnostic representation to support non-English directions better than before. Their system achieves great performances and outperforms a strong Transformer baseline by a large margin.\"]},\"195\":{\"h\":\"Baseline\",\"t\":[\"The base model of mRASP2 is the Transformer model. They apply a 12-layer encoder and 12-layer decoder, 1024 hidden dimension, and 16 heads. This increases the model capacity to be trained on multilingual translation that can be seen as a many-to-many mapping function. Layer normalization and pre-norm residual connection are also applied. Last but not least, special language identification token is added to both source and target side, at the beginning of each sentence.\"]},\"196\":{\"h\":\"Multilingual Contrastive Learning\",\"t\":[\"The idea of contrastive learning is to provide a pair of positive samples and a pair of negative samples. Intuitively, the model must learn to project the inputs into a space where the positive pairs are close to each other, while the negative pairs are far away. Since multilingual translation is considered, the transformer model should learn a shared representation across different languages. For example, \\\"<En>I love you\\\" and \\\"<Fr> Je t'aime\\\" have the same meaning. Therefore, the model encoder should project them as two adjacent vectors in the high-dimensional embedding space. On the other hand, \\\"<Zh>你是谁\\\" has a complete different meaning and should stay away from the two vectors in the space.\",\"Formally, if we denote the anchor (i.e. source sentence) vector as R(xi), the positive sample (i.e. target sentence) as R(xj), the negative sample (i.e. target sentence of another sample) as R(yj). We can have the following contrastive loss to optimize where sim(⋅,⋅) adoptes the dot product to measure the similarity:\",\"Lctr​=−xi,xj∈D∑​log∑yj​esim(R(xi),R(yj))/τesim(R(xi),R(xj))/τ​\",\"They average the output from the encoder of each token to represent the sentence embedding R(x). τ is a common \\\"temperature\\\" parameter to control the difficulty to distinguish between positive and negative pairs.\"]},\"197\":{\"h\":\"Aligned Augmentation\",\"t\":[\"The other important technique proposed in this paper is called \\\"Aligned Augmentation\\\" (AA), distinguisheed from previous \\\"Random Aligned Substitution\\\" (RAS). AA is essentially a data augmentation method, and also a pretext task in self-supervised training. \",\"The idea is straightforward -- replacing words in source language as corresponding translation in target languages. As is shown in (a), the word singing is replaced with \\\"唱歌\\\" in Chinese and the output is the French correspondence. You can imagine that the encoder will learn an embedding space where \\\"singing\\\", \\\"唱歌\\\", and \\\"chanter\\\" are close to each other. Similarly, (b) shows the augmentation process of monolingual text. RAS is in fact equivalent to (a) bilingual augmentation, while (b) requires a multilingual synonym dictionary. This multilingual synonym dictionary is crucial because it determines the quality of AA. As is stated in the paper, the authors will release their synonym dictionary.\"]},\"198\":{\"h\":\"Datasets\",\"t\":[\"Two datasets are considered in their experiments. PC32 is a dataset containing 97.6 million English-centric parallel sentence pairs of 32 languages. In addition, they propose a monolingual dataset called MC24, which contains 1.01 billion.\",\"As for the evaluation datasets, they use WMT, IWSLT, and OPUS-100 benchmarks for supervised directions. For zero-shot directions, 6 languages are picked from OPUS-100, resulting in 15 language pairs and 30 translation directions.\"]},\"199\":{\"h\":\"Supervised Direction\",\"t\":[\"The above table shows the performance of mRASP2 in English-centric directions. mRASP2 significantly outperforms the multilingual baseline m-Transformer in all 10 directions. Compared to pre-training and fine-tuned models, mRASP also exceeds their performance in 7/10 direction, almost on par with mRASP in other 3 directions except Fr-En. In the English-centric direction, mRASP2 surpasses bilingual, pre-train & fine-tuned, and multilingual baselines in most directions.\"]},\"200\":{\"h\":\"Unsupervised Direction\",\"t\":[\"Unsupervised directions mean that one of the language in the pair has only appeared in monolingual corpora. Therefore, only Nl, Pt, and Pl satisfy this assumption and are shown in the table above. We observe that mRASP2 performs much better than m-Transformer baseline and mRASP in this setup. m-Transformer generates reasonable transltion on Nl-En and Pt-En, with 7.0 and 10.7 BLEU score, but completely fails on other directions, especially En-X directions. This is because some similar langauges such as Fr and Es in PC32 is exposed to the model.\",\"But for other languages, m-Transformer cannot learn an accurate correspondence from monolingual corpora. As a comparison, mRASP2 achieves +14.13 BLEU improvement on average, without explicit supervision signals. In addition, mRASP2 also obtains reasonable performance on Nl<->Pt. This reflects that mRASP2 enables unsupervised translation through a unified framework by incorporating monolingual data (MC24) with parallel data (PC32).\"]},\"201\":{\"h\":\"Zero-shot non-English Translation\",\"t\":[\"mRASP2 also demonstrates strong performance on zero-shot non-English translation. The question is: can we achieve direct translation between non-English paris when we only have parallel corpus between English and other languages? As can be seen from the table above, mRASP2 significantly outperforms m-Transformer. It even achieves an average of 29.0 BLEU on Zh<->X and 23.6 BLEU on Fr<->X.\",\"This shows that mRASP2 successfully learns a joint representation of non-English languages even without parallel pairs. The reason is that contrastive learning promotes the language-agnostic sentence representation, and AA helps with word-level joint representation. The introduction of MC24 also helps with learning a universal language-agnostic embedding space. mRASP2 improves the zero-shot translation by a large margin, while maintaining a outstanding performance on English-centric directions.\"]},\"202\":{\"h\":\"What is the importance of each contribution?\",\"t\":[\"The authors also demonstrate the importance of contrastive learning, AA, and MC24 by doing an ablation study. The following table shows their results. We can observe that: (1) Contrastive loss is the main contributor to zero-shot translation. Comparing 1 and 3, CTL hugely improves zero-shot translation quality by almost 10.0 BLEU without harming performance on supervised/unsupervised directions. In fact, both supervised/unsupervised quality is slightly improved with CTL. (2) AA boosts up all 3-ways by over 1.0 BLEU if compare 3 and 4. It can be seen as a stable data augmentation method to improve translation quality on unified multilingual framework. (3) Monolingual dataset, MC24 hugely improves the unsupervised direction translation by nearly 13.0 BLEU, and also other two ways by a certain margin. It is beneficial for the overall unified many-to-many translation system.\"]},\"203\":{\"h\":\"How is the alignment of different languages in Visualization?\",\"t\":[\"The authors build a dataset called Ted-M from the Ted test set with 15-language parallel data. They obtain the 1-24-dim sentence representation of these synonymous sentences in the embedding space. Then they apply T-SNE to reduce the dimension to 2 and select 3 representative languages: English, German, and Japanese. As can be seen in the following figure, mRASP2 effectively aligns the semantic space of different languages while m-Transformer cannot align well. The plot depicts the bivariate kernel density estimation on 2 dimension space. If two languages align well, their projected density distribution should overlap with each other by a large amount.\",\"Now we can come to a conclusion of the paper. This paper proposes a unified multilingual translation system called mRASP2 with simple but effective components, including contrastive learning, aligned augmentation, and monolingual datasets. Through comprehensive experimental results, they demonstrate that contrastive learning significantly improves the zero-shot translation quality. Aligned Augmentation is a stable and effective techinque for all translation setups. Monolingual data also improves the performance on unsupervised translation by a large margin. Combining all three techinques, mRASP2 achieves substantial improvements over all translation directions of multilingual NMT. They also showcase the learned language-agnostic representation by visualizing the alignment of different languages in a 2-dimensional space. mRASP2 shows the possibility of a true many-to-many Multilingual NMT that supports translation in all directions.\",\"https://github.com/PANXiao1994/mRASP2\",\"Xiao Pan, Mingxuan Wang, Liwei Wu, Lei Li. Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. ACL 2021.\"]},\"204\":{\"c\":[\"MT\",\"DL4MT\"]},\"205\":{\"c\":[\"Multilingual MT\",\"Contrastive Learning\",\"Zero-shot Translation\",\"mRASP\",\"Random Aligned Substitution\"]},\"206\":{\"h\":\"Learned Metrics for Machine Translation\",\"t\":[\"How to automatically evaluate the quality of a machine translation system? Human evaluation is accurate, but expensive. It is not suitable for MT model development.\",\"Reading Time: About 15 minutes.\"]},\"207\":{\"h\":\"A brief history of MT evaluation metrics\"},\"208\":{\"h\":\"Human evaluation\",\"t\":[\"In 1966, United States, the Automatic Language Processing Advisory Committee (ALPAC) conducted a large scale study on the evaluation of the state-of-the-art Russian-to-English Machine Translation (MT) systems at that time [1]. Indeed, the ALPAC report was infamous for holding a negative opinion toward the development of MT, and caused the suspension of research into related fields for two decodes. However, one of the first practical method for the evaluation of translation quality was developed from the study. Basically, six trained translators were each assigned to evaluate 144 sentences from 4 passages. The evaluation was based on \\\"intelligibility\\\" and \\\"fidelity\\\". \\\"Intelligibility\\\" measures to what extent the sentence can be understood, and \\\"fidelity\\\" measures how much information the translated sentence retained compared to the source. Human evaluation was based on these two variables by giving a score on the scale of 1-9. This is one of the earlest systematic MT evaluation metrics based on human judgement. \"]},\"209\":{\"h\":\"Automatic evaluation\",\"t\":[\"Even though employing human judgement as measuring metric is the most effective approach, purely depending on human is expensive as well as slow in face of the growing size of data, which promoted the need for automation. In 2002, the most commonly used evaluation metric, Bilingual Evaluation Understudy (BLEU), was developed by Kishore et al. [2]. BLEU measures the difference between references and machine translation candidates through n-grams and brevity penalty. Based on the preliminary that the “highest correlation with monolingual human judgements” is four, n-grams measure the exact word segment correspondence of length one to four in the sentence pair. The brevity penalty is included to avoid short candidates receiving unreasonably high BLEU scores. BLEU remains popular till today due to its light-weightedness and fastness. A simple example [3] of word-level BLEU is demonstrated below. \"]},\"210\":{\"h\":\"BERTScore\",\"t\":[\"Recent works on MT quality evaluation have provided stronger metrics and supports to the increased research interest in neural methods for training MT models and systems. BERTScore, which appeared in the 2020 International Conference on Learning Representations, aims to develop “an automatic evaluation metric for text generation” [4]. As a high level summary, BERTScore is one step forward from the commonly used BLEU, because BERTScore incorporates the additional contextual information into consideration to calculate the degree of difference between source and target sentence.\"]},\"211\":{\"h\":\"Motivation\",\"t\":[\"Generally speaking, there are two drawbacks in the n-gram-based metrics. Firstly, semantically-correct translations or paraphrases are excessively penalized for the n-gram metrics. In other words, different usage of words on the surface level will result in a low BLEU score. In the paper, the authors give the example of the source reference sentence “people like foreign cars,” and two of the candidates are “people like visiting places abroad” and “consumers prefer imported cars.” The latter uses synonyms to replace certain words in the reference, while preserving the original semantic meanings. However, n-gram-based metrics like BLEU will give higher score to the former candidate, even though the meaning is far from that of the reference sentence, since the exact string match of unigram and bigram values are higher. In face of this pitfall, the BERTScore authors are motivated to break the restrictions of n-grams, and to take advantage of contextualized token embedding as the matching metric, by calculating cosine similarities of all pairs in the reference and candidate.\",\"Secondly, n-gram metrics cannot capture semantic dependencies of distant words or penalize semantically-critical word order changes. For example, for short sentences, BLEU is able to capture the swap of cause and effect clauses, like “A results in B.” However, when A and B are long phrases, even the longest four-gram will fail to capture the cause-effect semantic dependencies of A and B if their order change. The n-gram metrics measures the similarity in a shallow way, which motivates the authros to develop a metric that is more effective in tackling the distant dependencies and ordering problems.\"]},\"212\":{\"h\":\"Technique\",\"t\":[\"The workflow of BERTScore computation is illustrated in the diagram below. Having a reference sentence x tokenized to (x1, …, xk) and a candidate sentence x̂ tokenized to (x̂1, ..., x̂k), the technique transforms the tokens into contextual imbeddings, and compute the match among all takens by cosine similarity. As an option, multiplying an additional weight based on the inverse document frequency of matching words can be helpful in some scenarios. The outcome includes a precision (R_BERT), recall (P_BERT), and combined metric scores(F1). \",\"BERTScore uses the BERT model to generate contextual embeddings for each token. BERT tokenizes the input text into a sequence of word pieces, and splits the unknown words into commonly observed sequences of characters. The Transformer encoder computes the representation for each word piece by repeatedly applying self-attention and nonlinear transformation alternatively. The resulting contextual embedding from word piece will generate different vector representation for the same word piece in different contexts with regard to surrounding words, which is significantly different from the exact string match metric in BLEU.\",\"Due to the vector representation of word embedding, BERTScore is able to perform a soft measure of similarity compared to exact-string matching in BLEU. The cosine similarity of a reference token xi and a candidate token x̂j is : \",\"With similarity measurement of each pair of reference token and candidate token in preparation, we can move on to compute precision and recall. In the greedy match perspective, we match each token in x with the highest similarity score in x̂.Recall is computed by matching each token in x to a token in x̂, while precision is by matching each token in x to the corresponding token in x̂. F1 score is calculated by combining precision and recall with the formular listed below. Extensive experiments indicate that F1 score performs reliably well across different settings, and therefore is the most recommended score to be used for evaluation. \",\"Optionally, we can add an importance weighting to different words to optimize the metric, because previous works indicated that “are words can be more indicative for sentence similarity than common words” [5]. From experiments, apply idf-based weight can render small benefits in some scenarios, but have limited contribution in other cases. The authors use the inverse document frequency (idf) scores to assign higher weights to rare words. Because there is limited preformance improvement when applying importance weighting, details about this optional stage will not be discussed further.\",\"A simple example of BERTScore calculation without importance from the ref-cand cosine similarity matrix is illustrated below. Basically, R_BERT is calculated by the sum of maximum values in each row divided by the number of rows, and P_BERT is calculated by the sum of the maximum values in each column divided by the number of columns. F1 is computed by 2 times the product of R_BERT and P_BERT divided by their sum. The BERTScore with importance weighting can be computed by multiplying the corresponding weight to each cosine similarity. \"]},\"213\":{\"h\":\"Effectiveness\",\"t\":[\"For the evaluation of BERTScore, this blog will focus on the machine translation task in the original paper. The experiment’s main evaluation corpus is the WMT18 metric evaluation dataset, containing predictions of 149 translation systems across 14 language pairs, gold references, and two types of human judgment scores. The evaluation is completed with regard to both segment-level and system-level. The Segment-level human judgment score is for each reference-candidate pair, while the system-level human judgments score is based on all pairs in the test set.\",\"Table below demonstrates the system-level correlation to human judgements. The higher the score is, the closer the system evaluation is to human evaluation. Focusing on FBERT score (F1 score), we can see a large number of bold correlations of metrics for FBERT, indicating it is the top performance system compared to the others. \",\"Apart from system-level correlation, the table below illustrating the segment-level correlations, BERTScore shows a considerably higher performance compared to the others. The outperformance in segment-level correlations further exhibits the quality of BERTScore for sentence level evaluation. \"]},\"214\":{\"h\":\"COMET\",\"t\":[\"In 2020, Rei et al. presented “a neural framework for training multilingual machine translation evaluation models which obtains new state-of-the-art levels of correlation with human judgements” at the 2020 Conference of Empirical Methods in Natural Language Processing [6]. The system, COMET, employs a different approach in improving evaluation metric. COMET builds an additional regression model to exploit information from source, hypothesis, and reference embeddings, and training the model to give a prediction on the quality of translation that highly correlates with human judgement.\"]},\"215\":{\"h\":\"Motivation\",\"t\":[\"As the authors point out, “the MT research community still relies largely on outdated metrics and no new, widely-adopted standard has emerged”. This creates motivation for a metric scheme that uses a network model to actually learn and predict how well a machine translation will be in a human rating perspective. We knew that BLEU transformed MT quality evaluation from human rating to automated script, BERTScore improved the evaluation scheme by incoporating context, whereas COMET is motivated to learn how human will evaluate the quality of the translation, specifically scores from direct assessment (DA), human-mediated translation edit rate (HTER), and metrics compliant with multidimensional quality metric framework (MQM). After all, humans are the best to evaluate the translation quality of our own language. In short, COMET aims at closing the gap between automated metric with actual human evaluation.\"]},\"216\":{\"h\":\"Technique\",\"t\":[\"The first step of COMET score computation is to encode the source, MT hypothesis, and reference sentence into token embeddings. The authors take advantage of a pretrained, cross-lingual encoder model, XLM_RoBERTa, to generate the three sequences (src, hyp, ref) into token embeddings. For each input sequence x = [x0, x1, …, xn], the encoder will produce an embedding e_j(l) for each token xj and each layer l ∈ {0, 1, …, k}.\",\"The word embeddings from the last layer of the encoders are fed into a pooling layer. Using a layer-wise attention mechanism, the information from the most important encoder layers are pooled into a single embedding for each token ej. μ is a trainable weight coefficient, E_j = [e_j(0), e_j(1), ..., e_j(k)] corresponds to the vector of layer embeddings for token xj, and α = softmax([α(1), α(2), . . . , α(k)]) is a vector corresponding to the layer-wise trainable weights. \",\"After applying an average pooling to the resulting word embeddings, a sentence embedding can be concatenated into a single vector from segments. The process is repeated three times for source, hypothesis, and reference sequences. Specifically, two models, the Estimator model and the Translation Ranking model, were developed for different usages.\",\"For the Estimator model, a single vector x is computed from the three sentence embeddings s, h, and r specified below: \",\"Where h⊙s and h⊙r denotes the element-wise source product and reference product, and |h-s| and |h-r| denotes the absolute element-wise source difference and reference difference. The combined feature x serves as input to a feed-forward regression network. The network is trained to minimize the mean squared error loss between its predicted scores and human quality assessment scores (DA, HTER or MQM).\",\"The Translation Ranking model, on the other hand, has different inputs {s,h+,h-,r}, i.e. a source, a higher-ranked hypothesis h+, a lower-ranked hypothesis h-, and a reference. After transforming them into sentence embeddings {s,h+,h-,r}, the triplet margin loss in relation to the source and reference is calculated: \",\"d(u, v) denotes the euclidean distance between u and v and ε is a margin. In this way during training, the model will optimize the embedding space so the distance between the anchors (s and r) and the “worse” hypothesis h− is larger by at least ε than the distance between the anchors and “better” hypothesis.\",\"In the inference stage, the model will receive a triplet input (s,ĥ,r) with only one hypothesis, and the quality score will be the harmonic mean between the distance to the source d(s,ĥ) and that to the reference d(r,ĥ), and normalized it to a 0 to 1 range: \",\"In short, the Translation Ranking model is trained to minimize the distance between a “better” hypothesis and both its corresponding reference and its original source. \"]},\"217\":{\"h\":\"Effectiveness\",\"t\":[\"To test the effectiveness of COMET, the authors trained 3 MT translations models that target different types of human judgment (DA, HTER, and MQM) from the corresponding datasets: the QT21 corpus, the WMT DARR corpus, and the MQM corpus. Two Estimator models and one Translation Ranking model are trained. One regressed on HTER (COMET-HTER) is trained with the QT21 corpus, and another model regressed on MQM (COMET-MQM) is trained with the MQM corpus. COMET-RANK is trained with the WMT DARR corpus. The evaluation method employed is the official Kendall’s Tau-like formulation. Concordant is the number of times the metric gives a higher score to the defined \\\"better\\\" hypothesis, while Discordant is the number of times the metrics give a higher score to the \\\"worse\\\" hypothesis or the scores is the same for the two hypothesis. \",\"As shown in table the first table below, for as much as seven in eight language pair evaluation with English as source, COMET-RANK outperforms all other evaluation systems, including BLEU, two encoder models of BERTScore, and its two Estimator models, to a large extent. Similarly, for the language pair evaluation with English as target in the second table below, COMET also exceeds the other metrics in the overall performance, including the 2019 task winning metric YISI-1. \"]},\"218\":{\"h\":\"Case Study\",\"t\":[\"In order to measure how well BLEU, BERTScore, and COMET can evaluate on existing MT systems, I managed to find a dataset with human judgment scores (e.g DA) [7]. Unfortunately, the MT systems that have the DA score is not available to the public, e.g. I cannot access the Baidu-system.6940 with the highest DA score in WMT19. With this preliminary, the experiment to compare how our evaluation metrics scores with a human judgement score (e.g. DA) is unattainable. Another simpler case study for the metrics is initialized instead.\",\"For the setup, a group of 10 source-reference sentence pairs were prepared from a Chinese-English parallel Yiyan corpus [8]. The source Chinese sentences are fed to two common NMT systems: Google translate which uses Google Neural Machine Translation (GNMT) [9] and SYSTRAN translate [10], and the output of translation is stored as their corresponding hypthesis.\",\"For BERTScore, we use the encoder from roberta without the importance weighting, and F1 score to evaluate the translated hypothesis. For COMET, we use the reference-free Estimation model “wmt20-comet-qe-da”, trained based on DA and used Quality Estimation (QE) as a metric, for the evaluation on GNMT and SYSTRAN. The scores from BLEU, BERTScore, and COMET are illustrated in the table below. With the limited 10 data samples, BERTScore and COMET consider Google Translator performing better, while the BLEU score for SYSTRAN Translator is higher.\",\"System-level score\",\"Google\",\"SYSTRAN\",\"BLEU\",\"33.96\",\"37.60\",\"BERTScore F1\",\"0.7934\",\"0.7562\",\"COMET\",\"0.7215\",\"0.6418\",\"The limitation of BLEU as compared to BERTScore and COMET is mostly exposed in the second sentence, as illustrated in the table below. The BLEU score for Google is 19.29, while that of SYSTRAN is 44.96. Though there is no DA scores from experts, the meanings of the two hypothesis and the reference are very similar, and the difference mostly lies on the different choice of same-meaning words. The n-gram's measurement based on the exact string match causes the large difference in the evaluation result. In comparison, the context-based BERTScore and human-judgement-trained COMET do not have a significant difference in their scores, and this example suggests the outdatedness of n-gram-based metrics to some extent.\",\"Type\",\"Sentence\",\"Src\",\"我们在网络搜索和广告的创新，已使我们的网站成为全世界的顶级网站，使我们的品牌成全世界最获认可的品牌。\",\"Ref\",\"Our innovations in web search and advertising have made our web site a top internet property and our brand one of the most recognized in the world.\",\"Hyp_Google\",\"Our innovation in online search and advertising has made our website a top website in the world, and our brand has become the most recognized brand in the world.\",\"Hyp_SYSTRAN\",\"Our innovations in online search and advertising have made our website the world's top website and made our brand the most recognized in the world.\",\"Segment-level score for 2nd sentence\",\"Google\",\"SYSTRAN\",\"BLEU\",\"19.29\",\"44.96\",\"BERTScore F1\",\"0.7515\",\"0.7820\",\"COMET\",\"0.7399\",\"0.7396\",\"Let’s take a closer look at the 8th sentence shown below. Because the SYSTRAN's translation exactly matched the reference sentence, BLEU for this sentence is 100. In BERTScore, SYSTRAN also receives a score 0.2 higher than GNMT, because the former's translation matched more with the reference. However, we can clearly see that the result from Google Translate matches more with the source sentence in Chinese, especially the choice of word of “registered” instead of “incorporated” for \\\"注册\\\", and “Delaware, USA” instead of “Delaware” for \\\"美国特拉华州\\\". The COMET score for this sentence is 0.5144 for GNMT versus 0.3090 for SYSTRAN, which correlates more with human judgement. This is because COMET does not take the reference sentences but the source sentences in Chinese as input. COMET aims to mimic how human judgement (DA under this experimental setup) evaluates the translation, and clearly the Google translation provides a more exact translation from source. This example can be used to illustrate the limitation of metrics that purely depend on the reference sentence.\",\"Type\",\"Sentence\",\"Src\",\"我们于1998年9月在加利福尼亚州注册成立 2003年8月在美国特拉华州重新注册。\",\"Ref\",\"We were incorporated in California in September 1998 and reincorporated in Delaware in August 2003.\",\"Hyp_Google\",\"We were registered in California in September 1998 and re-registered in Delaware, USA in August 2003.\",\"Hype_SYSTRAN\",\"We were incorporated in California in September 1998 and reincorporated in Delaware in August 2003.\",\"Segment-level score for 8th sentence\",\"Google\",\"SYSTRAN\",\"BLEU\",\"37.06\",\"100\",\"BERTScore F1\",\"0.7948\",\"1.0000\",\"COMET\",\"0.5144\",\"0.3090\",\"Not a trained translator myself, I cannot give my personal judgements on GNMT and SYSTRAN, but through the two examples, we clearly see the limitation of BLEU, and the limitation of BERTScore to some extent. However, it is still debatable if reference sentences should be evaluated in the metric. For COMET, inferring human judgement directly from source is appealing, but free-of-reference may result in loss of information in certain perspectives. Considering the experimental results has proven its effectiveness compared to BLEU and BERTScore, COMET may have pointed another direction for future MT evaluation metrics.\"]},\"219\":{\"h\":\"Conclusion\",\"t\":[\"To sum up, two more advanced MT metric, BERTScore and COMET, are introduced. BERTScore enriches the information used in evaluation by incorporating contextual embedding to compute the degree of difference, and COMET employs an additional regression model to exploit information to make prediction score that correlates with human judgement. Walking through the history of MT metrics, we start from the most labor-intensive human evaluation, move a step further to automated n-gram-based metrics like BLEU, develop further on taking contextual information into consideration in BERTScore, and finally arrive at training models to evaluate like human in COMET. The development is exciting, but it is also worth noted that comparing to the recent dramatic improvement in MT quality, MT evaluation has fallen behind. In 2019, the WMT News Translation shared Task has 153 submissions, while the Metrics Shared Task only has 24 submissions [6]. The importance of MT evaluation should be the same as the MT techniques. With more advanced evaluation metrics to support and give feedbacks to new MT systems, the future development of MT realm as a whole can prosper.\"]},\"220\":{\"h\":\"Code\",\"t\":[\"BERTScore: https://github.com/Tiiiger/bert_score COMET: https://github.com/Unbabel/COMET\"]},\"221\":{\"h\":\"Reference\",\"t\":[\"[1] ALPAC (1966) Languages and machines: computers in translation and linguistics. A report by the Automatic Language Processing Advisory Committee, Division of Behavioral Sciences, National Academy of Sciences, National Research Council. Washington, D.C.: National Academy of Sciences, National Research Council, 1966. (Publication 1416.)\",\"[2] Kishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. Bleu: a method for automatic eval- uation of machine translation. ACL 2002.\",\"[3] Lei Li. \\\"Data, Vocabulary and Evaluation,\\\" page 35-36. 2021. https://sites.cs.ucsb.edu/~lilei/course/dl4mt21fa/lecture2evaluation.pdf\",\"[4] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. “BERTScore: Evaluating Text Generation with BERT,” ICLR 2020. https://openreview.net/forum?id=SkeHuCVFDr.\",\"[5] Satanjeev Banerjee and Alon Lavie. METEOR: An automatic metric for mt evaluation with improved correlation with human judgments. In IEEvaluation@ACL, 2005.\",\"[6] Rei, Ricardo, Craig Stewart, Ana C Farinha, and Alon Lavie. “COMET: A Neural Framework for MT Evaluation.” EMNLP, 2020. https://doi.org/10.18653/v1/2020.emnlp-main.213.\",\"[7] marvinKaster, \\\"global-explainability-metrics,\\\" 2021. https://github.com/SteffenEger/global-explainability-metrics/blob/main/WMT19/DA-syslevel.csv\",\"[8] Corpus Research Group, Beijing Foreign Studies University Foreign Language. \\\"Yiyan English-Chinese Parallel Corpus,\\\" 2020. http://corpus.bfsu.edu.cn/info/1082/1693.htm\",\"[9] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. 2016. Google’s neural machine translation system: Bridging the gap between human and machine translation.\",\"[10] Guillaume Klein, Dakun Zhang, Clement Chouteau, Josep M Crego, and Jean Senellart. 2020. Efficient and high-quality neural machine translation with opennmt. In Proceedings of the Fourth Workshop on Neural Generation and Translation.\"]},\"222\":{\"c\":[\"MT\",\"DL4MT\"]},\"223\":{\"c\":[\"MT Evaluation\",\"BERTScore\",\"COMET\",\"BERT\"]},\"224\":{\"h\":\"Neural Machine Translation with Monolingual Translation Memory\",\"t\":[\"Hello fellow readers! In this post, I would like to share a recent advance in the field of Machine Translation. Specifically, I will be presenting the paper Neural Machine Translation with Monolingual Translation Memory by Cai et al, which received one of the six distinguished paper awards from ACL 2021.\",\"Paper: https://aclanthology.org/2021.acl-long.567/ Code: https://github.com/jcyk/copyisallyouneed\"]},\"225\":{\"h\":\"So... what is Machine Translation?\",\"t\":[\"You can probably guess from the name: over the last few decades, researchers have tried to get computers (a.k.a. machines) to translate between human languages. Their hard work has resulted in a plethora of products, like Google Translate and Microsoft Translator. I'm sure all of you have played with these tools before (if not, there's no time like the present) and have tried inputting various kinds of sentences. Their translation quality is quite impressive, and you can get near-native translations in many contexts (e.g. simple sentences between widely-spoken languages). However, you also may have noticed that some languages have better performance than others. This difference is due to the amount of usable translation data available (we'll go over what this means below). One of the key challenges being worked on today is to bridge this gap between low-resource and high-resource languages.\",\"The Spanish output seems to be accurate, but it might be possible to improve the Xhosa translation (disclaimer - I do not speak Xhosa). The word \\\"recurrent\\\" is being translated into \\\"oluqhubekayo\\\", which means \\\"ongoing\\\". In order to better capture the spirit of recurrent neural networks, however, a word closer to \\\"self-referencing\\\" might be more appropriate. This example is intended to illustrate the need for better low-resource language performance in jargon-heavy contexts. \"]},\"226\":{\"h\":\"Data is Key\",\"t\":[\"In order to understand what translation data is and why it is crucial for a good machine translation (MT) system, we first need to understand how these systems work. All of the current state-of-the-art use special kinds of programs called neural networks, which are infamous for being able to approximate any mathematical function by looking at examples.\",\"In this case, the network is learning to approximate f(x) = x + 1 just by looking at set of examples. The end goal to make correct guesses for unseen inputs, like passing 1.5 and getting 2.5. \",\"If we can convert an English sentence into a list of numbers, and if we can do the same for a Spanish sentence, then in theory, it should be possible for the network to learn how to convert the numbers from one form into the other. And if we can train it on a large number of sentence pairs, it just might learn the grammatical rules well enough to provide good translations for unseen inputs.\",\"Instead of a single number, the network is learning to map between entire sequences of numbers. This is still possible, and there are special network architectures optimized for \\\"sequence to sequence\\\" tasks. \",\"Generally, hundreds-of-thousands or millions of parallel sentences are needed for good performance. However, it is hard to obtain pure, parallel datasets of this size for low-resource languages.\"]},\"227\":{\"h\":\"Monolingual Data\",\"t\":[\"Even though low-resource languages like Xhosa may lack large amounts of parallel data, they still have vast amounts of untranslated text. If incorporated creatively, this monolingual (i.e. untranslated) text can also be used to help the network learn. Many strategies exist:\",\"Back-translation uses an okay-performing, reversed translation model to turn each sentence from the monolingual data into a synthetic (fake) parallel pair. We can then train the main model on this new parallel data to hopefully expose it to a wider variety of sentences.\",\"One could also use this data to pre-train the model before training on the parallel data. During the pre-training, all one has to do is delete random words from the monolingual corpus (e.g. a Xhosa book) and train the model to fill in the blanks. If the model does this task successfully and then trains on the parallel data, it may make better translations (at least, according to results published in Multilingual Denoising Pre-training for Neural Machine Translation).\",\"However, the main advance I will be sharing with you presents an entirely new way of using monolingual data. Specifically, it combines monolingual data with a mechanism called Translation Memory.\"]},\"228\":{\"h\":\"Translation Memory\",\"t\":[\"Before getting into what Translation Memory actually is, let me first motivate it a little. Intuitively, a good-performing translation program should be able to perform well in a wide variety of contexts. Specifically, it should be able to translate sentences from speeches, news articles, folk tales, research papers, tweets, random blog posts on machine translation, etc. However, if you want a generic, jack-of-all-trades model to make passable translations in all of these areas, you inevitably have to make some sacrifices. This is where the infrequent words problem comes in: words that are infrequently-encountered by the model during training get discarded as noise, reducing performance in specialized domains. For example, it could forget the word \\\"chromosome\\\" and translate a biology textbook incorrectly. This happens to humans too. If you're trying to become an expert at 10 topics in a short timespan, you may easily forget technical words crucial to each of the 10 topics. If one of those topics is the Medieval History of Mathematics, you may easily forget who al-Khawarizmi was, causing you to mis-attribute his discoveries. (It's even harder for a neural network, as it could never exploit the mnemonic connection between algorithm and al-Khawarizmi 😄).\",\"However, the good news is that computers can look things up extremely quickly, far more quickly than humans. Imagine if you were tested on the Medieval History of Mathematics, but you had the textbook's glossary with you. All of a sudden, if you were asked about al-Khawarizmi, you could provide the correct answer in the time that it takes you to look him up. Translation Memory essentially imbues the neural network with this same capability.\",\"Essentially, each time the network is asked to generate a word, it can reference the translation memory (a bilingual dictionary mapping words between the source and target languages) to provide a more nuanced translation. The original researchers who proposed this concept came up with a two-component model architecture. One component consists of a neural network that generates its own \\\"guess\\\" for the translation word-by-word. The other component, called a memory component, retrieves the translations for each source word from a large dictionary. These two proposals are then combined, so that the one with higher confidence is used in the final translation.\",\"(Note that everything in this section comes from Memory-augmented Neural Machine Translation [2]. If you want to learn more, go read their paper! I promise you, it's very interesting).\"]},\"229\":{\"h\":\"End of Intro\",\"t\":[\"Thank you so much for bearing with me through the introduction. I did my best to put these topics into understandable words, but I may have accidentally glossed over something without explaining. If you have any questions or feedback, please don't hesitate to reach out to me at rajansaini@ucsb.edu.\"]},\"230\":{\"h\":\"Monolingual Translation Memory\",\"t\":[\"Now, the moment we have all been waiting for has finally arrived. We can finally talk about what Monolingual Translation Memory is, how it exploits monolingual data, and what its implications are.\"]},\"231\":{\"h\":\"Intuition\",\"t\":[\"The original Translation Memory introduced above is quite powerful, but it has a few limitations:\",\"The first is that it requires a parallel, bilingual dictionary. This means that when trying to come up with a translation for an unknown word, the model will try to translate it directly rather than use the entire sentence's context.\",\"In addition, it is impossible for the retrieval mechanism itself to adapt as the model trains (a dictionary cannot change, even though other words might be more relevant).\",\"The new Monolingual Translation Memory is designed to solve both of these issues by:\",\"Using entire aligned sentences instead of a word-to-word dictionary. Such a sentence-sentence dictionary would be prohibitively long for humans to read through, but a clever retrieval mechanism would make it usable for a computer program. Furthermore, they use another neural network called a \\\"parallel encoder\\\" to determine whether two sentences are translations of each other. This allows them to associate monolingual sentences with existing translations, exploding the number of possibilities! (If you're confused by this, don't worry; this will be explained in more detail in a section below)\",\"Making the retrieval mechanism learnable. This means that as the model trains on a parallel corpus, the retrieval mechanism should also be able to adapt itself. Specifically, it should learn to provide the most relevant translations from a large set of sentences (including sentences outside the original sentence-sentence dictionary).\"]},\"232\":{\"h\":\"Parallel Encoders\",\"t\":[\"The main secret behind this advance is its usage of parallel encoders. These are neural networks (i.e. mathematical functions) that map sentences to their meaning. More precisely, they map sentence embeddings (the original sentence converted to numbers, see \\\"Data is Key\\\") to an encoding vector. The hope is for sentences with the same meaning to have the same encoding, even if they are expressed differently. For example, a good encoder would give \\\"I find recurrent neural networks fascinating\\\" and \\\"recurrent neural networks are fascinating to me\\\" similar encodings.\",\"This concept being illustrated is also known as a Siamese network. They have been used successfully outside of machine translation, for tasks like handwritten signature verifiction and facial recognition. \",\"We can also extend this idea across languages! We can have an encoder for each language that converts their sentences into a shared \\\"meaning space\\\". More precisely, two sentences from different languages that share the same meaning should get mapped to similar encoding vectors:\",\"Before we train our main neural network, we first train the target and source encoders on parallel text. The goal is for them to output identical encodings when they have the same meaning and different encodings when their meaning is different. This is called the \\\"alignment step\\\". Then we can run the target encoder over a large untranslated corpus to encode each sentence. Then, every time the user wants a new sentence translated, we can find the target sentence with closest meaning by comparing the encodings:\",\"Through this method, every sentence ever written in the target language can now be retrieved (at least in theory). The researchers that proposed this process found that searching for the most-similar encoding is equivalent to performing a Maximum Inner Product Search (MIPS). Fast algorithms that solve MIPS have already been discovered, so they can also be used for a speedy retrieval.\"]},\"233\":{\"h\":\"Main Translation Model\",\"t\":[\"The retrieval model described above will give native translations, since it searches through text originally written by humans. However, what about completely new inputs for which direct translations have never existed? In that case, we would still want to use a larger neural network to create novel translations. If we could somehow allow that network to have access to some of the best-matched sentences found by the retrieval model, this should give us the best of both worlds. In highly domain-specific cases, the retrieval model could pull up relevant words or context that the network can use. The network could then produce a translation that matches the source sentence while taking advantage of these technical words.\",\"This figure was taken from the original paper. The retrieval model is expected to output a list of sentence encodings (z1, z2, ...) and their similarities to the original input sentence (f(x,z1), f(x,z2), ...). This information is then fed into the main network (the Translation Model), along with the source sentence's encoding. \",\"In order to pass the encodings and retrieved sentences to the translation model, we can use a memory encoder and an attention mechanism. The memory encoder is a simple learnable matrix that maps each sentence to a new vector space (this section is a little more advanced, but \\\"learnable\\\" means that the matrix's weights will get adjusted during training) . I would guess that this is done so that the source sentence and retrieved sentences get mapped to the same vector space. This way, they can be meaningfully compared with and added to each other. After the retrieved sentences get transformed into memory embeddings, an attention mechanism combines them with the source sentences (scaled back by their confidences). I will not explain the full details behind how the attention mechanism works (this article has a great explanation), but the intuitive idea is that it highlights the relevant items from the memory encoder based on the source embeddings. After that, a decoder network converts the attention scores into the final translation, word-by-word.\"]},\"234\":{\"h\":\"Done! At last\",\"t\":[\"Whew! That was a lot! Anyway, this is my possibly-confusing attempt at sharing one of the latest advances in Machine Translation. If you need any clarification (especially with the translation model above), definitely feel free to reach out! Otherwise, thank you so much for your patience to have made it this far.\"]},\"235\":{\"h\":\"References\",\"t\":[\"[1] Deng Cai, Yan Wang, Huayang Li, Wai Lam, Lemao Liu. Neural Machine Translation with Monolingual Translation Memory. ACL 2021.\",\"[2] Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, Andrew Abel. Memory-augmented Neural Machine Translation. EMNLP 2017.\",\"[3] Victor Zhou. “Neural Networks from Scratch.” Victor Zhou, Victor Zhou, 9 Feb. 2020, https://victorzhou.com/series/neural-networks-from-scratch/.\"]},\"236\":{\"c\":[\"MT\",\"DL4MT\"]},\"237\":{\"c\":[\"Translation Memory\"]},\"238\":{\"h\":\"Recurrent Attention for Neural Machine Translation\",\"t\":[\"​Upon its emergence, the Transformer Neural Networks [1] dominates the sequence-to-sequence tasks. It even outperforms the Google Neural Machine Translation model in specific tasks. Specifically, the multi-head attention mechanism that depends on element-wise dot-product is deemed as one of the critical building blocks to get things to work. But is it really that important?\",\"Reading Time: About 10 minutes.\",\"Paper：https://aclanthology.org/2021.emnlp-main.258/\",\"Github: https://github.com/lemon0830/RAN\"]},\"239\":{\"h\":\"Introduction\",\"t\":[\"A recent work that appeared at the 2021 Conference of Empirical Methods in Natural Language Processing, dives into analyzing the efficacy of the dot-product self-attention module. As recent research has shown that most attention heads only learn simple positional patterns, this paper steps further towards this line and propose a novel substitute mechanism for self-attention: Recurrent AtteNtion (RAN).\",\"The basic idea of RAN is to directly learn attention weights without any token-to-token interaction and perform layer-to-layer interaction. By performing a massive number of experiments on 10 machine translation tasks, this paper empirically proves that the RAN models are competitive and outperform their Transformer counterparts in certain scenarios, with fewer parameters and inference time. Specifically, applying RAN to the decoder of Transformer yields consistent improvements by about +0.5 BLEU on 6 translation tasks and +1.0 BLEU on Turkish-English translation tasks.\",\"This blog post is organized in the following way: 1) Brief introduction of the Transformer Neural Network, with a focus on the basics of the multi-head self-attention module 2) Problem associated with the self-attention module 3) The solution provided by the RAN mechanism 4) The performance and analysis of RAN.\"]},\"240\":{\"h\":\"Multi-head Attention Module\",\"t\":[\"The figure above gives an overview of the Transformer Architecture. The left-hand side provides the encoder architecture, while the right-hand side gives the decoder architecture. Both of the encoder and decoder are stacked by N sub-layers, and the multi-head attention module is the main component in both the encoder and decoder layer. The encoder encodes the inputs and generates the context vector, which serves as an input to the decoder for decoding the output sequences. We refer the interested readers to the original paper [1] and only focus on the Multi-Head Attention module in this article.\",\"The figure above depicts the computation of the dot-product self-attention of the k-th head in the l-th encoder layer. Given a sequence of token representations with a length of n, the self-attention model first converts the representations into three matrice Q, K and V, representing queries, keys, and values, respectively. And d_k is the dimensionality of the vector in the k-th head. Then, the attention matrix is calculated via the dot product of queries and keys followed by rescaling:\",\"Finally, a softmax operation is applied on this unnormalized attention matrix, and then the output is used to compute a weighted sum of values:\",\"where H is a new contextual representation of the l-th layer. This procedure can be implemented with a multi-head mechanism by projecting the input into different subspaces, which requires extra splitting and concatenation operations. The output is fed into a position-wise feed-forward network to get the final representations of this layer.\"]},\"241\":{\"h\":\"Problem Associated with the Self-attention\",\"t\":[\"While flexible, it has been proven that there exists redundant information with pair-wise calculation. Many studies have shown that pairwise self-attention is over-parameterized, leading to a costly inference [2, 3, 4]. The RAN method takes this direction to an extreme by showing that self-attention is empirically replaceable. And next, we will formally introduce the RAN method.\"]},\"242\":{\"h\":\"RAN: Recurrent Attention\",\"t\":[\"RAN consists of a set of global Initial Attention Matrices and a Recurrent Transition Module. Instead of computing the attention weights on the fly as in the original multi-head attention module in each layer, RAN directly learn the attention weights, denoted as\",\"which are exactly the so-called Initial Attention Matrices. Here h denotes the number of heads. On the other hand, the Recurrent Transition Module takes the set of A0 as input, and recursively updates the attention matrices layer by layer. Note that the Initial Attention Matrices, the Recurrent Transition Module, and the other modules are optimized jointly. The attention matrices are completely agnostic to the input representations and can be retrieved directly without recomputation during inference.\",\"Figure above gives the model architecture of the RAN, where the dotted line denotes parameter sharing. It also shows the computation of the k-th head in the l-th encoder layer. The recurrent transition module obtains the attention weights in l-th layer Rec(∗) with the attention matrix from the last layer.\",\"Moreover, the Recurrent Transition Module is implemented using a single feed-forward network with tanh as its activation function followed by a layer normalization and a residual connection:\",\"Notably, the parameters of the transition module are shared across all heads and all layers.\"]},\"243\":{\"h\":\"Effectiveness and Analysis of the RAN.\"},\"244\":{\"h\":\"1. Main results\",\"t\":[\"The original paper evaluates RAN on WMT and NIST translation tasks, including 10 different language pairs altogether. Besides, the authors tried to apply RAN to the encoder (RAN-E), the decoder (RAN-D), or both of them (RAN-ALL), respectively. They compare against the standard Transformer (TransF) [1], and the two most related works are Hard-coded Transformer (HCSA) [5] and Random Synthesizer. (Syn-R) [6].\",\"Table 1 shows the overall results on the ten language pairs. Compared with TransF, the RAN models consistently yield competitive or even better results against TransF on all datasets. Concretely, 0.13/0.16, 0.48/0.44, and 0.16/0.22 more average BLEU/SacreBLEU are achieved by RAN-E, RAND, and RAN-ALL, respectively. Although different languages have different linguistic and syntactic structures, RAN can learn reasonable global attention patterns over the whole training corpus.\",\"Interestingly, RAN-D performs best, which significantly outperforms the TransF on most language pairs. The biggest performance gain comes from the low resource translation task Tr⇒En where RAN-D outperforms TransF by 0.97/1.0 BLEU/SacreBLEU points. We conjecture that the position-based attention without tokenwise interaction is easier to learn and the RAN can capture more generalized attention patterns. By contrast, the dot-product self-attention is forced to learn the semantic relationship between tokens and may fall into sub-optimal local minima, especially when the training scale is low. In brief, the improvement indicates that NMT systems can benefit from simplified decoders when training data is insufficient. Besides, although both RAN-E and RAN-D are effective, their effects can not be accumulated.\",\"Moreover, we can see that RAN-ALL vastly outperforms the other two related methods. RAN bridges the performance gap between Transformer and the models without the dot-product self-attention, demonstrating the effectiveness of RAN. And from the figure below, we can see that RAN-ALL successfully speeds up the inference phase.\"]},\"245\":{\"h\":\"2. Analysis\",\"t\":[\"The figure below visualizes the attention patterns of RAN over positions\",\"We find that in the encoder, RAN focuses its attention on a local neighborhood around each position. Specifically, in the last layer of the encoder, the weights become more concentrated, potentially due to the hidden representations being contextualized. Interestingly, except attending local windows to the current position, the decoder weights are most concentrated in the first token of target sequences. This may demonstrate the mechanism of decoder self-attention that the RAN decoder attends to source-side hidden states based on global source sentence representations aggregated by the start tokens.\",\"The figure above depicts the Jensen-Shannon divergence of attention between each pair of layers. The conclusions are as follows: First, the attention similarity in TransF is not salient, but the attention distribution of adjacent layers is similar to some extent. Second, there are no noticeable patterns found in Syn-R. Third, as for RAN-ALL, the attention similarity is high, especially in the decoder (the JS-divergence ranges from 0.08 to 0.2), and is remarkable between adjacent layers.\"]},\"246\":{\"h\":\"Summary\",\"t\":[\"The RAN architecture is proposed to simplify the Transformer architecture for Neural Machine Translation without costly dot-product self-attention. It takes the Initial Attention Matrices as a whole and updates it by a Recurrent Transition Module recurrently. Experiments on ten representative translation tasks show the effectiveness of RAN.\"]},\"247\":{\"h\":\"References\",\"t\":[\"[1] Vaswani, Ashish, et al. \\\"Attention is all you need.\\\" Advances in neural information processing systems. 2017.\",\"[2] Sanh, Victor, et al. \\\"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.\\\" arXiv preprint arXiv:1910.01108 (2019).\",\"[3] Correia, Gonçalo M., et al. \\\"Adaptively sparse transformers.\\\" arXiv preprint arXiv:1909.00015 (2019).\",\"[4] Xiao, Tong, et al. Sharing attention weights for fast transformer. In Proceedings of IJCAI 2019, pages 5292–5298.\",\"[5] You, Weiqiu, et al. Hard-coded gaussian attention for neural machine translation. In Proceedings of ACL 2020, pages 7689–7700.\",\"[6] Tay, Yi, et al. \\\"Synthesizer: Rethinking self-attention for transformer models.\\\" International Conference on Machine Learning. PMLR, 2021.\"]},\"248\":{\"c\":[\"MT\",\"DL4MT\"]},\"249\":{\"c\":[\"Transformer\",\"Recurrent Attention\"]},\"250\":{\"h\":\"Revisiting Self-training for Neural Sequence Generation\",\"t\":[\"Self-training is a very prevalent semi-supervised method. Its key idea is to augment the original labeled dataset with unlabeled data paired with the model's prediction (i.e. the pseudo-parallel data). Self-training has been widely used in classification tasks. However, will it work on sequence generation tasks (e.g. machine translation)? If so, how does it work? This blog introduces a work [1] which investigates these questions and gives the answers.\",\"Reading Time: About 10 minutes.\",\"Paper：https://arxiv.org/abs/1909.13788\",\"Github: https://github.com/jxhe/self-training-text-generation\"]},\"251\":{\"h\":\"1. Introduction\",\"t\":[\" Deep neural networks often require large amounts of labeled data to achieve good performance. However, it is very costly to acquire labels. So what if there is not enough labeled data? Researchers try to fully utilize the unlabeled data to improve the model performance. Self-training is a simple but effective method. As can be seen in the figure above, in self-training, a base model trained with labeled data acts as a “teacher” to label the unannotated data, which is then used to augment the original small training set. Then, a “student” model is trained with this new training set to yield the final model. Self-training is originally designed for classification problems, and it is believed that this method may be effective only when a good fraction of the predictions on unlabeled samples are correct, otherwise errors will be accumulated.\",\"However, self-training has not been studied extensively in neural sequence generation tasks like machine translation, where the target output is natural language. So the question arises: can self-training still be useful in this case? Here we introduce a work [1] which investigate the problem and answer the two questions:\",\"How does self-training perform in sequence generation tasks like machine translation?\",\"If self-training helps improving the baseline, what contributes to its success?\"]},\"252\":{\"h\":\"2. Case Study on Machine Translation\",\"t\":[\"The authors first analyze the machine translation task, and then perform ablation analysis to understand the contributing factors of the performance gains.\",\"They work with the standard WMT 2014 English-German dataset. As a preliminary experiment, they randomly sample 100K sentences from the training set (WMT100K) and use the remaining English sentences as the unlabeled monolingual data. They train with the Base Transformer architecture and use beam search decoding (beam size 5).\",\" Green bars in the above figure shows the result of applying self-training for three iterations, which includes:\",\"Pseudo-training (PT): the first step of self-training where we train a new model (from scratch) using only the pseudo parallel data generated by the current model\",\"Fine-tuning (FT): the fine-tuned system using real parallel data based on the pretrained model from the PT step.\",\"It is surprising that the pseudo-training step at the first iteration is able to improve BLEU even if the model is only trained on its own predictions, and fine-tuning further boosts the performance. An explanation is that the added pseudo-parallel data might implicitly change the training trajectory towards a (somehow) better local optimum, given that we train a new model from scratch at each iteration.\",\"Methods\",\"PT\",\"FT\",\"baseline\",\"-\",\"15.6\",\"baseline (w/o dropout)\",\"-\",\"5.2\",\"ST (beam search, w/ dropout)\",\"16.5\",\"17.5\",\"ST (sampling, w/ dropout)\",\"16.1\",\"17.0\",\"ST (beam search, w/o dropout)\",\"15.8\",\"16.3\",\"ST (sampling, w/o dropout)\",\"15.5\",\"16.0\",\"Noisy ST (beam search, w/o dropout)\",\"15.8\",\"17.9\",\"Noisy ST (beam search, w/ dropout)\",\"16.6\",\"19.3\"]},\"253\":{\"h\":\"3. The Secret Behind Self-training\",\"t\":[\"To decode the secret of self-training and understand where the gain comes from, they formulate two hypotheses:\",\"Decoding Strategy: According to this hypothesis, the gains come from the use of beam search for decoding unlabeled data. The above table shows the performance using different decoding strategies. As can be seen, the performance drops by 0.5 BLEU when the decoding strategy is changed to sampling, which implies that beam search does contribute a bit to the performance gains. This phenomenon makes sense intuitively since beam search tends to generate higher-quality pseudo targets than sampling. However, the decoding strategy hypothesis does not fully explain it, as there is still a gain of 1.4 BLEU points over the baseline from sampling decoding with dropout.\",\"Dropout: The results in the above table indicate that without dropout the performance of beam search decoding drops by 1.2 BLEU, just 0.7 BLEU higher than the baseline. Moreover, the pseudo-training performance of sampling without dropout is almost the same as the baseline.\",\"In summary, beam-search decoding contributes only partially to the performance gains, while the implicit perturbation i.e., dropout accounts for most of it. The authors also conduct experiment on a toy dataset to show that noise is beneficial for self-training because it enforces local smoothness for this task, that is, semantically similar inputs are mapped to the same or similar targets.\"]},\"254\":{\"h\":\"4. The Proposed Method: Noisy Self-training\",\"t\":[\"To further improve performance, the authors considers a simple model-agnostic perturbation process - perturbing the input, which is referred to as noisy self-training. Note that they apply both input perturbation and dropout in the pseudo-training step for noisy ST. They first apply noisy ST to the WMT100K translation task. Two different perturbation function are tested:\",\"Synthetic noise: the input tokens are randomly dropped, masked, and shuffled.\",\"Paraphrase: they translate the source English sentences to German and translate it back to obtain a paraphrase as the perturbation.\",\"Figure 2 shows the results over three iterations. Noisy ST greatly outperforms the supervised baseline and normal ST, while synthetic noise does not exhibit much difference from paraphrase. Since synthetic noise is much simpler and more general, it is defaulted in Noisy ST. Table 1 also reports an ablation study of Noisy ST when removing dropout at the pseudo-training step. Noisy ST without dropout improves the baseline by 2.3 BLEU points and is comparable to normal ST with dropout. When combined together, noisy ST with dropout produces another 1.4 BLEU improvement, indicating that the two perturbations are complementary.\"]},\"255\":{\"h\":\"5. Experiments\"},\"256\":{\"h\":\"Machine Translation\",\"t\":[\"The author test the proposed noisy ST on a high-resource MT benchmark: WMT14 English-German and a low-resource one: FloRes English-Nepali.\",\"Methods\",\"WMT14 100K\",\"WMT14 3.9M\",\"FloRes En-Origin\",\"FloRes Ne-Origin\",\"FloRes Overall\",\"baseline\",\"15.6\",\"28.3\",\"6.7\",\"2.3\",\"4.8\",\"BT\",\"20.5\",\"-\",\"8.2\",\"4.5\",\"6.5\",\"Noisy ST\",\"21.4\",\"29.3\",\"8.9\",\"3.5\",\"6.5\",\"The overall results are shown in the above table. For almost all cases in both datasets, the noisy ST outperforms the baselines by a large margin, and noisy ST still improves the baseline even when this is very weak.\"]},\"257\":{\"h\":\"Comparison with Back Translation\",\"t\":[\"It can be seen that noisy ST is able to beat BT on WMT100K and on the en-origin test set of FloRes. In contrast, BT is more effective on the ne-origin test set according to BLEU, which is not surprising as the ne-origin test is likely to benefit more from Nepali than English monolingual data.\"]},\"258\":{\"h\":\"Analysis\",\"t\":[\"The authors analyze the effect of the following three factors on noisy self-training on the WMT14 dataset:\",\"Parallel dat size\",\"Monolingual dat size\",\"Noise level The result is shown in the above figure. In (a) we see that the performance gain is larger for intermediate value of the size of the parallel dataset, as expected. (b) illustrates that the performance keeps improving as the monolingual data size increases, albeit with diminishing returns. (c) demonstrates that performance is quite sensitive to noise level, and that intermediate values work best. It is still unclear how to select the noise level a priori, besides the usual hyper-parameter search to maximize BLEU on the validation set.\"]},\"259\":{\"h\":\"Summary\",\"t\":[\"This work revisit self-training for neural sequence generation, especially machine translation task. It is shown that self-training can be an effective method to improve generalization, particularly when labeled data is scarce. Through comprehensive experiments, they prove that noise injected during self-training is critical and thus propose to perturb the input to obtain a variant of self-training, named noisy self-training, which show great power on machine translation and also text summarization tasks.\"]},\"260\":{\"h\":\"References\",\"t\":[\"[1] He, Junxian, et al. \\\"Revisiting Self-Training for Neural Sequence Generation.\\\" International Conference on Learning Representations. 2019.\"]},\"261\":{\"c\":[\"MT\",\"DL4MT\"]},\"262\":{\"c\":[\"Self-training\"]},\"263\":{\"h\":\"Unsupervised Machine Translation using Monolingual Corpora Only\",\"t\":[\"Can one build a neural machine translation model without parallel data?\",\"Recently, the neural machine translation model has developed greatly thanks to the transformer-based encoder-decoder translation model and the corresponding parallel corpus. The parallel corpus refers to the parallel sentence/paragraph pairs that have the same meanings, but one in the source language and the other in the target language. During training, the model will encode the source language sentences, and decode autoregressively to generate the sentences in the target language fields, and the losses are calculated based on the similarity between the generated sentences and the corresponding ground truth target sentences. Therefore, the performance of transformer-based encoder-decoder model highly depends on the quality and quantity of the parallel corpus.\",\"While there are many parallel corpus resources for commonly used languages, there are also many low-resource languages that fail to present enough parallel corpus for training, and some of them have much more monolingual resources, without translations. Is it possible to utilize those monolingual resources to do machine translations?\",\"This might look crazy - imagine that when someone learns a new language but he/she is not told the translations for a sentence. It is indeed not be able to be achieved by a traditional neural machine translation model. However, with the help of unsupervised learning, it is possible to use only monolingual corpus to achieve a fair performance on many machine translation tasks. The method is proposed by G. Lample et al. in 2017 in the Facebook AI Research Group and the Sorbonne University. Let's take a further look at how this work bridges the gap between two unpaired languages.\"]},\"264\":{\"h\":\"Motivations and Overview\",\"t\":[\"As previously discussed, the proposed method is unsupervised. The key problem here is how to self-align the same meanings from different languages. Specifically, in the embedding spaces of two different languages, the words and sentences that have similar meanings should be mapped to each other. To see this clearly, let's first visually take a look at the word-level map, which is proposed by the same research group in the paper \\\"Word Translation Without Parallel Data\\\"[2].\",\"As suggested in the image, to map embedding of two different languages in the word level, it is possible to learn a matrix $$W$$ that transforms the embedding of the words in one language to words in the other language. The key idea here is, to map the languages is equivalent to mapping the embedding space of the languages.\",\"In this work, the map is also done by learning to properly map the embedding space. However, different from their word-level work, they no longer map one language to the other one directly. Instead, they achieve the map by learning a shared latent space. This is a more natural way in sentence-level translation, since in an encoder-decoder MT model, the encoder exactly transforms the sentences from the source space to a latent space. If the latent spaces of two different languages are actually shared, the alignment is done without a need for supervised inputs, or parallel sentence pairs.\"]},\"265\":{\"h\":\"Methods\",\"t\":[\"The proposed method is demonstrated in the figure below. \",\"To learn a shared latent space, the translation model needs to encode different languages into the same embedding space, and similarly, decodes from the shared space. Therefore, this work also learns aggregate encoder and decoder as $$e(x,l)$$ and $$d(x,l)$$, where $$x$$ is the embedding and $$l$$ denotes the language.\",\"With this new encoder-decoder structure, the remaining task is to correctly learn the encoder and decoder so that a shared embedding space can be obtained. Therefore, this work proposes 3 training objectives:\",\"Reconstruction loss\",\"Cross-domain loss\",\"Generative and discriminative loss\"]},\"266\":{\"h\":\"Reconstruction loss\",\"t\":[\"The word \\\"reconstruction\\\" refers to recovering the encoded sentences to the original ones, which is demonstrated in the previous left sub-figure. Namely, the encoder will encode the sentences from source or target space to latent space, and the decoder should be able to restore the exact sentences from the latent space.\",\"In practice, we perturb the input sentence using a function $$C(\\\\cdot)$$ so that the encoder learns in a slightly noisy distribution. To add noise to the original input, this work applies 2 methods: First, they randomly drop some of the words in the sentences with probability $$p_{wd}$$. Second, they slightly re-permute the words with the restriction that the words' order does not change too much from the original ones. Specifically, the parameter $$k$$ controls the maximum allowed order changed from the original ones. The following figure (cited from [4]) demonstrates how the $$k$$ restricts the re-permutation. \",\"The reconstruciotn loss is given by\",\"Lauto​(θenc​,θdnc​,Z,ℓ)=Ex∼Dl​,x^∼d(e(C(x),l),l)​[Δ(x^,x)],\",\"where $$\\\\theta_{enc}$$ and $$\\\\theta_{dnc}$$ denote the parameters for the encoder and decoder, and $$x$$ and $$\\\\hat{x}$$ are the original sentences and reconstructed sentences. This loss measures the difference between reconstructed sentences and original ones with small perturbations, and it reflects the ability of encoder and decoder to transform between sentence embedding spaces and latent spaces. $$Z$$ is the words embedding that are unchanged during the encoder and decoder learning.\"]},\"267\":{\"h\":\"Cross-domain loss\",\"t\":[\"The motivation of the cross-domain loss is demonstrated in the previous right sub-figure. In machine translation, the model translates a sentence from one language to another one. The cross-domain loss effectively measures the performance of the translation. Specifically, after we obtain the translated sentence, the cross-domain loss measures if the encoder and decoder is able to back-translate[3] the sentence in the target language domain.\",\"Formally, the cross domain loss is\",\"Lcd​(θenc​,θdnc​,Z,ℓ1​,ℓ2​)=Ex∼Dl1​,x^∼d(e(C(M(x)),ℓ2​),ℓ1​)​[Δ(x^,x)],\",\"where $$M(x)$$ means applying the current translation model to sentence $$x$$ and obtain sentence $$M(x)$$ in the target language domain. Similar to previous setting, the sentence $$M(x)$$ is also perturbed with random noise by function $$C$$. The cross domain loss finally measures the difference between the original sentences and the back-translated sentences.\"]},\"268\":{\"h\":\"Generative and discriminative loss\",\"t\":[\"The adversarial training is introduced to ensure embedding of two languages map to the same latent space. Specifically, the discriminator distinguishes the latent vectors from 2 different languages and tries to specify which language does the given latent vector come from, while the generator, which is our encoder in this case, should generate similar latent vectors to fool the discriminator. The generative and discriminative loss is\",\"Ladv​(θenc​,Z∣θD​)=−E(xi​,ℓi​)​[logpD​(lj​∣e(xi​,ℓi​))].\",\"The loss is minimized when the discriminator does not know which language it comes from. Mathematically, it corresponds to the case when the probability of classifying a sentence to correct language is minimized.\",\"Finally, the objective function is the combination of the 3 losses above. The whole procedure can be summarized in the figure below. \"]},\"269\":{\"h\":\"Experiments and Case study\",\"t\":[\"Although the paper says the code will be released upon acceptance, to my best knowledge, the code is not publicly available now. A search on Github does not give related code, and paperwithcode points on the following website [https://github.com/facebookresearch/MUSE], which is a different work in Facebook AI Research. Therefore, the following discussion is based on the reported numbers and figures in the original paper.\",\"This unsupervised method works pretty well. Let's first take a look at their BLEU scores on Multi30k-Task1 and WMT datasets.\",\"From their results, we can observe that the proposed unsupervised learning method on MT significantly outperforms the previous method, such as the trivial word-by-word method. Although there is a 10~25 score gap between the supervised MT method and the proposed method, it is surprisingly enough to observe that the proposed method has achieved very good translation without using any parallel corpus.\",\"Also, the following experiments further shows the effectiveness of this proposed methods. The left subfigure shows how the model learns with the iterations increase, demonstrating that the total objective functions successfully boost the performance of the encoders and decoders in the translation model. The right subfigure shows that this proposed method is comparable to the supervised method with 100,000 parallel sentences pairs. This demonstrates that the unsupervised method in this work can be very useful for the low-resources languages with lower amount of parallel sentences available.\",\"Finally, let's take a case study and check how the performance of translations improved at each iteration. From the following experiments, we can observe that at the first iteration, the model is already able to translate the source sentences to the target field, while their meanings are stil in fragments. However, after 3 iterations, the translations become pretty good and convey most, if not all, of the original meanings.\"]},\"270\":{\"h\":\"Conclusion\",\"t\":[\"In this work, the authors propose a novel unsupervised way to do machine translations by learning a shared latent space between the source and target languages. This method shows surprisingly good performance on different MT tasks, and is comparable to or outperforms the supervised methods with few parallel sentence pairs. Therefore, this proposed unsupervised method is very useful in low-resource language machine translations.\"]},\"271\":{\"h\":\"Reference\",\"t\":[\"[1] Lample, Guillaume, et al. \\\"Unsupervised machine translation using monolingual corpora only.\\\" arXiv preprint arXiv:1711.00043 (2017).\\n[2] Conneau, Alexis, et al. \\\"Word translation without parallel data.\\\" arXiv preprint arXiv:1710.04087 (2017).\\n[3] Brislin, Richard W. \\\"Back-translation for cross-cultural research.\\\" Journal of cross-cultural psychology 1.3 (1970): 185-216.\\n[4] https://zhuanlan.zhihu.com/p/31404350\"]},\"272\":{\"c\":[\"MT\",\"DL4MT\"]},\"273\":{\"c\":[\"Unsupervised Machine Translation\"]},\"274\":{\"h\":\"Mt\"},\"275\":{\"h\":\"Nlp\"},\"276\":{\"h\":\"2021\"},\"277\":{\"h\":\"Dl4mt\"}},\"dirtCount\":0,\"index\":[[\"δ\",{\"1\":{\"266\":1,\"267\":1}}],[\"ℓi​\",{\"1\":{\"268\":2}}],[\"ℓ2​\",{\"1\":{\"267\":2}}],[\"ℓ1​\",{\"1\":{\"267\":2}}],[\"ℓ\",{\"1\":{\"266\":1}}],[\"∗\",{\"1\":{\"242\":1}}],[\"😄\",{\"1\":{\"228\":1}}],[\"~lilei\",{\"1\":{\"221\":1}}],[\"美国特拉华州\",{\"1\":{\"218\":1}}],[\"注册\",{\"1\":{\"218\":1}}],[\"使我们的品牌成全世界最获认可的品牌\",{\"1\":{\"218\":1}}],[\"使用\",{\"1\":{\"18\":1}}],[\"已使我们的网站成为全世界的顶级网站\",{\"1\":{\"218\":1}}],[\"ĥ\",{\"1\":{\"216\":3}}],[\"ε\",{\"1\":{\"216\":2}}],[\"α\",{\"1\":{\"216\":4}}],[\"μ\",{\"1\":{\"216\":1}}],[\"∈\",{\"1\":{\"216\":1}}],[\"唱歌\",{\"1\":{\"197\":2}}],[\"τ\",{\"1\":{\"196\":1}}],[\"τ​\",{\"1\":{\"196\":1}}],[\"τesim\",{\"1\":{\"196\":1}}],[\"⋅\",{\"1\":{\"196\":2}}],[\"|h\",{\"1\":{\"216\":2}}],[\"|\",{\"1\":{\"181\":1,\"183\":2,\"184\":1}}],[\"était\",{\"1\":{\"175\":4}}],[\"éducation\",{\"1\":{\"37\":1}}],[\"×\",{\"1\":{\"140\":1}}],[\"×m​\",{\"1\":{\"112\":1}}],[\"časom\",{\"1\":{\"125\":1}}],[\"ísť\",{\"1\":{\"125\":2}}],[\"→\",{\"1\":{\"123\":1}}],[\"⊕\",{\"1\":{\"111\":1}}],[\"θdnc​\",{\"1\":{\"266\":1,\"267\":1}}],[\"θdec∗​=θdec∗​+wdec​lt​\",{\"1\":{\"112\":1}}],[\"θdec∗​=θdec∗​⊕g\",{\"1\":{\"111\":1}}],[\"θdec∗​\",{\"1\":{\"111\":1}}],[\"θdec​\",{\"1\":{\"110\":1,\"111\":1}}],[\"θ\",{\"1\":{\"181\":1,\"183\":1}}],[\"θenc∗​=θenc∗​+wenc​ls​\",{\"1\":{\"112\":1}}],[\"θenc∗​=θenc∗​⊕g\",{\"1\":{\"111\":1}}],[\"θenc∗​\",{\"1\":{\"111\":1}}],[\"θenc​=wenc​penc​ls​\",{\"1\":{\"112\":1}}],[\"θenc​\",{\"1\":{\"110\":1,\"111\":1,\"266\":1,\"267\":1,\"268\":1}}],[\"θg​\",{\"1\":{\"111\":1}}],[\"∣s∣∗∣t∣\",{\"1\":{\"110\":1}}],[\"łukasz\",{\"1\":{\"102\":1}}],[\"−qϕt​\",{\"1\":{\"69\":1}}],[\"=−e\",{\"1\":{\"268\":1}}],[\"=ex∼dl1​\",{\"1\":{\"267\":1}}],[\"=ex∼dl​\",{\"1\":{\"266\":1}}],[\"=\",{\"1\":{\"216\":3,\"226\":1}}],[\"=1\",{\"1\":{\"113\":1}}],[\"=1−qϕt​\",{\"1\":{\"69\":1}}],[\"=1−∑i=1∣z∣​\",{\"1\":{\"69\":1}}],[\"=∑i=1∣z∣​qϕ​\",{\"1\":{\"69\":1}}],[\"==>\",{\"1\":{\"24\":2}}],[\"qe\",{\"1\":{\"218\":2}}],[\"qt21\",{\"1\":{\"217\":2}}],[\"qou\",{\"1\":{\"126\":1}}],[\"q\",{\"1\":{\"105\":1,\"175\":1,\"183\":1,\"221\":1,\"240\":1}}],[\"qin\",{\"1\":{\"89\":1,\"221\":1}}],[\"qiaoben\",{\"1\":{\"74\":1}}],[\"qϕt​\",{\"1\":{\"69\":3}}],[\"quoc\",{\"1\":{\"221\":1}}],[\"queries\",{\"1\":{\"41\":1,\"44\":1,\"96\":2,\"97\":1,\"240\":2}}],[\"query\",{\"1\":{\"41\":1,\"42\":2,\"96\":1}}],[\"questions\",{\"0\":{\"68\":1,\"79\":1},\"1\":{\"66\":1,\"68\":6,\"79\":1,\"124\":4,\"229\":1,\"250\":1,\"251\":1}}],[\"question\",{\"1\":{\"1\":1,\"2\":1,\"24\":1,\"66\":1,\"68\":7,\"124\":2,\"201\":1,\"251\":1}}],[\"qualitative\",{\"0\":{\"189\":1},\"1\":{\"124\":1}}],[\"quality\",{\"1\":{\"22\":2,\"23\":1,\"25\":1,\"93\":3,\"105\":3,\"130\":1,\"132\":1,\"142\":1,\"171\":2,\"172\":2,\"178\":1,\"181\":1,\"184\":1,\"187\":1,\"188\":1,\"190\":1,\"197\":1,\"202\":3,\"203\":1,\"206\":1,\"208\":1,\"210\":1,\"213\":1,\"214\":1,\"215\":4,\"216\":2,\"218\":1,\"219\":1,\"221\":1,\"225\":1,\"253\":1,\"263\":1}}],[\"quanyu\",{\"1\":{\"143\":1}}],[\"quanquan\",{\"1\":{\"89\":1}}],[\"quantitative\",{\"0\":{\"187\":1},\"1\":{\"124\":2}}],[\"quantitatively\",{\"1\":{\"43\":1,\"123\":1}}],[\"quantity\",{\"1\":{\"23\":1,\"142\":1,\"263\":1}}],[\"quick\",{\"1\":{\"109\":1}}],[\"quickly\",{\"1\":{\"21\":1,\"228\":2}}],[\"quinta\",{\"1\":{\"30\":1}}],[\"quite\",{\"1\":{\"1\":2,\"65\":1,\"113\":1,\"130\":3,\"225\":1,\"231\":1,\"258\":1}}],[\"$$m\",{\"1\":{\"267\":3}}],[\"$$z$$\",{\"1\":{\"266\":1}}],[\"$$k$$\",{\"1\":{\"266\":2}}],[\"$$p\",{\"1\":{\"266\":1}}],[\"$$c$$\",{\"1\":{\"267\":1}}],[\"$$c\",{\"1\":{\"266\":1}}],[\"$$l$$\",{\"1\":{\"265\":1}}],[\"$$x$$\",{\"1\":{\"265\":1,\"266\":1,\"267\":1}}],[\"$$d\",{\"1\":{\"265\":1}}],[\"$$\",{\"1\":{\"265\":2,\"266\":8,\"267\":3}}],[\"$$e\",{\"1\":{\"265\":1}}],[\"$$w$$\",{\"1\":{\"264\":1}}],[\"$100\",{\"1\":{\"125\":1}}],[\"$\",{\"1\":{\"66\":1}}],[\"$c\",{\"1\":{\"66\":1}}],[\"ϵ\",{\"1\":{\"42\":1}}],[\"9m\",{\"1\":{\"256\":1}}],[\"91\",{\"1\":{\"174\":1}}],[\"97\",{\"1\":{\"174\":1,\"198\":1,\"244\":1}}],[\"9th\",{\"1\":{\"105\":1}}],[\"90\",{\"1\":{\"55\":1}}],[\"93\",{\"1\":{\"54\":1,\"122\":1,\"126\":1,\"174\":1}}],[\"9∼12\",{\"1\":{\"54\":1}}],[\"96\",{\"1\":{\"53\":1,\"218\":3}}],[\"9\",{\"1\":{\"35\":1,\"37\":1,\"187\":2,\"208\":1,\"218\":1,\"221\":1,\"235\":1,\"252\":1,\"256\":1}}],[\"9k\",{\"1\":{\"6\":1}}],[\"对中产阶级而言\",{\"1\":{\"32\":2}}],[\"对于机器翻译也起到了非常重要的作用\",{\"1\":{\"18\":1}}],[\"对于机器翻译来说\",{\"1\":{\"13\":1,\"15\":1}}],[\"对于模型解码不需要有任何更改\",{\"1\":{\"17\":1}}],[\"z∣θd​\",{\"1\":{\"268\":1}}],[\"z2\",{\"1\":{\"233\":2}}],[\"z1\",{\"1\":{\"233\":2}}],[\"zaixiang\",{\"1\":{\"191\":1}}],[\"zajtra\",{\"1\":{\"125\":1}}],[\"zahrajme\",{\"1\":{\"125\":1}}],[\"za\",{\"1\":{\"125\":1}}],[\"z\",{\"1\":{\"69\":1,\"116\":1,\"125\":1,\"181\":2,\"183\":1,\"184\":2,\"266\":1,\"267\":1}}],[\"zied\",{\"1\":{\"105\":1}}],[\"ziad\",{\"1\":{\"93\":1}}],[\"ziniu\",{\"1\":{\"89\":1}}],[\"zi​∈sup\",{\"1\":{\"69\":1}}],[\"zijn\",{\"1\":{\"30\":1}}],[\"z=sup\",{\"1\":{\"69\":2}}],[\"zeng\",{\"1\":{\"49\":1,\"61\":1}}],[\"zero\",{\"0\":{\"201\":1},\"1\":{\"37\":1,\"113\":3,\"115\":1,\"120\":2,\"122\":1,\"126\":2,\"146\":5,\"198\":1,\"201\":2,\"202\":2,\"203\":1},\"2\":{\"39\":1,\"205\":1}}],[\"zehui\",{\"1\":{\"37\":1,\"146\":1}}],[\"zhihu\",{\"1\":{\"271\":1}}],[\"zhifeng\",{\"1\":{\"221\":1}}],[\"zhiyuan\",{\"1\":{\"61\":1}}],[\"zh<\",{\"1\":{\"201\":1}}],[\"zheng\",{\"1\":{\"191\":1}}],[\"zhenghao\",{\"1\":{\"61\":1}}],[\"zhuanlan\",{\"1\":{\"271\":1}}],[\"zhu\",{\"1\":{\"105\":1,\"221\":1}}],[\"zhang\",{\"1\":{\"74\":1,\"105\":2,\"221\":2,\"235\":2}}],[\"zhao\",{\"1\":{\"41\":1,\"46\":1,\"105\":2}}],[\"zhou\",{\"1\":{\"61\":1,\"74\":1,\"89\":1,\"102\":1,\"175\":1,\"191\":1,\"235\":3}}],[\"zh\",{\"0\":{\"29\":1,\"32\":1},\"1\":{\"18\":1,\"27\":1,\"186\":2,\"187\":1}}],[\"<zh>你是谁\",{\"1\":{\"196\":1}}],[\"<fr>\",{\"1\":{\"196\":1}}],[\"<en>i\",{\"1\":{\"196\":1}}],[\"<x\",{\"1\":{\"146\":1}}],[\"<\",{\"1\":{\"30\":2}}],[\"公开\",{\"1\":{\"29\":1}}],[\"非\",{\"1\":{\"29\":1}}],[\"非常实用\",{\"1\":{\"17\":1}}],[\"安理会\",{\"1\":{\"29\":1}}],[\"安全\",{\"1\":{\"29\":1}}],[\"组织\",{\"1\":{\"29\":2}}],[\"基金\",{\"1\":{\"29\":2}}],[\"基于门控制的融合\",{\"0\":{\"16\":1}}],[\"基于对灾难性遗忘的假设\",{\"1\":{\"14\":1}}],[\"货币\",{\"1\":{\"29\":2}}],[\"国际\",{\"1\":{\"29\":2}}],[\"事实上\",{\"1\":{\"29\":1}}],[\"议程\",{\"1\":{\"29\":2}}],[\"临时\",{\"1\":{\"29\":2}}],[\"会议\",{\"1\":{\"29\":2}}],[\"闭门\",{\"1\":{\"29\":1}}],[\"次\",{\"1\":{\"29\":2}}],[\"第\",{\"1\":{\"29\":2}}],[\"理事会\",{\"1\":{\"29\":1}}],[\"✔\",{\"1\":{\"27\":4}}],[\">pt\",{\"1\":{\"200\":1}}],[\">cn\",{\"1\":{\"178\":1}}],[\">en\",{\"1\":{\"146\":1}}],[\">x\",{\"1\":{\"146\":1,\"201\":2}}],[\">ti\",{\"1\":{\"146\":7}}],[\">\",{\"1\":{\"30\":2}}],[\">fr\",{\"1\":{\"26\":1}}],[\">de\",{\"1\":{\"26\":1}}],[\"+1\",{\"1\":{\"239\":1}}],[\"+14\",{\"1\":{\"200\":1}}],[\"+0\",{\"1\":{\"239\":1}}],[\"+5\",{\"1\":{\"187\":2}}],[\"+\",{\"1\":{\"25\":2,\"27\":1,\"100\":2,\"172\":1,\"226\":1}}],[\"++\",{\"1\":{\"24\":1}}],[\"天安门\",{\"1\":{\"24\":3}}],[\"北京\",{\"1\":{\"24\":3}}],[\"我们于1998年9月在加利福尼亚州注册成立\",{\"1\":{\"218\":1}}],[\"我们在网络搜索和广告的创新\",{\"1\":{\"218\":1}}],[\"我们将\",{\"1\":{\"17\":1}}],[\"我\",{\"1\":{\"24\":3}}],[\"爱\",{\"1\":{\"24\":4}}],[\"8th\",{\"1\":{\"218\":2}}],[\"88\",{\"1\":{\"124\":1}}],[\"86\",{\"1\":{\"123\":1}}],[\"8b\",{\"1\":{\"112\":1}}],[\"80\",{\"1\":{\"93\":1,\"166\":1}}],[\"87\",{\"1\":{\"54\":1}}],[\"83\",{\"1\":{\"54\":1}}],[\"8555\",{\"1\":{\"125\":1}}],[\"85\",{\"1\":{\"54\":1}}],[\"82\",{\"1\":{\"54\":1,\"124\":1}}],[\"8\",{\"1\":{\"22\":1,\"23\":1,\"25\":1,\"29\":1,\"37\":1,\"53\":1,\"86\":1,\"97\":3,\"99\":2,\"113\":1,\"119\":1,\"124\":1,\"146\":2,\"157\":1,\"159\":1,\"218\":1,\"221\":1,\"252\":2,\"256\":3}}],[\"8k\",{\"1\":{\"6\":1}}],[\"04087\",{\"1\":{\"271\":1}}],[\"04805\",{\"1\":{\"167\":1}}],[\"08\",{\"1\":{\"245\":1}}],[\"08581\",{\"1\":{\"175\":1}}],[\"06\",{\"1\":{\"218\":1}}],[\"01108\",{\"1\":{\"247\":1}}],[\"01\",{\"1\":{\"198\":1}}],[\"00m\",{\"1\":{\"186\":3}}],[\"00\",{\"1\":{\"166\":1}}],[\"00043\",{\"1\":{\"271\":1}}],[\"00015\",{\"1\":{\"247\":1}}],[\"0000\",{\"1\":{\"218\":1}}],[\"000\",{\"1\":{\"22\":1,\"25\":1,\"27\":1,\"30\":1,\"53\":2,\"269\":1}}],[\"09704\",{\"1\":{\"175\":1}}],[\"09259\",{\"1\":{\"146\":1}}],[\"09654\",{\"1\":{\"143\":1}}],[\"09\",{\"1\":{\"78\":1}}],[\"05\",{\"1\":{\"187\":1}}],[\"05864\",{\"1\":{\"77\":1}}],[\"053\",{\"1\":{\"53\":1}}],[\"05672\",{\"1\":{\"12\":1}}],[\"02~2\",{\"1\":{\"55\":1}}],[\"02\",{\"1\":{\"43\":1}}],[\"03095\",{\"1\":{\"92\":1,\"175\":1}}],[\"03\",{\"1\":{\"54\":1}}],[\"03312\",{\"1\":{\"41\":1,\"46\":1}}],[\"03142\",{\"1\":{\"21\":1}}],[\"0\",{\"1\":{\"25\":1,\"29\":1,\"30\":1,\"43\":3,\"54\":1,\"70\":1,\"102\":1,\"125\":11,\"126\":1,\"146\":1,\"174\":1,\"175\":1,\"186\":3,\"200\":1,\"201\":1,\"202\":3,\"216\":3,\"218\":14,\"239\":1,\"244\":8,\"245\":2,\"252\":2,\"253\":2}}],[\"是非常有潜力的方向\",{\"1\":{\"18\":1}}],[\"得到进一步提升\",{\"1\":{\"18\":1}}],[\"未来如何研究更好的将\",{\"1\":{\"18\":1}}],[\"所以局部的\",{\"1\":{\"18\":1}}],[\"之间有\",{\"1\":{\"18\":1}}],[\"并且\",{\"1\":{\"18\":1}}],[\"并且在机器翻译benchmark\",{\"1\":{\"14\":1}}],[\"可能分布不一样\",{\"1\":{\"18\":1}}],[\"可以很好的避免这种遗忘\",{\"1\":{\"18\":1}}],[\"可以发现\",{\"1\":{\"18\":1}}],[\"可以发现在数据量比较少的时候\",{\"1\":{\"18\":1}}],[\"目前只初始化\",{\"1\":{\"18\":1}}],[\"效果不明显\",{\"1\":{\"18\":1}}],[\"效果并不是一样好\",{\"1\":{\"18\":1}}],[\"初始化\",{\"1\":{\"18\":1}}],[\"初始化效果最好\",{\"1\":{\"18\":1}}],[\"采用\",{\"1\":{\"18\":1}}],[\"总结来说\",{\"1\":{\"18\":1}}],[\"或者\",{\"1\":{\"18\":2}}],[\"发现简单的再\",{\"1\":{\"18\":1}}],[\"此外\",{\"1\":{\"18\":1}}],[\"就会相对下降\",{\"1\":{\"18\":1}}],[\"就可以了\",{\"1\":{\"18\":1}}],[\"直接做\",{\"1\":{\"18\":1}}],[\"普通的\",{\"1\":{\"18\":1}}],[\"分析了数据量和效果之间的关系\",{\"1\":{\"18\":1}}],[\"分钟\",{\"1\":{\"12\":1}}],[\"接下来\",{\"1\":{\"18\":1}}],[\"接下来再一个小数据上进行微调模型\",{\"1\":{\"13\":1}}],[\"提升了接近三个点\",{\"1\":{\"18\":1}}],[\"提出了三种策略来逐步缓解问题\",{\"1\":{\"14\":1}}],[\"相比\",{\"1\":{\"18\":1}}],[\"通过下图的实验可以发现\",{\"1\":{\"18\":1}}],[\"通过知识蒸馏来保持预训练模型的知识在下游微调中不要被忘记\",{\"1\":{\"14\":1}}],[\"语种上都做了实验\",{\"1\":{\"18\":1}}],[\"三个单独的策略都起到了很明显的作用\",{\"1\":{\"18\":1}}],[\"三个\",{\"1\":{\"18\":1}}],[\"实验效果和未来方向\",{\"0\":{\"18\":1}}],[\"实际上这个参数也可以反过来控制更新的程度\",{\"1\":{\"16\":1}}],[\"知识\",{\"1\":{\"17\":1}}],[\"看作老师\",{\"1\":{\"17\":1}}],[\"持续学习中一个重要的方法就是蒸馏策略\",{\"1\":{\"17\":1}}],[\"渐进蒸馏策略\",{\"0\":{\"17\":1}}],[\"渐进式学习策略\",{\"0\":{\"14\":1}}],[\"也简单做了一些关于\",{\"1\":{\"18\":1}}],[\"也可以保持不忘记老师的知识\",{\"1\":{\"17\":1}}],[\"也可以很好的避免灾难性遗忘问题\",{\"1\":{\"16\":1}}],[\"也就是学生不断学习老师的知识\",{\"1\":{\"17\":1}}],[\"也就是模型随着不断微调逐渐忘记了预训练的知识\",{\"1\":{\"13\":1}}],[\"模型就可以将机器翻译和\",{\"1\":{\"16\":1}}],[\"贡献的比例\",{\"1\":{\"16\":1}}],[\"和ctnmt\",{\"1\":{\"18\":1}}],[\"和\",{\"1\":{\"16\":1,\"18\":4}}],[\"和更久的时间\",{\"1\":{\"13\":1}}],[\"简单说门机制引入一个可学习的参数控制\",{\"1\":{\"16\":1}}],[\"又引入了门机制来更自动的控制这种更新\",{\"1\":{\"16\":1}}],[\"又可以适应小模型的数据\",{\"1\":{\"13\":1}}],[\"最后实验得到了\",{\"1\":{\"18\":1}}],[\"最重要的是\",{\"1\":{\"17\":1}}],[\"最大程度利用到预训练知识\",{\"1\":{\"15\":1}}],[\"最简单的策略是在下游任务更新的时候\",{\"1\":{\"15\":1}}],[\"最简单的也是最直接的通过学习率来控制\",{\"1\":{\"14\":1}}],[\"而且也可以让参数更好的适应下游任务\",{\"1\":{\"15\":1}}],[\"部分的参数\",{\"1\":{\"15\":1}}],[\"只更新\",{\"1\":{\"15\":1}}],[\"只占了整体参数中一半的参数量\",{\"1\":{\"15\":1}}],[\"再将\",{\"1\":{\"15\":1}}],[\"再打开\",{\"1\":{\"15\":1}}],[\"更有趣的是\",{\"1\":{\"18\":1}}],[\"更有趣的地方在于指出了机器翻译预训练微调框架中存在的问题\",{\"1\":{\"14\":1}}],[\"更新一定步骤之后\",{\"1\":{\"15\":1}}],[\"然后一起更新着两部分参数\",{\"1\":{\"15\":1}}],[\"然而目前预训练技术在文本生成领域\",{\"1\":{\"12\":1}}],[\"当这部分参数更新差不多的时候\",{\"1\":{\"15\":1}}],[\"先更新随机初始化部分的参数\",{\"1\":{\"15\":1}}],[\"参数更新的开始和结束\",{\"1\":{\"16\":1}}],[\"参数固定下来\",{\"1\":{\"15\":1}}],[\"参数\",{\"1\":{\"15\":2}}],[\"的模型选择实验\",{\"1\":{\"18\":1}}],[\"的提升\",{\"1\":{\"18\":1}}],[\"的方法差异非常小\",{\"1\":{\"18\":1}}],[\"的\",{\"1\":{\"18\":1,\"29\":1}}],[\"的参数\",{\"1\":{\"15\":1}}],[\"的学习控制在一个比较小的范围\",{\"1\":{\"15\":1}}],[\"的学习率\",{\"1\":{\"15\":1}}],[\"随机初始化的参数传递的梯度会有大量噪音\",{\"1\":{\"15\":1}}],[\"如果一开始所有参数一起调整\",{\"1\":{\"15\":1}}],[\"如此大的数据量就给预训练模式带来了挑战\",{\"1\":{\"13\":1}}],[\"还有中产阶级\",{\"1\":{\"32\":1}}],[\"还有很大的提升空间\",{\"1\":{\"18\":1}}],[\"还有另外一半没有被初始化\",{\"1\":{\"15\":1}}],[\"还是一个开放问题\",{\"1\":{\"12\":1}}],[\"作为\",{\"1\":{\"15\":1}}],[\"任务\",{\"1\":{\"15\":1}}],[\"任务中观察到了显著提升\",{\"1\":{\"14\":1}}],[\"不同于其它\",{\"1\":{\"15\":1}}],[\"将\",{\"1\":{\"15\":1,\"17\":1}}],[\"控制bert\",{\"1\":{\"15\":1}}],[\"梯度控制简单有效\",{\"1\":{\"16\":1}}],[\"梯度控制\",{\"0\":{\"15\":1}}],[\"验证了假设\",{\"1\":{\"14\":1}}],[\"以及提出了几个简单的方法\",{\"1\":{\"14\":1}}],[\"策略\",{\"1\":{\"14\":1}}],[\"中最常见的策略\",{\"1\":{\"14\":1}}],[\"由模型来决定预训练模型参数和机器翻译模型参数的贡献比例\",{\"1\":{\"14\":1}}],[\"动态的基于门控制策略\",{\"1\":{\"14\":1}}],[\"缓解灾难性遗忘问题\",{\"0\":{\"14\":1}}],[\"那么预训练模型的威力就很难在下游任务中得到体现\",{\"1\":{\"13\":1}}],[\"一个直接影响就是灾难性遗忘\",{\"1\":{\"13\":1}}],[\"下游任务的微调需要更多步骤\",{\"1\":{\"13\":1}}],[\"但是数据量增大的时候\",{\"1\":{\"18\":1}}],[\"但是很大的一个问题在于需要超参来控制\",{\"1\":{\"16\":1}}],[\"但是\",{\"1\":{\"13\":1,\"18\":1}}],[\"但是机器翻译任务的数据量一般都是千万级别\",{\"1\":{\"13\":1}}],[\"因而保持了稳定的提升\",{\"1\":{\"18\":1}}],[\"因而会有不错的表现\",{\"1\":{\"13\":1}}],[\"因此\",{\"1\":{\"16\":1,\"18\":1}}],[\"因此最优的策略应该是一开始固定\",{\"1\":{\"15\":1}}],[\"因为一般预训练模式\",{\"1\":{\"13\":1}}],[\"这部分也没有办法初始化\",{\"1\":{\"18\":1}}],[\"这部分噪音会很大程度影响\",{\"1\":{\"15\":1}}],[\"这是由于随着数据量的增大\",{\"1\":{\"18\":1}}],[\"这个原因主要是数据量少的时候灾难性遗忘的问题不是很严重\",{\"1\":{\"18\":1}}],[\"这三个方法加在一起还可以进一步提升模型效果\",{\"1\":{\"18\":1}}],[\"这三个数据也是业界比较公认的\",{\"1\":{\"18\":1}}],[\"这种方法只需要更改模型训练\",{\"1\":{\"17\":1}}],[\"这样就可以同时保持机器翻译参数的灵活性和保留\",{\"1\":{\"17\":1}}],[\"这样就可以很大程度上避免了灾难性遗忘的问题\",{\"1\":{\"15\":1}}],[\"这样学生网络在不断更新的情况下\",{\"1\":{\"17\":1}}],[\"这样模型保留了大数据的知识\",{\"1\":{\"13\":1}}],[\"这篇工作最重要的贡献并不是提出了这三种\",{\"1\":{\"14\":1}}],[\"这篇论文\",{\"1\":{\"12\":1}}],[\"都是在较大的训练数据上预训练模型\",{\"1\":{\"13\":1}}],[\"万平行数据\",{\"1\":{\"13\":1}}],[\"万句规模\",{\"1\":{\"13\":1}}],[\"有机结合起来\",{\"1\":{\"16\":1}}],[\"有了这种自动控制机制\",{\"1\":{\"16\":1}}],[\"有效但是实际操作需要比较仔细的参数控制策略\",{\"1\":{\"14\":1}}],[\"有\",{\"1\":{\"13\":1}}],[\"训练数据一般只有3\",{\"1\":{\"13\":1}}],[\"很多自然语言处理任务\",{\"1\":{\"13\":1}}],[\"机器翻译和传统自然语言处理很大的一个差异点在于有海量训练数据\",{\"1\":{\"13\":1}}],[\"机器翻译中的\",{\"0\":{\"12\":1}}],[\"灾难性遗忘引起的问题越来越显著\",{\"1\":{\"18\":1}}],[\"灾难性遗忘\",{\"0\":{\"13\":1}}],[\"论文链接\",{\"1\":{\"12\":1}}],[\"阅读时间大概\",{\"1\":{\"12\":1}}],[\"预训练和\",{\"1\":{\"18\":1}}],[\"预训练和机器翻译的融合还有什么潜力\",{\"1\":{\"12\":1}}],[\"预训练技术在机器翻译领域存在的挑战\",{\"0\":{\"13\":1}}],[\"预训练技术\",{\"1\":{\"12\":2}}],[\"需要怎么最大程度利用预训练知识\",{\"1\":{\"12\":1}}],[\"针对这些调整\",{\"1\":{\"12\":1}}],[\"在英德方向上\",{\"1\":{\"18\":1}}],[\"在主流的\",{\"1\":{\"18\":1}}],[\"在这个工作中\",{\"1\":{\"17\":1}}],[\"在机器翻译中的应用存在什么挑战\",{\"1\":{\"12\":1}}],[\"在自然语言处理领域\",{\"1\":{\"12\":1}}],[\"从三个方面介绍这个问题\",{\"1\":{\"12\":1}}],[\"能够取得什么样的效果\",{\"1\":{\"12\":1}}],[\"尤其是自然语言理解任务取得了巨大的成功\",{\"1\":{\"12\":1}}],[\"比如机器翻译领域\",{\"1\":{\"12\":1}}],[\"比如\",{\"1\":{\"12\":2,\"13\":2}}],[\"​upon\",{\"1\":{\"238\":1}}],[\"​​\",{\"1\":{\"112\":1}}],[\"​for\",{\"1\":{\"24\":1,\"95\":1}}],[\"​\\t直觉上讲\",{\"1\":{\"18\":1}}],[\"​\",{\"1\":{\"12\":1,\"13\":1,\"14\":1,\"15\":1,\"16\":1,\"17\":1,\"18\":3,\"21\":1,\"266\":1,\"267\":1,\"268\":1}}],[\"应用\",{\"0\":{\"12\":1}}],[\"7700\",{\"1\":{\"247\":1}}],[\"7396\",{\"1\":{\"218\":1}}],[\"7399\",{\"1\":{\"218\":1}}],[\"7515\",{\"1\":{\"218\":1}}],[\"7562\",{\"1\":{\"218\":1}}],[\"7215\",{\"1\":{\"218\":1}}],[\"7948\",{\"1\":{\"218\":1}}],[\"7934\",{\"1\":{\"218\":1}}],[\"7913\",{\"1\":{\"175\":1}}],[\"7909\",{\"1\":{\"175\":1}}],[\"7421\",{\"1\":{\"175\":1}}],[\"7424\",{\"1\":{\"29\":2}}],[\"7424th\",{\"1\":{\"29\":3}}],[\"7424e\",{\"1\":{\"29\":1}}],[\"7409\",{\"1\":{\"175\":1}}],[\"70\",{\"1\":{\"86\":1,\"93\":1}}],[\"7196\",{\"1\":{\"125\":1,\"126\":1}}],[\"71\",{\"1\":{\"54\":1}}],[\"7820\",{\"1\":{\"218\":1}}],[\"7892\",{\"1\":{\"105\":1}}],[\"7881\",{\"1\":{\"105\":1}}],[\"7880\",{\"1\":{\"37\":1}}],[\"78\",{\"1\":{\"58\":1}}],[\"7871\",{\"1\":{\"37\":1}}],[\"7689\",{\"1\":{\"247\":1}}],[\"76\",{\"1\":{\"35\":1}}],[\"7\",{\"1\":{\"9\":1,\"23\":1,\"29\":1,\"36\":1,\"37\":1,\"53\":1,\"65\":1,\"86\":1,\"95\":1,\"122\":1,\"126\":1,\"199\":1,\"200\":2,\"218\":1,\"221\":1,\"253\":1,\"256\":1}}],[\"7k\",{\"1\":{\"6\":1}}],[\"6940\",{\"1\":{\"218\":1}}],[\"62m\",{\"1\":{\"186\":1}}],[\"622\",{\"1\":{\"105\":1}}],[\"65\",{\"1\":{\"124\":1}}],[\"60\",{\"1\":{\"218\":1}}],[\"6008\",{\"1\":{\"102\":1,\"175\":1}}],[\"60k\",{\"1\":{\"2\":1,\"7\":3}}],[\"6418\",{\"1\":{\"218\":1}}],[\"64\",{\"1\":{\"97\":1}}],[\"64k\",{\"1\":{\"25\":1,\"146\":1}}],[\"6313\",{\"1\":{\"125\":1}}],[\"63\",{\"1\":{\"54\":1}}],[\"619\",{\"1\":{\"105\":1}}],[\"61~1\",{\"1\":{\"55\":1}}],[\"61\",{\"1\":{\"53\":1}}],[\"6\",{\"1\":{\"23\":1,\"37\":1,\"54\":2,\"97\":2,\"124\":1,\"146\":1,\"159\":1,\"174\":1,\"187\":1,\"198\":2,\"201\":1,\"214\":1,\"219\":1,\"221\":1,\"239\":1,\"244\":1,\"247\":1,\"252\":2,\"256\":4}}],[\"6k\",{\"1\":{\"6\":1}}],[\"50m\",{\"1\":{\"186\":1}}],[\"507\",{\"1\":{\"105\":1}}],[\"5x\",{\"1\":{\"163\":1}}],[\"57\",{\"1\":{\"124\":1}}],[\"578\",{\"1\":{\"105\":1}}],[\"58th\",{\"1\":{\"105\":1,\"175\":1}}],[\"5144\",{\"1\":{\"218\":2}}],[\"513\",{\"1\":{\"105\":1}}],[\"512\",{\"1\":{\"97\":3}}],[\"5998\",{\"1\":{\"102\":1,\"175\":1}}],[\"59\",{\"1\":{\"93\":1}}],[\"567\",{\"1\":{\"224\":1}}],[\"563\",{\"1\":{\"105\":1}}],[\"56\",{\"1\":{\"53\":1,\"124\":1}}],[\"54th\",{\"1\":{\"9\":1}}],[\"5k\",{\"1\":{\"6\":1}}],[\"5298\",{\"1\":{\"247\":1}}],[\"5292\",{\"1\":{\"247\":1}}],[\"5247\",{\"1\":{\"125\":1}}],[\"52\",{\"1\":{\"4\":1,\"123\":1}}],[\"5\",{\"0\":{\"167\":1,\"255\":1},\"1\":{\"4\":1,\"23\":1,\"37\":2,\"43\":1,\"54\":1,\"58\":1,\"95\":1,\"96\":1,\"102\":1,\"153\":1,\"167\":1,\"186\":1,\"212\":1,\"221\":1,\"226\":2,\"239\":1,\"244\":1,\"247\":1,\"252\":5,\"253\":1,\"256\":5}}],[\"48\",{\"1\":{\"244\":1}}],[\"4833\",{\"1\":{\"125\":1}}],[\"46\",{\"1\":{\"174\":2}}],[\"43\",{\"1\":{\"102\":1}}],[\"49\",{\"1\":{\"37\":1,\"187\":1}}],[\"416\",{\"1\":{\"37\":1}}],[\"4186\",{\"1\":{\"37\":1}}],[\"4171\",{\"1\":{\"37\":1}}],[\"44\",{\"1\":{\"22\":1,\"25\":1,\"26\":1,\"218\":2,\"244\":1}}],[\"47\",{\"1\":{\"22\":1}}],[\"4k\",{\"1\":{\"6\":1}}],[\"40th\",{\"1\":{\"105\":1}}],[\"40\",{\"1\":{\"22\":1,\"53\":1,\"93\":1,\"97\":1,\"187\":1}}],[\"40k\",{\"1\":{\"5\":1}}],[\"4000\",{\"1\":{\"13\":1}}],[\"400\",{\"1\":{\"3\":2}}],[\"42\",{\"1\":{\"5\":1,\"187\":1}}],[\"4\",{\"0\":{\"142\":1,\"162\":1,\"163\":1,\"164\":1,\"165\":1,\"166\":2,\"254\":1},\"1\":{\"4\":1,\"37\":1,\"54\":1,\"96\":1,\"97\":1,\"102\":1,\"122\":1,\"123\":1,\"124\":1,\"153\":1,\"167\":1,\"174\":1,\"186\":1,\"187\":1,\"202\":1,\"208\":1,\"210\":1,\"221\":1,\"239\":1,\"241\":1,\"247\":1,\"253\":1,\"254\":1,\"256\":3,\"266\":1,\"271\":1}}],[\"45\",{\"1\":{\"3\":1}}],[\"x^\",{\"1\":{\"266\":1,\"267\":1}}],[\"x^∼d\",{\"1\":{\"266\":1,\"267\":1}}],[\"xhosa\",{\"1\":{\"225\":2,\"227\":2}}],[\"xn\",{\"1\":{\"216\":1}}],[\"x0\",{\"1\":{\"216\":1}}],[\"x̂j\",{\"1\":{\"212\":1}}],[\"x̂k\",{\"1\":{\"212\":1}}],[\"x̂1\",{\"1\":{\"212\":1}}],[\"x̂\",{\"1\":{\"212\":4}}],[\"xk\",{\"1\":{\"212\":1}}],[\"x1\",{\"1\":{\"212\":1,\"216\":1}}],[\"xj∈d∑​log∑yj​esim\",{\"1\":{\"196\":1}}],[\"xj\",{\"1\":{\"196\":2,\"216\":2}}],[\"xs\",{\"1\":{\"183\":1}}],[\"xy\",{\"1\":{\"181\":1}}],[\"xla\",{\"1\":{\"152\":1}}],[\"xlm\",{\"1\":{\"105\":2,\"216\":1}}],[\"xi​\",{\"1\":{\"268\":2}}],[\"xi\",{\"1\":{\"196\":3,\"212\":1}}],[\"xin\",{\"1\":{\"191\":1}}],[\"xinbo\",{\"1\":{\"74\":1}}],[\"xiaohui\",{\"1\":{\"167\":1}}],[\"xiao\",{\"1\":{\"74\":1,\"203\":1,\"247\":1}}],[\"xiang\",{\"1\":{\"46\":1}}],[\"xu\",{\"1\":{\"61\":2,\"89\":1}}],[\"xuandong\",{\"1\":{\"46\":1}}],[\"xuandongzhao\",{\"1\":{\"41\":1}}],[\"xvii\",{\"1\":{\"9\":1}}],[\"x\",{\"1\":{\"3\":2,\"27\":8,\"69\":2,\"146\":1,\"165\":1,\"181\":3,\"182\":2,\"183\":4,\"184\":3,\"196\":1,\"200\":1,\"212\":4,\"216\":3,\"226\":2,\"233\":2,\"265\":2,\"266\":3,\"267\":5}}],[\"yj\",{\"1\":{\"196\":2}}],[\"yt\",{\"1\":{\"183\":4}}],[\"y>\",{\"1\":{\"146\":1}}],[\"yonghui\",{\"1\":{\"221\":1}}],[\"yoav\",{\"1\":{\"105\":1,\"221\":1}}],[\"your\",{\"1\":{\"93\":1,\"234\":1}}],[\"you\",{\"1\":{\"22\":3,\"27\":1,\"36\":1,\"37\":1,\"65\":1,\"93\":2,\"102\":1,\"119\":1,\"121\":1,\"125\":4,\"126\":1,\"127\":1,\"130\":1,\"131\":1,\"159\":1,\"160\":1,\"167\":1,\"175\":1,\"196\":1,\"197\":1,\"225\":4,\"227\":1,\"228\":14,\"229\":2,\"231\":1,\"234\":2,\"247\":2}}],[\"y∣z\",{\"1\":{\"69\":1}}],[\"yz​\",{\"1\":{\"69\":2}}],[\"yz​=nei\",{\"1\":{\"69\":1}}],[\"yz​=ref\",{\"1\":{\"69\":2}}],[\"yz​=sup\",{\"1\":{\"69\":2}}],[\"y∈sup\",{\"1\":{\"69\":1}}],[\"yan\",{\"1\":{\"235\":1}}],[\"yankai\",{\"1\":{\"61\":1}}],[\"yanghua\",{\"1\":{\"74\":1}}],[\"yangtze\",{\"1\":{\"36\":1}}],[\"yang\",{\"1\":{\"21\":1,\"37\":1,\"89\":1,\"105\":1,\"235\":1}}],[\"yao\",{\"1\":{\"53\":2,\"61\":1}}],[\"yuxiong\",{\"1\":{\"167\":1}}],[\"yuhao\",{\"1\":{\"102\":1}}],[\"yuan\",{\"1\":{\"61\":1,\"221\":1}}],[\"yu\",{\"1\":{\"46\":1,\"191\":1}}],[\"yuen\",{\"1\":{\"21\":3,\"22\":1,\"36\":2}}],[\"yi\",{\"1\":{\"247\":1}}],[\"yiyan\",{\"1\":{\"218\":1,\"221\":1}}],[\"yisi\",{\"1\":{\"105\":2,\"217\":1}}],[\"yiming\",{\"1\":{\"89\":1}}],[\"yinhan\",{\"1\":{\"37\":1}}],[\"yields\",{\"1\":{\"42\":1,\"54\":2,\"239\":1}}],[\"yield\",{\"1\":{\"22\":1,\"93\":1,\"244\":1,\"251\":1}}],[\"yes\",{\"1\":{\"172\":1}}],[\"yellow\",{\"1\":{\"94\":1}}],[\"ye\",{\"1\":{\"61\":1,\"175\":1}}],[\"years\",{\"1\":{\"36\":1,\"95\":4,\"119\":1}}],[\"year\",{\"1\":{\"24\":3}}],[\"yet\",{\"1\":{\"23\":1,\"27\":1}}],[\"y\",{\"1\":{\"3\":2,\"165\":1,\"181\":3,\"182\":2,\"183\":1,\"184\":4}}],[\"28\",{\"1\":{\"256\":1}}],[\"282\",{\"1\":{\"102\":1}}],[\"2nd\",{\"1\":{\"218\":1}}],[\"29\",{\"1\":{\"201\":1,\"218\":2,\"256\":1}}],[\"271\",{\"1\":{\"102\":1}}],[\"275\",{\"1\":{\"53\":1}}],[\"2d\",{\"1\":{\"81\":1}}],[\"26th\",{\"1\":{\"105\":1,\"167\":1}}],[\"26\",{\"1\":{\"59\":1}}],[\"22\",{\"1\":{\"54\":1,\"244\":1}}],[\"2210\",{\"1\":{\"41\":1,\"46\":1}}],[\"2284\",{\"1\":{\"35\":1}}],[\"220\",{\"1\":{\"25\":1}}],[\"216\",{\"1\":{\"271\":1}}],[\"215\",{\"1\":{\"97\":1}}],[\"2105\",{\"1\":{\"92\":1,\"146\":1,\"175\":1}}],[\"21\",{\"1\":{\"30\":6,\"256\":1}}],[\"213\",{\"1\":{\"9\":1,\"221\":1}}],[\"258\",{\"1\":{\"238\":1}}],[\"25\",{\"1\":{\"29\":1}}],[\"256\",{\"1\":{\"26\":1}}],[\"23\",{\"1\":{\"5\":1,\"9\":1,\"105\":1,\"201\":1}}],[\"24\",{\"1\":{\"5\":1,\"203\":1,\"219\":1}}],[\"2\",{\"0\":{\"6\":1,\"27\":1,\"35\":1,\"100\":1,\"133\":1,\"134\":1,\"135\":1,\"136\":2,\"140\":1,\"152\":1,\"154\":1,\"155\":1,\"156\":2,\"157\":1,\"160\":1,\"164\":1,\"245\":1,\"252\":1},\"1\":{\"5\":1,\"9\":1,\"22\":1,\"23\":2,\"30\":1,\"35\":1,\"37\":2,\"43\":5,\"51\":2,\"54\":5,\"55\":1,\"65\":1,\"67\":2,\"68\":1,\"70\":1,\"74\":1,\"79\":1,\"81\":1,\"89\":1,\"93\":1,\"94\":1,\"95\":1,\"99\":1,\"100\":1,\"101\":1,\"102\":3,\"105\":1,\"109\":2,\"113\":1,\"116\":1,\"119\":2,\"120\":1,\"124\":1,\"125\":1,\"127\":1,\"146\":5,\"151\":1,\"167\":1,\"172\":1,\"175\":1,\"187\":1,\"202\":1,\"203\":3,\"209\":1,\"212\":1,\"216\":1,\"218\":1,\"221\":1,\"226\":1,\"228\":1,\"235\":1,\"239\":1,\"241\":1,\"245\":1,\"247\":1,\"252\":1,\"253\":1,\"254\":2,\"256\":2,\"264\":1,\"266\":1,\"268\":1,\"271\":1}}],[\"2k\",{\"1\":{\"2\":1,\"6\":1}}],[\"20m\",{\"1\":{\"186\":2}}],[\"20th\",{\"1\":{\"114\":1}}],[\"2022\",{\"1\":{\"41\":1,\"46\":2,\"74\":2}}],[\"2020\",{\"1\":{\"22\":1,\"37\":4,\"49\":1,\"61\":1,\"66\":1,\"77\":1,\"81\":1,\"89\":2,\"102\":1,\"105\":4,\"167\":3,\"175\":5,\"191\":1,\"210\":1,\"214\":2,\"221\":5,\"235\":1,\"247\":1}}],[\"2021\",{\"0\":{\"276\":1},\"1\":{\"0\":1,\"102\":1,\"143\":1,\"146\":1,\"175\":2,\"203\":1,\"221\":2,\"224\":2,\"235\":1,\"238\":1,\"239\":1,\"247\":1}}],[\"204\",{\"1\":{\"9\":1}}],[\"2011\",{\"1\":{\"77\":1}}],[\"2018\",{\"1\":{\"37\":1,\"116\":1,\"167\":1}}],[\"2017\",{\"1\":{\"37\":2,\"102\":1,\"105\":2,\"119\":1,\"167\":1,\"175\":2,\"235\":1,\"247\":1,\"263\":1,\"271\":2}}],[\"2014\",{\"1\":{\"26\":1,\"37\":1,\"252\":1}}],[\"2010\",{\"1\":{\"21\":1,\"167\":1}}],[\"2019\",{\"1\":{\"9\":2,\"37\":2,\"53\":2,\"61\":1,\"78\":2,\"81\":2,\"82\":1,\"87\":1,\"89\":3,\"105\":8,\"116\":1,\"217\":1,\"219\":1,\"247\":3,\"260\":1}}],[\"2016\",{\"1\":{\"9\":2,\"26\":1,\"105\":4,\"221\":1}}],[\"2012\",{\"1\":{\"0\":1,\"64\":1}}],[\"20\",{\"1\":{\"7\":1,\"26\":1,\"27\":1,\"43\":1,\"97\":1,\"123\":2,\"167\":1,\"256\":1}}],[\"20k\",{\"1\":{\"6\":1,\"27\":1,\"29\":1}}],[\"2003\",{\"1\":{\"218\":3}}],[\"2003年8月在美国特拉华州重新注册\",{\"1\":{\"218\":1}}],[\"2006\",{\"1\":{\"175\":1}}],[\"2005\",{\"1\":{\"167\":1,\"221\":1}}],[\"2004\",{\"1\":{\"102\":1}}],[\"2002\",{\"1\":{\"59\":1,\"105\":2,\"209\":1,\"221\":1}}],[\"2009\",{\"1\":{\"49\":1,\"105\":2,\"143\":1,\"175\":1}}],[\"2000\",{\"1\":{\"30\":2}}],[\"200\",{\"1\":{\"3\":1,\"93\":1}}],[\"1s\",{\"1\":{\"146\":1}}],[\"1710\",{\"1\":{\"271\":1}}],[\"1711\",{\"1\":{\"271\":1}}],[\"1703\",{\"1\":{\"175\":1}}],[\"175\",{\"1\":{\"123\":1}}],[\"1774\",{\"1\":{\"93\":1}}],[\"17\",{\"1\":{\"78\":1,\"113\":2,\"114\":1,\"252\":3}}],[\"1−qϕ​\",{\"1\":{\"69\":1}}],[\"1693\",{\"1\":{\"221\":1}}],[\"165m\",{\"1\":{\"97\":1}}],[\"16\",{\"1\":{\"54\":1,\"86\":1,\"95\":1,\"97\":1,\"195\":1,\"244\":2,\"252\":5}}],[\"13788\",{\"1\":{\"250\":1}}],[\"13752\",{\"1\":{\"49\":1}}],[\"13887\",{\"1\":{\"167\":1}}],[\"139m\",{\"1\":{\"112\":1}}],[\"13\",{\"1\":{\"95\":1,\"200\":1,\"202\":1,\"244\":1}}],[\"13577\",{\"1\":{\"64\":1}}],[\"132\",{\"1\":{\"53\":1}}],[\"153\",{\"1\":{\"219\":1}}],[\"15\",{\"1\":{\"35\":1,\"92\":1,\"113\":2,\"114\":1,\"198\":1,\"203\":1,\"206\":1,\"252\":4,\"256\":1}}],[\"15671\",{\"1\":{\"0\":1}}],[\"11477\",{\"1\":{\"175\":1}}],[\"11942\",{\"1\":{\"116\":1}}],[\"1168\",{\"1\":{\"105\":1}}],[\"1159\",{\"1\":{\"105\":1}}],[\"115\",{\"1\":{\"105\":1}}],[\"110\",{\"1\":{\"25\":1}}],[\"11\",{\"1\":{\"23\":1,\"58\":1,\"122\":1,\"166\":1}}],[\"1970\",{\"1\":{\"271\":1}}],[\"1910\",{\"1\":{\"247\":1}}],[\"1998\",{\"1\":{\"218\":3}}],[\"1966\",{\"1\":{\"208\":1,\"221\":2}}],[\"1909\",{\"1\":{\"116\":1,\"247\":1,\"250\":1}}],[\"1908\",{\"1\":{\"12\":1}}],[\"19th\",{\"1\":{\"114\":1}}],[\"1920\",{\"1\":{\"21\":1}}],[\"19\",{\"1\":{\"9\":1,\"54\":1,\"218\":2,\"252\":1}}],[\"18653\",{\"1\":{\"221\":1}}],[\"1867\",{\"1\":{\"71\":2}}],[\"1810\",{\"1\":{\"167\":1}}],[\"185\",{\"1\":{\"271\":1}}],[\"1859\",{\"1\":{\"93\":1}}],[\"1854\",{\"1\":{\"93\":1}}],[\"1807\",{\"1\":{\"93\":1}}],[\"18th\",{\"1\":{\"71\":1}}],[\"18\",{\"1\":{\"7\":1}}],[\"10~25\",{\"1\":{\"269\":1}}],[\"1082\",{\"1\":{\"221\":1}}],[\"1024\",{\"1\":{\"195\":1}}],[\"105\",{\"1\":{\"105\":1}}],[\"100k\",{\"1\":{\"252\":1,\"256\":1}}],[\"100m\",{\"1\":{\"112\":1}}],[\"100\",{\"1\":{\"93\":2,\"97\":1,\"120\":1,\"140\":1,\"167\":1,\"198\":2,\"218\":2,\"269\":1}}],[\"10th\",{\"1\":{\"93\":1}}],[\"10+\",{\"1\":{\"27\":1}}],[\"10\",{\"1\":{\"12\":1,\"13\":1,\"22\":2,\"23\":1,\"25\":2,\"27\":1,\"37\":1,\"43\":5,\"64\":1,\"95\":1,\"120\":1,\"199\":2,\"200\":1,\"202\":1,\"218\":3,\"221\":2,\"228\":2,\"238\":1,\"239\":1,\"244\":1,\"250\":1}}],[\"10k\",{\"1\":{\"6\":1}}],[\"10x\",{\"1\":{\"5\":1}}],[\"1416\",{\"1\":{\"221\":1}}],[\"14165\",{\"1\":{\"167\":1}}],[\"149\",{\"1\":{\"213\":1}}],[\"144\",{\"1\":{\"208\":1}}],[\"14\",{\"1\":{\"4\":1,\"30\":1,\"95\":1,\"142\":1,\"213\":1}}],[\"128\",{\"1\":{\"112\":1,\"140\":2}}],[\"12460\",{\"1\":{\"102\":1}}],[\"12449\",{\"1\":{\"102\":1}}],[\"12\",{\"1\":{\"2\":1,\"4\":1,\"9\":1,\"25\":1,\"27\":1,\"30\":1,\"37\":1,\"43\":1,\"86\":1,\"112\":2,\"195\":2}}],[\"1k\",{\"1\":{\"2\":1,\"6\":1}}],[\"1\",{\"0\":{\"5\":1,\"26\":1,\"34\":1,\"99\":1,\"131\":1,\"132\":2,\"133\":1,\"135\":1,\"139\":1,\"141\":1,\"150\":1,\"151\":2,\"152\":1,\"153\":1,\"155\":1,\"159\":1,\"163\":1,\"244\":1,\"251\":1},\"1\":{\"1\":1,\"9\":3,\"18\":1,\"22\":2,\"23\":1,\"24\":1,\"25\":2,\"30\":2,\"35\":2,\"37\":2,\"41\":1,\"42\":2,\"46\":1,\"51\":2,\"53\":3,\"55\":1,\"58\":1,\"65\":1,\"66\":1,\"67\":1,\"70\":1,\"74\":1,\"79\":1,\"81\":1,\"93\":2,\"95\":1,\"97\":2,\"99\":1,\"101\":1,\"102\":1,\"105\":2,\"109\":3,\"112\":1,\"113\":1,\"116\":1,\"120\":1,\"125\":4,\"127\":1,\"140\":1,\"146\":6,\"151\":1,\"152\":1,\"153\":1,\"167\":1,\"171\":1,\"174\":3,\"186\":3,\"198\":1,\"202\":3,\"203\":1,\"208\":2,\"216\":4,\"217\":1,\"218\":1,\"221\":1,\"226\":2,\"235\":1,\"238\":1,\"239\":1,\"240\":1,\"244\":3,\"247\":1,\"250\":1,\"251\":1,\"252\":1,\"253\":2,\"254\":2,\"260\":1,\"271\":2}}],[\"37\",{\"1\":{\"218\":2}}],[\"360\",{\"1\":{\"166\":1}}],[\"36\",{\"1\":{\"146\":2,\"221\":1}}],[\"3×3\",{\"1\":{\"140\":1}}],[\"31404350\",{\"1\":{\"271\":1}}],[\"31\",{\"1\":{\"187\":1}}],[\"318\",{\"1\":{\"105\":1}}],[\"311\",{\"1\":{\"105\":1}}],[\"385\",{\"1\":{\"93\":1,\"97\":1}}],[\"38\",{\"1\":{\"93\":1}}],[\"384\",{\"1\":{\"1\":1,\"2\":1}}],[\"34m\",{\"1\":{\"186\":1}}],[\"3457\",{\"1\":{\"125\":1}}],[\"34\",{\"1\":{\"55\":1}}],[\"35\",{\"1\":{\"221\":1}}],[\"3553\",{\"1\":{\"125\":1}}],[\"354\",{\"1\":{\"53\":1}}],[\"351\",{\"1\":{\"37\":1}}],[\"399\",{\"1\":{\"37\":1}}],[\"339\",{\"1\":{\"37\":1}}],[\"33\",{\"1\":{\"36\":1,\"102\":1,\"187\":2,\"218\":1}}],[\"32\",{\"1\":{\"22\":1,\"25\":2,\"95\":1,\"198\":1}}],[\"3k\",{\"1\":{\"2\":1,\"6\":1}}],[\"3090\",{\"1\":{\"218\":2}}],[\"300+\",{\"1\":{\"6\":1}}],[\"30k\",{\"1\":{\"5\":4,\"6\":1,\"146\":1}}],[\"30\",{\"1\":{\"1\":1,\"18\":1,\"26\":1,\"146\":1,\"187\":1,\"198\":1}}],[\"3\",{\"0\":{\"7\":1,\"28\":1,\"138\":1,\"139\":1,\"140\":1,\"141\":1,\"153\":1,\"157\":1,\"158\":1,\"159\":1,\"160\":1,\"161\":2,\"165\":1,\"253\":1},\"1\":{\"1\":1,\"22\":2,\"24\":1,\"25\":1,\"26\":2,\"30\":1,\"35\":1,\"37\":1,\"53\":1,\"54\":1,\"68\":1,\"93\":1,\"95\":2,\"97\":1,\"102\":1,\"113\":1,\"119\":4,\"120\":3,\"121\":4,\"122\":2,\"123\":5,\"124\":11,\"125\":5,\"126\":7,\"146\":3,\"151\":1,\"159\":2,\"163\":1,\"167\":1,\"172\":1,\"174\":3,\"187\":1,\"199\":1,\"202\":4,\"203\":1,\"209\":1,\"217\":1,\"221\":1,\"235\":1,\"239\":1,\"241\":1,\"247\":1,\"252\":2,\"254\":1,\"256\":5,\"265\":1,\"267\":1,\"268\":1,\"269\":1,\"271\":2}}],[\"khawarizmi\",{\"1\":{\"228\":3}}],[\"klein\",{\"1\":{\"221\":1}}],[\"klaus\",{\"1\":{\"221\":1}}],[\"krikun\",{\"1\":{\"221\":1}}],[\"knew\",{\"1\":{\"215\":1}}],[\"knows\",{\"1\":{\"71\":1}}],[\"knowldge\",{\"1\":{\"69\":1}}],[\"knowledge\",{\"1\":{\"49\":2,\"68\":1,\"71\":2,\"72\":4,\"93\":2,\"98\":2,\"101\":1,\"114\":1,\"124\":1,\"135\":1,\"142\":1,\"167\":1,\"269\":1}}],[\"knowing\",{\"1\":{\"3\":1}}],[\"known\",{\"1\":{\"3\":1,\"41\":1,\"232\":1}}],[\"know\",{\"1\":{\"1\":2,\"3\":1,\"71\":3,\"93\":2,\"268\":1}}],[\"kdd\",{\"1\":{\"167\":1}}],[\"koncerte\",{\"1\":{\"125\":1}}],[\"kong\",{\"1\":{\"93\":1}}],[\"kuracie\",{\"1\":{\"125\":1}}],[\"kullback\",{\"1\":{\"42\":1}}],[\"kúpim\",{\"1\":{\"125\":1}}],[\"kúpiť\",{\"1\":{\"125\":1}}],[\"kilian\",{\"1\":{\"105\":1,\"221\":1}}],[\"kiu\",{\"1\":{\"105\":1}}],[\"kishore\",{\"1\":{\"105\":2,\"209\":1,\"221\":2}}],[\"kind\",{\"1\":{\"105\":1}}],[\"kinds\",{\"1\":{\"51\":1,\"101\":1,\"225\":1,\"226\":1}}],[\"kindly\",{\"1\":{\"22\":1,\"93\":1}}],[\"kaiser\",{\"1\":{\"102\":1}}],[\"kaitao\",{\"1\":{\"37\":1}}],[\"kawin\",{\"1\":{\"89\":1}}],[\"kendall\",{\"1\":{\"217\":1}}],[\"kernel\",{\"1\":{\"155\":4,\"203\":1}}],[\"keeps\",{\"1\":{\"188\":1,\"258\":1}}],[\"keep\",{\"1\":{\"146\":1,\"184\":1}}],[\"keď\",{\"1\":{\"125\":2}}],[\"kevin\",{\"1\":{\"89\":1}}],[\"keys\",{\"1\":{\"96\":1,\"240\":2}}],[\"key\",{\"0\":{\"226\":1},\"1\":{\"1\":2,\"8\":2,\"22\":1,\"30\":1,\"42\":1,\"54\":1,\"93\":1,\"96\":1,\"120\":1,\"134\":1,\"146\":1,\"225\":1,\"232\":1,\"250\":1,\"264\":2}}],[\"kgat\",{\"1\":{\"72\":1}}],[\"k\",{\"1\":{\"42\":1,\"83\":1,\"120\":3,\"156\":2,\"216\":3,\"225\":1,\"240\":4,\"242\":1}}],[\"ucsb\",{\"1\":{\"221\":1,\"229\":1}}],[\"uation\",{\"1\":{\"221\":1}}],[\"uvidím\",{\"1\":{\"125\":1}}],[\"učiť\",{\"1\":{\"125\":1}}],[\"uiuc\",{\"1\":{\"93\":1}}],[\"u\",{\"1\":{\"50\":4,\"216\":2}}],[\"ultimately\",{\"1\":{\"126\":1}}],[\"ultimate\",{\"1\":{\"36\":2}}],[\"utilizing\",{\"1\":{\"124\":1,\"172\":1}}],[\"utilize\",{\"1\":{\"54\":1,\"93\":1,\"111\":1,\"124\":1,\"131\":1,\"137\":1,\"171\":1,\"183\":1,\"251\":1,\"263\":1}}],[\"utilized\",{\"1\":{\"24\":1,\"79\":1,\"94\":1}}],[\"utilizes\",{\"1\":{\"8\":1,\"60\":1,\"171\":1,\"175\":1,\"190\":1}}],[\"utility\",{\"1\":{\"3\":4}}],[\"unchanged\",{\"1\":{\"266\":1}}],[\"unclear\",{\"1\":{\"258\":1}}],[\"unpaired\",{\"1\":{\"263\":1}}],[\"unannotated\",{\"1\":{\"251\":1}}],[\"unattainable\",{\"1\":{\"218\":1}}],[\"unnormalized\",{\"1\":{\"240\":1}}],[\"untranslated\",{\"1\":{\"227\":2,\"232\":1}}],[\"until\",{\"1\":{\"43\":1,\"126\":1,\"146\":1}}],[\"unbabel\",{\"1\":{\"220\":1}}],[\"unreasonably\",{\"1\":{\"209\":1}}],[\"unrelated\",{\"1\":{\"188\":1}}],[\"unseen\",{\"1\":{\"146\":1,\"226\":2}}],[\"unsupervised\",{\"0\":{\"200\":1,\"263\":1},\"1\":{\"24\":1,\"84\":1,\"122\":1,\"130\":2,\"190\":1,\"200\":2,\"202\":3,\"203\":1,\"263\":1,\"264\":1,\"269\":3,\"270\":2,\"271\":1},\"2\":{\"273\":1}}],[\"unfiltered\",{\"1\":{\"119\":1}}],[\"unfortunately\",{\"1\":{\"94\":1,\"218\":1}}],[\"unwatermarked\",{\"1\":{\"43\":1}}],[\"une\",{\"1\":{\"31\":2}}],[\"underlying\",{\"1\":{\"137\":1}}],[\"underperformed\",{\"1\":{\"122\":1,\"146\":1}}],[\"underperform\",{\"1\":{\"78\":1}}],[\"undertaking\",{\"1\":{\"41\":1}}],[\"under\",{\"1\":{\"27\":1,\"31\":1,\"95\":1,\"111\":1,\"113\":1,\"137\":1,\"175\":1,\"188\":1,\"218\":1}}],[\"understudy\",{\"1\":{\"209\":1}}],[\"understood\",{\"1\":{\"22\":1,\"208\":1}}],[\"understandable\",{\"1\":{\"229\":1}}],[\"understanding\",{\"1\":{\"37\":2,\"49\":1,\"130\":1,\"132\":1,\"167\":1,\"171\":1}}],[\"understand\",{\"1\":{\"3\":2,\"28\":1,\"72\":1,\"95\":3,\"111\":1,\"124\":1,\"170\":1,\"171\":1,\"172\":3,\"175\":1,\"226\":2,\"252\":1,\"253\":1}}],[\"unlabeled\",{\"1\":{\"23\":1,\"250\":1,\"251\":2,\"252\":1,\"253\":1}}],[\"unlike\",{\"1\":{\"22\":1,\"24\":1,\"93\":1,\"119\":1}}],[\"university\",{\"1\":{\"221\":1,\"263\":1}}],[\"universal\",{\"0\":{\"108\":1},\"1\":{\"24\":1,\"109\":5,\"112\":1,\"116\":1,\"146\":2,\"201\":1}}],[\"unigram\",{\"1\":{\"211\":1}}],[\"unimportant\",{\"1\":{\"146\":1}}],[\"unimodal\",{\"1\":{\"94\":4,\"96\":1}}],[\"union\",{\"1\":{\"95\":1}}],[\"uniformly\",{\"1\":{\"113\":1}}],[\"unify\",{\"1\":{\"94\":1}}],[\"unifying\",{\"1\":{\"93\":1}}],[\"unified\",{\"1\":{\"21\":1,\"22\":1,\"23\":1,\"36\":1,\"105\":1,\"146\":2,\"175\":1,\"181\":1,\"194\":3,\"200\":1,\"202\":2,\"203\":1}}],[\"unites\",{\"1\":{\"101\":1}}],[\"united\",{\"1\":{\"36\":1,\"71\":2,\"208\":1}}],[\"units\",{\"1\":{\"9\":1,\"66\":1}}],[\"unit\",{\"1\":{\"3\":1}}],[\"unused\",{\"1\":{\"3\":1}}],[\"unk\",{\"1\":{\"1\":5}}],[\"unknown\",{\"1\":{\"1\":1,\"114\":1,\"212\":1,\"231\":1}}],[\"upsampling\",{\"1\":{\"140\":1}}],[\"updated\",{\"1\":{\"146\":1,\"179\":1}}],[\"updates\",{\"1\":{\"146\":1,\"242\":1,\"246\":1}}],[\"update\",{\"1\":{\"120\":2,\"146\":2}}],[\"updating\",{\"1\":{\"111\":1}}],[\"upon\",{\"1\":{\"105\":1,\"119\":1,\"132\":1,\"184\":1,\"269\":1}}],[\"upper\",{\"1\":{\"36\":1,\"171\":1}}],[\"up\",{\"1\":{\"2\":1,\"8\":2,\"34\":1,\"86\":1,\"96\":1,\"124\":4,\"125\":1,\"202\":1,\"219\":1,\"228\":3,\"231\":1,\"233\":1,\"244\":1}}],[\"usual\",{\"1\":{\"131\":1,\"258\":1}}],[\"usually\",{\"1\":{\"81\":1,\"120\":1,\"124\":1,\"134\":1,\"156\":1}}],[\"uszkoreit\",{\"1\":{\"102\":1}}],[\"usa\",{\"1\":{\"105\":1,\"218\":2}}],[\"usable\",{\"1\":{\"25\":1,\"225\":1,\"231\":1}}],[\"usages\",{\"1\":{\"216\":1}}],[\"usage\",{\"1\":{\"3\":2,\"157\":1,\"211\":1,\"232\":1}}],[\"us\",{\"1\":{\"2\":1,\"71\":1,\"101\":1,\"126\":1,\"170\":1,\"233\":1}}],[\"user\",{\"1\":{\"232\":1}}],[\"users\",{\"1\":{\"157\":1}}],[\"useful\",{\"1\":{\"41\":1,\"82\":1,\"251\":1,\"269\":1,\"270\":1}}],[\"used\",{\"0\":{\"5\":1},\"1\":{\"3\":2,\"22\":2,\"24\":1,\"25\":1,\"27\":1,\"42\":2,\"43\":2,\"70\":1,\"78\":1,\"96\":1,\"97\":1,\"105\":1,\"110\":1,\"113\":1,\"115\":1,\"119\":1,\"122\":1,\"124\":2,\"126\":2,\"146\":1,\"151\":1,\"172\":1,\"209\":1,\"210\":1,\"212\":1,\"218\":2,\"219\":1,\"227\":1,\"228\":1,\"232\":2,\"240\":1,\"250\":1,\"251\":1,\"263\":1}}],[\"uses\",{\"1\":{\"1\":2,\"23\":2,\"25\":1,\"26\":2,\"41\":1,\"60\":1,\"66\":1,\"67\":1,\"97\":1,\"112\":1,\"146\":1,\"154\":1,\"155\":2,\"172\":1,\"211\":1,\"212\":1,\"215\":1,\"218\":1,\"227\":1}}],[\"use\",{\"1\":{\"1\":3,\"2\":2,\"3\":1,\"8\":1,\"23\":4,\"25\":1,\"35\":1,\"40\":1,\"41\":5,\"43\":1,\"45\":2,\"51\":1,\"54\":1,\"65\":1,\"66\":1,\"98\":2,\"105\":1,\"109\":3,\"110\":1,\"111\":2,\"112\":1,\"113\":3,\"120\":1,\"121\":1,\"124\":1,\"130\":1,\"152\":1,\"171\":1,\"178\":1,\"187\":1,\"194\":1,\"198\":1,\"212\":1,\"218\":2,\"226\":1,\"227\":1,\"231\":2,\"233\":3,\"252\":2,\"253\":1,\"263\":1}}],[\"using\",{\"0\":{\"158\":1,\"160\":1,\"161\":1,\"263\":1},\"1\":{\"1\":1,\"2\":1,\"3\":1,\"24\":1,\"25\":2,\"43\":2,\"44\":1,\"54\":3,\"66\":1,\"86\":1,\"89\":1,\"93\":1,\"96\":1,\"105\":3,\"110\":1,\"113\":2,\"119\":1,\"123\":1,\"124\":2,\"125\":1,\"126\":1,\"137\":1,\"146\":1,\"154\":1,\"156\":2,\"157\":1,\"160\":1,\"161\":1,\"163\":1,\"164\":2,\"172\":1,\"179\":1,\"186\":1,\"216\":1,\"227\":1,\"231\":1,\"242\":1,\"252\":2,\"253\":1,\"266\":1,\"269\":1,\"271\":1}}],[\"dnc\",{\"1\":{\"266\":1}}],[\"dnes\",{\"1\":{\"125\":1}}],[\"d\",{\"1\":{\"181\":3,\"216\":3,\"221\":1,\"240\":1,\"244\":4}}],[\"dqqcasia\",{\"1\":{\"175\":2}}],[\"dynamic\",{\"0\":{\"157\":1},\"1\":{\"152\":1,\"157\":1}}],[\"dynamically\",{\"1\":{\"42\":1}}],[\"dsi\",{\"1\":{\"146\":2}}],[\"dátumom\",{\"1\":{\"125\":1}}],[\"dbnary\",{\"1\":{\"105\":1}}],[\"dl4mt21fa\",{\"1\":{\"221\":1}}],[\"dl4mt\",{\"0\":{\"277\":1},\"2\":{\"103\":1,\"106\":1,\"117\":1,\"128\":1,\"144\":1,\"147\":1,\"168\":1,\"176\":1,\"192\":1,\"204\":1,\"222\":1,\"236\":1,\"248\":1,\"261\":1,\"272\":1}}],[\"druhej\",{\"1\":{\"125\":1}}],[\"dramatically\",{\"1\":{\"105\":1,\"146\":1}}],[\"dramatic\",{\"1\":{\"98\":1,\"146\":2,\"219\":1}}],[\"drawing\",{\"1\":{\"101\":1}}],[\"draw\",{\"1\":{\"71\":1,\"93\":1}}],[\"drawbacks\",{\"1\":{\"211\":1}}],[\"drawback\",{\"1\":{\"68\":1,\"71\":1}}],[\"drawn\",{\"1\":{\"34\":1,\"146\":1}}],[\"draws\",{\"0\":{\"34\":1,\"35\":1},\"1\":{\"34\":1,\"35\":1}}],[\"dreaminvoker\",{\"1\":{\"49\":1}}],[\"drw\",{\"0\":{\"42\":1},\"1\":{\"41\":4,\"42\":4,\"43\":6,\"45\":1}}],[\"dropped\",{\"1\":{\"254\":1}}],[\"dropout\",{\"1\":{\"252\":7,\"253\":5,\"254\":5}}],[\"drops\",{\"1\":{\"146\":3,\"253\":2}}],[\"drop\",{\"1\":{\"3\":1,\"43\":2,\"58\":1,\"146\":2,\"266\":1}}],[\"déterminer\",{\"1\":{\"31\":1}}],[\"dakun\",{\"1\":{\"221\":1}}],[\"darr\",{\"1\":{\"217\":2}}],[\"dai\",{\"1\":{\"191\":1}}],[\"daily\",{\"1\":{\"95\":1,\"130\":1,\"170\":1}}],[\"das\",{\"1\":{\"105\":1}}],[\"dashed\",{\"1\":{\"100\":1}}],[\"day\",{\"1\":{\"95\":1,\"105\":1}}],[\"days\",{\"1\":{\"26\":1}}],[\"da\",{\"1\":{\"30\":2,\"105\":1,\"215\":1,\"216\":1,\"217\":1,\"218\":8,\"221\":1}}],[\"dat\",{\"1\":{\"258\":2}}],[\"date\",{\"1\":{\"30\":1,\"59\":1,\"125\":2,\"126\":1}}],[\"data\",{\"0\":{\"170\":1,\"226\":1,\"227\":1},\"1\":{\"4\":1,\"21\":1,\"22\":2,\"23\":6,\"24\":2,\"25\":2,\"26\":2,\"35\":1,\"41\":1,\"43\":2,\"44\":2,\"78\":1,\"93\":6,\"94\":5,\"97\":1,\"98\":2,\"101\":1,\"113\":2,\"119\":1,\"120\":2,\"130\":1,\"146\":1,\"153\":1,\"167\":1,\"171\":3,\"172\":5,\"175\":2,\"178\":2,\"186\":2,\"187\":2,\"188\":4,\"189\":1,\"197\":1,\"200\":2,\"202\":1,\"203\":2,\"209\":1,\"218\":1,\"221\":1,\"225\":1,\"226\":1,\"227\":8,\"230\":1,\"232\":1,\"244\":1,\"250\":2,\"251\":5,\"252\":4,\"253\":1,\"257\":1,\"258\":1,\"259\":1,\"263\":1,\"264\":1,\"271\":1}}],[\"dataseta\",{\"1\":{\"114\":1}}],[\"dataset\",{\"0\":{\"53\":1,\"97\":1,\"186\":1},\"1\":{\"4\":3,\"42\":2,\"53\":2,\"60\":1,\"61\":1,\"70\":1,\"93\":2,\"94\":1,\"97\":1,\"99\":4,\"113\":3,\"114\":1,\"119\":2,\"120\":1,\"122\":1,\"124\":2,\"126\":2,\"146\":3,\"160\":1,\"174\":1,\"186\":1,\"194\":1,\"198\":2,\"202\":1,\"203\":1,\"213\":1,\"218\":1,\"250\":1,\"252\":1,\"253\":1,\"258\":2}}],[\"datasets\",{\"0\":{\"139\":1,\"198\":1},\"1\":{\"4\":1,\"93\":1,\"97\":1,\"113\":1,\"130\":1,\"139\":2,\"146\":2,\"198\":2,\"203\":1,\"217\":1,\"226\":1,\"244\":1,\"256\":1,\"269\":1}}],[\"dumplings\",{\"1\":{\"95\":1}}],[\"du\",{\"1\":{\"29\":2}}],[\"dutch\",{\"0\":{\"30\":1},\"1\":{\"25\":2,\"27\":1,\"35\":1,\"97\":1,\"114\":1}}],[\"due\",{\"1\":{\"23\":2,\"83\":1,\"94\":3,\"98\":1,\"152\":1,\"209\":1,\"212\":1,\"225\":1,\"245\":1}}],[\"during\",{\"0\":{\"27\":1},\"1\":{\"21\":1,\"27\":4,\"113\":2,\"114\":2,\"146\":4,\"175\":1,\"181\":1,\"184\":1,\"188\":2,\"190\":1,\"216\":1,\"227\":1,\"228\":1,\"233\":1,\"242\":1,\"259\":1,\"263\":1,\"266\":1}}],[\"dublin\",{\"1\":{\"9\":1}}],[\"defaulted\",{\"1\":{\"254\":1}}],[\"definitely\",{\"1\":{\"234\":1}}],[\"definition\",{\"0\":{\"135\":1},\"1\":{\"124\":1}}],[\"defines\",{\"1\":{\"157\":1}}],[\"define\",{\"1\":{\"3\":1,\"42\":1,\"112\":1}}],[\"defined\",{\"1\":{\"3\":3,\"83\":1,\"84\":2,\"111\":1,\"217\":1}}],[\"deficiency\",{\"1\":{\"88\":1}}],[\"deemed\",{\"1\":{\"238\":1}}],[\"deepspeed\",{\"1\":{\"153\":1,\"167\":1}}],[\"deepjudge\",{\"1\":{\"43\":3}}],[\"deep\",{\"1\":{\"37\":1,\"84\":1,\"105\":1,\"131\":1,\"152\":1,\"155\":1,\"167\":2,\"251\":1}}],[\"deeper\",{\"0\":{\"112\":1},\"1\":{\"23\":1}}],[\"delete\",{\"1\":{\"227\":1}}],[\"delaware\",{\"1\":{\"218\":5}}],[\"delay\",{\"0\":{\"166\":1},\"1\":{\"166\":1}}],[\"debatable\",{\"1\":{\"218\":1}}],[\"degree\",{\"1\":{\"210\":1,\"219\":1}}],[\"degradation\",{\"1\":{\"146\":2}}],[\"degeneration\",{\"1\":{\"89\":1}}],[\"dearth\",{\"1\":{\"94\":1}}],[\"der\",{\"1\":{\"93\":1}}],[\"derived\",{\"1\":{\"182\":1}}],[\"derive\",{\"1\":{\"42\":1,\"119\":1}}],[\"derivation\",{\"1\":{\"3\":1}}],[\"deng\",{\"1\":{\"235\":1}}],[\"denmark\",{\"1\":{\"105\":1}}],[\"denkowski\",{\"1\":{\"105\":2}}],[\"dense\",{\"1\":{\"112\":1,\"119\":1}}],[\"densely\",{\"1\":{\"83\":1}}],[\"density\",{\"1\":{\"84\":1,\"203\":2}}],[\"denotations\",{\"1\":{\"110\":1}}],[\"denoted\",{\"1\":{\"112\":1,\"156\":2,\"242\":1}}],[\"denotes\",{\"1\":{\"100\":2,\"216\":3,\"242\":2,\"265\":1}}],[\"denote\",{\"1\":{\"1\":1,\"100\":1,\"109\":1,\"110\":2,\"111\":2,\"196\":1,\"266\":1}}],[\"denoising\",{\"1\":{\"37\":2,\"227\":1}}],[\"demanded\",{\"1\":{\"170\":1}}],[\"demand\",{\"1\":{\"170\":1}}],[\"demonstrations\",{\"1\":{\"120\":6,\"126\":1}}],[\"demonstration\",{\"1\":{\"110\":1,\"123\":1}}],[\"demonstrating\",{\"1\":{\"95\":1,\"98\":1,\"244\":1,\"269\":1}}],[\"demonstrated\",{\"1\":{\"100\":1,\"146\":2,\"209\":1,\"265\":1,\"266\":1,\"267\":1}}],[\"demonstrate\",{\"1\":{\"86\":1,\"99\":1,\"146\":2,\"202\":1,\"203\":1,\"245\":1}}],[\"demonstrates\",{\"1\":{\"45\":1,\"95\":1,\"146\":3,\"188\":1,\"201\":1,\"213\":1,\"258\":1,\"266\":1,\"269\":1}}],[\"demo\",{\"1\":{\"64\":1}}],[\"deming\",{\"1\":{\"61\":1}}],[\"deduce\",{\"1\":{\"59\":1}}],[\"depicts\",{\"1\":{\"203\":1,\"240\":1,\"245\":1}}],[\"depictable\",{\"1\":{\"142\":1}}],[\"depth\",{\"1\":{\"130\":1}}],[\"depend\",{\"1\":{\"218\":1}}],[\"depending\",{\"1\":{\"126\":1,\"209\":1}}],[\"dependencies\",{\"1\":{\"211\":3}}],[\"dependency\",{\"1\":{\"51\":1,\"57\":1,\"172\":1}}],[\"dependent\",{\"1\":{\"96\":1,\"146\":1,\"157\":1}}],[\"depends\",{\"1\":{\"23\":1,\"94\":1,\"142\":1,\"238\":1,\"263\":1}}],[\"deployment\",{\"1\":{\"194\":1}}],[\"deploying\",{\"1\":{\"45\":1,\"166\":1}}],[\"deployed\",{\"1\":{\"41\":2,\"153\":1}}],[\"dev\",{\"1\":{\"54\":2,\"71\":1}}],[\"devlin\",{\"1\":{\"37\":1,\"105\":1,\"167\":1}}],[\"developmental\",{\"1\":{\"95\":1}}],[\"development\",{\"1\":{\"53\":1,\"70\":1,\"71\":1,\"105\":1,\"133\":1,\"206\":1,\"208\":1,\"219\":2}}],[\"developing\",{\"1\":{\"41\":1,\"94\":1}}],[\"develop\",{\"1\":{\"22\":1,\"64\":1,\"92\":1,\"93\":1,\"194\":1,\"210\":1,\"211\":1,\"219\":1}}],[\"developed\",{\"1\":{\"3\":1,\"22\":1,\"65\":1,\"69\":1,\"208\":1,\"209\":1,\"216\":1,\"263\":1}}],[\"deixis\",{\"1\":{\"31\":2}}],[\"determining\",{\"1\":{\"124\":1}}],[\"determine\",{\"1\":{\"124\":2,\"231\":1}}],[\"determined\",{\"1\":{\"34\":1,\"184\":1}}],[\"determines\",{\"1\":{\"27\":1,\"197\":1}}],[\"detector\",{\"1\":{\"130\":1}}],[\"detectable\",{\"1\":{\"45\":1}}],[\"detected\",{\"1\":{\"43\":1}}],[\"detecting\",{\"1\":{\"42\":1,\"43\":1,\"123\":1}}],[\"detection\",{\"1\":{\"42\":2,\"43\":5,\"44\":2,\"45\":1,\"130\":1}}],[\"detect\",{\"1\":{\"41\":1,\"42\":1,\"43\":1,\"65\":1,\"71\":2}}],[\"detail\",{\"1\":{\"30\":1,\"69\":1,\"231\":1}}],[\"detailed\",{\"1\":{\"24\":1,\"112\":1,\"140\":1,\"146\":1}}],[\"details\",{\"0\":{\"154\":1},\"1\":{\"3\":1,\"130\":1,\"212\":1,\"233\":1}}],[\"desired\",{\"1\":{\"120\":1}}],[\"designs\",{\"1\":{\"183\":1}}],[\"design\",{\"0\":{\"112\":1},\"1\":{\"24\":3,\"95\":3,\"96\":2,\"98\":1,\"109\":1,\"111\":1,\"112\":1,\"146\":1}}],[\"designed\",{\"1\":{\"22\":1,\"41\":1,\"43\":1,\"93\":1,\"100\":1,\"124\":1,\"130\":1,\"231\":1,\"251\":1}}],[\"describing\",{\"1\":{\"121\":1}}],[\"describe\",{\"1\":{\"111\":1}}],[\"described\",{\"1\":{\"93\":1,\"233\":1}}],[\"describes\",{\"1\":{\"49\":1}}],[\"description\",{\"1\":{\"111\":1,\"123\":1,\"155\":1}}],[\"despite\",{\"1\":{\"71\":1,\"78\":1,\"93\":1}}],[\"desperately\",{\"1\":{\"24\":1}}],[\"des\",{\"1\":{\"37\":1}}],[\"de\",{\"0\":{\"26\":1},\"1\":{\"18\":1,\"26\":1,\"29\":1,\"30\":6,\"31\":3,\"37\":2,\"97\":1,\"98\":2,\"114\":1,\"186\":4,\"187\":3}}],[\"decades\",{\"1\":{\"170\":1,\"225\":1}}],[\"decent\",{\"1\":{\"71\":1}}],[\"decouple\",{\"1\":{\"175\":1}}],[\"decouples\",{\"1\":{\"171\":1,\"175\":1}}],[\"decoding\",{\"0\":{\"184\":1},\"1\":{\"100\":1,\"181\":1,\"184\":3,\"188\":3,\"190\":1,\"240\":1,\"252\":1,\"253\":8}}],[\"decode\",{\"1\":{\"253\":1,\"263\":1}}],[\"decodes\",{\"1\":{\"96\":1,\"208\":1,\"265\":1}}],[\"decoders\",{\"1\":{\"153\":1,\"244\":1,\"269\":1}}],[\"decoder采用\",{\"1\":{\"18\":1}}],[\"decoder\",{\"1\":{\"18\":5,\"23\":1,\"96\":3,\"97\":1,\"110\":2,\"111\":4,\"112\":6,\"113\":1,\"136\":3,\"146\":4,\"153\":1,\"171\":1,\"172\":3,\"195\":1,\"233\":1,\"239\":1,\"240\":4,\"244\":1,\"245\":4,\"263\":2,\"264\":1,\"265\":3,\"266\":4,\"267\":1}}],[\"decompose\",{\"1\":{\"67\":1,\"181\":1}}],[\"decomposes\",{\"1\":{\"66\":1,\"67\":1}}],[\"decomposition\",{\"0\":{\"67\":1},\"1\":{\"67\":2,\"82\":1}}],[\"decided\",{\"1\":{\"125\":1}}],[\"decide\",{\"1\":{\"8\":1,\"146\":1}}],[\"decreased\",{\"1\":{\"123\":1,\"166\":1}}],[\"decrease\",{\"1\":{\"2\":1,\"55\":1,\"57\":1}}],[\"dictionary\",{\"1\":{\"197\":3,\"228\":2,\"231\":5}}],[\"dictionaries\",{\"1\":{\"24\":1}}],[\"dim\",{\"1\":{\"203\":1}}],[\"diminishing\",{\"1\":{\"258\":1}}],[\"diminish\",{\"1\":{\"146\":1}}],[\"dimensions\",{\"1\":{\"119\":1}}],[\"dimensionality\",{\"1\":{\"240\":1}}],[\"dimensional\",{\"1\":{\"97\":1,\"100\":1,\"196\":1,\"203\":1}}],[\"dimension\",{\"1\":{\"81\":1,\"97\":2,\"112\":1,\"140\":1,\"195\":1,\"203\":2}}],[\"dinner\",{\"1\":{\"125\":2}}],[\"ding\",{\"1\":{\"5\":1,\"9\":1}}],[\"dipanjan\",{\"1\":{\"105\":1}}],[\"di\",{\"1\":{\"89\":1}}],[\"didn\",{\"1\":{\"65\":1}}],[\"did\",{\"1\":{\"35\":1,\"43\":2,\"71\":2,\"98\":1,\"125\":1,\"229\":1}}],[\"diagram\",{\"1\":{\"212\":1}}],[\"diagnose\",{\"1\":{\"172\":1}}],[\"dialog\",{\"1\":{\"153\":1}}],[\"dialects\",{\"1\":{\"36\":1,\"93\":1}}],[\"dialect\",{\"1\":{\"21\":6}}],[\"dia\",{\"1\":{\"30\":1}}],[\"disadvantages\",{\"1\":{\"120\":2}}],[\"disparities\",{\"1\":{\"100\":1}}],[\"disperse\",{\"0\":{\"83\":1},\"1\":{\"83\":1}}],[\"dissimilar\",{\"1\":{\"94\":1}}],[\"disregard\",{\"1\":{\"65\":1}}],[\"distant\",{\"1\":{\"211\":2}}],[\"distance\",{\"1\":{\"51\":2,\"57\":1,\"100\":1,\"105\":1,\"172\":1,\"216\":5}}],[\"distilbert\",{\"1\":{\"247\":1}}],[\"distilled\",{\"1\":{\"247\":1}}],[\"distill\",{\"1\":{\"42\":2,\"69\":1}}],[\"distillation\",{\"1\":{\"41\":3,\"42\":1,\"43\":5,\"46\":1}}],[\"distinguishes\",{\"1\":{\"268\":1}}],[\"distinguished\",{\"1\":{\"224\":1}}],[\"distinguisheed\",{\"1\":{\"197\":1}}],[\"distinguish\",{\"1\":{\"71\":1,\"123\":2,\"196\":1}}],[\"distribute\",{\"1\":{\"45\":1,\"146\":4}}],[\"distributed\",{\"1\":{\"30\":1,\"57\":1,\"82\":1}}],[\"distributions\",{\"1\":{\"96\":1}}],[\"distribution\",{\"1\":{\"34\":1,\"65\":1,\"69\":2,\"74\":1,\"84\":3,\"183\":1,\"184\":1,\"203\":1,\"245\":1,\"266\":1}}],[\"distribuída\",{\"1\":{\"30\":1}}],[\"discarded\",{\"1\":{\"228\":1}}],[\"disclaimer\",{\"1\":{\"225\":1}}],[\"discordant\",{\"1\":{\"217\":1}}],[\"discovered\",{\"1\":{\"232\":1}}],[\"discoveries\",{\"1\":{\"228\":1}}],[\"discovery\",{\"1\":{\"167\":1}}],[\"discover\",{\"1\":{\"114\":1}}],[\"discriminative\",{\"0\":{\"268\":1},\"1\":{\"265\":1,\"268\":1}}],[\"discriminator\",{\"1\":{\"137\":1,\"268\":3}}],[\"discrepancy\",{\"1\":{\"23\":1}}],[\"discussion\",{\"1\":{\"269\":1}}],[\"discussin\",{\"0\":{\"142\":1}}],[\"discussed\",{\"1\":{\"2\":1,\"82\":1,\"212\":1,\"264\":1}}],[\"discuss\",{\"1\":{\"1\":1,\"2\":1,\"96\":1,\"109\":1,\"130\":1}}],[\"division\",{\"1\":{\"221\":1}}],[\"divide\",{\"1\":{\"156\":1}}],[\"divided\",{\"1\":{\"27\":1,\"212\":3}}],[\"dives\",{\"1\":{\"239\":1}}],[\"dive\",{\"0\":{\"112\":1},\"1\":{\"69\":1,\"71\":1}}],[\"diversity\",{\"1\":{\"137\":1}}],[\"diverse\",{\"1\":{\"1\":1}}],[\"divergence\",{\"1\":{\"42\":1,\"245\":2}}],[\"direct\",{\"1\":{\"29\":3,\"30\":2,\"31\":4,\"32\":1,\"71\":1,\"109\":1,\"146\":1,\"201\":1,\"215\":1,\"233\":1}}],[\"directly\",{\"1\":{\"22\":1,\"23\":1,\"42\":1,\"72\":2,\"78\":1,\"79\":1,\"105\":2,\"153\":1,\"170\":1,\"172\":1,\"175\":2,\"190\":1,\"218\":1,\"231\":1,\"239\":1,\"242\":2,\"264\":1}}],[\"directional\",{\"1\":{\"22\":1,\"24\":1,\"25\":1}}],[\"direction\",{\"0\":{\"199\":1,\"200\":1},\"1\":{\"22\":1,\"24\":1,\"25\":3,\"36\":1,\"94\":1,\"95\":1,\"97\":1,\"130\":1,\"146\":1,\"190\":1,\"199\":2,\"202\":1,\"218\":1,\"241\":1}}],[\"directions\",{\"1\":{\"22\":2,\"25\":1,\"27\":4,\"35\":1,\"84\":1,\"93\":2,\"146\":1,\"183\":1,\"194\":3,\"198\":3,\"199\":4,\"200\":3,\"201\":1,\"202\":1,\"203\":2}}],[\"difference\",{\"1\":{\"71\":1,\"93\":1,\"120\":1,\"123\":1,\"209\":1,\"210\":1,\"216\":2,\"218\":3,\"219\":1,\"225\":1,\"254\":1,\"266\":1,\"267\":1}}],[\"differently\",{\"1\":{\"93\":1,\"232\":1}}],[\"differentiate\",{\"1\":{\"71\":1,\"105\":1}}],[\"different\",{\"0\":{\"34\":1,\"35\":1,\"203\":1},\"1\":{\"1\":1,\"2\":1,\"4\":1,\"7\":1,\"24\":6,\"33\":2,\"34\":3,\"43\":2,\"50\":2,\"51\":3,\"54\":2,\"57\":1,\"60\":3,\"66\":1,\"71\":1,\"82\":1,\"94\":1,\"95\":1,\"100\":5,\"105\":2,\"109\":1,\"119\":1,\"120\":1,\"121\":1,\"122\":1,\"125\":1,\"126\":1,\"131\":1,\"146\":2,\"153\":1,\"174\":2,\"196\":2,\"203\":2,\"211\":1,\"212\":5,\"214\":1,\"216\":2,\"217\":1,\"218\":1,\"232\":3,\"240\":1,\"244\":3,\"253\":1,\"254\":1,\"264\":5,\"265\":1,\"268\":1,\"269\":1,\"270\":1}}],[\"difficulties\",{\"1\":{\"94\":1}}],[\"difficulty\",{\"1\":{\"94\":1,\"196\":1}}],[\"difficult\",{\"1\":{\"2\":1,\"23\":3,\"25\":1,\"27\":2,\"93\":2,\"123\":1}}],[\"doi\",{\"1\":{\"221\":1}}],[\"doing\",{\"1\":{\"202\":1}}],[\"dollars\",{\"1\":{\"125\":1}}],[\"dolárov\",{\"1\":{\"125\":1}}],[\"dobré\",{\"1\":{\"125\":1}}],[\"dominates\",{\"1\":{\"238\":1}}],[\"dominating\",{\"1\":{\"84\":1}}],[\"domu\",{\"1\":{\"125\":1}}],[\"doma\",{\"1\":{\"125\":1}}],[\"domains\",{\"1\":{\"115\":1,\"126\":1,\"132\":1,\"228\":1}}],[\"domain\",{\"0\":{\"267\":1},\"1\":{\"36\":1,\"42\":1,\"109\":1,\"130\":1,\"139\":1,\"186\":2,\"189\":3,\"233\":1,\"265\":1,\"267\":7}}],[\"dotted\",{\"1\":{\"242\":1}}],[\"dot\",{\"1\":{\"82\":1,\"196\":1,\"238\":1,\"239\":1,\"240\":2,\"244\":2,\"246\":1}}],[\"double\",{\"1\":{\"51\":1,\"60\":1,\"61\":1}}],[\"docred\",{\"1\":{\"53\":3,\"60\":1,\"61\":1}}],[\"documents\",{\"1\":{\"53\":2}}],[\"document\",{\"0\":{\"49\":1},\"1\":{\"49\":2,\"50\":1,\"51\":12,\"53\":1,\"54\":1,\"55\":1,\"60\":4,\"61\":2,\"122\":1,\"212\":2}}],[\"docked\",{\"1\":{\"21\":1}}],[\"dostoyevsky\",{\"1\":{\"95\":1}}],[\"dos\",{\"1\":{\"30\":1}}],[\"dong\",{\"1\":{\"175\":1,\"235\":1}}],[\"don\",{\"1\":{\"93\":1,\"229\":1,\"231\":1}}],[\"donderdag\",{\"1\":{\"30\":1}}],[\"done\",{\"0\":{\"234\":1},\"1\":{\"2\":1,\"68\":1,\"233\":1,\"264\":2}}],[\"dozens\",{\"1\":{\"25\":1,\"36\":1}}],[\"does\",{\"1\":{\"1\":2,\"2\":1,\"3\":1,\"5\":1,\"8\":1,\"24\":1,\"29\":1,\"33\":1,\"35\":1,\"42\":1,\"44\":2,\"71\":6,\"72\":2,\"73\":1,\"93\":1,\"101\":1,\"105\":1,\"109\":1,\"112\":1,\"113\":2,\"152\":1,\"218\":1,\"227\":1,\"250\":1,\"251\":1,\"253\":2,\"254\":1,\"266\":1,\"268\":2,\"269\":1}}],[\"do\",{\"1\":{\"1\":2,\"2\":1,\"8\":1,\"30\":1,\"41\":1,\"43\":1,\"54\":1,\"57\":1,\"71\":1,\"79\":2,\"121\":1,\"122\":1,\"124\":3,\"125\":3,\"126\":1,\"141\":1,\"152\":2,\"170\":1,\"218\":1,\"225\":1,\"226\":1,\"227\":1,\"263\":1,\"270\":1}}],[\"downstream\",{\"1\":{\"23\":1,\"33\":2,\"86\":1}}],[\"down\",{\"1\":{\"1\":1,\"34\":1,\"112\":1}}],[\"gn\",{\"1\":{\"188\":1}}],[\"gnmt\",{\"1\":{\"181\":1,\"187\":1,\"218\":5}}],[\"gtp\",{\"1\":{\"121\":1}}],[\"gmt\",{\"1\":{\"113\":1}}],[\"gdec​​\",{\"1\":{\"112\":1}}],[\"gyrus\",{\"1\":{\"94\":1}}],[\"glaciohound\",{\"1\":{\"92\":1}}],[\"glossed\",{\"1\":{\"229\":1}}],[\"glossary\",{\"1\":{\"228\":1}}],[\"glove\",{\"1\":{\"54\":7,\"55\":1,\"78\":1}}],[\"global\",{\"1\":{\"51\":1,\"174\":1,\"221\":2,\"242\":1,\"244\":1,\"245\":1}}],[\"guillaume\",{\"1\":{\"221\":1,\"271\":1}}],[\"guided\",{\"1\":{\"142\":1}}],[\"guide\",{\"1\":{\"78\":1,\"137\":1,\"161\":1,\"171\":2}}],[\"gu\",{\"1\":{\"89\":1}}],[\"guangtao\",{\"1\":{\"89\":1}}],[\"guarantees\",{\"1\":{\"42\":1}}],[\"gurevych\",{\"1\":{\"78\":1,\"87\":1,\"89\":1}}],[\"guesses\",{\"1\":{\"226\":1}}],[\"guess\",{\"1\":{\"71\":1,\"225\":1,\"228\":1,\"233\":1}}],[\"gcn\",{\"1\":{\"54\":1}}],[\"gcnn\",{\"1\":{\"54\":1}}],[\"gan\",{\"1\":{\"134\":2}}],[\"games\",{\"1\":{\"125\":2}}],[\"gabelentz\",{\"1\":{\"93\":1}}],[\"gaussian\",{\"1\":{\"84\":5,\"184\":1,\"247\":1}}],[\"gao\",{\"1\":{\"81\":1,\"82\":1,\"89\":1,\"105\":1,\"221\":1}}],[\"gathering\",{\"1\":{\"135\":1}}],[\"gat\",{\"1\":{\"54\":1}}],[\"gains\",{\"1\":{\"85\":1,\"88\":1,\"146\":2,\"187\":1,\"252\":1,\"253\":3}}],[\"gain\",{\"0\":{\"51\":1},\"1\":{\"49\":1,\"51\":2,\"54\":7,\"55\":2,\"57\":2,\"58\":4,\"59\":3,\"60\":3,\"244\":1,\"253\":2,\"258\":1}}],[\"gap\",{\"1\":{\"18\":1,\"23\":1,\"24\":1,\"33\":3,\"35\":1,\"93\":3,\"94\":2,\"95\":1,\"100\":1,\"132\":1,\"215\":1,\"221\":1,\"225\":1,\"244\":1,\"263\":1,\"269\":1}}],[\"g\",{\"1\":{\"42\":1,\"50\":2,\"51\":1,\"84\":1,\"105\":2,\"111\":3,\"178\":1,\"187\":4,\"218\":3,\"225\":1,\"227\":1,\"250\":1,\"263\":1}}],[\"gpt\",{\"0\":{\"119\":1,\"166\":1},\"1\":{\"12\":1,\"18\":3,\"22\":1,\"23\":2,\"81\":1,\"89\":1,\"119\":6,\"120\":4,\"121\":3,\"122\":2,\"123\":5,\"124\":10,\"125\":5,\"126\":7,\"151\":1,\"153\":1,\"166\":1}}],[\"gpus\",{\"0\":{\"149\":1},\"1\":{\"22\":2,\"25\":1,\"26\":1,\"97\":1,\"158\":1}}],[\"gpu\",{\"0\":{\"157\":1},\"1\":{\"1\":2,\"2\":1,\"6\":1,\"156\":1,\"157\":3},\"2\":{\"169\":1}}],[\"gh\",{\"1\":{\"6\":1}}],[\"growing\",{\"1\":{\"209\":1}}],[\"groups\",{\"1\":{\"156\":1}}],[\"group\",{\"1\":{\"141\":1,\"156\":1,\"218\":1,\"221\":1,\"263\":1,\"264\":1}}],[\"ground\",{\"1\":{\"105\":1,\"263\":1}}],[\"greedy\",{\"1\":{\"212\":1}}],[\"greek\",{\"1\":{\"95\":1}}],[\"green\",{\"1\":{\"94\":1,\"252\":1}}],[\"greatest\",{\"1\":{\"93\":1,\"126\":1}}],[\"greater\",{\"1\":{\"23\":1,\"43\":1}}],[\"greatly\",{\"1\":{\"35\":1,\"254\":1,\"263\":1}}],[\"great\",{\"1\":{\"2\":1,\"21\":1,\"36\":1,\"54\":1,\"78\":1,\"109\":1,\"194\":1,\"233\":1,\"259\":1}}],[\"graham\",{\"1\":{\"116\":1}}],[\"gradient\",{\"1\":{\"111\":1,\"182\":2}}],[\"grams\",{\"1\":{\"209\":2,\"211\":1}}],[\"gramatically\",{\"1\":{\"126\":1}}],[\"grammatical\",{\"1\":{\"124\":1,\"226\":1}}],[\"grammars\",{\"1\":{\"93\":1}}],[\"gram\",{\"1\":{\"105\":1,\"211\":6,\"218\":2,\"219\":1}}],[\"grabs\",{\"1\":{\"71\":1}}],[\"grained\",{\"1\":{\"67\":2,\"155\":1}}],[\"granularity\",{\"1\":{\"60\":1}}],[\"graph\",{\"1\":{\"51\":13,\"54\":3,\"55\":3,\"57\":1,\"60\":3,\"61\":1,\"122\":1,\"137\":1}}],[\"graphs\",{\"1\":{\"43\":1,\"60\":1}}],[\"graphed\",{\"1\":{\"3\":1}}],[\"grasp\",{\"1\":{\"24\":1,\"30\":1}}],[\"giving\",{\"1\":{\"208\":1}}],[\"gives\",{\"1\":{\"126\":2,\"217\":1,\"240\":2,\"242\":1,\"250\":1}}],[\"give\",{\"1\":{\"23\":1,\"65\":1,\"130\":1,\"211\":2,\"214\":1,\"217\":1,\"218\":1,\"219\":1,\"232\":1,\"233\":2,\"269\":1}}],[\"given\",{\"1\":{\"1\":1,\"42\":2,\"43\":1,\"45\":1,\"66\":1,\"68\":1,\"69\":1,\"71\":2,\"111\":2,\"123\":3,\"124\":2,\"126\":1,\"132\":1,\"135\":1,\"146\":1,\"182\":1,\"183\":1,\"240\":1,\"252\":1,\"266\":1,\"268\":1}}],[\"giuseppe\",{\"1\":{\"93\":1}}],[\"gifted\",{\"1\":{\"21\":1}}],[\"github\",{\"1\":{\"0\":1,\"21\":2,\"41\":1,\"49\":1,\"64\":1,\"77\":1,\"92\":2,\"146\":1,\"153\":1,\"163\":1,\"164\":1,\"175\":2,\"203\":1,\"220\":2,\"221\":1,\"224\":1,\"238\":2,\"250\":2,\"269\":2}}],[\"gonçalo\",{\"1\":{\"247\":1}}],[\"gold\",{\"1\":{\"213\":1}}],[\"goldwater\",{\"1\":{\"175\":1}}],[\"gomez\",{\"1\":{\"102\":1}}],[\"goebel\",{\"1\":{\"102\":1}}],[\"google\",{\"1\":{\"37\":1,\"98\":1,\"125\":4,\"218\":11,\"221\":1,\"225\":1,\"238\":1}}],[\"goodman\",{\"1\":{\"116\":1}}],[\"good\",{\"1\":{\"1\":1,\"3\":1,\"7\":1,\"23\":1,\"27\":1,\"125\":1,\"171\":1,\"178\":1,\"226\":3,\"228\":2,\"232\":1,\"251\":2,\"269\":2,\"270\":1}}],[\"governor\",{\"1\":{\"93\":1}}],[\"governos\",{\"1\":{\"30\":1}}],[\"governments\",{\"1\":{\"30\":1}}],[\"go\",{\"1\":{\"3\":1,\"125\":6,\"130\":1,\"225\":1,\"228\":1}}],[\"going\",{\"1\":{\"1\":1,\"8\":1,\"101\":1,\"130\":1,\"170\":2}}],[\"goals\",{\"1\":{\"36\":1}}],[\"goal\",{\"1\":{\"1\":1,\"3\":1,\"24\":1,\"36\":1,\"95\":1,\"110\":1,\"113\":1,\"179\":1,\"190\":1,\"226\":1,\"232\":1}}],[\"gemm\",{\"1\":{\"155\":2}}],[\"geometry\",{\"1\":{\"89\":1}}],[\"generic\",{\"1\":{\"228\":1}}],[\"generalized\",{\"1\":{\"124\":1,\"244\":1}}],[\"generalization\",{\"1\":{\"27\":1,\"146\":1,\"259\":1}}],[\"generally\",{\"1\":{\"33\":1,\"97\":1,\"142\":1,\"171\":1,\"211\":1,\"226\":1}}],[\"general\",{\"1\":{\"23\":1,\"24\":1,\"33\":1,\"93\":1,\"95\":1,\"101\":1,\"124\":1,\"155\":1,\"178\":1,\"186\":1,\"254\":1}}],[\"generators\",{\"1\":{\"112\":2}}],[\"generator→multilingual\",{\"1\":{\"111\":1}}],[\"generator\",{\"0\":{\"111\":1},\"1\":{\"109\":1,\"111\":5,\"112\":2,\"137\":1,\"268\":1}}],[\"generate\",{\"1\":{\"68\":2,\"109\":1,\"110\":1,\"111\":1,\"123\":1,\"126\":2,\"136\":1,\"142\":1,\"171\":1,\"212\":2,\"216\":1,\"228\":1,\"253\":1,\"263\":1,\"268\":1}}],[\"generates\",{\"1\":{\"42\":2,\"66\":1,\"68\":1,\"71\":1,\"96\":1,\"125\":1,\"200\":1,\"228\":1,\"240\":1}}],[\"generated\",{\"1\":{\"1\":6,\"3\":2,\"68\":2,\"109\":1,\"123\":3,\"124\":1,\"134\":2,\"137\":1,\"140\":1,\"172\":1,\"175\":1,\"252\":1,\"263\":1}}],[\"generativ\",{\"1\":{\"137\":1}}],[\"generative\",{\"0\":{\"119\":1,\"178\":1,\"268\":1},\"1\":{\"37\":1,\"68\":1,\"119\":1,\"126\":1,\"130\":1,\"136\":1,\"137\":1,\"143\":1,\"181\":1,\"190\":1,\"191\":1,\"265\":1,\"268\":1}}],[\"generating\",{\"1\":{\"65\":1,\"68\":1,\"131\":1}}],[\"generation\",{\"0\":{\"68\":1,\"108\":1,\"123\":1,\"250\":1},\"1\":{\"1\":1,\"22\":1,\"37\":2,\"89\":2,\"105\":3,\"109\":2,\"112\":1,\"116\":1,\"119\":3,\"121\":1,\"123\":1,\"151\":1,\"153\":1,\"210\":1,\"221\":2,\"250\":2,\"251\":2,\"259\":1,\"260\":1}}],[\"genc​​\",{\"1\":{\"112\":1}}],[\"genius\",{\"1\":{\"36\":2}}],[\"germany\",{\"1\":{\"9\":1}}],[\"german\",{\"1\":{\"1\":1,\"4\":2,\"23\":1,\"24\":2,\"93\":1,\"95\":2,\"97\":1,\"111\":1,\"113\":3,\"114\":1,\"163\":1,\"173\":1,\"203\":1,\"252\":1,\"254\":1,\"256\":1}}],[\"gets\",{\"1\":{\"25\":1,\"174\":1}}],[\"getting\",{\"1\":{\"2\":1,\"146\":1,\"226\":1,\"228\":1}}],[\"get\",{\"1\":{\"1\":1,\"6\":1,\"22\":1,\"44\":1,\"65\":1,\"100\":1,\"109\":1,\"111\":1,\"137\":1,\"172\":2,\"225\":2,\"228\":1,\"232\":1,\"233\":3,\"238\":1,\"240\":1}}],[\"jxhe\",{\"1\":{\"250\":1}}],[\"js\",{\"1\":{\"245\":1}}],[\"jcyk\",{\"1\":{\"224\":1}}],[\"jensen\",{\"1\":{\"245\":1}}],[\"jean\",{\"1\":{\"221\":1}}],[\"je\",{\"1\":{\"196\":1}}],[\"jeff\",{\"1\":{\"167\":1}}],[\"j\",{\"1\":{\"116\":1,\"175\":6,\"216\":5}}],[\"judgements\",{\"1\":{\"209\":1,\"213\":1,\"214\":1,\"218\":1}}],[\"judgement\",{\"1\":{\"208\":1,\"209\":1,\"214\":1,\"218\":5,\"219\":1}}],[\"judgments\",{\"1\":{\"213\":1,\"221\":1}}],[\"judgment\",{\"1\":{\"105\":2,\"213\":2,\"217\":1,\"218\":1}}],[\"jun\",{\"1\":{\"89\":1}}],[\"junxian\",{\"1\":{\"89\":1,\"260\":1}}],[\"just\",{\"1\":{\"1\":5,\"2\":2,\"3\":3,\"24\":1,\"79\":1,\"95\":1,\"123\":1,\"124\":1,\"151\":1,\"155\":1,\"171\":1,\"226\":2,\"253\":1}}],[\"ji\",{\"1\":{\"102\":1,\"175\":1}}],[\"jing\",{\"1\":{\"89\":1,\"221\":1}}],[\"jingjing\",{\"1\":{\"0\":1}}],[\"jiajun\",{\"1\":{\"191\":1}}],[\"jiaze\",{\"1\":{\"74\":1}}],[\"jiangjie\",{\"1\":{\"64\":1,\"74\":1}}],[\"jiangjiechen\",{\"1\":{\"64\":1}}],[\"jie\",{\"1\":{\"61\":1}}],[\"jargon\",{\"1\":{\"225\":1}}],[\"jaitly\",{\"1\":{\"175\":1}}],[\"jack\",{\"1\":{\"175\":8,\"228\":1}}],[\"jacob\",{\"1\":{\"37\":1,\"167\":1}}],[\"japanese\",{\"1\":{\"203\":1}}],[\"japan\",{\"1\":{\"105\":1}}],[\"jakob\",{\"1\":{\"102\":1}}],[\"java\",{\"1\":{\"24\":1}}],[\"já\",{\"1\":{\"30\":1}}],[\"josep\",{\"1\":{\"221\":1}}],[\"jones\",{\"1\":{\"102\":1}}],[\"john\",{\"1\":{\"93\":1}}],[\"johnson\",{\"1\":{\"37\":1}}],[\"joe\",{\"1\":{\"66\":1}}],[\"journal\",{\"1\":{\"37\":1,\"271\":1}}],[\"jour\",{\"1\":{\"29\":1}}],[\"joint\",{\"1\":{\"24\":1,\"105\":1,\"146\":1,\"181\":1,\"201\":2}}],[\"jointly\",{\"1\":{\"23\":1,\"146\":2,\"182\":1,\"190\":1,\"242\":1}}],[\"lj​∣e\",{\"1\":{\"268\":1}}],[\"lcd​\",{\"1\":{\"267\":1}}],[\"lctr​=−xi\",{\"1\":{\"196\":1}}],[\"lmx\",{\"1\":{\"184\":1}}],[\"lmy\",{\"1\":{\"184\":1}}],[\"lm\",{\"1\":{\"181\":4,\"184\":1,\"188\":3}}],[\"lut\",{\"0\":{\"172\":1,\"173\":1,\"175\":1},\"1\":{\"171\":1,\"172\":6,\"173\":3,\"174\":1,\"175\":5}}],[\"lunch\",{\"1\":{\"125\":2}}],[\"lt​∈rm\",{\"1\":{\"112\":1}}],[\"lt​​\",{\"1\":{\"112\":1}}],[\"lt​\",{\"1\":{\"111\":2}}],[\"l=∣s∪t∣\",{\"1\":{\"110\":1}}],[\"ls\",{\"1\":{\"160\":1,\"161\":1}}],[\"ls​​\",{\"1\":{\"112\":1}}],[\"ls​\",{\"1\":{\"111\":2,\"112\":1}}],[\"lsr\",{\"1\":{\"54\":4}}],[\"lstms\",{\"1\":{\"119\":1}}],[\"lstm\",{\"1\":{\"51\":1,\"54\":1,\"113\":1}}],[\"l2\",{\"1\":{\"35\":1}}],[\"l\",{\"1\":{\"31\":2,\"37\":1,\"216\":2,\"240\":2,\"242\":2,\"265\":2,\"266\":2}}],[\"líderes\",{\"1\":{\"30\":1}}],[\"light\",{\"1\":{\"209\":1}}],[\"lighter\",{\"1\":{\"173\":1,\"247\":1}}],[\"lightseq\",{\"0\":{\"150\":1,\"153\":1,\"158\":1,\"160\":1,\"161\":1},\"1\":{\"152\":3,\"153\":4,\"154\":1,\"155\":3,\"156\":1,\"157\":2,\"158\":1,\"159\":2,\"161\":2,\"164\":1,\"166\":1,\"167\":1}}],[\"lightweight\",{\"1\":{\"22\":1}}],[\"libraries\",{\"1\":{\"153\":1}}],[\"library\",{\"1\":{\"149\":1,\"153\":1,\"167\":1}}],[\"librispeech\",{\"1\":{\"93\":1,\"97\":1,\"98\":1,\"99\":2,\"101\":1,\"173\":1}}],[\"list\",{\"1\":{\"226\":1,\"233\":1}}],[\"listed\",{\"1\":{\"212\":1}}],[\"listen\",{\"1\":{\"171\":1,\"172\":2,\"175\":1}}],[\"listening\",{\"1\":{\"95\":1}}],[\"list5\",{\"1\":{\"71\":3}}],[\"living\",{\"1\":{\"93\":1}}],[\"liwei\",{\"1\":{\"89\":1,\"146\":1,\"203\":1}}],[\"lite\",{\"1\":{\"116\":1}}],[\"literature\",{\"1\":{\"84\":1}}],[\"littler\",{\"1\":{\"146\":1}}],[\"little\",{\"1\":{\"79\":1,\"94\":1,\"105\":1,\"228\":1,\"233\":1}}],[\"lixin\",{\"1\":{\"61\":1}}],[\"li\",{\"1\":{\"46\":1,\"61\":2,\"74\":1,\"77\":1,\"89\":2,\"102\":1,\"143\":1,\"146\":1,\"191\":1,\"203\":1,\"221\":1,\"235\":1}}],[\"liebler\",{\"1\":{\"42\":1}}],[\"lies\",{\"1\":{\"2\":1,\"218\":1}}],[\"liu\",{\"1\":{\"37\":1,\"61\":2,\"89\":1,\"105\":1,\"235\":1}}],[\"life\",{\"1\":{\"36\":1,\"65\":1,\"130\":1,\"170\":1}}],[\"limits\",{\"1\":{\"179\":1}}],[\"limitation\",{\"0\":{\"170\":1},\"1\":{\"23\":1,\"49\":1,\"172\":1,\"218\":4}}],[\"limitations\",{\"0\":{\"44\":1},\"1\":{\"23\":1,\"44\":2,\"45\":1,\"170\":1,\"231\":1}}],[\"limit\",{\"1\":{\"22\":1,\"133\":1}}],[\"limited\",{\"1\":{\"22\":1,\"23\":1,\"44\":1,\"113\":1,\"120\":1,\"170\":1,\"212\":2,\"218\":1}}],[\"linux\",{\"1\":{\"159\":1}}],[\"linked\",{\"1\":{\"100\":1}}],[\"linking\",{\"1\":{\"72\":1}}],[\"lingxiao\",{\"1\":{\"89\":1}}],[\"linguistic\",{\"1\":{\"114\":1,\"175\":1,\"244\":1}}],[\"linguistics\",{\"1\":{\"9\":2,\"37\":1,\"105\":7,\"175\":1,\"221\":1}}],[\"linguist\",{\"1\":{\"21\":1}}],[\"lingual\",{\"1\":{\"7\":1,\"24\":1,\"26\":1,\"105\":1,\"216\":1}}],[\"lin\",{\"1\":{\"37\":1,\"61\":1,\"146\":1}}],[\"linear\",{\"1\":{\"112\":2,\"130\":1}}],[\"lines\",{\"1\":{\"98\":1,\"100\":1,\"123\":1}}],[\"line\",{\"1\":{\"36\":1,\"239\":1,\"242\":1}}],[\"linzehui\",{\"1\":{\"21\":1}}],[\"likely\",{\"1\":{\"257\":1}}],[\"likelihood\",{\"1\":{\"81\":1,\"182\":1,\"183\":1}}],[\"like\",{\"1\":{\"3\":1,\"21\":1,\"24\":1,\"71\":1,\"78\":1,\"81\":1,\"93\":1,\"95\":1,\"105\":4,\"120\":1,\"123\":1,\"130\":1,\"137\":1,\"146\":1,\"152\":1,\"153\":2,\"155\":1,\"170\":2,\"171\":2,\"172\":2,\"211\":4,\"217\":1,\"219\":2,\"224\":1,\"225\":2,\"226\":1,\"227\":1,\"232\":1,\"251\":2}}],[\"llion\",{\"1\":{\"102\":1}}],[\"ll\",{\"1\":{\"1\":1,\"125\":2,\"130\":2,\"225\":1}}],[\"lo\",{\"1\":{\"105\":2}}],[\"loren\",{\"0\":{\"66\":1},\"1\":{\"64\":2,\"65\":6,\"66\":4,\"67\":2,\"68\":4,\"69\":2,\"71\":35,\"72\":7,\"73\":1,\"74\":1}}],[\"located\",{\"1\":{\"50\":1}}],[\"locally\",{\"1\":{\"119\":1}}],[\"local\",{\"0\":{\"68\":1},\"1\":{\"36\":2,\"66\":2,\"68\":3,\"71\":5,\"174\":1,\"244\":1,\"245\":2,\"252\":1,\"253\":1}}],[\"logpd​\",{\"1\":{\"268\":1}}],[\"log\",{\"1\":{\"182\":1}}],[\"logits\",{\"1\":{\"156\":3}}],[\"logics\",{\"1\":{\"73\":1}}],[\"logic\",{\"1\":{\"51\":1,\"65\":1,\"66\":2,\"69\":4,\"72\":1,\"74\":1},\"2\":{\"76\":1}}],[\"logically\",{\"1\":{\"124\":1}}],[\"logical\",{\"0\":{\"58\":1},\"1\":{\"50\":1,\"51\":2,\"53\":1,\"54\":1,\"58\":1,\"59\":1}}],[\"logo\",{\"1\":{\"41\":1}}],[\"lomb\",{\"1\":{\"42\":1}}],[\"losses\",{\"1\":{\"263\":1,\"268\":1}}],[\"loss\",{\"0\":{\"266\":1,\"267\":1,\"268\":1},\"1\":{\"42\":2,\"105\":1,\"146\":1,\"172\":1,\"196\":1,\"202\":1,\"216\":2,\"218\":1,\"265\":3,\"266\":2,\"267\":5,\"268\":2}}],[\"londres\",{\"1\":{\"31\":3}}],[\"london\",{\"1\":{\"31\":1}}],[\"longer\",{\"1\":{\"264\":1}}],[\"longest\",{\"1\":{\"211\":1}}],[\"long\",{\"1\":{\"2\":1,\"9\":1,\"51\":1,\"57\":1,\"71\":1,\"94\":1,\"126\":1,\"143\":1,\"171\":1,\"211\":1,\"224\":1,\"231\":1}}],[\"love\",{\"1\":{\"24\":4,\"196\":1}}],[\"look\",{\"1\":{\"3\":3,\"66\":1,\"71\":1,\"100\":1,\"172\":1,\"218\":1,\"228\":2,\"263\":2,\"264\":1,\"269\":1}}],[\"looking\",{\"1\":{\"1\":1,\"36\":1,\"94\":1,\"101\":1,\"125\":1,\"226\":2}}],[\"lots\",{\"1\":{\"71\":1,\"155\":1}}],[\"lot\",{\"1\":{\"1\":2,\"23\":1,\"101\":1,\"130\":1,\"170\":1,\"234\":1}}],[\"lowest\",{\"1\":{\"1\":1,\"146\":1}}],[\"lower\",{\"1\":{\"1\":1,\"2\":1,\"36\":1,\"42\":1,\"43\":1,\"112\":1,\"182\":1,\"183\":1,\"216\":1,\"269\":1}}],[\"low\",{\"0\":{\"6\":1,\"83\":1},\"1\":{\"1\":2,\"2\":1,\"22\":1,\"25\":1,\"82\":1,\"83\":2,\"93\":1,\"113\":3,\"115\":1,\"132\":1,\"174\":1,\"175\":1,\"186\":1,\"187\":2,\"211\":1,\"225\":2,\"226\":1,\"227\":1,\"244\":2,\"256\":1,\"263\":1,\"269\":1,\"270\":1}}],[\"lowly\",{\"1\":{\"1\":1,\"2\":1}}],[\"ladv​\",{\"1\":{\"268\":1}}],[\"lam\",{\"1\":{\"235\":1}}],[\"lample\",{\"1\":{\"105\":1,\"263\":1,\"271\":1}}],[\"lauto​\",{\"1\":{\"266\":1}}],[\"launch\",{\"1\":{\"155\":1}}],[\"laurent\",{\"1\":{\"105\":1}}],[\"lass\",{\"1\":{\"146\":22}}],[\"last\",{\"0\":{\"234\":1},\"1\":{\"27\":1,\"71\":2,\"124\":1,\"156\":1,\"174\":1,\"195\":1,\"216\":1,\"225\":1,\"242\":1,\"245\":1}}],[\"lastly\",{\"1\":{\"1\":1,\"4\":1,\"146\":1}}],[\"lan\",{\"1\":{\"116\":1}}],[\"langauges\",{\"1\":{\"200\":1}}],[\"langauge\",{\"1\":{\"110\":1,\"113\":1}}],[\"languages\",{\"0\":{\"7\":1,\"203\":1},\"1\":{\"1\":1,\"7\":3,\"21\":1,\"22\":2,\"23\":2,\"24\":13,\"25\":3,\"33\":3,\"34\":3,\"35\":2,\"36\":2,\"93\":11,\"94\":1,\"95\":6,\"97\":1,\"99\":2,\"101\":1,\"105\":1,\"109\":7,\"110\":3,\"114\":3,\"122\":2,\"126\":1,\"146\":7,\"194\":1,\"196\":1,\"197\":1,\"198\":2,\"200\":1,\"201\":2,\"203\":4,\"221\":1,\"225\":4,\"226\":1,\"227\":1,\"228\":1,\"232\":2,\"244\":1,\"263\":3,\"264\":6,\"265\":1,\"268\":2,\"269\":1,\"270\":1}}],[\"language\",{\"0\":{\"27\":1,\"34\":1,\"35\":1,\"64\":1,\"114\":1,\"149\":1},\"1\":{\"1\":2,\"3\":1,\"4\":2,\"5\":1,\"8\":3,\"22\":4,\"24\":12,\"27\":11,\"33\":2,\"35\":2,\"36\":3,\"37\":6,\"41\":3,\"64\":1,\"66\":1,\"77\":2,\"78\":2,\"80\":1,\"81\":1,\"82\":1,\"89\":3,\"92\":1,\"93\":1,\"94\":1,\"95\":4,\"96\":1,\"98\":2,\"101\":1,\"105\":4,\"109\":13,\"110\":3,\"111\":6,\"112\":5,\"113\":4,\"114\":2,\"116\":1,\"119\":2,\"124\":3,\"125\":2,\"126\":3,\"127\":1,\"130\":3,\"131\":2,\"134\":2,\"135\":2,\"137\":1,\"146\":50,\"151\":1,\"153\":1,\"167\":2,\"170\":1,\"172\":1,\"175\":1,\"178\":1,\"181\":2,\"183\":2,\"184\":1,\"188\":2,\"190\":1,\"194\":4,\"195\":1,\"197\":1,\"198\":1,\"200\":1,\"201\":2,\"203\":2,\"208\":1,\"213\":1,\"214\":1,\"215\":1,\"217\":2,\"221\":2,\"225\":1,\"232\":2,\"239\":1,\"244\":3,\"251\":1,\"263\":5,\"264\":3,\"265\":1,\"267\":3,\"268\":3,\"270\":1},\"2\":{\"129\":1,\"148\":1}}],[\"lavie\",{\"1\":{\"105\":2,\"221\":2}}],[\"layer\",{\"1\":{\"96\":2,\"97\":1,\"105\":1,\"112\":2,\"113\":1,\"130\":1,\"146\":2,\"155\":3,\"174\":2,\"195\":3,\"216\":6,\"239\":2,\"240\":4,\"242\":7,\"245\":1}}],[\"layers\",{\"1\":{\"25\":1,\"96\":2,\"97\":3,\"119\":1,\"146\":3,\"156\":1,\"174\":4,\"216\":1,\"240\":1,\"242\":1,\"245\":3}}],[\"lacks\",{\"1\":{\"109\":1,\"126\":1,\"170\":1}}],[\"lack\",{\"1\":{\"68\":1,\"227\":1}}],[\"la\",{\"1\":{\"29\":1,\"31\":3,\"71\":1}}],[\"latency\",{\"1\":{\"152\":1}}],[\"latent\",{\"0\":{\"69\":1},\"1\":{\"66\":1,\"69\":3,\"84\":2,\"181\":1,\"183\":1,\"184\":1,\"264\":3,\"265\":1,\"266\":3,\"268\":4,\"270\":1},\"2\":{\"193\":1}}],[\"latest\",{\"1\":{\"119\":1,\"126\":1,\"234\":1}}],[\"lateral\",{\"1\":{\"94\":1}}],[\"later\",{\"1\":{\"1\":2,\"2\":1,\"66\":2,\"68\":1,\"110\":1}}],[\"latter\",{\"1\":{\"54\":1,\"211\":1}}],[\"latin\",{\"1\":{\"27\":2}}],[\"labor\",{\"1\":{\"219\":1}}],[\"laborious\",{\"1\":{\"25\":1}}],[\"lab\",{\"1\":{\"93\":1}}],[\"labeled\",{\"1\":{\"42\":1,\"78\":1,\"94\":1,\"250\":1,\"251\":3,\"259\":1}}],[\"labels\",{\"1\":{\"42\":7,\"43\":4,\"44\":1,\"69\":1,\"156\":1,\"251\":1}}],[\"labeling\",{\"1\":{\"41\":1}}],[\"label\",{\"1\":{\"1\":1,\"42\":3,\"43\":1,\"51\":1,\"69\":2,\"71\":4,\"251\":1}}],[\"laptops\",{\"1\":{\"3\":6}}],[\"largest\",{\"1\":{\"25\":1,\"93\":1,\"97\":1,\"123\":2}}],[\"largely\",{\"1\":{\"23\":1,\"142\":1,\"215\":1}}],[\"larger\",{\"1\":{\"3\":1,\"71\":1,\"93\":1,\"130\":1,\"142\":1,\"146\":3,\"156\":1,\"216\":1,\"233\":1,\"258\":1}}],[\"large\",{\"0\":{\"7\":1},\"1\":{\"1\":1,\"23\":4,\"26\":1,\"33\":1,\"41\":1,\"42\":1,\"53\":1,\"54\":1,\"60\":1,\"61\":1,\"93\":1,\"94\":1,\"109\":1,\"119\":1,\"120\":1,\"126\":1,\"146\":3,\"151\":1,\"152\":1,\"178\":1,\"194\":1,\"201\":1,\"203\":2,\"208\":1,\"213\":1,\"217\":1,\"218\":1,\"226\":1,\"227\":1,\"228\":1,\"231\":1,\"232\":1,\"251\":1,\"256\":1}}],[\"left\",{\"1\":{\"240\":1,\"266\":1,\"269\":1}}],[\"lemon0830\",{\"1\":{\"238\":1}}],[\"lemao\",{\"1\":{\"235\":1}}],[\"le\",{\"1\":{\"221\":1}}],[\"lecture2evaluation\",{\"1\":{\"221\":1}}],[\"lexical\",{\"1\":{\"105\":1}}],[\"leo\",{\"1\":{\"102\":1}}],[\"length\",{\"1\":{\"94\":1,\"96\":1,\"152\":1,\"157\":1,\"165\":1,\"209\":1,\"240\":1}}],[\"lengths\",{\"1\":{\"2\":1,\"96\":1}}],[\"lei\",{\"1\":{\"46\":1,\"61\":1,\"74\":1,\"89\":1,\"102\":1,\"143\":1,\"146\":1,\"191\":1,\"203\":1,\"221\":1}}],[\"legal\",{\"1\":{\"45\":1}}],[\"lewis\",{\"1\":{\"37\":1}}],[\"leverage\",{\"1\":{\"67\":1,\"132\":2,\"137\":2}}],[\"leveraged\",{\"1\":{\"51\":1,\"135\":1}}],[\"leveraging\",{\"1\":{\"37\":1,\"93\":1}}],[\"levels\",{\"1\":{\"105\":1,\"214\":1}}],[\"levelrage\",{\"1\":{\"51\":1}}],[\"level\",{\"0\":{\"34\":1,\"35\":1,\"49\":1},\"1\":{\"1\":4,\"2\":4,\"33\":2,\"37\":1,\"42\":3,\"43\":6,\"49\":4,\"50\":1,\"51\":10,\"53\":1,\"55\":3,\"57\":1,\"60\":4,\"61\":2,\"66\":1,\"69\":1,\"93\":1,\"105\":1,\"122\":1,\"171\":1,\"174\":2,\"175\":1,\"201\":1,\"209\":1,\"210\":1,\"211\":1,\"213\":9,\"218\":3,\"258\":3,\"264\":4}}],[\"letting\",{\"1\":{\"120\":1}}],[\"letters\",{\"1\":{\"94\":1,\"102\":1}}],[\"lets\",{\"1\":{\"3\":1}}],[\"let\",{\"1\":{\"3\":2,\"69\":1,\"71\":1,\"125\":2,\"172\":1,\"218\":1,\"228\":1,\"263\":1,\"264\":1,\"269\":2}}],[\"less\",{\"1\":{\"1\":2,\"6\":1,\"8\":1,\"25\":2,\"43\":1,\"113\":1}}],[\"least\",{\"1\":{\"69\":1,\"93\":1,\"97\":1,\"195\":1,\"216\":1,\"227\":1,\"232\":1}}],[\"leading\",{\"1\":{\"87\":1,\"241\":1}}],[\"leads\",{\"1\":{\"43\":1,\"57\":1,\"65\":1,\"93\":1,\"189\":1}}],[\"leaders\",{\"1\":{\"30\":1}}],[\"leaning\",{\"1\":{\"0\":1}}],[\"learnable\",{\"1\":{\"231\":1,\"233\":2}}],[\"learned\",{\"0\":{\"206\":1},\"1\":{\"27\":1,\"77\":1,\"83\":1,\"84\":1,\"95\":2,\"98\":1,\"114\":1,\"146\":1,\"190\":1,\"203\":1}}],[\"learners\",{\"1\":{\"24\":2,\"95\":3,\"127\":1,\"167\":1}}],[\"learns\",{\"1\":{\"24\":4,\"95\":1,\"114\":1,\"146\":1,\"201\":1,\"263\":1,\"265\":1,\"266\":1,\"269\":1}}],[\"learn\",{\"1\":{\"0\":1,\"23\":1,\"24\":6,\"41\":2,\"93\":2,\"95\":5,\"101\":1,\"105\":1,\"110\":1,\"113\":1,\"130\":1,\"146\":1,\"172\":1,\"190\":1,\"194\":1,\"196\":2,\"197\":1,\"200\":1,\"215\":2,\"226\":2,\"227\":1,\"228\":1,\"231\":1,\"239\":2,\"242\":1,\"244\":3,\"264\":1,\"265\":2}}],[\"learning\",{\"0\":{\"0\":1,\"92\":1,\"194\":1,\"196\":1},\"1\":{\"14\":1,\"21\":1,\"23\":2,\"24\":11,\"33\":1,\"95\":3,\"100\":1,\"102\":2,\"105\":4,\"113\":1,\"115\":2,\"116\":1,\"119\":1,\"120\":1,\"130\":1,\"131\":1,\"146\":2,\"152\":1,\"155\":1,\"167\":1,\"171\":1,\"175\":2,\"181\":1,\"194\":1,\"196\":1,\"201\":2,\"202\":1,\"203\":3,\"210\":1,\"226\":2,\"247\":1,\"260\":1,\"263\":1,\"264\":2,\"266\":1,\"269\":1,\"270\":1},\"2\":{\"11\":1,\"193\":1,\"205\":1}}],[\"r|\",{\"1\":{\"216\":1}}],[\"rnmt\",{\"1\":{\"189\":1}}],[\"rnn\",{\"1\":{\"111\":1}}],[\"r\",{\"1\":{\"156\":2,\"175\":2,\"196\":8,\"212\":3,\"216\":6,\"244\":1,\"245\":1}}],[\"ráno\",{\"1\":{\"125\":1}}],[\"rte\",{\"1\":{\"124\":1}}],[\"ricardo\",{\"1\":{\"221\":1}}],[\"richard\",{\"1\":{\"271\":1}}],[\"richer\",{\"1\":{\"24\":1}}],[\"rich\",{\"1\":{\"22\":1,\"23\":1,\"25\":1,\"72\":1,\"93\":1,\"146\":1,\"186\":1,\"187\":2}}],[\"right\",{\"1\":{\"155\":1,\"240\":1,\"267\":1,\"269\":1}}],[\"rigid\",{\"1\":{\"105\":1}}],[\"rise\",{\"1\":{\"119\":1}}],[\"river\",{\"1\":{\"36\":1}}],[\"rows\",{\"1\":{\"212\":1}}],[\"row\",{\"1\":{\"212\":1}}],[\"room\",{\"1\":{\"126\":1}}],[\"robustness\",{\"1\":{\"137\":1}}],[\"robust\",{\"1\":{\"105\":1}}],[\"roberta\",{\"1\":{\"54\":1,\"58\":1,\"70\":1,\"71\":1,\"105\":1,\"124\":1,\"216\":1,\"218\":1}}],[\"rough\",{\"1\":{\"156\":1}}],[\"roughly\",{\"1\":{\"3\":1,\"134\":1}}],[\"roukos\",{\"1\":{\"105\":1,\"221\":1}}],[\"ro\",{\"1\":{\"97\":1,\"114\":1,\"186\":2,\"187\":1}}],[\"romanian\",{\"1\":{\"97\":1,\"114\":1}}],[\"rondgedeeld\",{\"1\":{\"30\":1}}],[\"role\",{\"1\":{\"22\":1,\"23\":2,\"49\":1,\"58\":1}}],[\"ruwase\",{\"1\":{\"167\":1}}],[\"ru\",{\"1\":{\"97\":1}}],[\"russia\",{\"1\":{\"71\":2}}],[\"russian\",{\"1\":{\"71\":10,\"95\":2,\"97\":1,\"208\":1}}],[\"russell\",{\"1\":{\"21\":3}}],[\"rules\",{\"1\":{\"69\":2,\"226\":1}}],[\"rumors\",{\"1\":{\"65\":1}}],[\"ruiliu\",{\"1\":{\"21\":1}}],[\"runxin\",{\"1\":{\"61\":1}}],[\"run\",{\"1\":{\"2\":2,\"6\":1,\"130\":1,\"160\":2,\"232\":1}}],[\"runs\",{\"1\":{\"1\":1,\"6\":1}}],[\"running\",{\"1\":{\"1\":1,\"2\":1,\"6\":1,\"158\":1,\"160\":1}}],[\"rajansaini\",{\"1\":{\"229\":1}}],[\"rajbhandari\",{\"1\":{\"167\":1}}],[\"rainer\",{\"1\":{\"102\":1}}],[\"raw\",{\"1\":{\"97\":1}}],[\"rapper\",{\"1\":{\"71\":4}}],[\"racial\",{\"1\":{\"65\":1,\"74\":1}}],[\"rating\",{\"1\":{\"215\":2}}],[\"rationales\",{\"1\":{\"65\":2,\"73\":1}}],[\"rationale\",{\"1\":{\"64\":1}}],[\"ratio\",{\"1\":{\"42\":2,\"43\":2}}],[\"rather\",{\"1\":{\"93\":1,\"95\":1,\"109\":1,\"126\":1,\"146\":1,\"231\":1}}],[\"rates\",{\"1\":{\"119\":1,\"165\":1}}],[\"rate\",{\"1\":{\"43\":1,\"146\":1,\"215\":1}}],[\"radford\",{\"1\":{\"37\":1}}],[\"rasley\",{\"1\":{\"167\":1}}],[\"ras\",{\"1\":{\"24\":2,\"34\":5,\"35\":3,\"197\":2}}],[\"rand\",{\"1\":{\"244\":1}}],[\"randomly\",{\"1\":{\"100\":1,\"146\":1,\"156\":1,\"252\":1,\"254\":1,\"266\":1}}],[\"random\",{\"1\":{\"24\":1,\"124\":1,\"146\":3,\"197\":1,\"227\":1,\"228\":1,\"244\":1,\"267\":1},\"2\":{\"39\":1,\"205\":1}}],[\"ran\",{\"0\":{\"242\":1,\"243\":1},\"1\":{\"238\":1,\"239\":6,\"241\":2,\"242\":3,\"244\":18,\"245\":4,\"246\":2}}],[\"ranked\",{\"1\":{\"216\":2}}],[\"ranks\",{\"1\":{\"105\":1}}],[\"rank\",{\"1\":{\"105\":1,\"146\":1,\"217\":2}}],[\"ranking\",{\"1\":{\"43\":1,\"72\":2,\"105\":3,\"216\":3,\"217\":1}}],[\"ranges\",{\"1\":{\"245\":1}}],[\"range\",{\"1\":{\"1\":1,\"3\":1,\"96\":1,\"97\":1,\"121\":1,\"216\":1}}],[\"rare\",{\"1\":{\"2\":1,\"9\":1,\"212\":1}}],[\"reincorporated\",{\"1\":{\"218\":2}}],[\"rei\",{\"1\":{\"214\":1,\"221\":1}}],[\"reimers\",{\"1\":{\"78\":1,\"87\":1,\"89\":1}}],[\"reuse\",{\"0\":{\"157\":1}}],[\"reunião\",{\"1\":{\"30\":1}}],[\"redundant\",{\"1\":{\"156\":2,\"241\":1}}],[\"reduction\",{\"1\":{\"81\":1,\"120\":1}}],[\"reducing\",{\"1\":{\"1\":1,\"228\":1}}],[\"reduced\",{\"1\":{\"3\":1,\"35\":1}}],[\"reduce\",{\"1\":{\"1\":3,\"115\":1,\"157\":1,\"170\":1,\"172\":1,\"203\":1}}],[\"red\",{\"1\":{\"94\":1}}],[\"remains\",{\"1\":{\"209\":1}}],[\"remaining\",{\"1\":{\"146\":1,\"252\":1,\"265\":1}}],[\"remain\",{\"1\":{\"126\":1}}],[\"remarkable\",{\"1\":{\"245\":1}}],[\"remark\",{\"1\":{\"82\":1,\"83\":1}}],[\"removal\",{\"1\":{\"57\":1}}],[\"removing\",{\"1\":{\"35\":1,\"55\":1,\"254\":1}}],[\"revisit\",{\"1\":{\"259\":1}}],[\"revisiting\",{\"0\":{\"250\":1},\"1\":{\"260\":1}}],[\"reversed\",{\"1\":{\"227\":1}}],[\"reveal\",{\"1\":{\"80\":1}}],[\"revolutionized\",{\"1\":{\"119\":1}}],[\"revue\",{\"1\":{\"37\":1}}],[\"reflect\",{\"1\":{\"137\":1}}],[\"reflects\",{\"1\":{\"111\":1,\"200\":1,\"266\":1}}],[\"refrigerator\",{\"1\":{\"125\":2}}],[\"refutes\",{\"1\":{\"71\":2}}],[\"refuted\",{\"1\":{\"66\":1,\"69\":2,\"71\":2}}],[\"ref\",{\"1\":{\"66\":1,\"69\":5,\"71\":2,\"212\":1,\"216\":1,\"218\":2}}],[\"referencing\",{\"1\":{\"225\":1}}],[\"reference\",{\"0\":{\"61\":1,\"89\":1,\"116\":1,\"143\":1,\"167\":1,\"191\":1,\"221\":1,\"271\":1},\"1\":{\"105\":7,\"125\":2,\"175\":4,\"211\":4,\"212\":3,\"213\":1,\"214\":1,\"216\":8,\"218\":9,\"228\":1}}],[\"references\",{\"0\":{\"9\":1,\"37\":1,\"46\":1,\"74\":1,\"102\":1,\"127\":1,\"235\":1,\"247\":1,\"260\":1},\"1\":{\"105\":1,\"124\":2,\"209\":1,\"213\":1}}],[\"referring\",{\"1\":{\"51\":2,\"124\":1}}],[\"referred\",{\"1\":{\"27\":1,\"254\":1}}],[\"refers\",{\"1\":{\"51\":1,\"263\":1,\"266\":1}}],[\"refer\",{\"1\":{\"24\":1,\"112\":1,\"140\":1,\"240\":1}}],[\"registered\",{\"1\":{\"218\":3}}],[\"region\",{\"1\":{\"100\":2}}],[\"regions\",{\"1\":{\"82\":1,\"94\":1}}],[\"regressed\",{\"1\":{\"217\":2}}],[\"regresses\",{\"1\":{\"105\":1}}],[\"regression\",{\"1\":{\"214\":1,\"216\":1,\"219\":1}}],[\"regressive\",{\"0\":{\"156\":1},\"1\":{\"156\":1}}],[\"regress\",{\"1\":{\"105\":1}}],[\"regularized\",{\"1\":{\"65\":1,\"74\":1},\"2\":{\"76\":1}}],[\"regard\",{\"1\":{\"212\":1,\"213\":1}}],[\"regarded\",{\"1\":{\"156\":1}}],[\"regarding\",{\"1\":{\"45\":1,\"68\":1}}],[\"regardless\",{\"1\":{\"22\":1,\"71\":1,\"100\":1}}],[\"released\",{\"1\":{\"269\":1}}],[\"release\",{\"1\":{\"197\":1}}],[\"relevant\",{\"1\":{\"66\":1,\"82\":1,\"231\":2,\"233\":2}}],[\"relu\",{\"1\":{\"140\":1}}],[\"rely\",{\"1\":{\"112\":1}}],[\"relying\",{\"1\":{\"65\":1}}],[\"reliably\",{\"1\":{\"212\":1}}],[\"reliable\",{\"1\":{\"65\":1}}],[\"relies\",{\"1\":{\"72\":1,\"96\":1,\"130\":1,\"215\":1}}],[\"related\",{\"1\":{\"71\":1,\"72\":1,\"73\":1,\"84\":1,\"100\":1,\"120\":1,\"153\":1,\"189\":1,\"208\":1,\"244\":2,\"269\":1}}],[\"relative\",{\"1\":{\"94\":1}}],[\"relatively\",{\"1\":{\"1\":1,\"23\":1,\"94\":1,\"111\":1}}],[\"relational\",{\"1\":{\"53\":1,\"58\":1,\"60\":1}}],[\"relations\",{\"1\":{\"49\":4,\"50\":1,\"51\":2,\"53\":1,\"54\":2,\"57\":1,\"58\":1,\"59\":1,\"60\":3,\"114\":1,\"146\":1}}],[\"relationships\",{\"1\":{\"114\":2,\"124\":1}}],[\"relationship\",{\"1\":{\"3\":1,\"124\":2,\"244\":1}}],[\"relation\",{\"0\":{\"49\":1,\"57\":1,\"58\":1},\"1\":{\"49\":2,\"50\":3,\"53\":2,\"54\":1,\"60\":2,\"61\":2,\"216\":1},\"2\":{\"63\":1}}],[\"re\",{\"1\":{\"49\":3,\"53\":1,\"54\":4,\"58\":1,\"59\":1,\"184\":1,\"218\":1,\"228\":1,\"231\":1,\"266\":2}}],[\"returns\",{\"1\":{\"258\":1}}],[\"rethinking\",{\"1\":{\"247\":1}}],[\"retrival\",{\"1\":{\"66\":1,\"71\":1}}],[\"retrieval\",{\"0\":{\"68\":1},\"1\":{\"35\":2,\"68\":1,\"71\":4,\"72\":2,\"231\":4,\"232\":1,\"233\":4}}],[\"retrieves\",{\"1\":{\"228\":1}}],[\"retrieved\",{\"1\":{\"71\":3,\"72\":2,\"232\":1,\"233\":3,\"242\":1}}],[\"retrieve\",{\"1\":{\"2\":1,\"66\":1,\"71\":1,\"79\":1}}],[\"retained\",{\"1\":{\"42\":1,\"208\":1}}],[\"reed\",{\"1\":{\"37\":1}}],[\"requiring\",{\"1\":{\"27\":1,\"58\":1}}],[\"requires\",{\"1\":{\"23\":2,\"25\":1,\"50\":1,\"59\":1,\"113\":1,\"158\":1,\"178\":1,\"197\":1,\"231\":1,\"240\":1}}],[\"require\",{\"1\":{\"1\":1,\"24\":1,\"53\":1,\"105\":1,\"141\":1,\"152\":1,\"251\":1}}],[\"required\",{\"1\":{\"1\":1,\"96\":1,\"100\":1}}],[\"reparameterization\",{\"1\":{\"182\":1}}],[\"reports\",{\"1\":{\"254\":1}}],[\"report\",{\"1\":{\"208\":1,\"221\":1}}],[\"reported\",{\"1\":{\"141\":1,\"269\":1}}],[\"repository\",{\"1\":{\"153\":1,\"163\":1,\"164\":1}}],[\"repetitive\",{\"1\":{\"126\":1}}],[\"repeatedly\",{\"1\":{\"212\":1}}],[\"repeated\",{\"1\":{\"98\":1,\"216\":1}}],[\"replacing\",{\"1\":{\"71\":2,\"146\":2,\"197\":1}}],[\"replaceable\",{\"1\":{\"241\":1}}],[\"replaces\",{\"1\":{\"71\":1}}],[\"replace\",{\"1\":{\"68\":1,\"211\":1}}],[\"replaced\",{\"1\":{\"24\":2,\"54\":1,\"71\":1,\"197\":1}}],[\"representing\",{\"1\":{\"240\":1}}],[\"represents\",{\"1\":{\"69\":1,\"94\":1,\"100\":1}}],[\"represent\",{\"1\":{\"42\":1,\"93\":1,\"96\":1,\"100\":1,\"130\":2,\"196\":1}}],[\"represented\",{\"1\":{\"35\":1,\"51\":2,\"112\":1}}],[\"representative\",{\"1\":{\"25\":1,\"98\":1,\"203\":1,\"246\":1}}],[\"representations\",{\"1\":{\"33\":1,\"51\":1,\"78\":1,\"89\":1,\"94\":2,\"100\":3,\"101\":1,\"102\":1,\"105\":2,\"116\":1,\"130\":2,\"142\":1,\"175\":1,\"210\":1,\"240\":3,\"242\":1,\"245\":2,\"260\":1}}],[\"representation\",{\"0\":{\"34\":1,\"35\":1},\"1\":{\"23\":1,\"24\":3,\"33\":3,\"34\":1,\"35\":4,\"42\":1,\"51\":2,\"54\":1,\"89\":1,\"93\":1,\"94\":1,\"95\":1,\"96\":1,\"100\":1,\"101\":1,\"110\":1,\"134\":2,\"136\":1,\"137\":4,\"172\":1,\"194\":1,\"196\":1,\"201\":3,\"203\":2,\"212\":3,\"240\":1}}],[\"reproduce\",{\"1\":{\"25\":1}}],[\"reason\",{\"1\":{\"71\":1,\"201\":1}}],[\"reasons\",{\"1\":{\"65\":1,\"152\":1}}],[\"reasoning\",{\"0\":{\"58\":1},\"1\":{\"50\":1,\"51\":3,\"54\":1,\"58\":1,\"60\":2,\"61\":1,\"65\":1,\"66\":1,\"71\":1,\"74\":1,\"124\":1},\"2\":{\"76\":1}}],[\"reasonable\",{\"1\":{\"22\":1,\"25\":1,\"114\":1,\"200\":2,\"244\":1}}],[\"realm\",{\"1\":{\"219\":1}}],[\"really\",{\"1\":{\"132\":1,\"238\":1}}],[\"real\",{\"0\":{\"166\":1},\"1\":{\"42\":1,\"78\":1,\"84\":1,\"101\":1,\"151\":1,\"171\":1,\"252\":1}}],[\"readers\",{\"1\":{\"224\":1,\"240\":1}}],[\"readable\",{\"1\":{\"126\":1}}],[\"reading\",{\"1\":{\"64\":1,\"68\":1,\"92\":1,\"94\":1,\"95\":1,\"97\":1,\"101\":1,\"206\":1,\"238\":1,\"250\":1}}],[\"read\",{\"1\":{\"27\":1,\"95\":1,\"109\":1,\"228\":1,\"231\":1}}],[\"reach\",{\"1\":{\"130\":1,\"229\":1,\"234\":1}}],[\"reached\",{\"1\":{\"35\":1}}],[\"reaches\",{\"1\":{\"26\":1,\"36\":2}}],[\"reaching\",{\"1\":{\"22\":1,\"93\":1}}],[\"rec\",{\"1\":{\"242\":1}}],[\"recursively\",{\"1\":{\"242\":1}}],[\"recurrently\",{\"1\":{\"246\":1}}],[\"recurrent\",{\"0\":{\"238\":1,\"242\":1},\"1\":{\"119\":1,\"225\":2,\"232\":2,\"239\":1,\"242\":5,\"246\":1},\"2\":{\"249\":1}}],[\"recall\",{\"1\":{\"212\":4}}],[\"received\",{\"1\":{\"224\":1}}],[\"receive\",{\"1\":{\"216\":1}}],[\"receives\",{\"1\":{\"184\":1,\"218\":1}}],[\"receiving\",{\"1\":{\"209\":1}}],[\"recently\",{\"1\":{\"41\":1,\"78\":1,\"105\":1,\"170\":1,\"263\":1}}],[\"recent\",{\"1\":{\"22\":1,\"49\":1,\"65\":1,\"93\":1,\"94\":1,\"146\":2,\"194\":1,\"210\":1,\"219\":1,\"224\":1,\"239\":2}}],[\"reconstruciotn\",{\"1\":{\"266\":1}}],[\"reconstruction\",{\"0\":{\"266\":1},\"1\":{\"265\":1,\"266\":1}}],[\"reconstructed\",{\"1\":{\"184\":1,\"266\":2}}],[\"recovering\",{\"1\":{\"266\":1}}],[\"recomputation\",{\"1\":{\"242\":1}}],[\"recommended\",{\"1\":{\"212\":1}}],[\"records\",{\"1\":{\"151\":1}}],[\"recordings\",{\"1\":{\"93\":1,\"97\":1}}],[\"record\",{\"1\":{\"93\":2}}],[\"recorded\",{\"1\":{\"3\":1,\"93\":1}}],[\"recognizing\",{\"1\":{\"124\":1}}],[\"recognized\",{\"1\":{\"218\":3}}],[\"recognizer\",{\"1\":{\"67\":1}}],[\"recognize\",{\"1\":{\"49\":1}}],[\"recognition\",{\"1\":{\"43\":1,\"170\":1,\"172\":1,\"174\":1,\"175\":1,\"232\":1}}],[\"render\",{\"1\":{\"212\":1}}],[\"renduchintala\",{\"1\":{\"9\":1}}],[\"ren\",{\"1\":{\"21\":3,\"22\":1,\"36\":2}}],[\"restricts\",{\"1\":{\"266\":1}}],[\"restriction\",{\"1\":{\"266\":1}}],[\"restrictions\",{\"1\":{\"211\":1}}],[\"restore\",{\"1\":{\"266\":1}}],[\"rescaling\",{\"1\":{\"240\":1}}],[\"residual\",{\"1\":{\"140\":1,\"195\":1,\"242\":1}}],[\"resistant\",{\"1\":{\"41\":1,\"46\":1}}],[\"resemble\",{\"1\":{\"97\":1}}],[\"researched\",{\"1\":{\"93\":1}}],[\"researchers\",{\"1\":{\"23\":1,\"41\":1,\"42\":1,\"43\":8,\"170\":1,\"225\":1,\"228\":1,\"232\":1,\"251\":1}}],[\"research\",{\"1\":{\"9\":1,\"22\":1,\"36\":1,\"93\":1,\"94\":1,\"98\":1,\"101\":1,\"115\":1,\"130\":2,\"146\":1,\"170\":3,\"190\":1,\"208\":1,\"210\":1,\"215\":1,\"221\":3,\"228\":1,\"239\":1,\"263\":1,\"264\":1,\"269\":1,\"271\":1}}],[\"responses\",{\"1\":{\"42\":1}}],[\"respective\",{\"1\":{\"125\":1,\"181\":1}}],[\"respectively\",{\"1\":{\"6\":1,\"23\":1,\"54\":1,\"57\":1,\"112\":1,\"146\":1,\"174\":1,\"240\":1,\"244\":2}}],[\"respect\",{\"1\":{\"3\":1,\"6\":1}}],[\"resulted\",{\"1\":{\"122\":1,\"225\":1}}],[\"resulting\",{\"1\":{\"2\":1,\"8\":1,\"25\":1,\"146\":1,\"198\":1,\"212\":1,\"216\":1}}],[\"results\",{\"0\":{\"54\":1,\"86\":1,\"87\":1,\"141\":1,\"187\":1,\"244\":1},\"1\":{\"1\":1,\"3\":3,\"5\":1,\"6\":2,\"7\":2,\"23\":2,\"25\":1,\"42\":1,\"43\":3,\"58\":1,\"60\":1,\"68\":1,\"71\":1,\"72\":1,\"85\":1,\"86\":1,\"93\":1,\"98\":3,\"99\":3,\"100\":1,\"105\":1,\"122\":1,\"125\":1,\"126\":1,\"130\":2,\"146\":1,\"157\":1,\"163\":1,\"164\":1,\"172\":2,\"184\":2,\"187\":1,\"189\":2,\"202\":1,\"203\":1,\"211\":1,\"218\":1,\"227\":1,\"244\":2,\"253\":1,\"254\":1,\"256\":1,\"269\":1}}],[\"result\",{\"1\":{\"1\":1,\"8\":1,\"23\":1,\"44\":1,\"65\":4,\"70\":1,\"71\":5,\"109\":2,\"112\":1,\"113\":2,\"114\":1,\"141\":1,\"146\":1,\"183\":1,\"184\":1,\"211\":1,\"218\":3,\"252\":1,\"258\":1}}],[\"resources\",{\"1\":{\"1\":1,\"93\":2,\"105\":2,\"263\":3,\"269\":1}}],[\"resource\",{\"0\":{\"6\":1},\"1\":{\"1\":1,\"6\":1,\"22\":3,\"23\":1,\"25\":1,\"93\":2,\"113\":3,\"146\":2,\"152\":1,\"175\":1,\"186\":2,\"187\":4,\"225\":3,\"226\":1,\"227\":1,\"244\":1,\"256\":2,\"263\":1,\"270\":1}}],[\"mnemonic\",{\"1\":{\"228\":1}}],[\"mnmt\",{\"1\":{\"141\":2}}],[\"mc24\",{\"1\":{\"194\":1,\"198\":1,\"200\":1,\"201\":1,\"202\":2}}],[\"mcgill\",{\"1\":{\"37\":2}}],[\"mgnmt\",{\"0\":{\"180\":1},\"1\":{\"178\":1,\"181\":2,\"182\":2,\"183\":5,\"184\":1,\"186\":1,\"187\":3,\"188\":3,\"189\":1,\"190\":4}}],[\"msi\",{\"1\":{\"146\":4}}],[\"ms\",{\"1\":{\"139\":1,\"166\":2}}],[\"mäso\",{\"1\":{\"125\":1}}],[\"môžete\",{\"1\":{\"125\":1}}],[\"môžeme\",{\"1\":{\"125\":2}}],[\"môcť\",{\"1\":{\"125\":1}}],[\"máš\",{\"1\":{\"125\":1}}],[\"mqm\",{\"1\":{\"105\":1,\"215\":1,\"216\":1,\"217\":5}}],[\"mlp\",{\"1\":{\"51\":1}}],[\"mbart\",{\"1\":{\"26\":1,\"35\":2}}],[\"mbert\",{\"1\":{\"26\":1}}],[\"mrinmaya\",{\"1\":{\"116\":1}}],[\"mrc\",{\"1\":{\"68\":2,\"71\":8}}],[\"mrpc\",{\"1\":{\"43\":2}}],[\"mrasp2\",{\"1\":{\"194\":1,\"195\":1,\"199\":3,\"200\":4,\"201\":4,\"203\":5}}],[\"mrasp\",{\"0\":{\"24\":1,\"25\":1,\"33\":1,\"34\":1,\"35\":1},\"1\":{\"21\":1,\"22\":13,\"23\":1,\"24\":6,\"25\":5,\"26\":2,\"27\":3,\"28\":1,\"29\":3,\"30\":3,\"31\":4,\"32\":1,\"33\":5,\"35\":7,\"36\":1,\"199\":2,\"200\":1},\"2\":{\"39\":1,\"205\":1}}],[\"mr\",{\"1\":{\"21\":1,\"36\":1}}],[\"m\",{\"1\":{\"4\":1,\"71\":1,\"96\":2,\"105\":1,\"112\":2,\"113\":3,\"116\":1,\"125\":2,\"130\":1,\"175\":9,\"199\":1,\"200\":3,\"201\":1,\"203\":2,\"221\":1,\"225\":1,\"247\":1,\"267\":1}}],[\"mips\",{\"1\":{\"232\":2}}],[\"microsoft\",{\"1\":{\"225\":1}}],[\"michael\",{\"1\":{\"102\":1,\"105\":1}}],[\"mimic\",{\"1\":{\"218\":1}}],[\"mi​\",{\"1\":{\"156\":2}}],[\"mi\",{\"1\":{\"125\":1}}],[\"mitchell\",{\"1\":{\"116\":1}}],[\"mitigating\",{\"1\":{\"84\":1}}],[\"mis\",{\"1\":{\"228\":1}}],[\"mister\",{\"1\":{\"175\":4}}],[\"mistake\",{\"1\":{\"71\":3,\"175\":1}}],[\"mismatches\",{\"1\":{\"189\":1}}],[\"mismatch\",{\"1\":{\"98\":1}}],[\"mild\",{\"1\":{\"188\":1}}],[\"milestones\",{\"1\":{\"95\":1}}],[\"millions\",{\"1\":{\"226\":1}}],[\"million\",{\"1\":{\"22\":1,\"25\":2,\"198\":1}}],[\"mirror\",{\"0\":{\"178\":1},\"1\":{\"95\":1,\"137\":1,\"181\":1,\"190\":1,\"191\":1}}],[\"mining\",{\"1\":{\"167\":1}}],[\"minima\",{\"1\":{\"244\":1}}],[\"minimized\",{\"1\":{\"268\":2}}],[\"minimize\",{\"1\":{\"216\":2}}],[\"minimizing\",{\"1\":{\"42\":2,\"43\":1}}],[\"minimum\",{\"1\":{\"156\":1}}],[\"mingxuan\",{\"1\":{\"89\":1,\"102\":1,\"143\":1,\"146\":1,\"203\":1}}],[\"minus\",{\"1\":{\"35\":2}}],[\"minutes\",{\"1\":{\"25\":1,\"27\":1,\"30\":3,\"64\":1,\"92\":1,\"206\":1,\"238\":1,\"250\":1}}],[\"minute\",{\"1\":{\"22\":1}}],[\"mike\",{\"1\":{\"37\":1,\"221\":1}}],[\"middle\",{\"1\":{\"32\":4,\"146\":2}}],[\"migrating\",{\"1\":{\"95\":1}}],[\"migrated\",{\"1\":{\"33\":1}}],[\"migrate\",{\"1\":{\"24\":1}}],[\"might\",{\"1\":{\"3\":1,\"132\":1,\"142\":1,\"225\":2,\"226\":1,\"231\":1,\"252\":1,\"263\":1}}],[\"mix\",{\"1\":{\"1\":1}}],[\"myself\",{\"1\":{\"218\":1}}],[\"my\",{\"1\":{\"2\":1,\"125\":3,\"126\":2,\"218\":1,\"229\":1,\"234\":1,\"269\":1}}],[\"mtsummit\",{\"1\":{\"9\":1}}],[\"mt\",{\"0\":{\"207\":1,\"274\":1},\"1\":{\"1\":1,\"15\":1,\"16\":1,\"17\":1,\"25\":1,\"33\":1,\"93\":4,\"94\":2,\"95\":1,\"98\":3,\"101\":2,\"105\":1,\"113\":1,\"146\":4,\"170\":1,\"171\":1,\"172\":3,\"206\":1,\"208\":3,\"210\":2,\"215\":2,\"216\":1,\"217\":1,\"218\":3,\"219\":8,\"221\":2,\"226\":1,\"256\":1,\"264\":1,\"269\":2,\"270\":1},\"2\":{\"10\":1,\"11\":1,\"19\":1,\"38\":1,\"39\":1,\"106\":1,\"107\":1,\"117\":1,\"118\":1,\"144\":1,\"147\":1,\"148\":1,\"192\":1,\"204\":1,\"205\":1,\"222\":1,\"223\":1,\"236\":1,\"248\":1,\"261\":1,\"272\":1}}],[\"medieval\",{\"1\":{\"228\":2}}],[\"mediated\",{\"1\":{\"215\":1}}],[\"medium\",{\"1\":{\"25\":1}}],[\"meet\",{\"1\":{\"171\":1}}],[\"meeting\",{\"1\":{\"9\":1,\"29\":3,\"30\":5,\"105\":2,\"125\":2,\"175\":1}}],[\"measuring\",{\"1\":{\"209\":1}}],[\"measurement\",{\"1\":{\"212\":1,\"218\":1}}],[\"measures\",{\"1\":{\"208\":2,\"209\":1,\"211\":1,\"266\":1,\"267\":3}}],[\"measured\",{\"1\":{\"123\":1}}],[\"measure\",{\"1\":{\"123\":1,\"124\":1,\"196\":1,\"209\":1,\"212\":1,\"218\":1}}],[\"meantime\",{\"1\":{\"135\":1}}],[\"mean\",{\"1\":{\"123\":1,\"200\":1,\"216\":2}}],[\"meanwhile\",{\"1\":{\"93\":1,\"94\":1,\"172\":1}}],[\"meaningfully\",{\"1\":{\"233\":1}}],[\"meaningful\",{\"1\":{\"115\":1}}],[\"meanings\",{\"1\":{\"79\":1,\"211\":1,\"218\":1,\"263\":1,\"264\":2,\"269\":2}}],[\"meaningless\",{\"1\":{\"31\":1}}],[\"meaning\",{\"1\":{\"3\":2,\"24\":1,\"69\":1,\"71\":1,\"83\":1,\"119\":1,\"122\":1,\"124\":1,\"126\":3,\"137\":1,\"172\":1,\"196\":2,\"211\":1,\"218\":1,\"232\":7}}],[\"means\",{\"1\":{\"1\":3,\"8\":1,\"33\":1,\"54\":1,\"66\":1,\"81\":1,\"84\":1,\"111\":2,\"113\":1,\"120\":1,\"194\":1,\"225\":2,\"231\":2,\"233\":1,\"267\":1}}],[\"meyer\",{\"1\":{\"105\":1}}],[\"memories\",{\"1\":{\"96\":5,\"100\":2}}],[\"memory\",{\"0\":{\"96\":1,\"157\":1,\"224\":1,\"228\":1,\"230\":1},\"1\":{\"95\":1,\"96\":6,\"97\":1,\"100\":6,\"112\":1,\"132\":1,\"152\":2,\"155\":1,\"156\":1,\"157\":4,\"224\":1,\"227\":1,\"228\":5,\"230\":1,\"231\":2,\"233\":4,\"235\":2},\"2\":{\"104\":1,\"237\":1}}],[\"mezzofanti\",{\"1\":{\"93\":1}}],[\"mexico\",{\"1\":{\"71\":1}}],[\"me\",{\"1\":{\"59\":2,\"69\":1,\"125\":2,\"228\":1,\"229\":2,\"232\":1}}],[\"mechanisms\",{\"1\":{\"54\":1}}],[\"mechanism\",{\"1\":{\"51\":1,\"60\":1,\"216\":1,\"227\":1,\"231\":4,\"233\":3,\"238\":1,\"239\":2,\"240\":1,\"245\":1}}],[\"mentions\",{\"1\":{\"51\":10,\"57\":1,\"60\":1}}],[\"mention\",{\"1\":{\"51\":9,\"55\":2,\"57\":1,\"60\":1,\"124\":2}}],[\"mentioned\",{\"1\":{\"50\":1,\"133\":1}}],[\"melvin\",{\"1\":{\"37\":1}}],[\"merges\",{\"1\":{\"2\":1}}],[\"merge\",{\"1\":{\"2\":1,\"9\":1}}],[\"merging\",{\"1\":{\"2\":1,\"51\":1}}],[\"meteor\",{\"1\":{\"105\":4,\"221\":1}}],[\"metric\",{\"1\":{\"2\":1,\"105\":4,\"124\":2,\"209\":2,\"210\":1,\"211\":2,\"212\":3,\"213\":1,\"214\":1,\"215\":3,\"217\":2,\"218\":2,\"219\":1,\"221\":1}}],[\"metrics\",{\"0\":{\"71\":1,\"206\":1,\"207\":1},\"1\":{\"1\":1,\"3\":1,\"54\":1,\"70\":1,\"105\":6,\"208\":1,\"210\":1,\"211\":5,\"213\":1,\"215\":2,\"217\":2,\"218\":5,\"219\":4,\"221\":2}}],[\"methodology\",{\"0\":{\"134\":1},\"1\":{\"1\":1}}],[\"methods\",{\"0\":{\"265\":1},\"1\":{\"1\":5,\"2\":1,\"6\":1,\"8\":2,\"22\":2,\"23\":1,\"25\":1,\"36\":1,\"37\":1,\"49\":1,\"54\":1,\"60\":1,\"93\":1,\"105\":1,\"109\":1,\"121\":1,\"130\":1,\"132\":1,\"154\":1,\"164\":1,\"170\":1,\"171\":1,\"172\":2,\"189\":1,\"210\":1,\"214\":1,\"239\":1,\"244\":1,\"252\":1,\"256\":1,\"266\":1,\"269\":1,\"270\":1}}],[\"method\",{\"0\":{\"84\":1,\"254\":1},\"1\":{\"1\":1,\"5\":1,\"6\":1,\"8\":2,\"24\":1,\"26\":1,\"31\":2,\"34\":1,\"41\":1,\"42\":1,\"43\":2,\"44\":1,\"45\":3,\"54\":1,\"65\":1,\"71\":1,\"73\":1,\"85\":1,\"87\":1,\"105\":1,\"109\":6,\"112\":6,\"113\":1,\"137\":1,\"141\":1,\"142\":1,\"146\":1,\"156\":1,\"171\":1,\"183\":1,\"188\":1,\"194\":1,\"197\":1,\"202\":1,\"208\":1,\"217\":1,\"221\":1,\"232\":1,\"241\":2,\"250\":1,\"251\":2,\"259\":1,\"263\":1,\"264\":1,\"265\":1,\"269\":10,\"270\":2}}],[\"muse\",{\"1\":{\"269\":1}}],[\"musím\",{\"1\":{\"125\":1}}],[\"muslim\",{\"1\":{\"93\":1}}],[\"must\",{\"1\":{\"1\":1,\"8\":1,\"93\":1,\"97\":1,\"98\":2,\"99\":2,\"101\":1,\"196\":1}}],[\"mundiais\",{\"1\":{\"30\":1}}],[\"muv\",{\"1\":{\"3\":13}}],[\"multidimensional\",{\"1\":{\"215\":1}}],[\"multiplying\",{\"1\":{\"212\":2}}],[\"multiply\",{\"1\":{\"155\":1}}],[\"multiple\",{\"1\":{\"2\":1,\"23\":1,\"36\":1,\"50\":1,\"51\":2,\"53\":1,\"57\":1,\"71\":1,\"132\":1,\"146\":3,\"151\":1,\"155\":1}}],[\"multiligual\",{\"1\":{\"146\":1,\"194\":1}}],[\"multilingual\",{\"0\":{\"21\":1,\"146\":1,\"194\":1,\"196\":1},\"1\":{\"1\":1,\"4\":1,\"21\":1,\"22\":2,\"23\":2,\"24\":2,\"26\":2,\"36\":2,\"37\":3,\"105\":1,\"109\":4,\"110\":2,\"111\":2,\"112\":1,\"113\":1,\"115\":1,\"146\":16,\"194\":1,\"195\":1,\"196\":1,\"197\":2,\"199\":2,\"202\":1,\"203\":4,\"214\":1,\"227\":1},\"2\":{\"11\":1,\"39\":1,\"118\":1,\"148\":1,\"205\":1}}],[\"multi30k\",{\"1\":{\"139\":1,\"269\":1}}],[\"multimodal\",{\"1\":{\"93\":1,\"130\":1,\"131\":2,\"136\":1,\"141\":1}}],[\"multi\",{\"0\":{\"240\":1},\"1\":{\"7\":1,\"51\":1,\"93\":1,\"94\":1,\"133\":1,\"171\":1,\"172\":1,\"238\":1,\"239\":1,\"240\":3,\"242\":1}}],[\"much\",{\"1\":{\"1\":4,\"3\":2,\"6\":1,\"24\":1,\"29\":1,\"35\":1,\"43\":1,\"78\":1,\"93\":2,\"112\":1,\"113\":1,\"120\":1,\"130\":1,\"170\":1,\"171\":2,\"200\":1,\"208\":1,\"217\":1,\"229\":1,\"234\":1,\"254\":2,\"263\":1,\"266\":1}}],[\"moment\",{\"1\":{\"230\":1}}],[\"mohammad\",{\"1\":{\"221\":1}}],[\"mohamed\",{\"1\":{\"102\":1,\"175\":1}}],[\"motivate\",{\"1\":{\"228\":1}}],[\"motivates\",{\"1\":{\"211\":1}}],[\"motivated\",{\"1\":{\"211\":1,\"215\":1}}],[\"motivations\",{\"0\":{\"264\":1}}],[\"motivation\",{\"0\":{\"24\":1,\"95\":1,\"133\":1,\"152\":1,\"211\":1,\"215\":1},\"1\":{\"22\":1,\"93\":1,\"130\":1,\"215\":1,\"267\":1}}],[\"morning\",{\"1\":{\"125\":1}}],[\"moreover\",{\"1\":{\"25\":1,\"53\":1,\"146\":1,\"184\":1,\"190\":1,\"242\":1,\"244\":1,\"253\":1}}],[\"more\",{\"0\":{\"165\":1},\"1\":{\"1\":1,\"6\":1,\"23\":1,\"24\":2,\"25\":2,\"28\":1,\"43\":1,\"53\":1,\"57\":1,\"60\":1,\"65\":1,\"71\":2,\"82\":1,\"93\":3,\"98\":1,\"101\":1,\"112\":1,\"115\":1,\"120\":2,\"142\":1,\"146\":6,\"155\":2,\"158\":1,\"174\":1,\"181\":1,\"184\":1,\"188\":1,\"211\":1,\"212\":1,\"218\":4,\"219\":2,\"225\":1,\"228\":3,\"231\":2,\"232\":2,\"233\":1,\"244\":2,\"245\":1,\"254\":1,\"257\":2,\"263\":1,\"264\":1}}],[\"move\",{\"1\":{\"212\":1,\"219\":1}}],[\"mover\",{\"1\":{\"105\":1}}],[\"moverscore\",{\"1\":{\"105\":2}}],[\"movie\",{\"1\":{\"98\":1,\"170\":1}}],[\"movies\",{\"1\":{\"95\":1}}],[\"modal\",{\"1\":{\"95\":1,\"133\":1,\"135\":1}}],[\"modalities\",{\"1\":{\"93\":2,\"94\":1,\"95\":1,\"100\":2,\"101\":1,\"137\":1}}],[\"modality\",{\"1\":{\"93\":4,\"94\":5,\"95\":1,\"100\":2}}],[\"mode\",{\"1\":{\"71\":1}}],[\"modelled\",{\"1\":{\"174\":1}}],[\"modelling\",{\"1\":{\"153\":1,\"172\":1,\"175\":1},\"2\":{\"129\":1}}],[\"modeling\",{\"1\":{\"81\":1,\"119\":2,\"188\":1}}],[\"modeled\",{\"1\":{\"51\":3}}],[\"model\",{\"0\":{\"33\":1,\"51\":1,\"69\":1,\"71\":1,\"175\":1,\"233\":1},\"1\":{\"2\":2,\"3\":1,\"21\":3,\"22\":9,\"23\":8,\"24\":4,\"25\":2,\"26\":1,\"27\":4,\"31\":1,\"33\":1,\"36\":1,\"41\":6,\"42\":14,\"43\":11,\"44\":4,\"45\":2,\"46\":1,\"51\":5,\"53\":1,\"54\":1,\"59\":1,\"60\":2,\"64\":1,\"65\":1,\"66\":1,\"68\":4,\"69\":1,\"70\":1,\"71\":3,\"72\":1,\"78\":1,\"80\":1,\"92\":1,\"93\":3,\"95\":1,\"100\":1,\"105\":10,\"109\":7,\"110\":2,\"111\":7,\"112\":1,\"113\":6,\"114\":2,\"115\":2,\"119\":2,\"120\":6,\"121\":1,\"122\":3,\"123\":8,\"124\":8,\"125\":3,\"126\":5,\"134\":1,\"136\":1,\"139\":1,\"146\":21,\"149\":1,\"152\":1,\"154\":2,\"155\":2,\"156\":1,\"166\":1,\"171\":2,\"172\":1,\"173\":1,\"175\":2,\"178\":1,\"181\":1,\"188\":2,\"190\":1,\"194\":2,\"195\":3,\"196\":3,\"200\":1,\"206\":1,\"212\":1,\"214\":2,\"215\":1,\"216\":8,\"217\":2,\"218\":1,\"219\":1,\"227\":5,\"228\":3,\"231\":3,\"233\":6,\"234\":1,\"238\":1,\"240\":1,\"242\":1,\"250\":1,\"251\":4,\"252\":5,\"254\":1,\"263\":6,\"264\":1,\"265\":1,\"267\":2,\"269\":3},\"2\":{\"48\":1,\"148\":1,\"193\":1}}],[\"models\",{\"0\":{\"2\":1,\"40\":1,\"151\":1},\"1\":{\"1\":1,\"2\":1,\"8\":1,\"22\":3,\"25\":1,\"26\":1,\"36\":1,\"40\":1,\"41\":5,\"42\":1,\"43\":7,\"45\":4,\"49\":1,\"54\":3,\"65\":3,\"71\":1,\"77\":2,\"78\":1,\"82\":1,\"84\":1,\"89\":2,\"92\":1,\"93\":1,\"105\":2,\"109\":1,\"111\":2,\"113\":3,\"115\":1,\"119\":1,\"120\":1,\"121\":2,\"122\":1,\"124\":3,\"126\":5,\"127\":1,\"146\":1,\"151\":4,\"152\":3,\"153\":4,\"155\":1,\"157\":1,\"163\":2,\"164\":1,\"167\":2,\"170\":1,\"172\":1,\"175\":1,\"181\":2,\"186\":1,\"190\":1,\"194\":1,\"199\":1,\"210\":1,\"214\":1,\"216\":1,\"217\":4,\"219\":1,\"239\":1,\"244\":2,\"247\":1}}],[\"module\",{\"0\":{\"240\":1},\"1\":{\"51\":4,\"55\":1,\"58\":1,\"71\":4,\"72\":1,\"95\":1,\"96\":9,\"97\":2,\"100\":1,\"134\":1,\"174\":2,\"239\":3,\"240\":2,\"242\":7,\"246\":1}}],[\"modules\",{\"1\":{\"51\":1,\"60\":1,\"96\":1,\"111\":1,\"136\":1,\"172\":1,\"242\":1}}],[\"modify\",{\"1\":{\"111\":1}}],[\"modifying\",{\"1\":{\"43\":1}}],[\"modified\",{\"1\":{\"43\":1}}],[\"monetary\",{\"1\":{\"29\":2}}],[\"money\",{\"1\":{\"3\":1}}],[\"monolingual\",{\"0\":{\"224\":1,\"227\":1,\"230\":1,\"263\":1},\"1\":{\"24\":1,\"25\":1,\"26\":2,\"113\":2,\"181\":1,\"188\":1,\"194\":2,\"197\":1,\"198\":1,\"200\":3,\"202\":1,\"203\":2,\"209\":1,\"224\":1,\"227\":5,\"230\":2,\"231\":2,\"235\":1,\"252\":1,\"257\":1,\"258\":2,\"263\":3,\"271\":1}}],[\"month\",{\"1\":{\"24\":1}}],[\"months\",{\"1\":{\"24\":1}}],[\"mostly\",{\"1\":{\"218\":2}}],[\"most\",{\"1\":{\"1\":1,\"2\":1,\"4\":1,\"5\":1,\"7\":1,\"27\":1,\"37\":1,\"51\":1,\"71\":2,\"95\":1,\"98\":1,\"105\":1,\"114\":1,\"120\":3,\"124\":2,\"132\":1,\"170\":1,\"172\":1,\"194\":1,\"199\":1,\"209\":2,\"212\":1,\"216\":1,\"218\":3,\"219\":1,\"231\":1,\"232\":1,\"239\":1,\"244\":2,\"245\":1,\"253\":1,\"269\":1}}],[\"maps\",{\"1\":{\"233\":1}}],[\"mapped\",{\"1\":{\"232\":1,\"233\":1,\"253\":1,\"264\":1}}],[\"mapping\",{\"1\":{\"84\":1,\"195\":1,\"228\":1,\"264\":1}}],[\"map\",{\"1\":{\"226\":1,\"232\":2,\"264\":7,\"268\":1}}],[\"macherey\",{\"1\":{\"221\":2}}],[\"machinery\",{\"1\":{\"130\":1}}],[\"machines\",{\"1\":{\"1\":1,\"221\":1,\"225\":1}}],[\"machine\",{\"0\":{\"0\":1,\"21\":1,\"23\":1,\"105\":1,\"108\":1,\"130\":1,\"146\":1,\"178\":1,\"194\":1,\"206\":1,\"224\":1,\"225\":1,\"238\":1,\"252\":1,\"256\":1,\"263\":1},\"1\":{\"0\":2,\"1\":2,\"5\":1,\"8\":2,\"9\":4,\"21\":1,\"22\":7,\"23\":7,\"24\":3,\"25\":1,\"27\":1,\"33\":1,\"36\":5,\"37\":4,\"41\":1,\"68\":1,\"93\":4,\"95\":2,\"101\":1,\"105\":9,\"109\":3,\"112\":1,\"115\":3,\"116\":1,\"119\":1,\"125\":1,\"126\":1,\"130\":3,\"131\":1,\"132\":1,\"136\":1,\"137\":1,\"141\":1,\"143\":1,\"146\":7,\"151\":1,\"153\":1,\"164\":1,\"170\":1,\"172\":2,\"178\":1,\"191\":1,\"203\":1,\"206\":1,\"208\":1,\"209\":1,\"213\":1,\"214\":1,\"215\":1,\"218\":1,\"221\":4,\"224\":2,\"226\":1,\"227\":1,\"228\":2,\"232\":1,\"234\":1,\"235\":2,\"238\":1,\"239\":1,\"246\":1,\"247\":2,\"250\":1,\"251\":2,\"252\":1,\"259\":2,\"263\":5,\"267\":1,\"270\":2,\"271\":1},\"2\":{\"145\":1,\"273\":1}}],[\"magnitude\",{\"1\":{\"146\":1}}],[\"mať\",{\"1\":{\"125\":1}}],[\"mail\",{\"1\":{\"125\":1}}],[\"maintaining\",{\"1\":{\"201\":1}}],[\"maintains\",{\"1\":{\"31\":1}}],[\"mainly\",{\"1\":{\"33\":1,\"71\":2,\"96\":1}}],[\"main\",{\"0\":{\"54\":1,\"233\":1,\"244\":1},\"1\":{\"1\":1,\"4\":1,\"71\":1,\"93\":1,\"99\":2,\"141\":1,\"146\":1,\"154\":1,\"202\":1,\"213\":1,\"221\":2,\"227\":2,\"232\":2,\"233\":1,\"238\":1,\"240\":1}}],[\"mal\",{\"1\":{\"175\":4}}],[\"maldon\",{\"1\":{\"175\":5}}],[\"mali\",{\"1\":{\"125\":1}}],[\"malicious\",{\"1\":{\"40\":1,\"41\":1}}],[\"mall\",{\"1\":{\"125\":2}}],[\"maxim\",{\"1\":{\"221\":1}}],[\"maximize\",{\"1\":{\"184\":1,\"258\":1}}],[\"maximizing\",{\"1\":{\"183\":1}}],[\"maximal\",{\"1\":{\"157\":1}}],[\"maxime\",{\"1\":{\"105\":1}}],[\"maximum\",{\"1\":{\"81\":1,\"156\":1,\"157\":1,\"163\":1,\"182\":1,\"212\":2,\"232\":1,\"266\":1}}],[\"maosong\",{\"1\":{\"61\":1}}],[\"major\",{\"0\":{\"79\":1},\"1\":{\"50\":1,\"79\":1,\"120\":1}}],[\"majority\",{\"1\":{\"23\":1,\"65\":1}}],[\"marvinkaster\",{\"1\":{\"221\":1}}],[\"margin\",{\"1\":{\"105\":1,\"146\":1,\"194\":1,\"201\":1,\"202\":1,\"203\":1,\"216\":2,\"256\":1}}],[\"marginal\",{\"1\":{\"3\":4,\"94\":1,\"183\":1}}],[\"maryland\",{\"1\":{\"50\":2}}],[\"marks\",{\"1\":{\"100\":2}}],[\"mark\",{\"1\":{\"42\":1,\"105\":1}}],[\"mady\",{\"1\":{\"37\":1}}],[\"made\",{\"1\":{\"3\":1,\"71\":1,\"96\":1,\"119\":1,\"120\":1,\"124\":3,\"170\":1,\"218\":4,\"234\":1}}],[\"mathematics\",{\"1\":{\"228\":2}}],[\"mathematically\",{\"1\":{\"268\":1}}],[\"mathematical\",{\"1\":{\"226\":1,\"232\":1}}],[\"matrix\",{\"1\":{\"155\":1,\"212\":1,\"233\":2,\"240\":2,\"242\":1,\"264\":1}}],[\"matrice\",{\"1\":{\"240\":1}}],[\"matrices\",{\"1\":{\"8\":1,\"242\":5,\"246\":1}}],[\"matrics\",{\"1\":{\"105\":1}}],[\"materials\",{\"1\":{\"101\":1}}],[\"matches\",{\"1\":{\"218\":1,\"233\":1}}],[\"matched\",{\"1\":{\"100\":1,\"218\":2,\"233\":1}}],[\"matching\",{\"1\":{\"211\":1,\"212\":4}}],[\"match\",{\"1\":{\"35\":1,\"105\":1,\"121\":1,\"211\":1,\"212\":4,\"218\":1}}],[\"masks\",{\"1\":{\"146\":3}}],[\"mask\",{\"1\":{\"68\":1,\"146\":12}}],[\"masking\",{\"1\":{\"68\":1}}],[\"masked\",{\"1\":{\"37\":1,\"80\":1,\"82\":1,\"254\":1}}],[\"mastered\",{\"1\":{\"33\":1,\"36\":1}}],[\"mass\",{\"1\":{\"23\":1,\"26\":1,\"37\":1}}],[\"massive\",{\"1\":{\"23\":1,\"24\":1,\"25\":1,\"26\":1,\"126\":1,\"239\":1}}],[\"making\",{\"1\":{\"6\":1,\"34\":1,\"36\":1,\"37\":1,\"181\":1,\"184\":1,\"194\":1,\"231\":1}}],[\"makes\",{\"1\":{\"23\":1,\"44\":1,\"101\":1,\"109\":2,\"130\":1,\"151\":1,\"253\":1}}],[\"make\",{\"1\":{\"1\":1,\"2\":1,\"3\":1,\"8\":1,\"23\":1,\"28\":1,\"41\":1,\"71\":2,\"79\":1,\"94\":1,\"95\":1,\"101\":1,\"105\":1,\"109\":1,\"110\":2,\"137\":1,\"152\":1,\"172\":1,\"178\":1,\"219\":1,\"226\":1,\"227\":1,\"228\":2,\"231\":1}}],[\"may\",{\"1\":{\"3\":1,\"22\":1,\"24\":5,\"50\":2,\"51\":1,\"59\":1,\"72\":1,\"84\":1,\"93\":1,\"114\":1,\"120\":1,\"124\":1,\"146\":1,\"171\":1,\"194\":1,\"218\":2,\"225\":1,\"227\":2,\"228\":2,\"229\":1,\"244\":1,\"245\":1,\"251\":1}}],[\"manifold\",{\"1\":{\"137\":1}}],[\"manual\",{\"1\":{\"133\":1}}],[\"mandhana\",{\"1\":{\"68\":2}}],[\"managed\",{\"1\":{\"218\":1}}],[\"manages\",{\"1\":{\"2\":1}}],[\"manageable\",{\"1\":{\"1\":1}}],[\"manner\",{\"1\":{\"1\":1}}],[\"many\",{\"0\":{\"194\":2},\"1\":{\"1\":1,\"4\":1,\"7\":1,\"23\":1,\"41\":1,\"50\":1,\"78\":2,\"83\":1,\"93\":1,\"95\":1,\"96\":1,\"105\":1,\"109\":2,\"119\":1,\"126\":1,\"146\":2,\"194\":3,\"195\":2,\"202\":2,\"203\":4,\"225\":1,\"227\":1,\"241\":1,\"263\":3}}],[\"s|\",{\"1\":{\"216\":1}}],[\"src\",{\"1\":{\"216\":1,\"218\":2}}],[\"srl\",{\"1\":{\"13\":1}}],[\"swap\",{\"1\":{\"211\":1}}],[\"swahili\",{\"1\":{\"95\":1}}],[\"sne\",{\"1\":{\"203\":1}}],[\"sgvb\",{\"1\":{\"182\":1}}],[\"svojich\",{\"1\":{\"125\":1}}],[\"svd\",{\"1\":{\"81\":1}}],[\"skončí\",{\"1\":{\"125\":1}}],[\"skills\",{\"1\":{\"23\":1,\"24\":1,\"53\":1}}],[\"s​\",{\"1\":{\"112\":1}}],[\"s×t\",{\"1\":{\"110\":1}}],[\"sme\",{\"1\":{\"125\":1}}],[\"smoothness\",{\"1\":{\"253\":1}}],[\"smoother\",{\"1\":{\"184\":1}}],[\"smooth\",{\"1\":{\"80\":1,\"84\":1}}],[\"smriti\",{\"1\":{\"68\":2}}],[\"smaller\",{\"1\":{\"1\":1,\"5\":1,\"34\":1,\"94\":1,\"146\":2,\"247\":1}}],[\"smallest\",{\"1\":{\"1\":1}}],[\"small\",{\"1\":{\"1\":1,\"21\":1,\"22\":1,\"23\":1,\"42\":1,\"44\":1,\"93\":1,\"94\":1,\"112\":1,\"137\":1,\"171\":1,\"172\":1,\"212\":1,\"251\":1,\"266\":1}}],[\"slow\",{\"1\":{\"209\":1}}],[\"slovak\",{\"1\":{\"125\":10,\"126\":1}}],[\"slightly\",{\"1\":{\"123\":1,\"124\":1,\"126\":1,\"187\":1,\"202\":1,\"266\":2}}],[\"slight\",{\"1\":{\"43\":1}}],[\"slang\",{\"1\":{\"21\":1}}],[\"sst\",{\"1\":{\"43\":4}}],[\"séance\",{\"1\":{\"29\":1}}],[\"syslevel\",{\"1\":{\"221\":1}}],[\"systran\",{\"1\":{\"218\":13}}],[\"systems\",{\"1\":{\"37\":1,\"102\":2,\"119\":1,\"141\":3,\"152\":1,\"167\":1,\"171\":2,\"175\":1,\"208\":1,\"210\":1,\"213\":1,\"217\":1,\"218\":3,\"219\":1,\"226\":1,\"244\":1,\"247\":1}}],[\"system\",{\"1\":{\"22\":1,\"29\":2,\"30\":1,\"31\":1,\"36\":1,\"37\":1,\"109\":3,\"111\":2,\"112\":1,\"167\":1,\"170\":1,\"194\":4,\"202\":1,\"203\":1,\"206\":1,\"213\":6,\"214\":1,\"218\":2,\"221\":1,\"226\":1,\"252\":1}}],[\"systematic\",{\"1\":{\"1\":1,\"208\":1}}],[\"symmetry\",{\"1\":{\"181\":1}}],[\"symmetric\",{\"1\":{\"137\":1}}],[\"syntactic\",{\"1\":{\"244\":1}}],[\"synthetic\",{\"1\":{\"227\":1,\"254\":3}}],[\"synthesizer\",{\"1\":{\"244\":1,\"247\":1}}],[\"synthesize\",{\"1\":{\"135\":1}}],[\"synthesized\",{\"1\":{\"132\":1}}],[\"synthesizing\",{\"1\":{\"133\":1}}],[\"synthesis\",{\"1\":{\"126\":1}}],[\"syn\",{\"1\":{\"244\":1,\"245\":1}}],[\"synonym\",{\"1\":{\"197\":3}}],[\"synonymous\",{\"1\":{\"33\":1,\"35\":1,\"203\":1}}],[\"synonyms\",{\"1\":{\"24\":2,\"33\":1,\"34\":2,\"35\":1,\"211\":1}}],[\"squared\",{\"1\":{\"216\":1}}],[\"square\",{\"1\":{\"24\":2}}],[\"sanh\",{\"1\":{\"247\":1}}],[\"salient\",{\"1\":{\"245\":1}}],[\"salim\",{\"1\":{\"105\":1,\"221\":1}}],[\"says\",{\"1\":{\"269\":1}}],[\"say\",{\"1\":{\"170\":1}}],[\"save\",{\"1\":{\"157\":1}}],[\"satanjeev\",{\"1\":{\"221\":1}}],[\"sat\",{\"1\":{\"124\":2}}],[\"satisfy\",{\"1\":{\"200\":1}}],[\"satisfies\",{\"1\":{\"84\":1}}],[\"satisfaction\",{\"1\":{\"3\":1}}],[\"sacrebleu\",{\"1\":{\"244\":2}}],[\"sacremoses\",{\"1\":{\"159\":1}}],[\"sacrifices\",{\"1\":{\"228\":1}}],[\"sacrifice\",{\"1\":{\"35\":1}}],[\"sacrificing\",{\"1\":{\"3\":1}}],[\"sachan\",{\"1\":{\"116\":1}}],[\"sa\",{\"1\":{\"31\":3,\"125\":5}}],[\"sampling\",{\"1\":{\"252\":2,\"253\":4}}],[\"sample\",{\"1\":{\"113\":2,\"184\":1,\"196\":3,\"252\":1}}],[\"samples\",{\"1\":{\"25\":1,\"43\":2,\"100\":2,\"137\":1,\"146\":1,\"183\":1,\"196\":2,\"218\":1,\"251\":1}}],[\"samyam\",{\"1\":{\"167\":1}}],[\"same\",{\"1\":{\"3\":1,\"21\":1,\"24\":6,\"25\":1,\"34\":1,\"50\":1,\"51\":3,\"59\":1,\"71\":2,\"100\":3,\"109\":2,\"111\":1,\"119\":1,\"124\":1,\"125\":2,\"146\":1,\"196\":1,\"212\":1,\"217\":1,\"218\":1,\"219\":1,\"226\":1,\"228\":1,\"232\":4,\"233\":1,\"253\":2,\"263\":1,\"264\":2,\"265\":1,\"268\":1}}],[\"said\",{\"1\":{\"22\":1,\"93\":1,\"95\":1}}],[\"script\",{\"1\":{\"215\":1}}],[\"scratch\",{\"1\":{\"25\":1,\"43\":1,\"235\":2,\"252\":2}}],[\"schuster\",{\"1\":{\"221\":1}}],[\"scheme\",{\"1\":{\"215\":2}}],[\"school\",{\"1\":{\"3\":4,\"95\":1}}],[\"science\",{\"1\":{\"130\":1}}],[\"sciences\",{\"1\":{\"37\":1,\"221\":3}}],[\"scarce\",{\"1\":{\"132\":1,\"172\":1,\"259\":1}}],[\"scargle\",{\"1\":{\"42\":1}}],[\"scatterplot\",{\"1\":{\"81\":1}}],[\"scalar\",{\"1\":{\"42\":1}}],[\"scalability\",{\"1\":{\"41\":1}}],[\"scaled\",{\"1\":{\"233\":1}}],[\"scales\",{\"1\":{\"188\":1}}],[\"scale\",{\"1\":{\"23\":1,\"26\":1,\"53\":1,\"60\":1,\"61\":1,\"109\":1,\"126\":1,\"142\":1,\"146\":2,\"151\":1,\"208\":2,\"244\":1}}],[\"scenario\",{\"1\":{\"27\":1,\"187\":1}}],[\"scenarios\",{\"1\":{\"23\":2,\"25\":1,\"60\":1,\"78\":1,\"187\":1,\"212\":2,\"239\":1}}],[\"scores\",{\"1\":{\"5\":1,\"55\":1,\"122\":1,\"126\":1,\"209\":1,\"212\":2,\"213\":1,\"215\":1,\"216\":2,\"217\":1,\"218\":5,\"233\":1,\"269\":1}}],[\"score\",{\"1\":{\"2\":2,\"3\":11,\"5\":1,\"6\":1,\"18\":1,\"22\":1,\"27\":2,\"35\":1,\"51\":1,\"54\":1,\"71\":3,\"93\":1,\"105\":1,\"122\":5,\"125\":5,\"126\":1,\"184\":2,\"200\":1,\"208\":1,\"211\":2,\"212\":4,\"213\":5,\"216\":2,\"217\":2,\"218\":11,\"219\":1,\"220\":1,\"269\":1}}],[\"shiyue\",{\"1\":{\"235\":1}}],[\"shifts\",{\"1\":{\"170\":1}}],[\"ship\",{\"1\":{\"21\":3}}],[\"sh\",{\"1\":{\"160\":4}}],[\"shuffled\",{\"1\":{\"254\":1}}],[\"shujian\",{\"1\":{\"191\":1}}],[\"shuang\",{\"1\":{\"61\":1}}],[\"shuoyang\",{\"1\":{\"5\":1}}],[\"shelf\",{\"1\":{\"68\":2}}],[\"she\",{\"1\":{\"24\":3,\"263\":1}}],[\"shannon\",{\"1\":{\"245\":1}}],[\"shanghai\",{\"1\":{\"21\":1}}],[\"shallow\",{\"1\":{\"211\":1}}],[\"shapes\",{\"1\":{\"157\":1}}],[\"sharing\",{\"1\":{\"109\":1,\"146\":3,\"227\":1,\"234\":1,\"242\":1,\"247\":1}}],[\"shares\",{\"1\":{\"109\":1}}],[\"share\",{\"1\":{\"98\":1,\"181\":1,\"224\":1,\"232\":1}}],[\"shared\",{\"0\":{\"92\":1,\"96\":1},\"1\":{\"2\":2,\"30\":2,\"34\":1,\"70\":1,\"93\":1,\"95\":1,\"96\":6,\"97\":2,\"98\":1,\"100\":1,\"101\":3,\"102\":1,\"105\":1,\"157\":1,\"175\":1,\"183\":1,\"190\":1,\"196\":1,\"219\":2,\"232\":1,\"242\":1,\"264\":2,\"265\":3,\"270\":1},\"2\":{\"104\":1}}],[\"shazeer\",{\"1\":{\"102\":1,\"175\":1}}],[\"shots\",{\"1\":{\"120\":1,\"122\":1}}],[\"shot\",{\"0\":{\"201\":1},\"1\":{\"37\":1,\"113\":3,\"115\":1,\"120\":10,\"122\":3,\"124\":2,\"125\":1,\"126\":4,\"127\":1,\"146\":5,\"167\":1,\"198\":1,\"201\":2,\"202\":2,\"203\":1},\"2\":{\"39\":1,\"205\":1}}],[\"short\",{\"1\":{\"22\":1,\"209\":1,\"211\":1,\"215\":1,\"216\":1,\"228\":1}}],[\"shorter\",{\"1\":{\"2\":1}}],[\"showcase\",{\"1\":{\"203\":1}}],[\"showcasing\",{\"1\":{\"124\":1}}],[\"showed\",{\"1\":{\"93\":1}}],[\"showing\",{\"1\":{\"71\":1,\"174\":1,\"241\":1}}],[\"shown\",{\"1\":{\"4\":1,\"43\":1,\"59\":1,\"113\":1,\"125\":1,\"197\":1,\"200\":1,\"217\":1,\"218\":1,\"239\":1,\"241\":1,\"256\":1,\"258\":1,\"259\":1}}],[\"shows\",{\"1\":{\"3\":1,\"7\":2,\"50\":1,\"59\":1,\"67\":1,\"71\":1,\"95\":1,\"114\":1,\"121\":1,\"122\":1,\"146\":1,\"154\":1,\"155\":1,\"166\":1,\"174\":1,\"188\":1,\"197\":1,\"199\":1,\"201\":1,\"202\":1,\"203\":1,\"213\":1,\"242\":1,\"244\":1,\"252\":1,\"253\":1,\"254\":1,\"269\":3,\"270\":1}}],[\"show\",{\"1\":{\"1\":1,\"3\":2,\"43\":2,\"58\":1,\"59\":2,\"60\":1,\"71\":1,\"85\":1,\"95\":1,\"101\":1,\"105\":1,\"124\":1,\"139\":1,\"246\":1,\"253\":1,\"259\":1}}],[\"should\",{\"1\":{\"1\":1,\"22\":1,\"24\":1,\"43\":1,\"65\":1,\"71\":1,\"96\":1,\"111\":1,\"125\":2,\"196\":3,\"203\":1,\"218\":1,\"219\":1,\"226\":1,\"228\":2,\"231\":2,\"232\":1,\"233\":1,\"264\":1,\"266\":1,\"268\":1}}],[\"spirit\",{\"1\":{\"225\":1}}],[\"spiders\",{\"1\":{\"72\":3}}],[\"spoken\",{\"1\":{\"225\":1}}],[\"spontaneously\",{\"1\":{\"24\":1}}],[\"sp\",{\"1\":{\"94\":1}}],[\"spreading\",{\"1\":{\"65\":1}}],[\"splitting\",{\"1\":{\"240\":1}}],[\"splits\",{\"1\":{\"212\":1}}],[\"split\",{\"1\":{\"43\":1,\"53\":1,\"70\":1,\"146\":1}}],[\"spatial\",{\"1\":{\"135\":1}}],[\"sparce\",{\"1\":{\"119\":1}}],[\"sparse\",{\"1\":{\"247\":1}}],[\"sparsely\",{\"0\":{\"83\":1},\"1\":{\"83\":1}}],[\"sparsity\",{\"1\":{\"2\":1,\"83\":1}}],[\"spaces\",{\"1\":{\"64\":1,\"264\":2,\"266\":2}}],[\"space\",{\"0\":{\"81\":1,\"82\":1,\"92\":1},\"1\":{\"24\":1,\"80\":1,\"81\":3,\"83\":2,\"84\":3,\"93\":1,\"98\":1,\"101\":1,\"102\":1,\"105\":1,\"175\":1,\"181\":1,\"190\":1,\"196\":3,\"197\":1,\"201\":1,\"203\":4,\"216\":1,\"232\":1,\"233\":2,\"264\":5,\"265\":4,\"266\":3,\"268\":1,\"270\":1}}],[\"spanish\",{\"1\":{\"24\":1,\"97\":1,\"225\":1,\"226\":1}}],[\"sperber\",{\"1\":{\"175\":1}}],[\"speech\",{\"0\":{\"92\":1,\"94\":1,\"170\":1},\"1\":{\"43\":1,\"67\":1,\"92\":2,\"93\":9,\"94\":3,\"95\":3,\"96\":2,\"97\":1,\"100\":6,\"101\":3,\"102\":3,\"130\":1,\"170\":5,\"171\":1,\"172\":3,\"174\":1,\"175\":9},\"2\":{\"104\":1,\"177\":1}}],[\"speeches\",{\"1\":{\"21\":1,\"98\":1,\"228\":1}}],[\"speeds\",{\"1\":{\"244\":1}}],[\"speedy\",{\"1\":{\"232\":1}}],[\"speed\",{\"1\":{\"24\":2,\"119\":1,\"153\":1,\"154\":2}}],[\"specify\",{\"1\":{\"268\":1}}],[\"specified\",{\"1\":{\"216\":1}}],[\"specifically\",{\"1\":{\"41\":1,\"120\":1,\"126\":1,\"146\":2,\"172\":1,\"186\":1,\"215\":1,\"216\":1,\"224\":1,\"227\":1,\"228\":1,\"231\":1,\"238\":1,\"239\":1,\"245\":1,\"264\":1,\"266\":1,\"267\":1,\"268\":1}}],[\"specific\",{\"1\":{\"22\":2,\"23\":1,\"41\":1,\"51\":1,\"71\":1,\"100\":2,\"109\":2,\"112\":2,\"120\":5,\"121\":1,\"123\":1,\"126\":3,\"146\":18,\"178\":1,\"233\":1,\"238\":1},\"2\":{\"148\":1}}],[\"specialized\",{\"1\":{\"228\":1}}],[\"special\",{\"1\":{\"23\":1,\"195\":1,\"226\":2}}],[\"spectrum\",{\"1\":{\"1\":1,\"42\":1,\"84\":1,\"89\":1}}],[\"speaking\",{\"1\":{\"93\":2,\"95\":1,\"101\":1,\"211\":1}}],[\"speakerver\",{\"1\":{\"174\":3}}],[\"speakers\",{\"1\":{\"95\":1}}],[\"speaker\",{\"1\":{\"24\":1,\"174\":2}}],[\"speak\",{\"1\":{\"21\":1,\"36\":1,\"93\":2,\"95\":3,\"225\":1}}],[\"spearman\",{\"1\":{\"3\":7,\"86\":1}}],[\"sorbonne\",{\"1\":{\"263\":1}}],[\"sort\",{\"1\":{\"126\":1}}],[\"som\",{\"1\":{\"125\":1}}],[\"someone\",{\"1\":{\"263\":1}}],[\"somehow\",{\"1\":{\"233\":1,\"252\":1}}],[\"something\",{\"1\":{\"229\":1}}],[\"sometimes\",{\"1\":{\"125\":1,\"170\":1}}],[\"some\",{\"1\":{\"1\":1,\"3\":1,\"4\":1,\"5\":1,\"22\":1,\"25\":1,\"44\":1,\"45\":1,\"65\":2,\"71\":2,\"72\":1,\"98\":1,\"100\":1,\"105\":1,\"110\":1,\"114\":1,\"120\":1,\"121\":1,\"122\":1,\"124\":1,\"126\":2,\"130\":2,\"132\":1,\"134\":1,\"135\":1,\"200\":1,\"212\":2,\"218\":2,\"225\":1,\"228\":1,\"233\":1,\"245\":1,\"263\":1,\"266\":1}}],[\"sota\",{\"1\":{\"88\":1,\"93\":1,\"96\":1,\"134\":1}}],[\"softmax\",{\"1\":{\"82\":1,\"216\":1,\"240\":1}}],[\"soften\",{\"1\":{\"69\":1}}],[\"soft\",{\"1\":{\"42\":4,\"43\":4,\"44\":1,\"66\":2,\"69\":1,\"73\":1,\"212\":1}}],[\"songs\",{\"1\":{\"95\":1}}],[\"song\",{\"1\":{\"37\":1}}],[\"sound\",{\"1\":{\"126\":1}}],[\"sounds\",{\"1\":{\"94\":2,\"102\":1,\"120\":1,\"130\":1}}],[\"south\",{\"1\":{\"36\":1}}],[\"source\",{\"1\":{\"8\":1,\"24\":1,\"27\":7,\"29\":1,\"30\":1,\"31\":2,\"32\":1,\"65\":1,\"68\":1,\"71\":1,\"105\":4,\"109\":1,\"110\":3,\"111\":3,\"131\":1,\"135\":1,\"136\":1,\"137\":3,\"141\":1,\"146\":1,\"149\":1,\"153\":1,\"159\":1,\"171\":1,\"172\":1,\"181\":4,\"183\":1,\"184\":1,\"195\":1,\"196\":1,\"197\":1,\"208\":1,\"210\":1,\"211\":1,\"214\":1,\"216\":8,\"217\":1,\"218\":6,\"228\":2,\"232\":1,\"233\":5,\"245\":2,\"254\":1,\"263\":2,\"264\":1,\"266\":1,\"269\":1,\"270\":1}}],[\"soon\",{\"1\":{\"23\":1}}],[\"solely\",{\"1\":{\"132\":1}}],[\"solution\",{\"1\":{\"3\":1,\"109\":1,\"146\":1,\"239\":1}}],[\"solve\",{\"1\":{\"3\":1,\"22\":1,\"65\":1,\"101\":1,\"109\":1,\"126\":1,\"146\":1,\"171\":1,\"175\":1,\"231\":1,\"232\":1}}],[\"so\",{\"0\":{\"225\":1},\"1\":{\"1\":1,\"23\":2,\"24\":2,\"33\":1,\"43\":2,\"51\":1,\"71\":3,\"72\":1,\"96\":1,\"119\":1,\"122\":1,\"151\":1,\"155\":1,\"216\":1,\"228\":1,\"229\":1,\"232\":1,\"233\":1,\"234\":1,\"242\":1,\"250\":1,\"251\":2,\"265\":1,\"266\":1}}],[\"sudden\",{\"1\":{\"228\":1}}],[\"suggested\",{\"1\":{\"264\":1}}],[\"suggests\",{\"1\":{\"218\":1}}],[\"suggesting\",{\"1\":{\"146\":1}}],[\"sum\",{\"1\":{\"212\":3,\"219\":1,\"240\":1}}],[\"summarization\",{\"1\":{\"41\":1,\"151\":1,\"259\":1}}],[\"summarized\",{\"1\":{\"268\":1}}],[\"summarize\",{\"1\":{\"24\":1,\"70\":1,\"71\":1}}],[\"summary\",{\"0\":{\"8\":1,\"36\":1,\"45\":1,\"101\":1,\"115\":1,\"246\":1,\"259\":1},\"1\":{\"25\":1,\"98\":1,\"210\":1,\"253\":1}}],[\"summit\",{\"1\":{\"9\":1}}],[\"sure\",{\"1\":{\"225\":1}}],[\"surrounding\",{\"1\":{\"212\":1}}],[\"surface\",{\"1\":{\"211\":1}}],[\"surpasses\",{\"1\":{\"187\":1,\"199\":1}}],[\"surprising\",{\"1\":{\"252\":1,\"257\":1}}],[\"surprisingly\",{\"1\":{\"22\":1,\"25\":1,\"93\":1,\"94\":1,\"188\":1,\"269\":1,\"270\":1}}],[\"surprise\",{\"1\":{\"22\":1}}],[\"suspension\",{\"1\":{\"208\":1}}],[\"suspects\",{\"1\":{\"43\":1}}],[\"suspect\",{\"1\":{\"42\":3,\"43\":1}}],[\"suitable\",{\"1\":{\"152\":1,\"206\":1}}],[\"sufficient\",{\"1\":{\"171\":1}}],[\"suffixes\",{\"1\":{\"94\":1}}],[\"suffers\",{\"1\":{\"146\":1}}],[\"suffer\",{\"1\":{\"49\":1,\"146\":1}}],[\"superglue\",{\"1\":{\"124\":1}}],[\"superotemporal\",{\"1\":{\"94\":1}}],[\"supervision\",{\"0\":{\"86\":1,\"87\":1},\"1\":{\"79\":1,\"86\":1,\"87\":1,\"171\":2,\"175\":2,\"200\":1}}],[\"supervised\",{\"0\":{\"199\":1},\"1\":{\"68\":1,\"102\":1,\"113\":3,\"116\":1,\"122\":1,\"126\":1,\"130\":1,\"175\":1,\"197\":1,\"198\":1,\"202\":2,\"250\":1,\"254\":1,\"264\":1,\"269\":2,\"270\":1},\"2\":{\"193\":1}}],[\"supplement\",{\"1\":{\"101\":1}}],[\"suppressed\",{\"1\":{\"84\":1}}],[\"supposed\",{\"1\":{\"66\":1,\"120\":1}}],[\"supported\",{\"1\":{\"71\":2,\"194\":1}}],[\"supports\",{\"1\":{\"66\":1,\"71\":1,\"146\":1,\"153\":1,\"159\":1,\"203\":1,\"210\":1}}],[\"supportive\",{\"1\":{\"66\":1,\"69\":2}}],[\"support\",{\"1\":{\"25\":1,\"71\":1,\"109\":6,\"112\":1,\"113\":1,\"153\":1,\"194\":1,\"219\":1}}],[\"sup\",{\"1\":{\"66\":1,\"69\":3,\"71\":3}}],[\"sunday\",{\"1\":{\"95\":1}}],[\"sun\",{\"1\":{\"61\":1,\"74\":1}}],[\"success\",{\"1\":{\"23\":1,\"78\":1,\"95\":1,\"96\":1,\"251\":1}}],[\"successfully\",{\"1\":{\"30\":1,\"43\":1,\"59\":1,\"71\":2,\"98\":2,\"101\":1,\"201\":1,\"227\":1,\"232\":1,\"244\":1,\"269\":1}}],[\"successful\",{\"1\":{\"22\":1,\"23\":1,\"36\":1,\"71\":1,\"93\":1,\"131\":1}}],[\"such\",{\"1\":{\"1\":2,\"3\":1,\"5\":1,\"8\":1,\"22\":1,\"23\":3,\"24\":1,\"27\":1,\"31\":1,\"41\":1,\"42\":1,\"51\":1,\"53\":1,\"72\":1,\"78\":1,\"93\":2,\"95\":2,\"100\":1,\"101\":1,\"105\":1,\"109\":1,\"115\":1,\"119\":1,\"130\":1,\"132\":1,\"133\":1,\"137\":1,\"142\":1,\"157\":1,\"170\":1,\"171\":1,\"188\":1,\"200\":1,\"231\":1,\"269\":1}}],[\"subfigure\",{\"1\":{\"269\":2}}],[\"submissions\",{\"1\":{\"219\":2}}],[\"subtitling\",{\"1\":{\"170\":1}}],[\"subtitles\",{\"1\":{\"95\":1,\"98\":1}}],[\"subnetworks\",{\"1\":{\"146\":1}}],[\"subnetwork\",{\"1\":{\"146\":2}}],[\"subjects\",{\"1\":{\"94\":1}}],[\"subject\",{\"1\":{\"50\":1,\"124\":1}}],[\"substitute\",{\"1\":{\"239\":1}}],[\"substitution\",{\"1\":{\"24\":1,\"197\":1},\"2\":{\"39\":1,\"205\":1}}],[\"substantial\",{\"1\":{\"203\":1}}],[\"subspaces\",{\"1\":{\"240\":1}}],[\"subspace\",{\"1\":{\"100\":2}}],[\"subsections\",{\"1\":{\"121\":1}}],[\"subset\",{\"1\":{\"99\":2}}],[\"subsequently\",{\"1\":{\"24\":2}}],[\"subword\",{\"1\":{\"9\":2,\"25\":1}}],[\"sub\",{\"1\":{\"1\":8,\"2\":6,\"68\":1,\"96\":1,\"109\":1,\"146\":7,\"240\":1,\"244\":1,\"266\":1,\"267\":1},\"2\":{\"148\":1}}],[\"stil\",{\"1\":{\"269\":1}}],[\"still\",{\"1\":{\"1\":1,\"22\":1,\"23\":1,\"65\":1,\"71\":4,\"82\":1,\"93\":1,\"95\":1,\"109\":2,\"123\":1,\"124\":1,\"125\":1,\"126\":2,\"215\":1,\"218\":1,\"226\":1,\"227\":1,\"233\":1,\"251\":1,\"253\":1,\"256\":1,\"258\":1}}],[\"stir\",{\"1\":{\"170\":1}}],[\"style\",{\"1\":{\"124\":2,\"189\":1}}],[\"stored\",{\"1\":{\"218\":1}}],[\"stores\",{\"1\":{\"96\":1}}],[\"stochastic\",{\"1\":{\"182\":1}}],[\"stock\",{\"1\":{\"175\":1}}],[\"stoian\",{\"1\":{\"175\":1}}],[\"sto\",{\"1\":{\"125\":1}}],[\"stolen\",{\"1\":{\"40\":1,\"41\":1,\"42\":2,\"45\":1}}],[\"st\",{\"0\":{\"171\":1},\"1\":{\"92\":1,\"93\":7,\"94\":2,\"95\":1,\"97\":1,\"98\":1,\"101\":4,\"170\":5,\"171\":11,\"172\":3,\"175\":3,\"252\":6,\"254\":9,\"256\":4,\"257\":1},\"2\":{\"103\":1,\"176\":1}}],[\"stewart\",{\"1\":{\"221\":1}}],[\"stems\",{\"1\":{\"120\":1}}],[\"steffeneger\",{\"1\":{\"221\":1}}],[\"steffen\",{\"1\":{\"105\":1}}],[\"steroids\",{\"1\":{\"105\":1}}],[\"steal\",{\"1\":{\"41\":1}}],[\"steps\",{\"1\":{\"66\":2,\"146\":1,\"156\":1,\"172\":1,\"239\":1}}],[\"step\",{\"1\":{\"0\":1,\"67\":2,\"71\":1,\"95\":1,\"101\":1,\"134\":1,\"136\":1,\"146\":2,\"156\":1,\"181\":1,\"210\":1,\"216\":1,\"219\":1,\"232\":1,\"252\":3,\"254\":2}}],[\"string\",{\"1\":{\"211\":1,\"212\":2,\"218\":1}}],[\"stride\",{\"1\":{\"140\":1}}],[\"strides\",{\"1\":{\"36\":1}}],[\"strategies\",{\"1\":{\"227\":1,\"253\":1}}],[\"strategy\",{\"1\":{\"146\":1,\"172\":1,\"253\":3}}],[\"straightforward\",{\"1\":{\"67\":1,\"130\":1,\"197\":1}}],[\"stretnutia\",{\"1\":{\"125\":1}}],[\"stream\",{\"1\":{\"94\":1}}],[\"strengthens\",{\"1\":{\"146\":1}}],[\"strengths\",{\"1\":{\"93\":1}}],[\"strength\",{\"1\":{\"42\":1,\"101\":1}}],[\"stronger\",{\"1\":{\"210\":1}}],[\"strongly\",{\"1\":{\"100\":1}}],[\"strong\",{\"1\":{\"54\":2,\"95\":1,\"100\":1,\"120\":1,\"146\":3,\"194\":1,\"201\":1}}],[\"structures\",{\"1\":{\"152\":1,\"244\":1}}],[\"structured\",{\"1\":{\"98\":1}}],[\"structure\",{\"1\":{\"23\":1,\"100\":1,\"136\":1,\"137\":1,\"155\":1,\"265\":1}}],[\"student\",{\"1\":{\"251\":1}}],[\"students\",{\"1\":{\"3\":1}}],[\"studied\",{\"1\":{\"125\":1,\"251\":1}}],[\"studies\",{\"1\":{\"65\":1,\"221\":1,\"241\":1}}],[\"study\",{\"0\":{\"28\":1,\"55\":1,\"59\":1,\"125\":1,\"188\":1,\"218\":1,\"252\":1,\"269\":1},\"1\":{\"28\":1,\"55\":1,\"59\":1,\"60\":1,\"71\":1,\"92\":1,\"113\":1,\"125\":3,\"126\":1,\"202\":1,\"208\":2,\"218\":1,\"254\":1,\"269\":1}}],[\"stacked\",{\"1\":{\"240\":1}}],[\"stable\",{\"1\":{\"202\":1,\"203\":1}}],[\"stay\",{\"1\":{\"146\":1,\"196\":1}}],[\"stand\",{\"1\":{\"93\":1}}],[\"standard\",{\"1\":{\"22\":1,\"53\":1,\"84\":2,\"86\":1,\"96\":1,\"130\":3,\"184\":1,\"215\":1,\"244\":1,\"252\":1}}],[\"status\",{\"1\":{\"126\":1}}],[\"statistics\",{\"1\":{\"82\":1}}],[\"statistically\",{\"1\":{\"41\":1}}],[\"statistical\",{\"1\":{\"23\":1}}],[\"stated\",{\"1\":{\"95\":1,\"197\":1}}],[\"statement\",{\"1\":{\"64\":1,\"66\":1}}],[\"state\",{\"1\":{\"43\":1,\"54\":1,\"85\":1,\"87\":1,\"93\":1,\"98\":2,\"101\":1,\"105\":1,\"120\":1,\"121\":1,\"123\":2,\"124\":2,\"126\":1,\"130\":1,\"132\":1,\"137\":1,\"151\":1,\"208\":1,\"214\":1,\"226\":1}}],[\"states\",{\"1\":{\"36\":1,\"71\":2,\"130\":1,\"134\":1,\"208\":1,\"245\":1}}],[\"stages\",{\"1\":{\"153\":1,\"171\":1}}],[\"stage\",{\"1\":{\"24\":2,\"27\":4,\"33\":1,\"35\":1,\"175\":1,\"212\":1,\"216\":1}}],[\"start\",{\"1\":{\"146\":2,\"219\":1,\"245\":1}}],[\"starred\",{\"1\":{\"3\":1,\"71\":3}}],[\"star\",{\"1\":{\"3\":1}}],[\"sites\",{\"1\":{\"221\":1}}],[\"site\",{\"1\":{\"218\":1}}],[\"situations\",{\"1\":{\"27\":1}}],[\"six\",{\"1\":{\"155\":2,\"208\":1,\"224\":1}}],[\"si\",{\"1\":{\"125\":3,\"146\":1}}],[\"side\",{\"1\":{\"112\":4,\"146\":1,\"188\":1,\"195\":1,\"240\":2,\"245\":1}}],[\"sides\",{\"1\":{\"27\":1}}],[\"sir\",{\"1\":{\"93\":1}}],[\"siamese\",{\"1\":{\"89\":1,\"232\":1}}],[\"sigkdd\",{\"1\":{\"167\":1}}],[\"sigmoid\",{\"1\":{\"51\":1}}],[\"significance\",{\"1\":{\"109\":1}}],[\"significantly\",{\"1\":{\"22\":1,\"55\":1,\"78\":1,\"93\":1,\"114\":1,\"126\":1,\"171\":1,\"199\":1,\"201\":1,\"203\":1,\"212\":1,\"244\":1,\"269\":1}}],[\"significant\",{\"1\":{\"22\":1,\"23\":1,\"25\":1,\"41\":1,\"85\":1,\"88\":1,\"93\":1,\"172\":1,\"187\":1,\"218\":1}}],[\"signals\",{\"1\":{\"42\":1,\"170\":1,\"200\":1}}],[\"signal\",{\"1\":{\"42\":6,\"94\":1,\"175\":2}}],[\"signature\",{\"1\":{\"41\":1,\"232\":1}}],[\"singing\",{\"1\":{\"197\":2}}],[\"singular\",{\"1\":{\"84\":2}}],[\"single\",{\"1\":{\"22\":1,\"24\":1,\"25\":1,\"49\":1,\"51\":1,\"57\":1,\"109\":1,\"110\":1,\"121\":1,\"146\":4,\"194\":2,\"216\":3,\"226\":1,\"242\":1}}],[\"sinkhorn\",{\"1\":{\"3\":1}}],[\"since\",{\"1\":{\"1\":2,\"34\":1,\"51\":1,\"71\":1,\"72\":3,\"93\":1,\"96\":1,\"101\":1,\"109\":2,\"114\":1,\"115\":1,\"119\":1,\"124\":1,\"125\":1,\"133\":1,\"141\":1,\"146\":2,\"152\":1,\"156\":1,\"171\":1,\"183\":1,\"196\":1,\"211\":1,\"233\":1,\"253\":1,\"254\":1,\"264\":1}}],[\"sim\",{\"1\":{\"196\":1}}],[\"simliar\",{\"1\":{\"123\":1}}],[\"simultaneous\",{\"1\":{\"170\":1}}],[\"simultaneously\",{\"1\":{\"93\":1,\"157\":1}}],[\"simulates\",{\"1\":{\"120\":1}}],[\"simplify\",{\"1\":{\"246\":1}}],[\"simplification\",{\"1\":{\"112\":1}}],[\"simplified\",{\"1\":{\"3\":1,\"244\":1}}],[\"simply\",{\"1\":{\"25\":1,\"54\":1,\"105\":1}}],[\"simple\",{\"1\":{\"23\":1,\"24\":1,\"188\":1,\"203\":1,\"209\":1,\"212\":1,\"225\":1,\"233\":1,\"239\":1,\"251\":1,\"254\":1}}],[\"simpler\",{\"1\":{\"1\":1,\"78\":1,\"218\":1,\"254\":1}}],[\"similarly\",{\"1\":{\"146\":1,\"197\":1,\"217\":1,\"265\":1}}],[\"similarities\",{\"1\":{\"43\":1,\"211\":1,\"233\":1}}],[\"similarity\",{\"1\":{\"35\":2,\"78\":1,\"80\":2,\"82\":4,\"85\":1,\"86\":3,\"88\":2,\"105\":1,\"114\":1,\"146\":3,\"196\":1,\"211\":1,\"212\":8,\"245\":2,\"263\":1}}],[\"similar\",{\"1\":{\"2\":1,\"6\":1,\"22\":1,\"43\":1,\"79\":1,\"93\":1,\"94\":1,\"100\":1,\"112\":1,\"113\":1,\"114\":2,\"120\":1,\"122\":1,\"124\":2,\"152\":2,\"184\":1,\"187\":1,\"200\":1,\"218\":1,\"232\":3,\"245\":1,\"253\":2,\"264\":1,\"267\":1,\"268\":1}}],[\"sizes\",{\"1\":{\"1\":3,\"2\":2,\"8\":2,\"119\":1}}],[\"size\",{\"1\":{\"1\":8,\"2\":3,\"3\":6,\"5\":2,\"7\":1,\"8\":2,\"96\":1,\"112\":3,\"113\":3,\"122\":1,\"123\":1,\"146\":3,\"151\":1,\"152\":1,\"165\":1,\"209\":1,\"226\":1,\"252\":1,\"258\":4}}],[\"seven\",{\"1\":{\"217\":1}}],[\"severe\",{\"1\":{\"146\":1}}],[\"several\",{\"1\":{\"6\":1,\"26\":1,\"50\":1,\"170\":1}}],[\"segments\",{\"1\":{\"216\":1}}],[\"segment\",{\"1\":{\"209\":1,\"213\":4,\"218\":2}}],[\"segmentfault\",{\"1\":{\"165\":1,\"166\":1}}],[\"semi\",{\"1\":{\"250\":1},\"2\":{\"193\":1}}],[\"semanticequivalent\",{\"1\":{\"136\":1}}],[\"semantically\",{\"1\":{\"79\":1,\"211\":2,\"253\":1}}],[\"semantics\",{\"1\":{\"24\":1,\"35\":1,\"137\":1}}],[\"semantic\",{\"0\":{\"92\":1,\"96\":1,\"174\":1},\"1\":{\"23\":1,\"35\":1,\"49\":1,\"78\":1,\"79\":3,\"80\":4,\"82\":2,\"83\":1,\"85\":1,\"86\":1,\"88\":2,\"93\":2,\"95\":1,\"96\":12,\"97\":1,\"98\":1,\"100\":10,\"101\":2,\"102\":1,\"105\":2,\"130\":1,\"137\":2,\"142\":1,\"171\":3,\"172\":4,\"174\":8,\"175\":2,\"181\":2,\"190\":1,\"203\":1,\"211\":3,\"244\":1},\"2\":{\"104\":1}}],[\"seamlessly\",{\"1\":{\"122\":1}}],[\"searching\",{\"1\":{\"156\":1,\"232\":1}}],[\"searches\",{\"1\":{\"72\":1,\"233\":1}}],[\"search\",{\"0\":{\"156\":1},\"1\":{\"1\":1,\"6\":3,\"72\":1,\"156\":2,\"164\":1,\"184\":1,\"218\":3,\"232\":1,\"252\":5,\"253\":5,\"258\":1,\"269\":1}}],[\"series\",{\"1\":{\"119\":1,\"235\":1}}],[\"servan\",{\"1\":{\"105\":2}}],[\"serving\",{\"1\":{\"94\":1,\"151\":1}}],[\"service\",{\"1\":{\"41\":1}}],[\"services\",{\"1\":{\"41\":1,\"45\":1}}],[\"serve\",{\"1\":{\"94\":1}}],[\"serves\",{\"1\":{\"51\":1,\"69\":1,\"183\":1,\"216\":1,\"240\":1}}],[\"seq2seq\",{\"1\":{\"110\":1,\"111\":3,\"151\":1}}],[\"sequential\",{\"1\":{\"54\":1}}],[\"sequence\",{\"0\":{\"250\":1},\"1\":{\"2\":1,\"23\":4,\"37\":4,\"41\":1,\"68\":2,\"119\":2,\"122\":2,\"151\":3,\"153\":1,\"154\":2,\"157\":1,\"165\":1,\"172\":1,\"175\":2,\"212\":1,\"216\":1,\"226\":2,\"238\":2,\"240\":1,\"250\":1,\"251\":2,\"259\":1,\"260\":1}}],[\"sequences\",{\"1\":{\"2\":2,\"97\":1,\"212\":1,\"216\":2,\"226\":1,\"240\":1,\"245\":1}}],[\"session\",{\"1\":{\"66\":1}}],[\"sessão\",{\"1\":{\"30\":1}}],[\"seus\",{\"1\":{\"30\":1}}],[\"separate\",{\"1\":{\"109\":2,\"112\":1}}],[\"separately\",{\"1\":{\"24\":1,\"27\":1}}],[\"september\",{\"1\":{\"30\":4,\"218\":3}}],[\"sellam\",{\"1\":{\"105\":2}}],[\"seldom\",{\"1\":{\"94\":1}}],[\"self\",{\"0\":{\"241\":1,\"250\":1,\"253\":1,\"254\":1},\"1\":{\"23\":1,\"68\":1,\"102\":1,\"116\":1,\"175\":1,\"197\":1,\"212\":1,\"225\":1,\"239\":4,\"240\":2,\"241\":2,\"244\":2,\"245\":1,\"246\":1,\"247\":1,\"250\":3,\"251\":7,\"252\":2,\"253\":2,\"254\":1,\"258\":1,\"259\":5,\"260\":1,\"264\":1},\"2\":{\"262\":1}}],[\"selected\",{\"1\":{\"100\":1}}],[\"selects\",{\"1\":{\"72\":1}}],[\"selecting\",{\"1\":{\"6\":1,\"112\":1}}],[\"select\",{\"1\":{\"6\":1,\"113\":1,\"156\":1,\"203\":1,\"258\":1}}],[\"sensitive\",{\"1\":{\"258\":1}}],[\"sense\",{\"1\":{\"68\":1,\"72\":1,\"124\":1,\"253\":1}}],[\"senellart\",{\"1\":{\"221\":1}}],[\"sentiment\",{\"1\":{\"153\":1}}],[\"sentencebert\",{\"1\":{\"89\":1}}],[\"sentences\",{\"1\":{\"24\":3,\"27\":1,\"33\":1,\"35\":1,\"49\":1,\"50\":2,\"51\":1,\"53\":2,\"57\":2,\"59\":1,\"72\":1,\"79\":1,\"80\":1,\"98\":1,\"105\":1,\"110\":2,\"123\":1,\"124\":4,\"125\":1,\"141\":1,\"146\":1,\"178\":1,\"179\":5,\"203\":1,\"208\":1,\"211\":1,\"218\":4,\"225\":2,\"226\":1,\"227\":1,\"228\":1,\"231\":5,\"232\":4,\"233\":5,\"252\":2,\"254\":1,\"263\":4,\"264\":2,\"266\":7,\"267\":2,\"269\":3}}],[\"sentence\",{\"0\":{\"35\":1,\"57\":1},\"1\":{\"1\":2,\"2\":1,\"4\":1,\"22\":1,\"24\":3,\"25\":4,\"29\":1,\"30\":1,\"33\":2,\"35\":4,\"49\":3,\"51\":1,\"57\":1,\"59\":1,\"60\":2,\"72\":2,\"77\":2,\"78\":2,\"79\":1,\"80\":1,\"84\":1,\"85\":1,\"87\":1,\"88\":2,\"89\":2,\"105\":4,\"110\":1,\"122\":2,\"124\":4,\"131\":1,\"137\":1,\"146\":2,\"172\":1,\"183\":1,\"195\":1,\"196\":4,\"198\":1,\"201\":1,\"203\":1,\"208\":2,\"209\":1,\"210\":1,\"211\":2,\"212\":3,\"213\":1,\"216\":4,\"218\":12,\"226\":3,\"227\":1,\"231\":5,\"232\":6,\"233\":6,\"245\":1,\"263\":2,\"264\":2,\"266\":2,\"267\":6,\"268\":1,\"270\":1}}],[\"send\",{\"1\":{\"125\":2}}],[\"sends\",{\"1\":{\"41\":1}}],[\"sennrich\",{\"1\":{\"9\":1}}],[\"secrete\",{\"1\":{\"130\":1}}],[\"secret\",{\"0\":{\"253\":1},\"1\":{\"41\":1,\"232\":1,\"253\":1}}],[\"security\",{\"1\":{\"29\":1}}],[\"second\",{\"1\":{\"3\":1,\"22\":1,\"24\":1,\"37\":1,\"71\":5,\"84\":1,\"93\":1,\"95\":1,\"105\":1,\"114\":1,\"141\":2,\"217\":1,\"218\":1,\"245\":1,\"266\":1}}],[\"secondly\",{\"1\":{\"1\":1,\"211\":1}}],[\"section\",{\"1\":{\"1\":1,\"2\":1,\"113\":1,\"139\":1,\"228\":1,\"231\":1,\"233\":1}}],[\"seeing\",{\"1\":{\"125\":1}}],[\"seemed\",{\"1\":{\"124\":1}}],[\"seems\",{\"1\":{\"6\":1,\"93\":1,\"225\":1}}],[\"seem\",{\"1\":{\"2\":1,\"3\":1,\"6\":1,\"124\":1}}],[\"see\",{\"1\":{\"1\":2,\"2\":2,\"71\":4,\"121\":1,\"124\":1,\"125\":2,\"126\":1,\"131\":1,\"146\":1,\"213\":1,\"218\":2,\"232\":1,\"244\":2,\"258\":1,\"264\":1}}],[\"seen\",{\"0\":{\"27\":1},\"1\":{\"1\":1,\"25\":1,\"26\":1,\"27\":9,\"34\":1,\"35\":2,\"100\":1,\"113\":1,\"119\":1,\"141\":1,\"146\":1,\"195\":1,\"201\":1,\"202\":1,\"203\":1,\"251\":1,\"253\":1,\"257\":1}}],[\"setups\",{\"1\":{\"203\":1}}],[\"setup\",{\"1\":{\"130\":1,\"131\":1,\"200\":1,\"218\":2}}],[\"setembro\",{\"1\":{\"30\":2}}],[\"sets\",{\"1\":{\"8\":1,\"22\":1,\"43\":1,\"100\":1}}],[\"setting\",{\"1\":{\"4\":1,\"7\":1,\"42\":2,\"113\":3,\"120\":1,\"124\":2,\"126\":1,\"146\":1,\"267\":1}}],[\"settings\",{\"1\":{\"1\":1,\"113\":2,\"130\":1,\"140\":1,\"212\":1}}],[\"set\",{\"1\":{\"1\":1,\"8\":2,\"24\":1,\"26\":2,\"35\":2,\"43\":1,\"44\":1,\"54\":5,\"55\":1,\"70\":1,\"71\":1,\"94\":1,\"96\":1,\"110\":4,\"124\":1,\"125\":2,\"175\":1,\"203\":1,\"213\":1,\"226\":1,\"231\":1,\"242\":2,\"251\":2,\"252\":1,\"257\":2,\"258\":1}}],[\"s\",{\"0\":{\"66\":1},\"1\":{\"1\":1,\"3\":5,\"5\":1,\"6\":2,\"21\":1,\"22\":1,\"37\":1,\"42\":1,\"50\":4,\"65\":2,\"66\":1,\"68\":2,\"69\":1,\"71\":16,\"72\":1,\"93\":1,\"94\":1,\"96\":1,\"98\":2,\"100\":1,\"110\":1,\"115\":1,\"116\":1,\"124\":4,\"125\":4,\"140\":1,\"146\":2,\"172\":2,\"175\":2,\"213\":1,\"216\":6,\"217\":1,\"218\":5,\"221\":1,\"225\":1,\"228\":3,\"231\":1,\"233\":2,\"250\":1,\"263\":1,\"264\":1,\"269\":2}}],[\"psychology\",{\"1\":{\"271\":1}}],[\"pseudo\",{\"1\":{\"42\":1,\"179\":2,\"183\":2,\"250\":1,\"252\":4,\"253\":2,\"254\":2}}],[\"pmlr\",{\"1\":{\"247\":1}}],[\"pmi\",{\"1\":{\"82\":1}}],[\"p\",{\"1\":{\"181\":1,\"182\":1,\"183\":1,\"184\":1,\"212\":3,\"271\":1}}],[\"p4\",{\"0\":{\"165\":1}}],[\"py\",{\"1\":{\"161\":2}}],[\"pypi\",{\"1\":{\"159\":1}}],[\"pytorch\",{\"1\":{\"152\":1,\"155\":1,\"164\":1}}],[\"python\",{\"1\":{\"24\":1,\"159\":1,\"161\":3}}],[\"pnmt\",{\"1\":{\"113\":1}}],[\"pdec​\",{\"1\":{\"112\":1}}],[\"pdf\",{\"1\":{\"0\":2,\"92\":2,\"175\":2,\"221\":1}}],[\"p1​\",{\"1\":{\"110\":1}}],[\"pp\",{\"1\":{\"102\":1}}],[\"pc32\",{\"1\":{\"198\":1,\"200\":2}}],[\"pca\",{\"1\":{\"100\":2}}],[\"pc​\",{\"1\":{\"42\":1,\"110\":1}}],[\"pθ​\",{\"1\":{\"69\":1}}],[\"peyrard\",{\"1\":{\"105\":1}}],[\"penalize\",{\"1\":{\"211\":1}}],[\"penalized\",{\"1\":{\"211\":1}}],[\"penalty\",{\"1\":{\"209\":2}}],[\"penultimate\",{\"1\":{\"130\":1}}],[\"penc​∈rm\",{\"1\":{\"112\":1}}],[\"penc​\",{\"1\":{\"112\":1}}],[\"pennsylvania\",{\"1\":{\"105\":1}}],[\"peng\",{\"1\":{\"61\":1}}],[\"peak\",{\"1\":{\"42\":1}}],[\"people\",{\"1\":{\"27\":1,\"65\":1,\"71\":2,\"93\":1,\"95\":2,\"120\":1,\"130\":1,\"170\":1,\"211\":2}}],[\"permutation\",{\"1\":{\"266\":1}}],[\"permute\",{\"1\":{\"266\":1}}],[\"perturbed\",{\"1\":{\"267\":1}}],[\"perturb\",{\"1\":{\"259\":1,\"266\":1}}],[\"perturbing\",{\"1\":{\"254\":1}}],[\"perturbations\",{\"1\":{\"137\":1,\"254\":1,\"266\":1}}],[\"perturbation\",{\"1\":{\"42\":2,\"253\":1,\"254\":4}}],[\"percent\",{\"1\":{\"146\":1}}],[\"perspectives\",{\"1\":{\"218\":1}}],[\"perspective\",{\"1\":{\"212\":1,\"215\":1}}],[\"persepctive\",{\"1\":{\"137\":1}}],[\"persian\",{\"1\":{\"95\":2}}],[\"personal\",{\"1\":{\"24\":1,\"218\":1}}],[\"perfect\",{\"1\":{\"124\":1}}],[\"perfectly\",{\"1\":{\"43\":1}}],[\"performer\",{\"1\":{\"59\":1}}],[\"performed\",{\"1\":{\"3\":1,\"41\":1,\"43\":2,\"100\":1,\"124\":1,\"126\":2}}],[\"perform\",{\"1\":{\"41\":1,\"43\":1,\"79\":1,\"86\":1,\"120\":2,\"122\":1,\"126\":2,\"152\":2,\"156\":1,\"173\":1,\"212\":1,\"228\":1,\"239\":1,\"251\":1,\"252\":1}}],[\"performing\",{\"1\":{\"3\":1,\"6\":1,\"8\":1,\"218\":1,\"227\":1,\"228\":1,\"232\":1,\"239\":1}}],[\"performs\",{\"1\":{\"1\":1,\"7\":1,\"22\":1,\"71\":1,\"93\":1,\"105\":1,\"120\":1,\"187\":1,\"200\":1,\"212\":1,\"244\":1}}],[\"performances\",{\"1\":{\"194\":1}}],[\"performance\",{\"0\":{\"5\":1,\"71\":1,\"113\":1,\"162\":1,\"163\":1,\"164\":1,\"165\":1},\"1\":{\"1\":1,\"2\":1,\"3\":3,\"5\":1,\"6\":1,\"8\":2,\"22\":1,\"23\":1,\"43\":3,\"54\":1,\"65\":1,\"70\":1,\"71\":2,\"80\":1,\"85\":1,\"87\":1,\"88\":2,\"93\":2,\"98\":2,\"101\":1,\"105\":1,\"109\":1,\"112\":1,\"113\":3,\"115\":4,\"120\":2,\"123\":1,\"132\":1,\"146\":13,\"149\":1,\"153\":1,\"163\":1,\"166\":2,\"167\":1,\"171\":3,\"173\":1,\"178\":1,\"179\":2,\"183\":1,\"188\":1,\"199\":2,\"200\":1,\"201\":2,\"202\":1,\"203\":1,\"213\":2,\"217\":1,\"225\":2,\"226\":1,\"228\":1,\"239\":1,\"244\":2,\"251\":2,\"252\":2,\"253\":6,\"254\":1,\"258\":3,\"263\":2,\"267\":1,\"269\":2,\"270\":1}}],[\"period\",{\"1\":{\"42\":1}}],[\"periodogram\",{\"1\":{\"42\":1}}],[\"periodic\",{\"1\":{\"42\":3}}],[\"per\",{\"1\":{\"1\":1,\"3\":1,\"41\":1,\"105\":1,\"109\":3,\"112\":1}}],[\"pt\",{\"0\":{\"30\":1},\"1\":{\"25\":1,\"27\":1,\"97\":1,\"98\":1,\"200\":2,\"252\":3}}],[\"pékin\",{\"1\":{\"24\":3}}],[\"plethora\",{\"1\":{\"225\":1}}],[\"please\",{\"1\":{\"24\":1,\"140\":1,\"229\":1}}],[\"pl\",{\"1\":{\"200\":1}}],[\"plot\",{\"1\":{\"166\":1,\"188\":1,\"203\":1}}],[\"plots\",{\"1\":{\"163\":2}}],[\"plm\",{\"1\":{\"71\":1}}],[\"plus\",{\"1\":{\"24\":1,\"36\":1}}],[\"platanios\",{\"1\":{\"116\":1}}],[\"plain\",{\"1\":{\"113\":1,\"178\":1}}],[\"playground\",{\"1\":{\"146\":1}}],[\"played\",{\"1\":{\"125\":2,\"225\":1}}],[\"plays\",{\"1\":{\"49\":1,\"58\":1}}],[\"play\",{\"1\":{\"23\":2,\"125\":6}}],[\"places\",{\"1\":{\"211\":1}}],[\"placed\",{\"1\":{\"2\":1,\"3\":1}}],[\"place\",{\"1\":{\"1\":1}}],[\"pull\",{\"1\":{\"233\":1}}],[\"put\",{\"1\":{\"115\":1,\"229\":1}}],[\"puts\",{\"1\":{\"24\":1}}],[\"punctuation\",{\"1\":{\"94\":1}}],[\"purely\",{\"1\":{\"209\":1,\"218\":1}}],[\"pure\",{\"1\":{\"93\":1,\"226\":1}}],[\"purchased\",{\"1\":{\"71\":1}}],[\"purpose\",{\"1\":{\"66\":1}}],[\"publicly\",{\"1\":{\"269\":1}}],[\"public\",{\"1\":{\"98\":1,\"115\":1,\"218\":1}}],[\"publication\",{\"1\":{\"59\":1,\"221\":1}}],[\"published\",{\"1\":{\"22\":1,\"41\":1,\"65\":1,\"93\":2,\"119\":1,\"227\":1}}],[\"physicalqa\",{\"1\":{\"124\":1}}],[\"philadelphia\",{\"1\":{\"105\":1}}],[\"philosopher\",{\"1\":{\"21\":1}}],[\"photo\",{\"1\":{\"78\":1}}],[\"phrases\",{\"1\":{\"67\":9,\"69\":1,\"71\":2,\"122\":1,\"125\":3,\"211\":1}}],[\"phrase\",{\"1\":{\"66\":5,\"68\":5,\"69\":4,\"71\":12,\"73\":1}}],[\"phase\",{\"0\":{\"27\":1},\"1\":{\"244\":1}}],[\"phenomenon\",{\"1\":{\"24\":1,\"81\":1,\"82\":1,\"95\":1,\"189\":1,\"253\":1}}],[\"pitfall\",{\"1\":{\"211\":1}}],[\"pitch\",{\"1\":{\"94\":1}}],[\"pip\",{\"1\":{\"159\":1,\"161\":1}}],[\"pipeline\",{\"1\":{\"72\":1}}],[\"pipes\",{\"1\":{\"65\":1}}],[\"pipe\",{\"1\":{\"65\":1,\"74\":1}}],[\"pixels\",{\"1\":{\"151\":1}}],[\"pixel\",{\"1\":{\"93\":1}}],[\"pivoting\",{\"1\":{\"113\":2}}],[\"pivot\",{\"1\":{\"51\":2}}],[\"picked\",{\"1\":{\"198\":1}}],[\"pick\",{\"1\":{\"2\":2}}],[\"pieces\",{\"1\":{\"212\":1}}],[\"piece\",{\"1\":{\"1\":3,\"2\":1,\"105\":1,\"212\":3}}],[\"practical\",{\"1\":{\"208\":1}}],[\"practices\",{\"1\":{\"37\":1}}],[\"practice\",{\"1\":{\"22\":1,\"97\":1,\"137\":1,\"266\":1}}],[\"pruning\",{\"1\":{\"146\":2}}],[\"prune\",{\"1\":{\"146\":1}}],[\"prudent\",{\"1\":{\"9\":1}}],[\"próprios\",{\"1\":{\"30\":1}}],[\"priateľov\",{\"1\":{\"125\":1}}],[\"primarily\",{\"1\":{\"72\":1}}],[\"primary\",{\"1\":{\"37\":1,\"68\":1,\"94\":1,\"170\":1}}],[\"priori\",{\"1\":{\"258\":1}}],[\"prior\",{\"1\":{\"42\":1,\"84\":1,\"121\":1,\"122\":2,\"184\":1}}],[\"privée\",{\"1\":{\"29\":1}}],[\"principles\",{\"1\":{\"24\":1,\"95\":1}}],[\"price\",{\"1\":{\"3\":2}}],[\"preformance\",{\"1\":{\"212\":1}}],[\"prefer\",{\"1\":{\"211\":1}}],[\"preferred\",{\"1\":{\"1\":1}}],[\"prepared\",{\"1\":{\"218\":1}}],[\"preparation\",{\"1\":{\"212\":1}}],[\"preprocess\",{\"1\":{\"146\":1}}],[\"preprocessing\",{\"0\":{\"97\":1}}],[\"preprint\",{\"1\":{\"116\":1,\"167\":3,\"175\":3,\"247\":2,\"271\":2}}],[\"precision\",{\"1\":{\"212\":4}}],[\"precisely\",{\"1\":{\"137\":1,\"232\":2}}],[\"preserving\",{\"1\":{\"211\":1}}],[\"presenting\",{\"1\":{\"224\":1}}],[\"presentation\",{\"1\":{\"94\":2}}],[\"presented\",{\"1\":{\"67\":1,\"214\":1}}],[\"presents\",{\"1\":{\"41\":1,\"42\":1,\"45\":1,\"77\":1,\"190\":1,\"227\":1}}],[\"present\",{\"1\":{\"1\":2,\"23\":1,\"146\":1,\"225\":1,\"263\":1}}],[\"premeditate\",{\"1\":{\"170\":1}}],[\"premises\",{\"0\":{\"68\":1},\"1\":{\"66\":1,\"68\":3,\"71\":4}}],[\"premise\",{\"1\":{\"66\":1,\"71\":1}}],[\"pretext\",{\"1\":{\"197\":1}}],[\"pretty\",{\"1\":{\"133\":1,\"269\":2}}],[\"pretraining\",{\"1\":{\"97\":1,\"98\":1,\"175\":1}}],[\"pretrained\",{\"1\":{\"22\":1,\"81\":1,\"126\":1,\"216\":1,\"252\":1}}],[\"preliminary\",{\"0\":{\"110\":1},\"1\":{\"209\":1,\"218\":1,\"252\":1}}],[\"predictors\",{\"1\":{\"94\":1}}],[\"predicted\",{\"1\":{\"71\":4,\"216\":1}}],[\"predicting\",{\"1\":{\"69\":1,\"123\":2,\"172\":1}}],[\"predictions\",{\"1\":{\"94\":1,\"213\":1,\"251\":1,\"252\":1}}],[\"prediction\",{\"0\":{\"123\":1},\"1\":{\"42\":1,\"65\":1,\"71\":4,\"121\":1,\"172\":1,\"214\":1,\"219\":1,\"250\":1}}],[\"predict\",{\"1\":{\"51\":1,\"59\":1,\"65\":1,\"71\":2,\"73\":1,\"105\":1,\"172\":1,\"215\":1}}],[\"predicts\",{\"1\":{\"49\":1}}],[\"pre\",{\"0\":{\"21\":1,\"23\":1,\"27\":1,\"119\":1},\"1\":{\"18\":1,\"22\":6,\"23\":12,\"24\":5,\"25\":5,\"26\":3,\"27\":8,\"33\":2,\"35\":2,\"36\":1,\"37\":6,\"77\":2,\"78\":1,\"80\":1,\"89\":1,\"95\":2,\"105\":3,\"112\":1,\"119\":1,\"126\":1,\"157\":1,\"167\":1,\"171\":2,\"172\":1,\"184\":1,\"188\":1,\"195\":1,\"199\":2,\"227\":3},\"2\":{\"20\":1,\"39\":1,\"91\":1,\"107\":1,\"129\":1}}],[\"prevalent\",{\"1\":{\"250\":1}}],[\"prevailing\",{\"1\":{\"1\":1}}],[\"preventing\",{\"1\":{\"45\":1}}],[\"prevents\",{\"1\":{\"44\":1}}],[\"prevent\",{\"1\":{\"41\":1,\"119\":1}}],[\"previews\",{\"1\":{\"2\":1}}],[\"previously\",{\"1\":{\"114\":1,\"264\":1}}],[\"previous\",{\"1\":{\"1\":1,\"2\":1,\"22\":1,\"23\":2,\"49\":1,\"54\":2,\"60\":1,\"93\":2,\"94\":1,\"109\":1,\"113\":1,\"119\":1,\"124\":1,\"137\":1,\"197\":1,\"212\":1,\"266\":1,\"267\":2,\"269\":1}}],[\"prohibitively\",{\"1\":{\"231\":1}}],[\"prosper\",{\"1\":{\"219\":1}}],[\"pronoun\",{\"1\":{\"124\":3}}],[\"proficient\",{\"1\":{\"124\":1}}],[\"promise\",{\"1\":{\"175\":1,\"228\":1}}],[\"promising\",{\"1\":{\"45\":1,\"130\":1}}],[\"prompt\",{\"1\":{\"125\":3}}],[\"prompts\",{\"1\":{\"124\":1}}],[\"promoted\",{\"1\":{\"209\":1}}],[\"promotes\",{\"1\":{\"201\":1}}],[\"promote\",{\"1\":{\"115\":1}}],[\"proves\",{\"1\":{\"239\":1}}],[\"prove\",{\"1\":{\"146\":1,\"259\":1}}],[\"proved\",{\"1\":{\"126\":1}}],[\"proven\",{\"1\":{\"96\":1,\"218\":1,\"241\":1}}],[\"providing\",{\"1\":{\"41\":1,\"65\":2,\"71\":1,\"73\":1,\"120\":1}}],[\"provided\",{\"1\":{\"96\":2,\"110\":1,\"124\":2,\"210\":1,\"239\":1}}],[\"provides\",{\"1\":{\"93\":1,\"94\":1,\"218\":1,\"240\":1}}],[\"provide\",{\"1\":{\"22\":1,\"41\":1,\"66\":1,\"71\":1,\"93\":1,\"100\":1,\"196\":1,\"226\":1,\"228\":2,\"231\":1}}],[\"provisional\",{\"1\":{\"29\":3}}],[\"provisoire\",{\"1\":{\"29\":1}}],[\"project\",{\"1\":{\"196\":2}}],[\"projected\",{\"1\":{\"130\":1,\"203\":1}}],[\"projection\",{\"1\":{\"96\":4,\"97\":1,\"100\":2,\"130\":1}}],[\"projecting\",{\"1\":{\"93\":1,\"101\":1,\"240\":1}}],[\"projects\",{\"1\":{\"42\":1}}],[\"protected\",{\"1\":{\"43\":1}}],[\"protection\",{\"1\":{\"41\":1,\"43\":1,\"46\":1},\"2\":{\"48\":1}}],[\"protecting\",{\"0\":{\"40\":1}}],[\"protect\",{\"1\":{\"40\":1,\"45\":1}}],[\"program\",{\"1\":{\"228\":1,\"231\":1}}],[\"programs\",{\"1\":{\"226\":1}}],[\"programming\",{\"1\":{\"24\":1}}],[\"progress\",{\"1\":{\"36\":1,\"101\":1}}],[\"probably\",{\"1\":{\"93\":1,\"225\":1}}],[\"probabilistic\",{\"1\":{\"84\":1,\"188\":1}}],[\"probabilities\",{\"1\":{\"42\":2,\"73\":1}}],[\"probability\",{\"1\":{\"24\":1,\"42\":1,\"66\":1,\"69\":3,\"71\":4,\"73\":1,\"84\":1,\"156\":1,\"181\":1,\"266\":1,\"268\":1}}],[\"probing\",{\"0\":{\"68\":1},\"1\":{\"66\":2,\"68\":5}}],[\"problems\",{\"1\":{\"3\":1,\"23\":2,\"71\":1,\"101\":1,\"211\":1,\"251\":1}}],[\"problem\",{\"0\":{\"77\":1,\"135\":1,\"241\":1},\"1\":{\"2\":1,\"3\":2,\"8\":2,\"22\":1,\"66\":1,\"84\":2,\"89\":1,\"109\":1,\"112\":1,\"131\":1,\"135\":1,\"175\":1,\"228\":1,\"239\":1,\"251\":1,\"264\":1}}],[\"proprietary\",{\"1\":{\"42\":8,\"43\":4,\"44\":2}}],[\"proposals\",{\"1\":{\"228\":1}}],[\"proposing\",{\"1\":{\"194\":1}}],[\"proposes\",{\"1\":{\"194\":1,\"203\":1,\"265\":1}}],[\"propose\",{\"1\":{\"51\":1,\"84\":1,\"88\":1,\"105\":1,\"109\":1,\"112\":1,\"146\":1,\"194\":1,\"198\":1,\"239\":1,\"259\":1,\"270\":1}}],[\"proposed\",{\"0\":{\"51\":1,\"84\":1,\"254\":1},\"1\":{\"23\":2,\"26\":1,\"54\":1,\"59\":1,\"60\":1,\"85\":1,\"105\":1,\"111\":2,\"113\":1,\"131\":1,\"139\":1,\"142\":1,\"146\":2,\"171\":1,\"197\":1,\"228\":1,\"232\":1,\"246\":1,\"256\":1,\"263\":1,\"264\":2,\"265\":1,\"269\":5,\"270\":1}}],[\"proportion\",{\"1\":{\"44\":1}}],[\"proportional\",{\"1\":{\"3\":1}}],[\"properties\",{\"1\":{\"84\":1,\"181\":1}}],[\"property\",{\"0\":{\"40\":1},\"1\":{\"41\":1,\"45\":1,\"218\":1}}],[\"properly\",{\"1\":{\"79\":1,\"93\":1,\"171\":1,\"264\":1}}],[\"proper\",{\"0\":{\"21\":1}}],[\"procedure\",{\"1\":{\"240\":1,\"268\":1}}],[\"proceedings\",{\"1\":{\"9\":2,\"61\":1,\"89\":4,\"105\":6,\"167\":1,\"175\":1,\"221\":1,\"247\":2}}],[\"processing\",{\"0\":{\"149\":1},\"1\":{\"22\":1,\"37\":2,\"41\":1,\"94\":1,\"96\":1,\"102\":2,\"105\":2,\"119\":1,\"124\":2,\"131\":1,\"151\":1,\"167\":1,\"171\":1,\"172\":1,\"175\":2,\"208\":1,\"214\":1,\"221\":1,\"239\":1,\"247\":1}}],[\"process\",{\"1\":{\"1\":1,\"8\":1,\"24\":1,\"25\":2,\"41\":2,\"66\":1,\"97\":1,\"109\":1,\"112\":1,\"132\":1,\"156\":1,\"171\":2,\"172\":2,\"197\":1,\"216\":1,\"232\":1,\"254\":1}}],[\"products\",{\"1\":{\"153\":1,\"225\":1}}],[\"product\",{\"1\":{\"3\":1,\"82\":1,\"196\":1,\"212\":1,\"216\":2,\"232\":1,\"238\":1,\"239\":1,\"240\":2,\"244\":2,\"246\":1}}],[\"produce\",{\"1\":{\"2\":1,\"5\":1,\"8\":1,\"41\":1,\"105\":1,\"110\":1,\"146\":1,\"171\":1,\"216\":1,\"233\":1}}],[\"produces\",{\"1\":{\"1\":1,\"6\":1,\"81\":1,\"254\":1}}],[\"produced\",{\"1\":{\"1\":1,\"6\":1,\"71\":1,\"183\":1}}],[\"poďme\",{\"1\":{\"125\":1}}],[\"poetry\",{\"1\":{\"95\":1}}],[\"polosukhin\",{\"1\":{\"102\":1}}],[\"polish\",{\"1\":{\"95\":2}}],[\"polymath\",{\"1\":{\"93\":1}}],[\"polyglots\",{\"1\":{\"93\":2,\"95\":1,\"101\":1}}],[\"polyglot\",{\"1\":{\"21\":1,\"22\":1,\"93\":1}}],[\"portions\",{\"1\":{\"94\":1}}],[\"portuguese\",{\"0\":{\"30\":1},\"1\":{\"25\":2,\"27\":1,\"97\":1}}],[\"point\",{\"1\":{\"95\":1,\"130\":1,\"215\":1}}],[\"pointed\",{\"1\":{\"81\":1,\"218\":1}}],[\"points\",{\"1\":{\"3\":1,\"86\":2,\"124\":1,\"244\":1,\"253\":1,\"254\":1,\"269\":1}}],[\"poisonous\",{\"1\":{\"72\":2}}],[\"pooling\",{\"1\":{\"216\":2}}],[\"pooled\",{\"1\":{\"35\":1,\"216\":1}}],[\"poobede\",{\"1\":{\"125\":1}}],[\"poorly\",{\"1\":{\"79\":1,\"83\":1,\"84\":1}}],[\"poor\",{\"1\":{\"72\":1}}],[\"potentially\",{\"1\":{\"245\":1}}],[\"potentials\",{\"1\":{\"65\":1}}],[\"potential\",{\"1\":{\"45\":2,\"58\":1,\"71\":2,\"93\":1,\"120\":1,\"130\":1}}],[\"pour\",{\"1\":{\"31\":3}}],[\"popular\",{\"1\":{\"5\":1,\"7\":1,\"97\":1,\"152\":1,\"155\":1,\"209\":1}}],[\"posts\",{\"1\":{\"228\":1}}],[\"post\",{\"1\":{\"224\":1,\"239\":1}}],[\"posterior\",{\"1\":{\"183\":1}}],[\"poslať\",{\"1\":{\"125\":1}}],[\"possibilities\",{\"1\":{\"231\":1}}],[\"possibility\",{\"1\":{\"203\":1}}],[\"possibly\",{\"1\":{\"94\":1,\"234\":1}}],[\"possible\",{\"1\":{\"1\":6,\"2\":3,\"7\":1,\"8\":2,\"23\":1,\"24\":2,\"41\":1,\"42\":1,\"51\":1,\"65\":1,\"171\":2,\"225\":1,\"226\":2,\"263\":2,\"264\":1}}],[\"possess\",{\"1\":{\"71\":1,\"72\":1}}],[\"pos\",{\"1\":{\"43\":2,\"67\":2}}],[\"pos等任务\",{\"1\":{\"13\":1}}],[\"positively\",{\"1\":{\"94\":1,\"146\":1}}],[\"positive\",{\"1\":{\"3\":1,\"43\":2,\"196\":4}}],[\"positions\",{\"1\":{\"245\":1}}],[\"positional\",{\"1\":{\"239\":1}}],[\"position\",{\"1\":{\"2\":1,\"240\":1,\"244\":1,\"245\":2}}],[\"powerful\",{\"1\":{\"54\":1,\"121\":2,\"124\":1,\"126\":1,\"231\":1}}],[\"power\",{\"1\":{\"1\":1,\"42\":1,\"72\":1,\"259\":1}}],[\"pan\",{\"1\":{\"203\":1}}],[\"panxiao1994\",{\"1\":{\"203\":1}}],[\"paulik\",{\"1\":{\"175\":1}}],[\"passable\",{\"1\":{\"228\":1}}],[\"passages\",{\"1\":{\"208\":1}}],[\"passage\",{\"1\":{\"123\":1}}],[\"passing\",{\"1\":{\"226\":1}}],[\"pass\",{\"1\":{\"175\":1,\"233\":1}}],[\"past\",{\"1\":{\"41\":1,\"119\":1}}],[\"painfully\",{\"1\":{\"105\":1}}],[\"paired\",{\"1\":{\"130\":1,\"132\":1,\"133\":2,\"135\":1,\"141\":1,\"178\":1,\"250\":1}}],[\"pairwise\",{\"1\":{\"110\":1,\"113\":1,\"241\":1}}],[\"pairs\",{\"1\":{\"3\":1,\"4\":3,\"22\":1,\"24\":4,\"25\":3,\"27\":3,\"30\":1,\"33\":1,\"51\":2,\"93\":2,\"98\":2,\"100\":1,\"109\":2,\"110\":2,\"111\":1,\"113\":1,\"146\":11,\"165\":1,\"179\":2,\"196\":3,\"198\":2,\"201\":1,\"211\":1,\"213\":2,\"218\":1,\"226\":1,\"244\":3,\"263\":1,\"264\":1,\"269\":1,\"270\":1}}],[\"pair\",{\"1\":{\"1\":1,\"3\":1,\"5\":1,\"8\":1,\"22\":1,\"24\":1,\"25\":1,\"27\":3,\"29\":2,\"51\":2,\"93\":1,\"97\":1,\"100\":1,\"105\":1,\"109\":1,\"110\":1,\"111\":1,\"113\":2,\"124\":1,\"146\":13,\"181\":1,\"183\":1,\"196\":2,\"200\":1,\"209\":1,\"212\":1,\"213\":1,\"217\":2,\"227\":1,\"241\":1,\"245\":1}}],[\"papineni\",{\"1\":{\"105\":2,\"221\":1}}],[\"paperwithcode\",{\"1\":{\"269\":1}}],[\"papers\",{\"1\":{\"5\":1,\"9\":1,\"105\":2,\"228\":1}}],[\"paper\",{\"1\":{\"0\":3,\"1\":1,\"3\":1,\"5\":1,\"8\":1,\"21\":1,\"24\":1,\"27\":1,\"28\":1,\"41\":3,\"42\":1,\"45\":1,\"49\":1,\"60\":1,\"64\":1,\"65\":1,\"66\":1,\"77\":2,\"79\":1,\"92\":1,\"98\":1,\"109\":2,\"110\":1,\"111\":2,\"112\":1,\"113\":1,\"119\":1,\"130\":3,\"131\":1,\"133\":1,\"140\":1,\"142\":1,\"146\":1,\"170\":1,\"173\":1,\"174\":1,\"175\":1,\"178\":2,\"190\":1,\"194\":1,\"197\":2,\"203\":2,\"211\":1,\"213\":1,\"224\":3,\"228\":1,\"233\":1,\"238\":1,\"239\":2,\"240\":1,\"244\":1,\"250\":1,\"264\":1,\"269\":2}}],[\"paving\",{\"1\":{\"101\":1}}],[\"paves\",{\"1\":{\"93\":1}}],[\"patience\",{\"1\":{\"234\":1}}],[\"patterns\",{\"1\":{\"100\":1,\"114\":1,\"119\":1,\"124\":1,\"239\":1,\"244\":2,\"245\":2}}],[\"patrick\",{\"1\":{\"74\":1}}],[\"paths\",{\"1\":{\"51\":2}}],[\"path\",{\"1\":{\"36\":1,\"51\":3,\"60\":1,\"101\":1}}],[\"pay\",{\"1\":{\"41\":1}}],[\"page\",{\"1\":{\"36\":1,\"221\":1}}],[\"pages\",{\"1\":{\"9\":1,\"102\":1,\"105\":6,\"247\":2}}],[\"par\",{\"1\":{\"199\":1}}],[\"park\",{\"1\":{\"125\":2}}],[\"parku\",{\"1\":{\"125\":1}}],[\"parikh\",{\"1\":{\"105\":1}}],[\"paris\",{\"1\":{\"31\":4,\"36\":1,\"201\":1}}],[\"parmar\",{\"1\":{\"102\":1,\"175\":1}}],[\"parser\",{\"1\":{\"67\":1}}],[\"paragraph\",{\"1\":{\"263\":1}}],[\"paraphrase\",{\"1\":{\"254\":3}}],[\"paraphrases\",{\"1\":{\"211\":1}}],[\"paralel\",{\"1\":{\"186\":1}}],[\"parallelly\",{\"1\":{\"178\":1}}],[\"paralleled\",{\"1\":{\"110\":1,\"113\":2}}],[\"parallel\",{\"0\":{\"182\":1,\"183\":1,\"232\":1},\"1\":{\"22\":4,\"23\":1,\"24\":4,\"25\":7,\"27\":4,\"29\":1,\"30\":1,\"33\":1,\"35\":2,\"94\":2,\"110\":1,\"133\":1,\"156\":1,\"170\":3,\"171\":1,\"172\":1,\"178\":2,\"179\":3,\"181\":3,\"182\":2,\"183\":3,\"186\":3,\"187\":4,\"188\":2,\"189\":1,\"190\":1,\"198\":1,\"200\":1,\"201\":2,\"203\":1,\"218\":1,\"221\":1,\"226\":2,\"227\":5,\"231\":3,\"232\":2,\"250\":1,\"252\":3,\"258\":2,\"263\":7,\"264\":2,\"269\":3,\"270\":1,\"271\":1}}],[\"paramters\",{\"1\":{\"111\":1,\"112\":2,\"113\":1}}],[\"paramter\",{\"1\":{\"110\":1,\"112\":1}}],[\"parameterized\",{\"1\":{\"241\":1}}],[\"parameterization\",{\"1\":{\"109\":2}}],[\"parameter\",{\"0\":{\"108\":1,\"111\":1},\"1\":{\"109\":2,\"111\":9,\"112\":4,\"116\":1,\"146\":10,\"152\":1,\"196\":1,\"242\":1,\"258\":1,\"266\":1}}],[\"parameters\",{\"1\":{\"23\":1,\"24\":1,\"41\":2,\"97\":2,\"109\":2,\"111\":3,\"112\":5,\"115\":1,\"119\":1,\"123\":1,\"146\":10,\"167\":1,\"173\":1,\"181\":1,\"239\":1,\"242\":1,\"266\":1}}],[\"paradigms\",{\"1\":{\"22\":1,\"23\":2}}],[\"paradigm\",{\"1\":{\"22\":1,\"23\":2,\"36\":1,\"93\":1,\"94\":1}}],[\"partially\",{\"1\":{\"253\":1}}],[\"particularly\",{\"1\":{\"125\":1,\"172\":1,\"259\":1}}],[\"particular\",{\"1\":{\"93\":1,\"95\":1,\"146\":1}}],[\"partilhadas\",{\"1\":{\"30\":1}}],[\"parts\",{\"1\":{\"43\":1,\"95\":1}}],[\"part\",{\"1\":{\"1\":2,\"8\":1,\"23\":3,\"43\":1,\"59\":1,\"66\":1,\"67\":1,\"68\":1,\"71\":1,\"72\":1,\"111\":1,\"137\":1,\"170\":1,\"172\":1}}],[\"hcsa\",{\"1\":{\"244\":1}}],[\"h−\",{\"1\":{\"216\":1}}],[\"h+\",{\"1\":{\"216\":3}}],[\"h⊙r\",{\"1\":{\"216\":1}}],[\"h⊙s\",{\"1\":{\"216\":1}}],[\"h\",{\"1\":{\"175\":2,\"216\":4,\"240\":1,\"242\":1}}],[\"hf\",{\"1\":{\"161\":1}}],[\"hral\",{\"1\":{\"125\":1}}],[\"hrať\",{\"1\":{\"125\":2}}],[\"htm\",{\"1\":{\"221\":1}}],[\"http\",{\"1\":{\"221\":1}}],[\"https\",{\"1\":{\"0\":2,\"12\":1,\"21\":2,\"41\":2,\"46\":1,\"49\":2,\"64\":3,\"77\":2,\"78\":1,\"92\":2,\"102\":1,\"143\":1,\"146\":2,\"175\":2,\"203\":1,\"220\":2,\"221\":4,\"224\":2,\"235\":1,\"238\":2,\"250\":2,\"269\":1,\"271\":1}}],[\"hter\",{\"1\":{\"105\":1,\"215\":1,\"216\":1,\"217\":3}}],[\"hyper\",{\"1\":{\"258\":1}}],[\"hype\",{\"1\":{\"218\":1}}],[\"hypthesis\",{\"1\":{\"218\":1}}],[\"hyp\",{\"1\":{\"216\":1,\"218\":3}}],[\"hypotheses\",{\"1\":{\"105\":3,\"126\":1,\"253\":1}}],[\"hypothesis\",{\"1\":{\"100\":1,\"105\":4,\"175\":4,\"214\":1,\"216\":8,\"217\":3,\"218\":2,\"253\":2}}],[\"hyphen\",{\"1\":{\"2\":1}}],[\"hmg\",{\"1\":{\"57\":2}}],[\"hlt\",{\"1\":{\"37\":1}}],[\"him\",{\"1\":{\"228\":1}}],[\"hidden\",{\"1\":{\"97\":1,\"130\":1,\"134\":1,\"137\":1,\"146\":1,\"172\":2,\"195\":1,\"245\":2}}],[\"hierarchical\",{\"0\":{\"156\":1},\"1\":{\"54\":1,\"156\":1}}],[\"hinder\",{\"1\":{\"78\":1}}],[\"hindi\",{\"1\":{\"27\":2}}],[\"hin\",{\"1\":{\"54\":2}}],[\"history\",{\"0\":{\"207\":1},\"1\":{\"71\":2,\"93\":1,\"170\":1,\"219\":1,\"228\":2}}],[\"his\",{\"1\":{\"36\":1,\"93\":1,\"95\":1,\"228\":1}}],[\"highlights\",{\"1\":{\"233\":1}}],[\"highlycosting\",{\"1\":{\"78\":1}}],[\"highly\",{\"1\":{\"25\":1,\"82\":2,\"94\":1,\"125\":1,\"170\":1,\"214\":1,\"233\":1,\"263\":1}}],[\"high\",{\"1\":{\"3\":1,\"71\":1,\"82\":1,\"83\":1,\"94\":1,\"98\":1,\"109\":1,\"112\":1,\"133\":1,\"146\":1,\"149\":1,\"152\":2,\"153\":1,\"167\":1,\"171\":1,\"174\":1,\"178\":1,\"196\":1,\"209\":1,\"210\":1,\"221\":1,\"225\":1,\"245\":1,\"256\":1}}],[\"highest\",{\"1\":{\"2\":1,\"3\":6,\"93\":1,\"105\":1,\"156\":1,\"209\":1,\"212\":1,\"218\":1}}],[\"higher\",{\"1\":{\"1\":2,\"3\":2,\"35\":1,\"42\":2,\"43\":2,\"71\":1,\"105\":1,\"124\":1,\"184\":1,\"211\":2,\"212\":1,\"213\":2,\"216\":1,\"217\":2,\"218\":2,\"228\":1,\"253\":2}}],[\"huayang\",{\"1\":{\"235\":1}}],[\"huang\",{\"1\":{\"61\":1,\"89\":2,\"191\":1}}],[\"hundred\",{\"1\":{\"125\":1}}],[\"hundreds\",{\"1\":{\"22\":1,\"226\":1}}],[\"hungarian\",{\"1\":{\"95\":2}}],[\"hugely\",{\"1\":{\"202\":2}}],[\"huge\",{\"1\":{\"93\":1,\"151\":1}}],[\"huggingface\",{\"1\":{\"64\":1}}],[\"hu\",{\"1\":{\"89\":1}}],[\"humans\",{\"1\":{\"41\":1,\"71\":1,\"93\":2,\"95\":1,\"120\":2,\"123\":2,\"124\":1,\"171\":1,\"172\":1,\"215\":1,\"228\":2,\"231\":1,\"233\":1}}],[\"human\",{\"0\":{\"172\":1,\"208\":1},\"1\":{\"24\":1,\"41\":1,\"53\":1,\"60\":1,\"86\":1,\"92\":1,\"94\":2,\"95\":2,\"97\":1,\"102\":1,\"105\":7,\"120\":1,\"123\":4,\"124\":1,\"132\":3,\"171\":1,\"172\":2,\"206\":1,\"208\":2,\"209\":3,\"213\":5,\"214\":2,\"215\":5,\"216\":1,\"217\":1,\"218\":6,\"219\":3,\"221\":2,\"225\":1}}],[\"house\",{\"1\":{\"125\":2}}],[\"hours\",{\"1\":{\"1\":2,\"2\":1,\"6\":3,\"8\":1,\"93\":2,\"97\":3}}],[\"hockey\",{\"1\":{\"125\":4}}],[\"hokej\",{\"1\":{\"125\":2}}],[\"home\",{\"1\":{\"125\":2}}],[\"hovers\",{\"1\":{\"125\":1}}],[\"hong\",{\"1\":{\"93\":1}}],[\"hope\",{\"1\":{\"232\":1}}],[\"hopefully\",{\"1\":{\"130\":1,\"227\":1}}],[\"hop\",{\"1\":{\"51\":1}}],[\"holding\",{\"1\":{\"208\":1}}],[\"holds\",{\"1\":{\"1\":1}}],[\"hole\",{\"1\":{\"84\":2}}],[\"holes\",{\"1\":{\"83\":1}}],[\"holistic\",{\"1\":{\"49\":1}}],[\"hot\",{\"1\":{\"42\":1}}],[\"however\",{\"1\":{\"1\":2,\"2\":1,\"6\":1,\"8\":1,\"22\":1,\"23\":2,\"24\":1,\"41\":1,\"49\":1,\"65\":1,\"71\":4,\"82\":1,\"93\":2,\"94\":1,\"109\":2,\"119\":1,\"146\":2,\"151\":1,\"152\":1,\"171\":2,\"172\":1,\"178\":1,\"188\":1,\"194\":1,\"208\":1,\"211\":2,\"218\":2,\"225\":2,\"226\":1,\"227\":1,\"228\":2,\"233\":1,\"250\":1,\"251\":2,\"253\":1,\"263\":1,\"264\":1,\"269\":1}}],[\"how\",{\"0\":{\"77\":1,\"203\":1},\"1\":{\"0\":1,\"2\":4,\"3\":3,\"7\":2,\"8\":2,\"40\":1,\"41\":1,\"43\":1,\"64\":1,\"65\":1,\"67\":1,\"68\":1,\"71\":2,\"72\":1,\"79\":1,\"89\":1,\"92\":1,\"93\":1,\"95\":2,\"101\":2,\"109\":1,\"111\":1,\"113\":1,\"121\":1,\"122\":1,\"124\":2,\"125\":1,\"132\":2,\"146\":1,\"171\":1,\"172\":1,\"194\":1,\"206\":1,\"208\":1,\"215\":2,\"218\":3,\"226\":2,\"230\":1,\"233\":1,\"250\":1,\"251\":1,\"258\":1,\"263\":1,\"264\":1,\"266\":1,\"269\":2}}],[\"hesitate\",{\"1\":{\"229\":1}}],[\"heschl\",{\"1\":{\"94\":1}}],[\"hello\",{\"1\":{\"224\":1}}],[\"helps\",{\"1\":{\"170\":1,\"172\":1,\"201\":2,\"251\":1}}],[\"helped\",{\"1\":{\"130\":1}}],[\"helpfulness\",{\"1\":{\"84\":1}}],[\"helpful\",{\"1\":{\"3\":1,\"212\":1}}],[\"help\",{\"0\":{\"130\":1},\"1\":{\"2\":1,\"36\":1,\"45\":2,\"57\":1,\"84\":1,\"93\":1,\"95\":1,\"114\":1,\"115\":1,\"131\":1,\"132\":2,\"135\":1,\"146\":1,\"184\":1,\"227\":1,\"263\":1}}],[\"her\",{\"1\":{\"123\":1}}],[\"herv´e\",{\"1\":{\"105\":1}}],[\"here\",{\"1\":{\"1\":1,\"2\":3,\"3\":4,\"4\":2,\"5\":1,\"7\":1,\"25\":1,\"66\":1,\"68\":1,\"71\":5,\"96\":1,\"98\":1,\"109\":1,\"124\":1,\"135\":1,\"152\":1,\"153\":1,\"155\":2,\"161\":1,\"164\":1,\"175\":1,\"242\":1,\"251\":1,\"264\":2}}],[\"heng\",{\"1\":{\"102\":1}}],[\"hence\",{\"1\":{\"1\":1,\"3\":1,\"5\":1,\"49\":1}}],[\"heavy\",{\"1\":{\"225\":1}}],[\"heavily\",{\"1\":{\"96\":1,\"151\":1}}],[\"heads\",{\"1\":{\"97\":1,\"195\":1,\"239\":1,\"242\":2}}],[\"head\",{\"0\":{\"240\":1},\"1\":{\"54\":1,\"238\":1,\"239\":1,\"240\":5,\"242\":2}}],[\"heterogeneous\",{\"1\":{\"51\":1,\"60\":1}}],[\"he\",{\"1\":{\"21\":3,\"24\":4,\"36\":1,\"71\":4,\"89\":2,\"95\":5,\"167\":1,\"260\":1,\"263\":1}}],[\"hat\",{\"1\":{\"266\":1}}],[\"happened\",{\"1\":{\"175\":1}}],[\"happen\",{\"1\":{\"156\":1}}],[\"happens\",{\"1\":{\"71\":1,\"156\":1,\"228\":1}}],[\"happy\",{\"1\":{\"125\":1}}],[\"harmonic\",{\"1\":{\"216\":1}}],[\"harming\",{\"1\":{\"202\":1}}],[\"harms\",{\"1\":{\"80\":1}}],[\"harder\",{\"1\":{\"228\":1}}],[\"hardware\",{\"1\":{\"152\":1}}],[\"hardly\",{\"1\":{\"146\":1}}],[\"hard\",{\"1\":{\"42\":5,\"43\":4,\"79\":1,\"109\":1,\"172\":1,\"225\":1,\"226\":1,\"244\":1,\"247\":1}}],[\"hao\",{\"1\":{\"74\":1,\"89\":1,\"191\":1}}],[\"hauf\",{\"1\":{\"74\":1}}],[\"hans\",{\"1\":{\"93\":1}}],[\"handwritten\",{\"1\":{\"232\":1}}],[\"hand\",{\"1\":{\"72\":1,\"130\":1,\"178\":1,\"196\":1,\"216\":1,\"240\":2,\"242\":1}}],[\"handle\",{\"1\":{\"58\":1}}],[\"han\",{\"1\":{\"61\":1,\"102\":1,\"175\":1}}],[\"haddow\",{\"1\":{\"9\":1}}],[\"had\",{\"1\":{\"4\":1,\"43\":1,\"119\":1,\"121\":1,\"124\":3,\"228\":1}}],[\"having\",{\"1\":{\"1\":1,\"2\":1,\"120\":1,\"212\":1}}],[\"have\",{\"1\":{\"1\":5,\"2\":4,\"3\":3,\"22\":2,\"23\":2,\"24\":1,\"25\":2,\"27\":4,\"30\":2,\"41\":2,\"42\":2,\"65\":3,\"71\":2,\"78\":1,\"81\":1,\"84\":1,\"93\":1,\"94\":3,\"96\":2,\"100\":2,\"105\":1,\"110\":2,\"111\":1,\"112\":1,\"119\":2,\"125\":4,\"137\":1,\"146\":1,\"152\":2,\"159\":1,\"170\":1,\"194\":1,\"196\":2,\"201\":1,\"210\":1,\"212\":1,\"218\":5,\"225\":5,\"227\":1,\"228\":1,\"229\":2,\"230\":1,\"232\":5,\"233\":2,\"234\":1,\"241\":1,\"244\":1,\"263\":2,\"264\":1}}],[\"hash\",{\"1\":{\"42\":1}}],[\"has\",{\"1\":{\"1\":2,\"3\":2,\"4\":1,\"22\":6,\"23\":3,\"24\":2,\"25\":3,\"26\":1,\"27\":7,\"30\":1,\"35\":2,\"36\":3,\"43\":1,\"44\":1,\"51\":1,\"53\":1,\"71\":3,\"84\":1,\"93\":4,\"94\":1,\"97\":2,\"98\":2,\"105\":1,\"113\":1,\"124\":1,\"130\":2,\"131\":1,\"146\":1,\"170\":3,\"171\":1,\"175\":1,\"196\":1,\"200\":1,\"215\":1,\"216\":1,\"218\":3,\"219\":3,\"225\":1,\"227\":1,\"230\":1,\"231\":1,\"233\":1,\"239\":1,\"241\":1,\"250\":1,\"251\":1,\"263\":1,\"269\":1}}],[\"bfsu\",{\"1\":{\"221\":1}}],[\"bt\",{\"1\":{\"179\":4,\"183\":3,\"184\":1,\"256\":1,\"257\":2}}],[\"b\",{\"1\":{\"167\":1,\"174\":1,\"197\":2,\"211\":3,\"258\":1}}],[\"bsi\",{\"1\":{\"146\":1}}],[\"b´erard\",{\"1\":{\"105\":1}}],[\"bold\",{\"1\":{\"213\":1}}],[\"bottom\",{\"1\":{\"146\":1}}],[\"bottlenecks\",{\"1\":{\"133\":1}}],[\"both\",{\"1\":{\"1\":2,\"3\":1,\"6\":1,\"8\":1,\"25\":1,\"27\":2,\"43\":1,\"44\":1,\"51\":1,\"59\":1,\"71\":1,\"92\":1,\"93\":2,\"94\":2,\"96\":1,\"105\":2,\"131\":1,\"137\":1,\"141\":1,\"146\":5,\"152\":2,\"153\":2,\"179\":1,\"181\":2,\"186\":1,\"194\":1,\"195\":1,\"202\":1,\"213\":1,\"216\":1,\"231\":1,\"233\":1,\"240\":2,\"244\":2,\"254\":1,\"256\":1}}],[\"bob\",{\"1\":{\"123\":2}}],[\"book\",{\"1\":{\"227\":1}}],[\"books\",{\"1\":{\"93\":1,\"97\":1}}],[\"boosts\",{\"1\":{\"183\":1,\"187\":1,\"202\":1,\"252\":1}}],[\"boosting\",{\"1\":{\"101\":1}}],[\"boost\",{\"1\":{\"93\":1,\"146\":2,\"178\":1,\"179\":1,\"269\":1}}],[\"bowring\",{\"1\":{\"93\":1}}],[\"born\",{\"1\":{\"93\":2,\"95\":2}}],[\"borrow\",{\"1\":{\"92\":1}}],[\"bohan\",{\"1\":{\"89\":1}}],[\"bohanli\",{\"1\":{\"77\":1}}],[\"bounds\",{\"1\":{\"183\":1}}],[\"bound\",{\"1\":{\"42\":1,\"182\":1}}],[\"brevity\",{\"1\":{\"209\":2}}],[\"break\",{\"0\":{\"170\":1},\"1\":{\"170\":1,\"172\":1,\"211\":1}}],[\"breaks\",{\"1\":{\"22\":1}}],[\"breaking\",{\"1\":{\"1\":1,\"151\":1}}],[\"brown\",{\"1\":{\"167\":1}}],[\"broken\",{\"1\":{\"101\":1}}],[\"broadway\",{\"1\":{\"31\":4}}],[\"brand\",{\"1\":{\"218\":4}}],[\"branch\",{\"1\":{\"41\":1}}],[\"brain\",{\"1\":{\"92\":1,\"94\":2,\"102\":1,\"172\":1}}],[\"brislin\",{\"1\":{\"271\":1}}],[\"brief\",{\"0\":{\"207\":1},\"1\":{\"239\":1,\"244\":1}}],[\"bringing\",{\"1\":{\"112\":1}}],[\"brings\",{\"1\":{\"23\":1,\"25\":1,\"109\":1,\"188\":1}}],[\"bridging\",{\"1\":{\"93\":3,\"221\":1}}],[\"bridges\",{\"1\":{\"244\":1,\"263\":1}}],[\"bridge\",{\"1\":{\"24\":1,\"41\":1,\"94\":1,\"95\":1,\"100\":1,\"132\":1,\"183\":1,\"225\":1}}],[\"bivariate\",{\"1\":{\"203\":1}}],[\"biology\",{\"1\":{\"125\":2,\"228\":1}}],[\"biológie\",{\"1\":{\"125\":1}}],[\"bias\",{\"1\":{\"109\":2}}],[\"biases\",{\"0\":{\"82\":1}}],[\"biased\",{\"1\":{\"72\":1}}],[\"bit\",{\"1\":{\"97\":1,\"253\":1}}],[\"bi\",{\"1\":{\"95\":1}}],[\"biden\",{\"1\":{\"65\":2,\"66\":1,\"74\":1}}],[\"bidirectional\",{\"1\":{\"37\":1,\"126\":1,\"167\":1}}],[\"billion\",{\"1\":{\"123\":1,\"167\":1,\"198\":1}}],[\"billions\",{\"1\":{\"25\":1,\"94\":1}}],[\"bilstm\",{\"1\":{\"54\":1,\"59\":1}}],[\"bilingual\",{\"1\":{\"4\":1,\"22\":1,\"23\":1,\"27\":1,\"133\":1,\"146\":1,\"190\":1,\"194\":1,\"197\":1,\"199\":1,\"209\":1,\"228\":1,\"231\":1}}],[\"biggest\",{\"1\":{\"244\":1}}],[\"bigram\",{\"1\":{\"211\":1}}],[\"big\",{\"1\":{\"8\":1,\"146\":2,\"157\":1,\"163\":1}}],[\"baidu\",{\"1\":{\"218\":1}}],[\"bayes\",{\"1\":{\"182\":1}}],[\"banerjee\",{\"1\":{\"221\":1}}],[\"bansal\",{\"1\":{\"175\":1}}],[\"banded\",{\"1\":{\"119\":1}}],[\"batches\",{\"1\":{\"146\":1}}],[\"batch\",{\"1\":{\"113\":1,\"119\":1,\"140\":1,\"146\":2,\"165\":1}}],[\"baevski\",{\"1\":{\"102\":1,\"175\":1}}],[\"bao\",{\"1\":{\"74\":1}}],[\"baobao\",{\"1\":{\"61\":1}}],[\"baoding\",{\"1\":{\"21\":1,\"36\":1}}],[\"baltimore\",{\"1\":{\"50\":1}}],[\"balance\",{\"1\":{\"3\":1,\"109\":1}}],[\"bars\",{\"1\":{\"252\":1}}],[\"bar\",{\"1\":{\"71\":1}}],[\"barrier\",{\"1\":{\"41\":1}}],[\"barriers\",{\"1\":{\"36\":1,\"101\":1}}],[\"bart\",{\"1\":{\"23\":1,\"37\":1,\"112\":1,\"161\":2}}],[\"basis\",{\"1\":{\"43\":1}}],[\"basics\",{\"1\":{\"239\":1}}],[\"basic\",{\"1\":{\"24\":1,\"95\":1,\"110\":1,\"111\":2,\"115\":1,\"239\":1}}],[\"basically\",{\"1\":{\"23\":1,\"208\":1,\"212\":1}}],[\"base\",{\"1\":{\"54\":4,\"58\":3,\"59\":3,\"68\":1,\"97\":1,\"112\":1,\"146\":4,\"164\":1,\"195\":1,\"251\":1,\"252\":1}}],[\"based\",{\"1\":{\"23\":2,\"24\":2,\"35\":1,\"49\":1,\"54\":4,\"61\":1,\"68\":2,\"69\":1,\"71\":2,\"72\":1,\"77\":1,\"81\":1,\"88\":1,\"95\":1,\"96\":2,\"105\":3,\"111\":3,\"115\":1,\"123\":1,\"124\":2,\"137\":1,\"142\":1,\"182\":1,\"208\":3,\"209\":1,\"211\":2,\"212\":2,\"213\":1,\"218\":4,\"219\":1,\"233\":1,\"244\":1,\"245\":1,\"252\":1,\"263\":3,\"269\":1}}],[\"baselines\",{\"1\":{\"54\":1,\"57\":1,\"59\":1,\"98\":1,\"113\":2,\"141\":1,\"146\":1,\"187\":2,\"199\":1,\"256\":1}}],[\"baseline\",{\"0\":{\"195\":1},\"1\":{\"18\":1,\"54\":1,\"71\":1,\"105\":1,\"124\":1,\"139\":1,\"146\":4,\"189\":1,\"194\":1,\"199\":1,\"200\":1,\"251\":1,\"252\":2,\"253\":3,\"254\":2,\"256\":2}}],[\"backpropogation\",{\"1\":{\"146\":1}}],[\"backpropagated\",{\"1\":{\"111\":1}}],[\"background\",{\"0\":{\"78\":1,\"131\":1,\"179\":1},\"1\":{\"130\":1}}],[\"backward\",{\"1\":{\"51\":1}}],[\"backbones\",{\"1\":{\"134\":1}}],[\"backbone\",{\"1\":{\"43\":1,\"111\":1,\"146\":1}}],[\"back\",{\"0\":{\"179\":1,\"257\":1},\"1\":{\"1\":1,\"25\":1,\"36\":1,\"71\":1,\"101\":1,\"130\":1,\"137\":1,\"179\":3,\"183\":1,\"190\":1,\"227\":1,\"233\":1,\"254\":1,\"267\":2,\"271\":1}}],[\"blanks\",{\"1\":{\"227\":1}}],[\"blanchon\",{\"1\":{\"105\":1}}],[\"blended\",{\"1\":{\"122\":1}}],[\"bleurt\",{\"1\":{\"105\":2}}],[\"bleu2vec\",{\"1\":{\"105\":2}}],[\"bleu\",{\"1\":{\"2\":1,\"3\":5,\"5\":2,\"18\":1,\"22\":1,\"25\":5,\"26\":2,\"27\":2,\"29\":2,\"30\":2,\"93\":1,\"105\":2,\"122\":6,\"125\":5,\"126\":2,\"146\":5,\"187\":7,\"200\":2,\"201\":2,\"202\":3,\"209\":5,\"210\":1,\"211\":3,\"212\":2,\"215\":1,\"217\":1,\"218\":11,\"219\":1,\"221\":1,\"239\":2,\"244\":2,\"252\":1,\"253\":4,\"254\":2,\"257\":1,\"258\":1,\"269\":1}}],[\"blob\",{\"1\":{\"221\":1}}],[\"blocks\",{\"1\":{\"238\":1}}],[\"block\",{\"1\":{\"140\":1}}],[\"blomert\",{\"1\":{\"102\":1}}],[\"blog\",{\"1\":{\"0\":1,\"49\":1,\"77\":1,\"115\":1,\"126\":1,\"146\":1,\"165\":1,\"166\":1,\"213\":1,\"228\":1,\"239\":1,\"250\":1}}],[\"blind\",{\"1\":{\"70\":1}}],[\"bpe\",{\"1\":{\"1\":2,\"2\":11,\"5\":2,\"6\":16,\"7\":3,\"25\":1,\"146\":1}}],[\"budem\",{\"1\":{\"125\":1}}],[\"builds\",{\"1\":{\"214\":1}}],[\"build\",{\"1\":{\"110\":1,\"171\":1,\"203\":1,\"263\":1}}],[\"building\",{\"1\":{\"1\":1,\"8\":1,\"43\":1,\"170\":1,\"238\":1}}],[\"built\",{\"1\":{\"105\":1,\"132\":1,\"153\":1,\"172\":1}}],[\"businesses\",{\"1\":{\"41\":2}}],[\"business\",{\"1\":{\"22\":1}}],[\"buy\",{\"1\":{\"3\":2,\"125\":4}}],[\"buying\",{\"1\":{\"3\":1}}],[\"bulk\",{\"1\":{\"3\":1}}],[\"but\",{\"1\":{\"1\":2,\"2\":2,\"5\":1,\"27\":2,\"30\":1,\"43\":3,\"57\":1,\"59\":1,\"65\":1,\"71\":7,\"72\":1,\"93\":3,\"94\":2,\"96\":1,\"109\":3,\"115\":1,\"120\":1,\"124\":2,\"125\":2,\"126\":2,\"130\":1,\"132\":1,\"142\":1,\"175\":1,\"195\":1,\"200\":2,\"203\":1,\"206\":1,\"212\":1,\"218\":3,\"219\":1,\"225\":1,\"228\":1,\"229\":1,\"231\":2,\"233\":2,\"238\":1,\"245\":1,\"251\":1,\"263\":2}}],[\"bytedance\",{\"1\":{\"22\":1,\"36\":1,\"93\":1}}],[\"byte\",{\"1\":{\"1\":1,\"5\":1,\"146\":1}}],[\"by\",{\"0\":{\"170\":1,\"172\":1},\"1\":{\"1\":3,\"2\":2,\"3\":1,\"5\":1,\"6\":1,\"21\":2,\"22\":4,\"23\":1,\"24\":5,\"25\":3,\"30\":1,\"31\":1,\"34\":2,\"37\":2,\"41\":1,\"42\":4,\"43\":3,\"44\":1,\"49\":1,\"51\":3,\"54\":4,\"55\":2,\"58\":1,\"65\":1,\"66\":1,\"67\":1,\"68\":4,\"71\":1,\"77\":2,\"82\":1,\"84\":1,\"86\":1,\"93\":5,\"94\":2,\"95\":2,\"96\":2,\"97\":1,\"98\":1,\"100\":3,\"101\":1,\"105\":1,\"110\":1,\"111\":1,\"112\":1,\"113\":1,\"114\":2,\"119\":1,\"122\":2,\"123\":3,\"124\":1,\"125\":1,\"130\":1,\"133\":2,\"134\":2,\"137\":1,\"146\":3,\"151\":1,\"155\":1,\"156\":1,\"157\":1,\"160\":1,\"170\":1,\"172\":1,\"175\":1,\"179\":3,\"181\":1,\"183\":1,\"184\":1,\"194\":2,\"200\":1,\"201\":1,\"202\":5,\"203\":3,\"208\":1,\"209\":1,\"211\":1,\"212\":12,\"215\":1,\"216\":1,\"219\":1,\"221\":1,\"224\":1,\"226\":2,\"228\":2,\"231\":2,\"232\":1,\"233\":4,\"239\":3,\"240\":3,\"241\":1,\"242\":2,\"244\":3,\"245\":1,\"246\":1,\"252\":1,\"253\":2,\"254\":1,\"256\":1,\"263\":2,\"264\":3,\"266\":1,\"267\":1,\"269\":1,\"270\":1}}],[\"beat\",{\"1\":{\"257\":1}}],[\"bearing\",{\"1\":{\"229\":1}}],[\"beam\",{\"1\":{\"156\":2,\"164\":1,\"184\":1,\"252\":6,\"253\":5}}],[\"beautiful\",{\"1\":{\"101\":1}}],[\"beacon\",{\"1\":{\"65\":1,\"74\":1}}],[\"behaviour\",{\"1\":{\"172\":1}}],[\"behavioral\",{\"1\":{\"221\":1}}],[\"behavior\",{\"1\":{\"120\":1}}],[\"behaves\",{\"1\":{\"71\":1,\"172\":1}}],[\"behind\",{\"0\":{\"253\":1},\"1\":{\"41\":1,\"66\":1,\"67\":1,\"109\":1,\"130\":1,\"219\":1,\"232\":1,\"233\":1}}],[\"besacier\",{\"1\":{\"105\":1}}],[\"besides\",{\"1\":{\"51\":1,\"142\":1,\"244\":2,\"258\":1}}],[\"best\",{\"1\":{\"0\":1,\"1\":5,\"2\":3,\"3\":2,\"6\":2,\"8\":1,\"23\":1,\"93\":1,\"120\":1,\"122\":1,\"126\":1,\"171\":1,\"173\":1,\"189\":1,\"215\":1,\"229\":1,\"233\":2,\"244\":1,\"258\":1,\"269\":1}}],[\"believe\",{\"1\":{\"101\":1,\"126\":1}}],[\"believed\",{\"1\":{\"93\":2,\"251\":1}}],[\"believes\",{\"1\":{\"33\":1,\"71\":1}}],[\"belonging\",{\"1\":{\"146\":1}}],[\"belong\",{\"1\":{\"114\":1}}],[\"belongs\",{\"1\":{\"50\":2,\"93\":1}}],[\"below\",{\"1\":{\"43\":4,\"50\":1,\"99\":1,\"113\":1,\"114\":1,\"120\":1,\"122\":1,\"124\":1,\"125\":1,\"126\":1,\"130\":1,\"131\":1,\"154\":1,\"156\":1,\"163\":1,\"165\":1,\"209\":1,\"212\":3,\"213\":2,\"216\":1,\"217\":2,\"218\":3,\"225\":1,\"231\":1,\"244\":1,\"245\":1,\"265\":1,\"268\":1}}],[\"beginning\",{\"1\":{\"35\":1,\"36\":1,\"71\":1,\"195\":1}}],[\"beijing\",{\"1\":{\"24\":2,\"221\":1}}],[\"beings\",{\"1\":{\"24\":1}}],[\"being\",{\"1\":{\"3\":1,\"8\":1,\"40\":1,\"66\":1,\"96\":1,\"225\":2,\"226\":1,\"232\":1,\"245\":1}}],[\"beneficial\",{\"1\":{\"202\":1,\"253\":1}}],[\"benefits\",{\"1\":{\"35\":1,\"93\":1,\"146\":1,\"212\":1}}],[\"benefit\",{\"1\":{\"3\":1,\"93\":1,\"95\":1,\"188\":1,\"244\":1,\"257\":1}}],[\"ben\",{\"1\":{\"137\":1}}],[\"benn\",{\"1\":{\"131\":1}}],[\"benchmarks\",{\"0\":{\"26\":1},\"1\":{\"86\":1,\"101\":1,\"146\":1,\"198\":1}}],[\"benchmark\",{\"0\":{\"99\":1},\"1\":{\"18\":1,\"93\":1,\"256\":1}}],[\"berkeley\",{\"1\":{\"36\":1}}],[\"bertscore\",{\"0\":{\"210\":1},\"1\":{\"105\":2,\"210\":3,\"211\":1,\"212\":5,\"213\":3,\"215\":1,\"217\":1,\"218\":12,\"219\":3,\"220\":1,\"221\":1},\"2\":{\"223\":1}}],[\"bertbase\",{\"1\":{\"54\":1}}],[\"bertrand\",{\"1\":{\"21\":1}}],[\"bert或者\",{\"1\":{\"12\":1}}],[\"bert等\",{\"1\":{\"12\":1}}],[\"bert\",{\"0\":{\"12\":1,\"77\":1,\"81\":1,\"84\":1,\"170\":1},\"1\":{\"15\":6,\"16\":3,\"17\":2,\"18\":4,\"22\":2,\"23\":3,\"26\":2,\"37\":2,\"43\":2,\"51\":1,\"54\":16,\"55\":1,\"58\":2,\"59\":3,\"70\":1,\"71\":1,\"77\":1,\"78\":4,\"79\":2,\"80\":3,\"81\":2,\"85\":1,\"86\":1,\"87\":1,\"88\":2,\"89\":2,\"105\":3,\"116\":1,\"151\":1,\"153\":1,\"167\":1,\"171\":1,\"172\":1,\"212\":8,\"220\":1,\"221\":1,\"247\":1},\"2\":{\"20\":1,\"91\":1,\"177\":1,\"223\":1}}],[\"berlin\",{\"1\":{\"9\":1}}],[\"been\",{\"1\":{\"3\":1,\"22\":2,\"25\":2,\"27\":3,\"30\":3,\"41\":1,\"78\":1,\"84\":1,\"93\":2,\"94\":4,\"96\":1,\"100\":2,\"105\":1,\"119\":1,\"171\":1,\"230\":1,\"232\":2,\"241\":1,\"250\":1,\"251\":1}}],[\"before\",{\"1\":{\"3\":1,\"69\":1,\"70\":1,\"71\":1,\"120\":4,\"171\":1,\"194\":1,\"225\":1,\"227\":1,\"228\":1,\"232\":1}}],[\"become\",{\"1\":{\"21\":1,\"23\":2,\"24\":1,\"36\":2,\"218\":1,\"228\":1,\"245\":1,\"269\":1}}],[\"becomes\",{\"1\":{\"2\":1,\"24\":2,\"34\":1,\"95\":1,\"146\":1}}],[\"because\",{\"1\":{\"1\":1,\"50\":1,\"68\":1,\"71\":6,\"79\":1,\"119\":1,\"120\":1,\"123\":1,\"126\":1,\"172\":1,\"194\":1,\"197\":1,\"200\":1,\"210\":1,\"212\":2,\"218\":3,\"253\":1}}],[\"better\",{\"0\":{\"5\":1,\"7\":1,\"170\":1},\"1\":{\"1\":4,\"2\":1,\"6\":1,\"7\":1,\"8\":2,\"43\":1,\"51\":2,\"54\":1,\"58\":1,\"60\":1,\"66\":1,\"68\":1,\"71\":1,\"93\":1,\"95\":2,\"100\":1,\"105\":1,\"109\":1,\"112\":1,\"126\":3,\"130\":1,\"146\":1,\"187\":1,\"194\":1,\"200\":1,\"216\":2,\"217\":1,\"218\":1,\"225\":3,\"227\":1,\"244\":1,\"252\":1}}],[\"between\",{\"1\":{\"1\":2,\"2\":1,\"3\":6,\"23\":1,\"24\":4,\"27\":1,\"33\":3,\"34\":2,\"35\":1,\"41\":1,\"43\":1,\"49\":2,\"50\":1,\"51\":4,\"58\":1,\"71\":1,\"80\":1,\"82\":1,\"86\":1,\"93\":4,\"94\":1,\"95\":1,\"98\":2,\"101\":1,\"105\":2,\"109\":3,\"110\":1,\"113\":2,\"114\":1,\"120\":1,\"123\":1,\"124\":3,\"125\":1,\"126\":1,\"136\":1,\"146\":2,\"152\":1,\"153\":1,\"194\":1,\"196\":1,\"201\":2,\"209\":1,\"210\":1,\"215\":1,\"216\":6,\"221\":1,\"225\":3,\"226\":1,\"228\":2,\"244\":2,\"245\":2,\"263\":2,\"266\":2,\"267\":1,\"269\":1,\"270\":1}}],[\"be\",{\"1\":{\"1\":9,\"2\":1,\"3\":2,\"6\":1,\"8\":1,\"22\":4,\"23\":2,\"24\":9,\"25\":1,\"26\":1,\"33\":1,\"34\":1,\"35\":4,\"41\":1,\"42\":3,\"43\":1,\"45\":1,\"50\":1,\"51\":4,\"53\":1,\"65\":2,\"66\":1,\"71\":3,\"72\":1,\"79\":1,\"82\":2,\"83\":2,\"84\":2,\"93\":4,\"95\":1,\"96\":1,\"100\":1,\"105\":1,\"109\":2,\"110\":2,\"111\":4,\"112\":3,\"113\":2,\"115\":2,\"119\":1,\"120\":2,\"121\":2,\"122\":1,\"123\":1,\"124\":2,\"125\":4,\"126\":1,\"130\":1,\"141\":1,\"142\":2,\"146\":2,\"153\":1,\"156\":1,\"175\":1,\"182\":1,\"187\":1,\"194\":1,\"195\":2,\"201\":1,\"202\":1,\"203\":1,\"208\":1,\"212\":5,\"215\":1,\"216\":2,\"218\":2,\"219\":1,\"224\":1,\"225\":3,\"226\":1,\"227\":2,\"228\":2,\"231\":4,\"232\":2,\"233\":1,\"240\":1,\"242\":1,\"244\":1,\"251\":4,\"253\":1,\"257\":1,\"259\":1,\"263\":2,\"264\":1,\"265\":1,\"266\":1,\"268\":1,\"269\":2}}],[\"nuanced\",{\"1\":{\"228\":1}}],[\"num\",{\"1\":{\"109\":1}}],[\"numbers\",{\"1\":{\"226\":3,\"232\":1,\"269\":1}}],[\"number\",{\"1\":{\"3\":1,\"33\":1,\"71\":2,\"96\":1,\"110\":2,\"112\":5,\"119\":1,\"123\":1,\"172\":1,\"212\":2,\"213\":1,\"217\":2,\"226\":2,\"231\":1,\"239\":1,\"242\":1}}],[\"nákupného\",{\"1\":{\"125\":1}}],[\"n−1\",{\"1\":{\"109\":1}}],[\"nmt\",{\"1\":{\"109\":10,\"110\":1,\"111\":1,\"113\":1,\"122\":2,\"126\":1,\"131\":2,\"132\":1,\"133\":1,\"135\":1,\"142\":1,\"146\":3,\"178\":2,\"181\":2,\"188\":1,\"190\":2,\"203\":2,\"218\":1,\"244\":1}}],[\"nist\",{\"1\":{\"244\":1}}],[\"nistzh\",{\"1\":{\"187\":1}}],[\"nisten\",{\"1\":{\"186\":2,\"187\":1}}],[\"niki\",{\"1\":{\"102\":1}}],[\"nienke\",{\"1\":{\"102\":1}}],[\"nils\",{\"1\":{\"89\":1}}],[\"nvidia\",{\"0\":{\"165\":1},\"1\":{\"97\":1,\"157\":1}}],[\"n\",{\"1\":{\"96\":2,\"102\":1,\"105\":1,\"109\":5,\"119\":1,\"120\":2,\"122\":1,\"175\":3,\"209\":2,\"211\":6,\"218\":2,\"219\":1,\"240\":2}}],[\"nl<\",{\"1\":{\"200\":1}}],[\"nli\",{\"0\":{\"86\":1,\"87\":1},\"1\":{\"87\":1}}],[\"nl\",{\"0\":{\"30\":1},\"1\":{\"25\":1,\"27\":1,\"35\":3,\"97\":1,\"114\":1,\"200\":2}}],[\"nlg\",{\"1\":{\"23\":1},\"2\":{\"128\":1}}],[\"nlu\",{\"1\":{\"22\":1,\"23\":1}}],[\"nlp\",{\"0\":{\"40\":1,\"151\":1,\"275\":1},\"1\":{\"0\":2,\"15\":1,\"23\":3,\"41\":5,\"45\":4,\"46\":1,\"78\":1,\"121\":2,\"126\":3,\"146\":1,\"149\":1},\"2\":{\"47\":1,\"75\":1,\"90\":1,\"168\":1}}],[\"na\",{\"1\":{\"125\":4}}],[\"najesť\",{\"1\":{\"125\":1}}],[\"name\",{\"1\":{\"67\":3,\"72\":1,\"225\":1}}],[\"named\",{\"1\":{\"43\":1,\"259\":1}}],[\"namely\",{\"1\":{\"2\":1,\"49\":1,\"59\":1,\"266\":1}}],[\"naacl\",{\"1\":{\"37\":1,\"143\":1}}],[\"narrow\",{\"1\":{\"81\":1,\"130\":1}}],[\"narrowing\",{\"1\":{\"33\":1}}],[\"narrows\",{\"1\":{\"33\":2,\"35\":1}}],[\"national\",{\"1\":{\"221\":4}}],[\"nations\",{\"1\":{\"101\":1}}],[\"native\",{\"1\":{\"24\":1,\"95\":1,\"125\":1,\"225\":1,\"233\":1}}],[\"natural\",{\"0\":{\"64\":1,\"149\":1},\"1\":{\"22\":2,\"37\":2,\"41\":1,\"64\":1,\"66\":1,\"78\":1,\"89\":1,\"93\":1,\"94\":1,\"95\":1,\"96\":1,\"105\":2,\"119\":1,\"122\":1,\"124\":3,\"131\":1,\"134\":2,\"151\":1,\"188\":1,\"214\":1,\"239\":1,\"251\":1,\"264\":1}}],[\"naturally\",{\"1\":{\"21\":1,\"24\":1}}],[\"nanjing\",{\"1\":{\"21\":1}}],[\"ne\",{\"1\":{\"256\":1,\"257\":2}}],[\"nepali\",{\"1\":{\"256\":1,\"257\":1}}],[\"net\",{\"1\":{\"221\":1}}],[\"networks\",{\"1\":{\"41\":2,\"89\":1,\"119\":1,\"146\":2,\"225\":1,\"226\":1,\"232\":3,\"235\":2,\"238\":1,\"251\":1}}],[\"network\",{\"1\":{\"21\":1,\"51\":2,\"54\":1,\"60\":1,\"112\":1,\"130\":1,\"136\":1,\"137\":3,\"140\":1,\"146\":9,\"172\":3,\"215\":1,\"216\":2,\"226\":4,\"227\":1,\"228\":4,\"231\":1,\"232\":2,\"233\":6,\"239\":1,\"240\":1,\"242\":1},\"2\":{\"76\":1,\"148\":1}}],[\"nebudeme\",{\"1\":{\"125\":1}}],[\"neubig\",{\"1\":{\"116\":1}}],[\"neuron\",{\"1\":{\"102\":1}}],[\"neuroimaging\",{\"1\":{\"94\":2}}],[\"neural\",{\"0\":{\"108\":1,\"146\":1,\"178\":1,\"194\":1,\"224\":1,\"238\":1,\"250\":1},\"1\":{\"0\":1,\"9\":2,\"21\":1,\"37\":5,\"41\":2,\"72\":1,\"89\":1,\"102\":2,\"109\":2,\"112\":1,\"116\":1,\"119\":1,\"141\":1,\"146\":1,\"164\":1,\"167\":1,\"175\":1,\"178\":1,\"191\":1,\"203\":1,\"210\":1,\"214\":1,\"218\":1,\"221\":4,\"224\":1,\"225\":1,\"226\":1,\"227\":1,\"228\":4,\"231\":1,\"232\":4,\"233\":1,\"235\":4,\"238\":2,\"239\":1,\"246\":1,\"247\":2,\"251\":2,\"259\":1,\"260\":1,\"263\":3},\"2\":{\"76\":1}}],[\"neat\",{\"1\":{\"109\":1}}],[\"nearly\",{\"1\":{\"119\":1,\"202\":1}}],[\"near\",{\"1\":{\"101\":1,\"225\":1}}],[\"nearest\",{\"1\":{\"35\":1,\"83\":1}}],[\"neither\",{\"1\":{\"69\":1}}],[\"nei\",{\"1\":{\"66\":1,\"69\":4,\"71\":1}}],[\"neighborhood\",{\"1\":{\"245\":1}}],[\"neighbors\",{\"1\":{\"83\":1}}],[\"neighbor\",{\"1\":{\"24\":1}}],[\"negatively\",{\"1\":{\"43\":1}}],[\"negative\",{\"1\":{\"43\":2,\"196\":4,\"208\":1}}],[\"ner\",{\"1\":{\"43\":2}}],[\"nevertheless\",{\"1\":{\"82\":1,\"125\":1}}],[\"never\",{\"1\":{\"25\":1,\"27\":1,\"35\":1,\"146\":1,\"228\":1,\"233\":1}}],[\"newsde\",{\"1\":{\"187\":1}}],[\"news\",{\"1\":{\"30\":2,\"65\":1,\"123\":3,\"178\":1,\"186\":2,\"189\":1,\"219\":1,\"228\":2}}],[\"new\",{\"1\":{\"3\":1,\"21\":2,\"23\":2,\"24\":3,\"25\":1,\"36\":2,\"42\":1,\"87\":1,\"93\":2,\"94\":2,\"95\":3,\"98\":1,\"101\":4,\"111\":2,\"120\":2,\"121\":1,\"124\":2,\"146\":5,\"153\":1,\"214\":1,\"215\":1,\"219\":1,\"227\":2,\"231\":1,\"232\":1,\"233\":2,\"240\":1,\"251\":1,\"252\":2,\"263\":1,\"265\":1}}],[\"next\",{\"1\":{\"1\":1,\"2\":1,\"22\":1,\"36\":1,\"42\":1,\"71\":1,\"93\":1,\"95\":1,\"96\":1,\"123\":2,\"134\":1,\"139\":1,\"241\":1}}],[\"needs\",{\"1\":{\"3\":3,\"22\":1,\"109\":1,\"151\":1,\"155\":1,\"265\":1}}],[\"needed\",{\"1\":{\"2\":1,\"226\":1}}],[\"need\",{\"1\":{\"1\":1,\"22\":1,\"37\":1,\"68\":1,\"93\":1,\"102\":1,\"109\":2,\"119\":2,\"120\":3,\"127\":1,\"133\":2,\"146\":1,\"152\":1,\"155\":1,\"156\":1,\"167\":1,\"172\":1,\"175\":1,\"209\":1,\"225\":1,\"226\":1,\"234\":1,\"247\":1,\"264\":1}}],[\"necessary\",{\"1\":{\"1\":2,\"24\":2,\"43\":1,\"49\":1}}],[\"noam\",{\"1\":{\"102\":1}}],[\"novelty\",{\"0\":{\"120\":1},\"1\":{\"120\":1}}],[\"novel\",{\"1\":{\"101\":1,\"109\":1,\"120\":1,\"124\":2,\"126\":1,\"142\":1,\"233\":1,\"239\":1,\"270\":1}}],[\"noisy\",{\"0\":{\"254\":1},\"1\":{\"252\":2,\"254\":8,\"256\":4,\"257\":1,\"258\":1,\"259\":1,\"266\":1}}],[\"noisier\",{\"1\":{\"93\":1}}],[\"noise\",{\"1\":{\"42\":2,\"140\":1,\"228\":1,\"253\":1,\"254\":3,\"258\":3,\"259\":1,\"266\":1,\"267\":1}}],[\"nonlinear\",{\"1\":{\"212\":1}}],[\"non\",{\"0\":{\"183\":1,\"201\":1},\"1\":{\"69\":1,\"80\":1,\"157\":1,\"178\":1,\"179\":1,\"181\":2,\"183\":1,\"186\":2,\"187\":3,\"188\":2,\"189\":1,\"190\":1,\"194\":2,\"201\":3}}],[\"nonetheless\",{\"1\":{\"2\":1,\"65\":1}}],[\"noun\",{\"1\":{\"67\":5}}],[\"node\",{\"1\":{\"51\":6,\"55\":1}}],[\"nodes\",{\"1\":{\"51\":4}}],[\"norouzi\",{\"1\":{\"221\":1}}],[\"norm\",{\"1\":{\"195\":1}}],[\"normal\",{\"1\":{\"93\":1,\"172\":1,\"254\":2}}],[\"normalization\",{\"1\":{\"140\":1,\"146\":1,\"195\":1,\"242\":1}}],[\"normalizing\",{\"1\":{\"84\":1}}],[\"normalized\",{\"1\":{\"35\":1,\"97\":1,\"216\":1}}],[\"north\",{\"1\":{\"36\":1}}],[\"no\",{\"1\":{\"1\":1,\"2\":1,\"23\":2,\"71\":1,\"84\":1,\"100\":1,\"102\":1,\"113\":1,\"120\":1,\"124\":1,\"171\":1,\"215\":1,\"218\":1,\"225\":1,\"245\":1,\"264\":1}}],[\"notably\",{\"1\":{\"242\":1}}],[\"noted\",{\"1\":{\"219\":1}}],[\"note\",{\"1\":{\"35\":1,\"66\":1,\"82\":1,\"111\":1,\"113\":1,\"228\":1,\"242\":1,\"254\":1}}],[\"notícias\",{\"1\":{\"30\":1}}],[\"notulen\",{\"1\":{\"30\":1}}],[\"noting\",{\"1\":{\"27\":1,\"98\":1}}],[\"noticeable\",{\"1\":{\"245\":1}}],[\"noticed\",{\"1\":{\"122\":1,\"125\":1,\"225\":1}}],[\"notice\",{\"1\":{\"3\":2}}],[\"not\",{\"0\":{\"27\":1},\"1\":{\"1\":5,\"2\":4,\"3\":2,\"5\":1,\"8\":2,\"23\":2,\"24\":1,\"27\":6,\"29\":1,\"30\":1,\"35\":1,\"41\":1,\"42\":1,\"43\":2,\"44\":2,\"54\":2,\"57\":1,\"65\":1,\"66\":1,\"71\":12,\"72\":5,\"78\":1,\"79\":1,\"80\":1,\"82\":1,\"93\":3,\"98\":2,\"105\":1,\"109\":2,\"112\":1,\"113\":2,\"115\":1,\"120\":2,\"123\":1,\"124\":2,\"125\":1,\"126\":2,\"132\":1,\"133\":1,\"141\":1,\"142\":2,\"152\":5,\"170\":3,\"171\":1,\"172\":1,\"175\":2,\"178\":1,\"194\":1,\"195\":1,\"206\":1,\"212\":1,\"218\":4,\"225\":2,\"233\":1,\"244\":1,\"245\":1,\"251\":2,\"253\":1,\"254\":1,\"257\":1,\"263\":2,\"266\":1,\"268\":1,\"269\":3}}],[\"nowadays\",{\"1\":{\"95\":1}}],[\"now\",{\"1\":{\"1\":3,\"3\":2,\"30\":1,\"71\":1,\"95\":1,\"111\":2,\"112\":1,\"124\":1,\"159\":1,\"203\":1,\"230\":1,\"232\":1,\"269\":1}}],[\"v1\",{\"1\":{\"221\":1}}],[\"v100\",{\"1\":{\"97\":1}}],[\"v\",{\"1\":{\"216\":2,\"221\":1,\"240\":1}}],[\"víkend\",{\"1\":{\"125\":1}}],[\"vs\",{\"0\":{\"175\":1},\"1\":{\"30\":1,\"105\":1}}],[\"veľmi\",{\"1\":{\"125\":1}}],[\"večeru\",{\"1\":{\"125\":1}}],[\"veteran\",{\"1\":{\"95\":1}}],[\"vectors\",{\"1\":{\"97\":1,\"196\":2,\"232\":1,\"268\":2}}],[\"vector\",{\"0\":{\"34\":1,\"35\":1},\"1\":{\"24\":1,\"33\":2,\"34\":1,\"35\":3,\"81\":1,\"105\":3,\"140\":1,\"196\":1,\"212\":2,\"216\":4,\"232\":1,\"233\":2,\"240\":2,\"268\":1}}],[\"verfies\",{\"1\":{\"146\":1}}],[\"version\",{\"1\":{\"247\":1}}],[\"versus\",{\"1\":{\"94\":2,\"218\":1}}],[\"versatile\",{\"0\":{\"7\":1},\"1\":{\"7\":1,\"25\":1}}],[\"verafication\",{\"2\":{\"76\":1}}],[\"veracity\",{\"1\":{\"65\":1,\"66\":2,\"68\":1,\"69\":4,\"71\":1,\"73\":2}}],[\"verbs\",{\"1\":{\"67\":2}}],[\"verifiction\",{\"1\":{\"232\":1}}],[\"verification\",{\"0\":{\"64\":1},\"1\":{\"65\":3,\"66\":1,\"68\":1,\"71\":1,\"72\":1,\"74\":1,\"174\":1}}],[\"verified\",{\"1\":{\"93\":1}}],[\"verifies\",{\"1\":{\"71\":1}}],[\"verifying\",{\"1\":{\"73\":1}}],[\"verify\",{\"1\":{\"64\":1,\"66\":1,\"68\":1,\"71\":1,\"72\":1,\"73\":1,\"97\":1}}],[\"vergadering\",{\"1\":{\"30\":1}}],[\"very\",{\"1\":{\"1\":1,\"24\":2,\"71\":1,\"95\":1,\"109\":3,\"115\":2,\"124\":2,\"125\":2,\"130\":1,\"171\":1,\"218\":1,\"228\":1,\"250\":1,\"251\":1,\"256\":1,\"269\":2,\"270\":1}}],[\"varsha\",{\"1\":{\"105\":1,\"221\":1}}],[\"varitey\",{\"1\":{\"124\":1}}],[\"variant\",{\"1\":{\"259\":1}}],[\"variants\",{\"1\":{\"54\":2,\"78\":1}}],[\"variance\",{\"1\":{\"94\":1,\"105\":1}}],[\"variational\",{\"1\":{\"84\":1,\"182\":1},\"2\":{\"193\":1}}],[\"variable\",{\"1\":{\"69\":2,\"84\":1,\"119\":1,\"152\":1,\"181\":1,\"183\":1,\"184\":1},\"2\":{\"193\":1}}],[\"variables\",{\"1\":{\"42\":2,\"208\":1}}],[\"various\",{\"0\":{\"121\":1},\"1\":{\"53\":1,\"94\":1,\"95\":1,\"101\":1,\"109\":1,\"119\":1,\"146\":1,\"225\":1}}],[\"variety\",{\"1\":{\"49\":1,\"85\":1,\"88\":1,\"121\":1,\"126\":1,\"227\":1,\"228\":1}}],[\"varying\",{\"1\":{\"43\":1}}],[\"validate\",{\"1\":{\"100\":1}}],[\"validation\",{\"1\":{\"43\":1,\"258\":1}}],[\"valued\",{\"1\":{\"66\":1}}],[\"values\",{\"1\":{\"42\":1,\"96\":1,\"125\":1,\"211\":1,\"212\":2,\"240\":2,\"258\":1}}],[\"value\",{\"1\":{\"3\":1,\"112\":1,\"156\":1,\"258\":1}}],[\"valuable\",{\"1\":{\"1\":1}}],[\"vaswani\",{\"1\":{\"37\":1,\"102\":1,\"167\":1,\"175\":1,\"247\":1}}],[\"vastly\",{\"1\":{\"244\":1}}],[\"vast\",{\"1\":{\"23\":1,\"227\":1}}],[\"vanilla\",{\"1\":{\"111\":1}}],[\"van\",{\"1\":{\"30\":2,\"102\":1}}],[\"victorzhou\",{\"1\":{\"235\":1}}],[\"victor\",{\"1\":{\"235\":3,\"247\":1}}],[\"victim\",{\"1\":{\"42\":1}}],[\"video\",{\"1\":{\"125\":2}}],[\"videohry\",{\"1\":{\"125\":1}}],[\"videos\",{\"1\":{\"93\":1}}],[\"vi\",{\"1\":{\"114\":1}}],[\"vietnam\",{\"1\":{\"114\":1}}],[\"vietnamese\",{\"1\":{\"114\":1}}],[\"view\",{\"1\":{\"3\":1}}],[\"vision\",{\"1\":{\"131\":1,\"134\":1,\"151\":2}}],[\"visiting\",{\"1\":{\"211\":1}}],[\"visit\",{\"1\":{\"95\":1,\"123\":1}}],[\"visited\",{\"1\":{\"21\":1}}],[\"visually\",{\"1\":{\"142\":1,\"264\":1}}],[\"visualizing\",{\"1\":{\"203\":1}}],[\"visualization\",{\"0\":{\"203\":1},\"1\":{\"100\":1,\"174\":1}}],[\"visualizations\",{\"0\":{\"100\":1},\"1\":{\"101\":1}}],[\"visualizes\",{\"1\":{\"245\":1}}],[\"visualized\",{\"1\":{\"142\":1}}],[\"visualize\",{\"1\":{\"71\":1,\"174\":1}}],[\"visual\",{\"0\":{\"130\":1},\"1\":{\"94\":3,\"130\":1,\"131\":1,\"132\":2,\"134\":3,\"136\":1,\"137\":5,\"140\":2,\"142\":1},\"2\":{\"145\":1}}],[\"via\",{\"1\":{\"0\":1,\"81\":1,\"171\":1,\"182\":1,\"240\":1}}],[\"von\",{\"1\":{\"93\":1}}],[\"voix\",{\"1\":{\"31\":3}}],[\"voice\",{\"1\":{\"31\":1}}],[\"volctrans\",{\"1\":{\"22\":1,\"36\":1,\"165\":1,\"166\":1}}],[\"volume\",{\"1\":{\"9\":2,\"94\":1,\"102\":1,\"105\":1}}],[\"volt\",{\"0\":{\"3\":1,\"4\":1},\"1\":{\"0\":2,\"1\":14,\"2\":2,\"3\":2,\"4\":1,\"5\":3,\"6\":3,\"7\":5,\"8\":3}}],[\"vocabularization\",{\"1\":{\"3\":1}}],[\"vocabularies\",{\"0\":{\"0\":1,\"5\":1},\"1\":{\"1\":13,\"2\":5,\"3\":2}}],[\"vocabulary\",{\"1\":{\"0\":3,\"1\":22,\"2\":7,\"3\":13,\"5\":2,\"6\":2,\"8\":1,\"25\":1,\"109\":1,\"146\":1,\"221\":1},\"2\":{\"11\":1}}],[\"euclidean\",{\"1\":{\"216\":1}}],[\"european\",{\"1\":{\"9\":1,\"95\":1}}],[\"ej\",{\"1\":{\"216\":1}}],[\"error\",{\"1\":{\"175\":2,\"216\":1}}],[\"errors\",{\"1\":{\"171\":1,\"251\":1}}],[\"erase\",{\"1\":{\"44\":1,\"156\":1}}],[\"eger\",{\"1\":{\"105\":1}}],[\"eight\",{\"1\":{\"93\":1,\"217\":1}}],[\"either\",{\"1\":{\"54\":2,\"71\":1,\"134\":1}}],[\"essentially\",{\"1\":{\"197\":1,\"228\":2}}],[\"essential\",{\"1\":{\"146\":1,\"188\":1}}],[\"essentials\",{\"1\":{\"65\":1}}],[\"es\",{\"1\":{\"97\":1,\"200\":1}}],[\"especially\",{\"1\":{\"57\":1,\"60\":1,\"100\":1,\"113\":1,\"122\":1,\"130\":1,\"146\":1,\"170\":1,\"200\":1,\"218\":1,\"234\":1,\"244\":1,\"245\":1,\"259\":1}}],[\"estimator\",{\"1\":{\"105\":3,\"216\":2,\"217\":2}}],[\"estimation\",{\"1\":{\"105\":2,\"203\":1,\"218\":2}}],[\"estimate\",{\"1\":{\"42\":1,\"182\":1}}],[\"establishes\",{\"1\":{\"66\":1,\"94\":1}}],[\"established\",{\"1\":{\"22\":1,\"36\":1,\"93\":1}}],[\"establish\",{\"1\":{\"41\":1}}],[\"establishment\",{\"1\":{\"36\":1}}],[\"est\",{\"1\":{\"31\":3}}],[\"eog\",{\"1\":{\"54\":1}}],[\"edu\",{\"1\":{\"221\":2,\"229\":1}}],[\"education\",{\"1\":{\"37\":1}}],[\"edit\",{\"1\":{\"215\":1}}],[\"edible\",{\"1\":{\"71\":1,\"72\":1}}],[\"edge\",{\"1\":{\"51\":5}}],[\"edges\",{\"1\":{\"51\":3}}],[\"elbo\",{\"1\":{\"182\":1,\"184\":1}}],[\"ellaborate\",{\"1\":{\"112\":1}}],[\"elloumi\",{\"1\":{\"105\":1}}],[\"elia\",{\"1\":{\"102\":1}}],[\"elmo\",{\"1\":{\"89\":1}}],[\"elegant\",{\"1\":{\"137\":1}}],[\"elevates\",{\"1\":{\"130\":1,\"143\":1}}],[\"element\",{\"1\":{\"100\":1,\"216\":2,\"238\":1}}],[\"elements\",{\"1\":{\"1\":1,\"8\":1,\"96\":1}}],[\"election\",{\"1\":{\"66\":1}}],[\"eldersburg\",{\"1\":{\"50\":3}}],[\"e\",{\"1\":{\"50\":2,\"51\":2,\"54\":1,\"71\":1,\"84\":1,\"97\":1,\"105\":2,\"125\":1,\"178\":1,\"187\":4,\"196\":3,\"216\":6,\"218\":3,\"225\":1,\"227\":2,\"232\":1,\"244\":3,\"250\":2,\"253\":1,\"266\":1,\"267\":1}}],[\"eval\",{\"1\":{\"221\":1}}],[\"evaluations\",{\"1\":{\"121\":1}}],[\"evaluation\",{\"0\":{\"105\":1,\"121\":1,\"173\":1,\"207\":1,\"208\":1,\"209\":1},\"1\":{\"54\":1,\"105\":11,\"124\":1,\"125\":1,\"186\":1,\"198\":1,\"206\":1,\"208\":5,\"209\":2,\"210\":2,\"212\":1,\"213\":7,\"214\":2,\"215\":3,\"217\":4,\"218\":4,\"219\":5,\"221\":3},\"2\":{\"107\":1,\"223\":1}}],[\"evaluating\",{\"1\":{\"43\":1,\"105\":2,\"221\":1}}],[\"evaluates\",{\"1\":{\"218\":1,\"244\":1}}],[\"evaluated\",{\"1\":{\"42\":1,\"43\":5,\"70\":1,\"113\":1,\"121\":2,\"124\":1,\"218\":1}}],[\"evaluate\",{\"1\":{\"41\":1,\"53\":1,\"57\":1,\"58\":1,\"70\":1,\"113\":1,\"124\":1,\"139\":1,\"206\":1,\"208\":1,\"215\":2,\"218\":2,\"219\":1}}],[\"evidences\",{\"0\":{\"68\":1},\"1\":{\"66\":2}}],[\"evidence\",{\"1\":{\"42\":1,\"45\":1,\"66\":2,\"68\":5,\"71\":17,\"72\":5,\"94\":2,\"95\":1,\"100\":1,\"182\":1}}],[\"ever\",{\"1\":{\"232\":1}}],[\"everything\",{\"1\":{\"130\":1,\"228\":1}}],[\"everyone\",{\"1\":{\"36\":1}}],[\"every\",{\"1\":{\"2\":2,\"3\":1,\"30\":1,\"95\":2,\"101\":1,\"124\":1,\"146\":1,\"232\":2}}],[\"evening\",{\"1\":{\"95\":1}}],[\"eventually\",{\"1\":{\"69\":1,\"70\":1,\"71\":2}}],[\"event\",{\"1\":{\"41\":1}}],[\"even\",{\"1\":{\"1\":2,\"24\":1,\"25\":1,\"71\":4,\"78\":2,\"93\":1,\"98\":1,\"111\":1,\"120\":1,\"121\":1,\"122\":1,\"123\":1,\"126\":2,\"151\":1,\"201\":2,\"209\":1,\"211\":2,\"227\":1,\"228\":1,\"231\":1,\"232\":1,\"238\":1,\"244\":1,\"252\":1,\"256\":1}}],[\"equity\",{\"1\":{\"65\":1,\"74\":1}}],[\"equivalent\",{\"1\":{\"25\":1,\"27\":1,\"137\":1,\"197\":1,\"232\":1,\"264\":1}}],[\"equation\",{\"1\":{\"3\":2,\"42\":1,\"81\":1}}],[\"employed\",{\"1\":{\"217\":1}}],[\"employs\",{\"1\":{\"214\":1,\"219\":1}}],[\"employing\",{\"1\":{\"209\":1}}],[\"emphasis\",{\"1\":{\"194\":1}}],[\"empire\",{\"1\":{\"71\":6}}],[\"empirically\",{\"1\":{\"80\":1,\"239\":1,\"241\":1}}],[\"empirical\",{\"1\":{\"22\":1,\"37\":1,\"86\":1,\"105\":1,\"214\":1,\"239\":1}}],[\"emerged\",{\"1\":{\"170\":1,\"215\":1}}],[\"emergence\",{\"1\":{\"36\":1,\"238\":1}}],[\"embodies\",{\"1\":{\"136\":1}}],[\"embeddings\",{\"0\":{\"77\":1,\"114\":1},\"1\":{\"77\":2,\"78\":3,\"79\":3,\"80\":2,\"81\":2,\"82\":2,\"85\":1,\"87\":1,\"88\":2,\"89\":3,\"105\":3,\"114\":2,\"212\":1,\"214\":1,\"216\":7,\"232\":1,\"233\":2}}],[\"embedding\",{\"0\":{\"81\":1,\"82\":1},\"1\":{\"34\":1,\"44\":1,\"51\":3,\"54\":3,\"81\":2,\"82\":1,\"83\":2,\"84\":2,\"86\":1,\"96\":1,\"97\":1,\"105\":1,\"112\":3,\"113\":2,\"114\":1,\"130\":1,\"196\":2,\"197\":1,\"201\":1,\"203\":1,\"211\":1,\"212\":2,\"216\":4,\"219\":1,\"264\":5,\"265\":3,\"266\":2,\"268\":1},\"2\":{\"91\":1}}],[\"embedded\",{\"1\":{\"24\":1,\"41\":1,\"42\":1}}],[\"email\",{\"1\":{\"125\":2}}],[\"emmanouil\",{\"1\":{\"116\":1}}],[\"eminem\",{\"1\":{\"59\":3,\"71\":4}}],[\"emnlp\",{\"1\":{\"41\":1,\"46\":1,\"49\":1,\"61\":1,\"77\":1,\"89\":3,\"105\":1,\"116\":1,\"221\":2,\"235\":1,\"238\":1}}],[\"economist\",{\"1\":{\"21\":1}}],[\"economics\",{\"1\":{\"3\":1}}],[\"ethayarajh\",{\"1\":{\"81\":1,\"89\":1}}],[\"ethical\",{\"1\":{\"45\":1}}],[\"etc\",{\"1\":{\"31\":1,\"81\":1,\"111\":2,\"130\":1,\"146\":1,\"228\":1}}],[\"et\",{\"1\":{\"9\":2,\"31\":3,\"37\":9,\"41\":1,\"49\":1,\"53\":2,\"77\":1,\"81\":2,\"82\":1,\"105\":7,\"116\":1,\"167\":4,\"175\":5,\"209\":1,\"214\":1,\"221\":1,\"224\":1,\"247\":6,\"260\":1,\"263\":1,\"271\":2}}],[\"efforts\",{\"1\":{\"170\":1}}],[\"efficicacy\",{\"1\":{\"146\":1}}],[\"efficient\",{\"1\":{\"1\":1,\"6\":1,\"22\":1,\"146\":1,\"181\":1,\"194\":1,\"221\":1}}],[\"efficiently\",{\"1\":{\"0\":1,\"3\":1,\"130\":1,\"190\":1}}],[\"efficacy\",{\"1\":{\"100\":1,\"239\":1}}],[\"effects\",{\"1\":{\"188\":1,\"244\":1}}],[\"effect\",{\"1\":{\"26\":1,\"28\":1,\"33\":1,\"42\":1,\"43\":2,\"98\":1,\"184\":1,\"211\":2,\"258\":1}}],[\"effectively\",{\"1\":{\"23\":1,\"88\":1,\"137\":1,\"172\":1,\"203\":1,\"267\":1}}],[\"effectiveness\",{\"0\":{\"4\":1,\"25\":1,\"98\":1,\"213\":1,\"217\":1,\"243\":1},\"1\":{\"41\":2,\"60\":1,\"97\":1,\"173\":1,\"179\":1,\"188\":1,\"217\":1,\"218\":1,\"244\":1,\"246\":1,\"269\":1}}],[\"effective\",{\"1\":{\"3\":1,\"27\":1,\"45\":1,\"50\":1,\"109\":1,\"172\":1,\"175\":1,\"203\":2,\"209\":1,\"211\":1,\"244\":1,\"251\":2,\"257\":1,\"259\":1}}],[\"earlest\",{\"1\":{\"208\":1}}],[\"earth\",{\"1\":{\"105\":1}}],[\"eat\",{\"1\":{\"125\":2}}],[\"easily\",{\"1\":{\"146\":1,\"153\":1,\"228\":2}}],[\"easier\",{\"1\":{\"24\":2,\"79\":1,\"95\":1,\"244\":1}}],[\"east\",{\"1\":{\"95\":1}}],[\"easy\",{\"1\":{\"3\":1,\"23\":1,\"25\":1,\"77\":1,\"109\":1,\"111\":1,\"124\":1,\"142\":1,\"178\":1,\"194\":1}}],[\"each\",{\"0\":{\"202\":1},\"1\":{\"1\":2,\"2\":2,\"3\":1,\"24\":2,\"42\":1,\"43\":3,\"66\":2,\"68\":2,\"69\":1,\"71\":2,\"73\":1,\"93\":1,\"95\":1,\"96\":1,\"97\":2,\"100\":4,\"110\":1,\"112\":1,\"120\":1,\"122\":1,\"130\":1,\"146\":7,\"156\":1,\"178\":1,\"184\":1,\"195\":1,\"196\":2,\"197\":1,\"203\":1,\"208\":1,\"212\":9,\"213\":1,\"216\":4,\"227\":1,\"228\":3,\"231\":1,\"232\":2,\"233\":2,\"242\":1,\"245\":2,\"252\":1,\"264\":1,\"269\":1}}],[\"enriches\",{\"1\":{\"219\":1}}],[\"enormous\",{\"1\":{\"178\":1}}],[\"enough\",{\"1\":{\"66\":1,\"69\":1,\"71\":1,\"79\":1,\"93\":1,\"121\":1,\"170\":1,\"178\":1,\"226\":1,\"251\":1,\"263\":1,\"269\":1}}],[\"en2de\",{\"1\":{\"160\":1}}],[\"enlargement\",{\"1\":{\"146\":1}}],[\"enforces\",{\"1\":{\"253\":1}}],[\"enforce\",{\"1\":{\"146\":1,\"171\":1}}],[\"enfin\",{\"1\":{\"31\":3}}],[\"en⇒fr\",{\"1\":{\"141\":1}}],[\"en⇒de\",{\"1\":{\"141\":1}}],[\"enhancing\",{\"1\":{\"137\":1}}],[\"enhanced\",{\"0\":{\"170\":1},\"1\":{\"189\":1}}],[\"enhance\",{\"1\":{\"137\":1,\"146\":1}}],[\"environments\",{\"1\":{\"101\":1,\"159\":1}}],[\"enc\",{\"1\":{\"266\":1}}],[\"encyclopedic\",{\"1\":{\"72\":1}}],[\"encountered\",{\"1\":{\"228\":1}}],[\"encountering\",{\"1\":{\"21\":1}}],[\"encourages\",{\"1\":{\"146\":1}}],[\"encodes\",{\"1\":{\"172\":1,\"240\":1}}],[\"encode\",{\"1\":{\"54\":1,\"94\":1,\"110\":1,\"216\":1,\"232\":1,\"263\":1,\"265\":1,\"266\":1}}],[\"encoded\",{\"1\":{\"35\":1,\"266\":1}}],[\"encoders\",{\"0\":{\"232\":1},\"1\":{\"84\":1,\"153\":1,\"172\":1,\"216\":1,\"232\":2,\"269\":1}}],[\"encoder预训练结合起来\",{\"1\":{\"18\":1}}],[\"encoder看作学生\",{\"1\":{\"17\":1}}],[\"encoder\",{\"0\":{\"170\":1},\"1\":{\"15\":1,\"16\":1,\"18\":3,\"23\":2,\"35\":1,\"51\":1,\"96\":3,\"97\":2,\"110\":2,\"111\":4,\"112\":6,\"113\":1,\"126\":1,\"130\":1,\"136\":3,\"137\":1,\"146\":3,\"153\":1,\"155\":2,\"171\":3,\"172\":6,\"174\":12,\"195\":1,\"196\":2,\"197\":1,\"212\":1,\"216\":3,\"217\":1,\"218\":1,\"231\":1,\"232\":3,\"233\":3,\"240\":5,\"242\":1,\"244\":1,\"245\":2,\"263\":2,\"264\":2,\"265\":3,\"266\":5,\"267\":1,\"268\":1}}],[\"encodings\",{\"1\":{\"232\":4,\"233\":2}}],[\"encoding\",{\"1\":{\"1\":1,\"2\":1,\"5\":1,\"51\":1,\"54\":1,\"96\":1,\"113\":1,\"146\":1,\"232\":4,\"233\":1}}],[\"enables\",{\"1\":{\"200\":1}}],[\"enable\",{\"1\":{\"51\":1,\"167\":1}}],[\"enabling\",{\"1\":{\"37\":1}}],[\"entirely\",{\"1\":{\"227\":1}}],[\"entire\",{\"1\":{\"84\":1,\"182\":1,\"226\":1,\"231\":2}}],[\"entities\",{\"1\":{\"49\":3,\"50\":1,\"51\":5,\"53\":1,\"58\":1,\"67\":2,\"142\":1}}],[\"entity\",{\"1\":{\"43\":1,\"50\":1,\"51\":19,\"55\":1,\"60\":1,\"67\":1,\"72\":2}}],[\"entropy\",{\"1\":{\"1\":5,\"3\":6,\"42\":1}}],[\"enquête\",{\"1\":{\"31\":3}}],[\"ensure\",{\"1\":{\"24\":1,\"43\":1,\"67\":1,\"268\":1}}],[\"en\",{\"0\":{\"26\":2,\"31\":1,\"32\":1},\"1\":{\"13\":1,\"18\":3,\"26\":4,\"31\":3,\"97\":2,\"98\":4,\"102\":1,\"146\":1,\"175\":1,\"178\":1,\"179\":5,\"187\":5,\"188\":1,\"199\":1,\"200\":3,\"256\":1,\"257\":1}}],[\"english\",{\"0\":{\"31\":1,\"32\":1,\"201\":1},\"1\":{\"1\":1,\"4\":3,\"5\":1,\"7\":1,\"21\":1,\"22\":1,\"23\":2,\"24\":1,\"25\":3,\"29\":1,\"30\":1,\"32\":1,\"93\":1,\"95\":1,\"97\":2,\"99\":2,\"111\":1,\"113\":4,\"122\":5,\"125\":6,\"126\":3,\"146\":1,\"163\":1,\"172\":1,\"173\":3,\"179\":3,\"188\":1,\"194\":4,\"198\":1,\"199\":2,\"201\":5,\"203\":1,\"208\":1,\"217\":2,\"218\":1,\"221\":1,\"226\":1,\"239\":1,\"252\":2,\"254\":1,\"256\":2,\"257\":1}}],[\"ends\",{\"1\":{\"125\":1}}],[\"end\",{\"0\":{\"171\":2,\"229\":1},\"1\":{\"1\":1,\"8\":1,\"36\":1,\"93\":2,\"136\":2,\"137\":2,\"146\":2,\"170\":4,\"171\":8,\"172\":8,\"175\":8,\"226\":1}}],[\"exhibit\",{\"1\":{\"254\":1}}],[\"exhibits\",{\"1\":{\"213\":1}}],[\"exhibiting\",{\"1\":{\"43\":1}}],[\"exeperiments\",{\"0\":{\"185\":1}}],[\"exact\",{\"1\":{\"209\":1,\"211\":1,\"212\":2,\"218\":2,\"266\":1}}],[\"exactly\",{\"1\":{\"119\":1,\"218\":1,\"242\":1,\"264\":1}}],[\"examples\",{\"0\":{\"160\":1,\"161\":1,\"189\":1},\"1\":{\"5\":1,\"71\":2,\"120\":4,\"123\":1,\"130\":1,\"160\":2,\"161\":1,\"218\":1,\"226\":2}}],[\"example\",{\"1\":{\"1\":3,\"2\":2,\"3\":1,\"23\":1,\"24\":2,\"30\":2,\"50\":1,\"58\":1,\"66\":1,\"67\":2,\"68\":1,\"71\":4,\"78\":1,\"93\":1,\"94\":1,\"109\":1,\"111\":1,\"112\":1,\"113\":2,\"114\":2,\"123\":1,\"130\":1,\"146\":1,\"156\":1,\"170\":1,\"172\":1,\"175\":1,\"183\":1,\"184\":1,\"196\":1,\"209\":1,\"211\":2,\"212\":1,\"218\":2,\"225\":1,\"228\":1,\"232\":1}}],[\"excessively\",{\"1\":{\"211\":1}}],[\"exceeds\",{\"1\":{\"199\":1,\"217\":1}}],[\"exception\",{\"1\":{\"119\":1}}],[\"except\",{\"1\":{\"71\":2,\"97\":1,\"111\":1,\"113\":2,\"199\":1,\"245\":1}}],[\"excited\",{\"1\":{\"115\":1}}],[\"exciting\",{\"1\":{\"101\":1,\"121\":1,\"219\":1}}],[\"exchange\",{\"1\":{\"98\":1}}],[\"existed\",{\"1\":{\"233\":1}}],[\"exist\",{\"1\":{\"72\":1,\"156\":1,\"227\":1}}],[\"exists\",{\"1\":{\"72\":1,\"241\":1}}],[\"existing\",{\"1\":{\"43\":1,\"84\":1,\"131\":1,\"133\":1,\"141\":1,\"146\":1,\"153\":1,\"171\":1,\"175\":1,\"218\":1,\"231\":1}}],[\"exotic\",{\"1\":{\"27\":12,\"29\":1,\"30\":1}}],[\"external\",{\"1\":{\"79\":1,\"87\":1,\"93\":1,\"95\":1,\"135\":1,\"139\":1,\"146\":1,\"188\":1}}],[\"extension\",{\"1\":{\"130\":1}}],[\"extensively\",{\"1\":{\"251\":1}}],[\"extensive\",{\"1\":{\"86\":1,\"124\":1,\"212\":1}}],[\"extent\",{\"1\":{\"23\":1,\"208\":1,\"217\":1,\"218\":2,\"245\":1}}],[\"extend\",{\"0\":{\"27\":1},\"1\":{\"22\":1,\"23\":2,\"232\":1}}],[\"extending\",{\"1\":{\"22\":1}}],[\"extra\",{\"1\":{\"152\":1,\"155\":1,\"171\":1,\"240\":1}}],[\"extraordinary\",{\"1\":{\"123\":1}}],[\"extracts\",{\"1\":{\"171\":1,\"172\":1}}],[\"extracting\",{\"1\":{\"49\":1,\"54\":1,\"60\":1,\"134\":1}}],[\"extraction\",{\"0\":{\"49\":1,\"57\":1,\"58\":1},\"1\":{\"42\":1,\"43\":1,\"49\":2,\"50\":1,\"60\":2,\"61\":2},\"2\":{\"63\":1}}],[\"extracted\",{\"1\":{\"43\":4,\"44\":2,\"53\":1,\"96\":1,\"134\":1}}],[\"extract\",{\"1\":{\"8\":1,\"54\":1,\"67\":2,\"100\":1,\"122\":1,\"124\":1,\"126\":2,\"171\":1}}],[\"extreme\",{\"1\":{\"22\":1,\"146\":1,\"241\":1}}],[\"extremely\",{\"1\":{\"1\":1,\"2\":1,\"6\":1,\"93\":1,\"126\":1,\"228\":1}}],[\"expose\",{\"1\":{\"227\":1}}],[\"exposed\",{\"1\":{\"200\":1,\"218\":1}}],[\"export\",{\"1\":{\"161\":2}}],[\"expands\",{\"1\":{\"130\":1}}],[\"expanded\",{\"1\":{\"24\":1,\"25\":1}}],[\"expressed\",{\"1\":{\"130\":1,\"232\":1}}],[\"express\",{\"1\":{\"111\":1}}],[\"expert\",{\"1\":{\"228\":1}}],[\"experts\",{\"1\":{\"218\":1}}],[\"experienced\",{\"1\":{\"170\":1}}],[\"experiment\",{\"0\":{\"70\":1,\"71\":1,\"113\":1},\"1\":{\"43\":1,\"70\":2,\"71\":2,\"113\":2,\"124\":1,\"125\":2,\"126\":1,\"163\":1,\"213\":1,\"218\":1,\"252\":1,\"253\":1}}],[\"experimental\",{\"1\":{\"25\":1,\"58\":1,\"60\":1,\"85\":1,\"98\":1,\"119\":1,\"130\":1,\"140\":1,\"146\":1,\"203\":1,\"218\":2}}],[\"experiments\",{\"0\":{\"43\":1,\"52\":1,\"85\":1,\"99\":1,\"138\":1,\"255\":1,\"269\":1},\"1\":{\"3\":1,\"4\":1,\"7\":1,\"86\":1,\"97\":1,\"146\":2,\"198\":1,\"212\":2,\"239\":1,\"246\":1,\"259\":1,\"269\":2}}],[\"expensive\",{\"1\":{\"93\":1,\"151\":1,\"206\":1,\"209\":1}}],[\"expect\",{\"1\":{\"82\":1}}],[\"expected\",{\"1\":{\"43\":1,\"93\":1,\"123\":1,\"233\":1,\"258\":1}}],[\"expectation\",{\"1\":{\"42\":1,\"93\":1}}],[\"expectations\",{\"1\":{\"24\":1}}],[\"explicit\",{\"1\":{\"200\":1}}],[\"explicitly\",{\"1\":{\"51\":1,\"60\":1,\"121\":1,\"172\":1}}],[\"exploding\",{\"1\":{\"231\":1}}],[\"exploits\",{\"1\":{\"230\":1}}],[\"exploit\",{\"1\":{\"172\":1,\"214\":1,\"219\":1,\"228\":1}}],[\"exploiting\",{\"0\":{\"146\":1}}],[\"exploited\",{\"1\":{\"79\":1,\"80\":1,\"93\":1}}],[\"exploration\",{\"1\":{\"170\":1}}],[\"exploring\",{\"1\":{\"72\":1}}],[\"explored\",{\"1\":{\"94\":1,\"131\":1}}],[\"explore\",{\"1\":{\"1\":1,\"6\":1,\"114\":1}}],[\"explanation\",{\"1\":{\"24\":1,\"233\":1,\"252\":1}}],[\"explainability\",{\"1\":{\"221\":2}}],[\"explained\",{\"0\":{\"105\":1},\"1\":{\"78\":1,\"82\":1,\"231\":1}}],[\"explaining\",{\"1\":{\"64\":1,\"94\":1,\"229\":1}}],[\"explains\",{\"1\":{\"41\":1}}],[\"explain\",{\"1\":{\"0\":1,\"65\":1,\"233\":1,\"253\":1}}],[\"ijcai\",{\"1\":{\"247\":1}}],[\"ijcnlp\",{\"1\":{\"89\":2,\"105\":1}}],[\"i=n\",{\"1\":{\"146\":1}}],[\"i=1\",{\"1\":{\"146\":1}}],[\"išiel\",{\"1\":{\"125\":1}}],[\"iwlst\",{\"1\":{\"114\":1,\"146\":1}}],[\"iwslt16en\",{\"1\":{\"186\":2,\"187\":1}}],[\"iwslt2018\",{\"1\":{\"173\":1}}],[\"iwslt2014\",{\"1\":{\"146\":1}}],[\"iwslt\",{\"1\":{\"113\":3,\"114\":1,\"146\":5,\"198\":1}}],[\"illustrating\",{\"1\":{\"213\":1}}],[\"illustration\",{\"1\":{\"146\":1}}],[\"illustrates\",{\"1\":{\"120\":1,\"141\":1,\"258\":1}}],[\"illustrate\",{\"1\":{\"68\":1,\"218\":1,\"225\":1}}],[\"illustrated\",{\"1\":{\"66\":1,\"71\":1,\"156\":1,\"212\":2,\"218\":2,\"232\":1}}],[\"illia\",{\"1\":{\"102\":1}}],[\"ikonomou\",{\"1\":{\"95\":2,\"102\":1}}],[\"ioannis\",{\"1\":{\"95\":1,\"102\":1}}],[\"icassp\",{\"1\":{\"175\":2}}],[\"ich\",{\"1\":{\"125\":1}}],[\"iclr\",{\"1\":{\"89\":2,\"191\":1,\"221\":1}}],[\"icml\",{\"1\":{\"37\":1}}],[\"iryna\",{\"1\":{\"89\":1}}],[\"ireland\",{\"1\":{\"9\":1}}],[\"ieevaluation\",{\"1\":{\"221\":1}}],[\"ieee\",{\"1\":{\"175\":2}}],[\"ie\",{\"2\":{\"62\":1}}],[\"ignoring\",{\"1\":{\"175\":1}}],[\"ignored\",{\"1\":{\"94\":1}}],[\"ignore\",{\"1\":{\"31\":1,\"65\":1}}],[\"ign\",{\"1\":{\"54\":4}}],[\"id=skehucvfdr\",{\"1\":{\"221\":1}}],[\"idf\",{\"1\":{\"212\":2}}],[\"id\",{\"1\":{\"51\":1}}],[\"identical\",{\"1\":{\"232\":1}}],[\"identification\",{\"1\":{\"50\":1,\"174\":1,\"195\":1}}],[\"identifies\",{\"1\":{\"94\":1}}],[\"identified\",{\"1\":{\"42\":1}}],[\"identifier\",{\"1\":{\"24\":1,\"35\":1}}],[\"identifying\",{\"1\":{\"49\":1,\"67\":1}}],[\"identify\",{\"1\":{\"24\":1,\"59\":1,\"67\":1,\"174\":1}}],[\"ideas\",{\"1\":{\"130\":1}}],[\"idea\",{\"0\":{\"111\":1},\"1\":{\"3\":1,\"22\":1,\"23\":1,\"66\":1,\"67\":1,\"93\":1,\"94\":1,\"95\":1,\"109\":2,\"111\":4,\"115\":2,\"146\":2,\"184\":1,\"196\":1,\"197\":1,\"232\":1,\"233\":1,\"239\":1,\"250\":1,\"264\":1}}],[\"imbues\",{\"1\":{\"228\":1}}],[\"imbeddings\",{\"1\":{\"212\":1}}],[\"imbalance\",{\"1\":{\"82\":1}}],[\"imitate\",{\"1\":{\"172\":2}}],[\"imagit\",{\"1\":{\"131\":1,\"134\":1,\"136\":1,\"139\":1,\"142\":1},\"2\":{\"145\":1}}],[\"imagination\",{\"0\":{\"130\":1},\"1\":{\"130\":1,\"134\":2,\"135\":2,\"136\":2,\"137\":1,\"140\":1,\"142\":2,\"143\":1},\"2\":{\"145\":1}}],[\"imagined\",{\"1\":{\"137\":5}}],[\"imagine\",{\"1\":{\"111\":1,\"197\":1,\"228\":1,\"263\":1}}],[\"images\",{\"1\":{\"93\":2,\"130\":1,\"131\":1,\"132\":2,\"133\":1,\"134\":1,\"135\":1,\"141\":2,\"142\":2,\"165\":1}}],[\"image\",{\"1\":{\"2\":1,\"130\":2,\"131\":1,\"133\":2,\"136\":1,\"137\":3,\"151\":1,\"154\":1,\"155\":1,\"163\":1,\"164\":1,\"166\":1,\"181\":1,\"264\":1}}],[\"immersed\",{\"1\":{\"95\":1}}],[\"immature\",{\"1\":{\"72\":1}}],[\"immaturity\",{\"1\":{\"71\":1}}],[\"imf\",{\"1\":{\"29\":2}}],[\"impact\",{\"1\":{\"188\":1}}],[\"impressive\",{\"1\":{\"113\":1,\"115\":1,\"126\":1,\"225\":1}}],[\"improving\",{\"1\":{\"37\":1,\"89\":1,\"184\":1,\"194\":1,\"214\":1,\"251\":1,\"258\":1}}],[\"improves\",{\"1\":{\"54\":2,\"58\":1,\"130\":1,\"153\":1,\"190\":1,\"201\":1,\"202\":2,\"203\":2,\"254\":1,\"256\":1}}],[\"improve\",{\"1\":{\"22\":1,\"24\":1,\"33\":1,\"86\":1,\"88\":1,\"92\":1,\"93\":2,\"115\":2,\"132\":1,\"137\":1,\"146\":1,\"163\":1,\"171\":2,\"172\":1,\"179\":1,\"181\":1,\"188\":2,\"202\":1,\"225\":1,\"251\":1,\"252\":1,\"254\":1,\"259\":1}}],[\"improved\",{\"1\":{\"22\":1,\"23\":1,\"25\":1,\"35\":1,\"43\":1,\"93\":1,\"105\":1,\"122\":2,\"146\":2,\"202\":1,\"215\":1,\"221\":1,\"269\":1}}],[\"improvements\",{\"0\":{\"72\":1},\"1\":{\"33\":2,\"65\":1,\"93\":2,\"94\":1,\"119\":1,\"146\":2,\"203\":1,\"239\":1}}],[\"improvement\",{\"1\":{\"22\":1,\"23\":1,\"25\":2,\"54\":2,\"98\":1,\"119\":1,\"122\":1,\"126\":1,\"146\":4,\"187\":1,\"200\":1,\"212\":1,\"219\":1,\"244\":1,\"254\":1}}],[\"implies\",{\"1\":{\"253\":1}}],[\"implicit\",{\"1\":{\"253\":1}}],[\"implicitly\",{\"1\":{\"33\":1,\"252\":1}}],[\"implications\",{\"1\":{\"230\":1}}],[\"implemented\",{\"1\":{\"155\":1,\"240\":1,\"242\":1}}],[\"implement\",{\"1\":{\"109\":1,\"132\":1}}],[\"imply\",{\"1\":{\"72\":1}}],[\"imported\",{\"1\":{\"211\":1}}],[\"importance\",{\"0\":{\"202\":1},\"1\":{\"65\":1,\"202\":1,\"212\":4,\"218\":1,\"219\":1}}],[\"important\",{\"1\":{\"8\":1,\"23\":2,\"58\":1,\"71\":1,\"101\":1,\"130\":1,\"146\":1,\"197\":1,\"216\":1,\"238\":1}}],[\"impossible\",{\"1\":{\"25\":1,\"231\":1}}],[\"iff\",{\"1\":{\"69\":3}}],[\"if\",{\"1\":{\"1\":3,\"2\":1,\"24\":4,\"42\":1,\"44\":1,\"51\":1,\"72\":2,\"79\":1,\"82\":1,\"112\":1,\"114\":1,\"123\":1,\"124\":1,\"125\":1,\"159\":1,\"160\":1,\"172\":1,\"187\":1,\"196\":1,\"202\":1,\"203\":1,\"211\":1,\"218\":1,\"225\":1,\"226\":3,\"227\":2,\"228\":6,\"229\":1,\"231\":1,\"232\":1,\"233\":1,\"234\":1,\"250\":1,\"251\":2,\"252\":1,\"264\":1,\"267\":1,\"269\":1}}],[\"items\",{\"1\":{\"233\":1}}],[\"iteration\",{\"1\":{\"252\":2,\"269\":2}}],[\"iterations\",{\"1\":{\"252\":1,\"254\":1,\"269\":2}}],[\"iteratively\",{\"1\":{\"146\":1}}],[\"iterative\",{\"1\":{\"96\":1,\"130\":1}}],[\"iterate\",{\"1\":{\"1\":1,\"2\":1,\"8\":1}}],[\"iterrogative\",{\"1\":{\"68\":1}}],[\"italy\",{\"1\":{\"105\":1}}],[\"italian\",{\"1\":{\"95\":1,\"97\":1,\"114\":1}}],[\"it\",{\"1\":{\"1\":9,\"2\":2,\"3\":6,\"5\":3,\"6\":2,\"7\":1,\"8\":5,\"22\":6,\"23\":8,\"24\":7,\"25\":1,\"26\":3,\"27\":2,\"30\":1,\"34\":1,\"35\":2,\"36\":1,\"42\":1,\"43\":2,\"45\":2,\"51\":1,\"59\":1,\"60\":1,\"65\":2,\"66\":6,\"67\":1,\"68\":4,\"70\":1,\"71\":11,\"72\":1,\"73\":1,\"77\":1,\"79\":1,\"93\":6,\"94\":2,\"95\":3,\"96\":2,\"97\":1,\"98\":2,\"100\":1,\"109\":5,\"111\":1,\"112\":1,\"113\":1,\"114\":1,\"115\":3,\"120\":2,\"123\":1,\"124\":2,\"125\":1,\"126\":6,\"130\":4,\"131\":1,\"132\":1,\"133\":1,\"135\":1,\"142\":1,\"146\":1,\"151\":1,\"153\":2,\"155\":1,\"171\":3,\"172\":4,\"174\":3,\"175\":6,\"178\":1,\"181\":1,\"183\":1,\"197\":1,\"201\":1,\"202\":2,\"206\":1,\"213\":1,\"216\":1,\"218\":1,\"219\":1,\"225\":1,\"226\":5,\"227\":3,\"228\":8,\"230\":1,\"231\":6,\"233\":2,\"234\":1,\"238\":2,\"241\":1,\"242\":1,\"246\":2,\"250\":2,\"251\":2,\"252\":1,\"253\":3,\"254\":2,\"257\":1,\"258\":1,\"259\":1,\"263\":3,\"264\":1,\"266\":1,\"268\":2,\"269\":1}}],[\"itself\",{\"1\":{\"123\":1,\"231\":2}}],[\"its\",{\"1\":{\"1\":3,\"2\":1,\"3\":2,\"31\":1,\"33\":1,\"41\":1,\"64\":1,\"68\":1,\"71\":3,\"78\":1,\"80\":1,\"93\":1,\"96\":1,\"98\":1,\"100\":1,\"115\":1,\"119\":1,\"120\":4,\"122\":1,\"124\":3,\"126\":2,\"133\":1,\"137\":1,\"139\":1,\"146\":2,\"170\":2,\"209\":1,\"216\":3,\"217\":1,\"218\":1,\"228\":1,\"230\":1,\"232\":1,\"238\":1,\"242\":1,\"245\":1,\"250\":1,\"251\":1,\"252\":1}}],[\"i\",{\"1\":{\"0\":1,\"24\":3,\"51\":1,\"54\":1,\"65\":1,\"66\":2,\"68\":1,\"70\":1,\"71\":8,\"124\":2,\"125\":15,\"126\":1,\"130\":3,\"155\":1,\"156\":1,\"196\":3,\"216\":1,\"218\":3,\"224\":2,\"225\":2,\"227\":2,\"228\":1,\"229\":2,\"232\":2,\"233\":2,\"250\":1,\"253\":1}}],[\"injected\",{\"1\":{\"259\":1}}],[\"inner\",{\"1\":{\"232\":1}}],[\"innovation\",{\"1\":{\"218\":1}}],[\"innovations\",{\"1\":{\"218\":2}}],[\"ingredient\",{\"1\":{\"130\":1}}],[\"inherently\",{\"1\":{\"113\":1}}],[\"inputting\",{\"1\":{\"225\":1}}],[\"inputs\",{\"1\":{\"93\":1,\"100\":1,\"152\":1,\"171\":1,\"196\":1,\"216\":1,\"226\":2,\"233\":1,\"240\":1,\"253\":1,\"264\":1}}],[\"input\",{\"1\":{\"68\":1,\"69\":1,\"92\":1,\"96\":5,\"97\":1,\"100\":1,\"125\":2,\"132\":1,\"133\":1,\"135\":1,\"141\":2,\"146\":1,\"171\":1,\"172\":1,\"212\":1,\"216\":3,\"218\":1,\"233\":1,\"240\":2,\"242\":2,\"254\":3,\"259\":1,\"266\":2}}],[\"infrequently\",{\"1\":{\"228\":1}}],[\"infrequent\",{\"1\":{\"228\":1}}],[\"info\",{\"1\":{\"221\":1}}],[\"informatoin\",{\"1\":{\"134\":1}}],[\"information\",{\"1\":{\"1\":3,\"3\":1,\"24\":1,\"30\":1,\"37\":2,\"51\":2,\"65\":2,\"66\":1,\"68\":1,\"69\":1,\"79\":2,\"80\":1,\"93\":2,\"96\":2,\"100\":1,\"102\":2,\"109\":2,\"112\":1,\"124\":1,\"126\":1,\"131\":1,\"132\":3,\"142\":1,\"167\":1,\"171\":3,\"174\":2,\"175\":2,\"208\":1,\"210\":1,\"214\":1,\"216\":1,\"218\":1,\"219\":3,\"233\":1,\"241\":1,\"247\":1}}],[\"informal\",{\"1\":{\"98\":1}}],[\"infamous\",{\"1\":{\"208\":1,\"226\":1}}],[\"influence\",{\"1\":{\"95\":1,\"111\":3,\"171\":1}}],[\"influential\",{\"1\":{\"71\":1}}],[\"inferring\",{\"1\":{\"218\":1}}],[\"inferior\",{\"1\":{\"78\":1,\"94\":1}}],[\"inferencing\",{\"1\":{\"149\":1}}],[\"inference\",{\"0\":{\"161\":1,\"164\":1,\"165\":1},\"1\":{\"51\":2,\"53\":2,\"55\":1,\"58\":3,\"59\":1,\"60\":1,\"120\":1,\"121\":1,\"124\":1,\"146\":2,\"151\":1,\"152\":3,\"153\":3,\"154\":1,\"155\":1,\"161\":2,\"164\":1,\"167\":1,\"216\":1,\"239\":1,\"241\":1,\"242\":1,\"244\":1},\"2\":{\"193\":1}}],[\"inferential\",{\"1\":{\"60\":1}}],[\"infer\",{\"1\":{\"58\":3,\"60\":1}}],[\"inevitably\",{\"1\":{\"228\":1}}],[\"inevitable\",{\"1\":{\"49\":1,\"65\":1}}],[\"inefficient\",{\"1\":{\"1\":1,\"72\":1}}],[\"involving\",{\"1\":{\"57\":1}}],[\"involves\",{\"1\":{\"43\":1,\"124\":1}}],[\"involved\",{\"1\":{\"41\":1,\"50\":1,\"188\":1}}],[\"involve\",{\"1\":{\"41\":1}}],[\"invasive\",{\"1\":{\"41\":1}}],[\"inverse\",{\"1\":{\"179\":1,\"212\":2}}],[\"inversely\",{\"1\":{\"3\":1}}],[\"invertigate\",{\"1\":{\"146\":1}}],[\"investigates\",{\"1\":{\"250\":1}}],[\"investigate\",{\"1\":{\"88\":1,\"251\":1}}],[\"investigation\",{\"1\":{\"31\":1}}],[\"insufficient\",{\"1\":{\"146\":1,\"171\":1,\"172\":1,\"175\":1,\"244\":1}}],[\"insight\",{\"1\":{\"109\":1}}],[\"insights\",{\"1\":{\"37\":1,\"93\":1}}],[\"inside\",{\"1\":{\"100\":1}}],[\"inspired\",{\"0\":{\"172\":1},\"1\":{\"93\":1,\"171\":1,\"181\":1}}],[\"inspiration\",{\"1\":{\"92\":1}}],[\"install\",{\"1\":{\"159\":1,\"161\":1}}],[\"installation\",{\"0\":{\"159\":1},\"1\":{\"159\":1}}],[\"instances\",{\"1\":{\"53\":1}}],[\"instance\",{\"1\":{\"1\":3,\"65\":1}}],[\"instead\",{\"1\":{\"8\":1,\"24\":1,\"135\":1,\"156\":1,\"218\":3,\"226\":1,\"231\":1,\"242\":1,\"264\":1}}],[\"industrial\",{\"1\":{\"151\":1}}],[\"inducing\",{\"1\":{\"137\":1}}],[\"induces\",{\"1\":{\"80\":1}}],[\"induced\",{\"1\":{\"79\":1,\"82\":2}}],[\"indeed\",{\"1\":{\"93\":1,\"100\":1,\"101\":1,\"208\":1,\"263\":1}}],[\"independence\",{\"1\":{\"41\":1}}],[\"independently\",{\"1\":{\"179\":1}}],[\"independent\",{\"1\":{\"33\":1}}],[\"indices\",{\"1\":{\"146\":1}}],[\"indicative\",{\"1\":{\"212\":1}}],[\"indicating\",{\"1\":{\"3\":1,\"71\":2,\"213\":1,\"254\":1}}],[\"indicator\",{\"1\":{\"146\":1}}],[\"indicated\",{\"1\":{\"146\":1,\"212\":1}}],[\"indicates\",{\"1\":{\"42\":1,\"57\":1,\"71\":1,\"244\":1}}],[\"indicate\",{\"1\":{\"6\":1,\"43\":1,\"114\":1,\"212\":1,\"253\":1}}],[\"individual\",{\"1\":{\"100\":1}}],[\"individually\",{\"1\":{\"27\":1}}],[\"indian\",{\"1\":{\"68\":3}}],[\"increasing\",{\"1\":{\"126\":1,\"170\":1,\"188\":1}}],[\"increases\",{\"1\":{\"146\":1,\"179\":1,\"195\":1,\"258\":1}}],[\"increased\",{\"1\":{\"123\":1,\"210\":1}}],[\"increase\",{\"1\":{\"2\":1,\"269\":1}}],[\"incredible\",{\"1\":{\"126\":2}}],[\"incluence\",{\"1\":{\"111\":1}}],[\"includes\",{\"1\":{\"173\":1,\"212\":1,\"252\":1}}],[\"include\",{\"1\":{\"121\":1,\"153\":1}}],[\"included\",{\"1\":{\"27\":1,\"96\":1,\"124\":1,\"146\":2,\"209\":1}}],[\"including\",{\"1\":{\"93\":1,\"113\":1,\"124\":1,\"134\":1,\"151\":1,\"153\":1,\"194\":1,\"203\":1,\"217\":2,\"231\":1,\"244\":1}}],[\"inc\",{\"1\":{\"102\":1}}],[\"incoporating\",{\"1\":{\"215\":1}}],[\"incorrectly\",{\"1\":{\"228\":1}}],[\"incorrect\",{\"1\":{\"175\":1}}],[\"incorporates\",{\"1\":{\"210\":1}}],[\"incorporated\",{\"1\":{\"112\":1,\"218\":3,\"227\":1}}],[\"incorporate\",{\"1\":{\"97\":1,\"115\":1,\"172\":1}}],[\"incorporating\",{\"1\":{\"93\":1,\"179\":1,\"187\":1,\"188\":1,\"200\":1,\"219\":1}}],[\"incoherent\",{\"1\":{\"126\":1}}],[\"inconsistency\",{\"1\":{\"23\":1,\"189\":1}}],[\"incendie\",{\"1\":{\"31\":3}}],[\"initialize\",{\"1\":{\"24\":1,\"112\":1}}],[\"initialized\",{\"1\":{\"23\":1,\"146\":2,\"184\":1,\"218\":1}}],[\"initial\",{\"1\":{\"3\":2,\"96\":1,\"146\":1,\"242\":3,\"246\":1}}],[\"intro\",{\"0\":{\"229\":1}}],[\"introduces\",{\"1\":{\"26\":1,\"153\":1,\"171\":1,\"181\":1,\"250\":1}}],[\"introduce\",{\"1\":{\"22\":1,\"60\":1,\"65\":1,\"66\":1,\"69\":1,\"93\":1,\"111\":1,\"112\":1,\"115\":1,\"170\":1,\"241\":1,\"251\":1}}],[\"introduced\",{\"1\":{\"8\":1,\"24\":1,\"34\":1,\"42\":1,\"65\":1,\"219\":1,\"231\":1,\"268\":1}}],[\"introduction\",{\"0\":{\"1\":1,\"22\":1,\"41\":1,\"65\":1,\"93\":1,\"109\":1,\"239\":1,\"251\":1},\"1\":{\"24\":1,\"201\":1,\"229\":1,\"239\":1}}],[\"intrinsic\",{\"1\":{\"93\":1}}],[\"intractable\",{\"1\":{\"78\":1}}],[\"intra\",{\"1\":{\"51\":2,\"57\":3}}],[\"intuitive\",{\"1\":{\"155\":1,\"188\":1,\"233\":1}}],[\"intuitively\",{\"1\":{\"1\":1,\"3\":1,\"28\":1,\"196\":1,\"228\":1,\"253\":1}}],[\"intuition\",{\"0\":{\"231\":1},\"1\":{\"94\":1}}],[\"intuitions\",{\"1\":{\"51\":1}}],[\"intended\",{\"1\":{\"225\":1}}],[\"intensive\",{\"1\":{\"219\":1}}],[\"intent\",{\"1\":{\"174\":1}}],[\"intention\",{\"1\":{\"174\":1}}],[\"intentide\",{\"1\":{\"174\":2}}],[\"integrate\",{\"1\":{\"130\":1,\"137\":1,\"190\":1}}],[\"integration\",{\"1\":{\"102\":1,\"188\":1}}],[\"intelligibility\",{\"1\":{\"208\":2}}],[\"intelligence\",{\"1\":{\"41\":1,\"94\":1}}],[\"intellectual\",{\"0\":{\"40\":1},\"1\":{\"41\":1,\"45\":1}}],[\"interpolation\",{\"1\":{\"188\":1}}],[\"interpretability\",{\"1\":{\"71\":1}}],[\"interpretable\",{\"1\":{\"65\":1,\"74\":1}}],[\"interpret\",{\"1\":{\"41\":1,\"71\":2}}],[\"interactive\",{\"1\":{\"183\":1}}],[\"interaction\",{\"1\":{\"51\":1,\"54\":1,\"60\":1,\"239\":2,\"244\":1}}],[\"interactions\",{\"1\":{\"51\":5,\"57\":1,\"95\":1,\"101\":1}}],[\"interested\",{\"1\":{\"240\":1}}],[\"interest\",{\"1\":{\"170\":1,\"210\":1}}],[\"interestingly\",{\"1\":{\"244\":1,\"245\":1}}],[\"interesting\",{\"1\":{\"24\":2,\"71\":1,\"95\":1,\"101\":1,\"114\":1,\"125\":1,\"170\":1,\"172\":2,\"174\":1,\"228\":1}}],[\"interference\",{\"1\":{\"146\":5}}],[\"intermediate\",{\"1\":{\"110\":1,\"157\":1,\"171\":1,\"172\":2,\"258\":2}}],[\"interview\",{\"1\":{\"95\":1}}],[\"interrogative\",{\"1\":{\"68\":2}}],[\"internal\",{\"1\":{\"131\":1}}],[\"international\",{\"1\":{\"29\":2,\"105\":3,\"167\":1,\"175\":1,\"210\":1,\"247\":1,\"260\":1}}],[\"internet\",{\"1\":{\"65\":2,\"218\":1}}],[\"inter\",{\"1\":{\"51\":2,\"57\":3,\"60\":2}}],[\"intonation\",{\"1\":{\"94\":1}}],[\"into\",{\"1\":{\"1\":2,\"2\":1,\"21\":1,\"24\":2,\"27\":1,\"43\":1,\"51\":4,\"66\":1,\"67\":2,\"69\":2,\"70\":1,\"71\":1,\"93\":2,\"96\":1,\"115\":1,\"122\":1,\"124\":1,\"125\":3,\"126\":1,\"130\":1,\"135\":1,\"141\":1,\"146\":2,\"156\":2,\"170\":1,\"172\":1,\"179\":1,\"196\":1,\"208\":1,\"210\":1,\"212\":3,\"216\":6,\"219\":1,\"225\":1,\"226\":2,\"227\":1,\"228\":1,\"229\":1,\"232\":1,\"233\":3,\"239\":1,\"240\":3,\"244\":1,\"265\":1}}],[\"in\",{\"0\":{\"23\":1,\"94\":1,\"203\":1},\"1\":{\"0\":1,\"1\":15,\"2\":3,\"3\":6,\"5\":3,\"6\":3,\"8\":4,\"9\":3,\"21\":2,\"22\":10,\"23\":9,\"24\":14,\"25\":7,\"27\":6,\"28\":2,\"29\":2,\"30\":2,\"32\":1,\"33\":2,\"35\":3,\"36\":10,\"37\":5,\"41\":9,\"42\":12,\"43\":5,\"44\":1,\"45\":5,\"46\":1,\"49\":3,\"50\":5,\"51\":6,\"53\":2,\"54\":2,\"55\":1,\"57\":3,\"58\":1,\"59\":1,\"60\":5,\"61\":1,\"65\":3,\"66\":4,\"67\":1,\"68\":5,\"71\":23,\"72\":6,\"73\":2,\"78\":1,\"79\":2,\"80\":1,\"81\":2,\"82\":2,\"83\":2,\"84\":3,\"86\":1,\"89\":5,\"93\":10,\"94\":7,\"95\":9,\"96\":5,\"97\":5,\"98\":5,\"99\":2,\"100\":2,\"101\":3,\"102\":5,\"105\":13,\"109\":3,\"110\":3,\"111\":1,\"112\":3,\"113\":6,\"115\":2,\"119\":3,\"120\":1,\"121\":1,\"122\":2,\"124\":12,\"125\":4,\"126\":3,\"130\":4,\"131\":2,\"132\":1,\"135\":2,\"139\":1,\"140\":1,\"146\":23,\"151\":1,\"153\":1,\"155\":2,\"156\":2,\"163\":1,\"167\":2,\"170\":3,\"171\":1,\"172\":4,\"174\":2,\"175\":3,\"178\":2,\"181\":1,\"183\":3,\"187\":1,\"188\":2,\"189\":3,\"194\":1,\"196\":2,\"197\":8,\"198\":3,\"199\":6,\"200\":6,\"202\":1,\"203\":4,\"208\":1,\"209\":3,\"210\":2,\"211\":10,\"212\":17,\"213\":3,\"214\":3,\"215\":2,\"216\":4,\"217\":4,\"218\":33,\"219\":5,\"221\":3,\"224\":2,\"225\":4,\"226\":3,\"227\":2,\"228\":8,\"231\":3,\"232\":2,\"233\":3,\"234\":1,\"238\":1,\"239\":3,\"240\":4,\"242\":4,\"244\":1,\"245\":6,\"247\":3,\"250\":1,\"251\":5,\"252\":1,\"253\":2,\"254\":2,\"256\":2,\"257\":1,\"258\":2,\"263\":5,\"264\":9,\"265\":1,\"266\":4,\"267\":4,\"268\":2,\"269\":5,\"270\":2}}],[\"isn\",{\"1\":{\"98\":1,\"125\":1}}],[\"isotropy\",{\"1\":{\"84\":1}}],[\"isotropic\",{\"1\":{\"84\":2}}],[\"issues\",{\"0\":{\"2\":1},\"1\":{\"1\":1,\"71\":1,\"78\":1,\"84\":1,\"98\":1,\"126\":1,\"171\":1,\"231\":1}}],[\"issue\",{\"1\":{\"1\":1,\"2\":1,\"65\":1,\"146\":1,\"188\":1,\"189\":1}}],[\"is\",{\"0\":{\"21\":1,\"77\":1,\"150\":1,\"202\":1,\"203\":1,\"225\":1,\"226\":1},\"1\":{\"0\":1,\"1\":21,\"2\":8,\"3\":17,\"5\":1,\"6\":1,\"7\":2,\"8\":3,\"21\":1,\"22\":5,\"23\":4,\"24\":10,\"25\":5,\"26\":4,\"27\":5,\"29\":1,\"31\":3,\"34\":3,\"35\":2,\"36\":2,\"37\":1,\"41\":2,\"42\":11,\"43\":3,\"44\":1,\"45\":1,\"49\":1,\"50\":1,\"51\":4,\"54\":1,\"59\":3,\"65\":1,\"66\":5,\"67\":1,\"68\":13,\"69\":9,\"70\":3,\"71\":30,\"72\":5,\"77\":1,\"78\":1,\"79\":1,\"80\":1,\"81\":2,\"82\":4,\"84\":1,\"86\":1,\"93\":11,\"94\":2,\"95\":9,\"96\":4,\"97\":3,\"98\":2,\"100\":4,\"101\":2,\"102\":1,\"105\":5,\"109\":11,\"110\":1,\"111\":2,\"112\":7,\"113\":9,\"114\":1,\"115\":1,\"119\":5,\"120\":5,\"121\":3,\"123\":1,\"124\":4,\"125\":1,\"126\":10,\"127\":1,\"130\":4,\"131\":2,\"132\":2,\"133\":1,\"134\":1,\"135\":2,\"136\":2,\"137\":1,\"139\":1,\"140\":2,\"141\":1,\"142\":1,\"146\":17,\"151\":2,\"152\":1,\"153\":2,\"157\":1,\"161\":1,\"163\":1,\"164\":1,\"166\":2,\"167\":1,\"170\":4,\"171\":3,\"172\":6,\"173\":1,\"174\":3,\"175\":5,\"178\":1,\"179\":2,\"181\":1,\"183\":1,\"184\":2,\"188\":2,\"190\":1,\"194\":1,\"195\":2,\"196\":3,\"197\":9,\"198\":1,\"200\":2,\"201\":2,\"202\":3,\"203\":1,\"206\":2,\"208\":1,\"209\":5,\"210\":1,\"211\":3,\"212\":13,\"213\":7,\"215\":1,\"216\":10,\"217\":7,\"218\":14,\"219\":2,\"225\":5,\"226\":6,\"227\":1,\"228\":6,\"230\":1,\"231\":4,\"232\":8,\"233\":6,\"234\":1,\"238\":2,\"239\":2,\"240\":7,\"241\":2,\"242\":1,\"244\":4,\"245\":4,\"246\":1,\"247\":1,\"250\":2,\"251\":8,\"252\":4,\"253\":5,\"254\":4,\"256\":1,\"257\":4,\"258\":4,\"259\":3,\"263\":5,\"264\":9,\"265\":3,\"266\":3,\"267\":4,\"268\":6,\"269\":7,\"270\":2}}],[\"wd\",{\"1\":{\"266\":1}}],[\"wdec​​\",{\"1\":{\"112\":1}}],[\"wdec​∈rpdec​timesm\",{\"1\":{\"112\":1}}],[\"wrong\",{\"1\":{\"172\":2}}],[\"wr\",{\"1\":{\"146\":1}}],[\"written\",{\"1\":{\"123\":3,\"232\":1,\"233\":1}}],[\"writing\",{\"1\":{\"101\":1}}],[\"write\",{\"1\":{\"95\":1,\"156\":1}}],[\"w\",{\"0\":{\"86\":1,\"87\":1},\"1\":{\"34\":2,\"35\":1,\"252\":7,\"271\":1}}],[\"wu\",{\"1\":{\"21\":1,\"105\":1,\"146\":1,\"203\":1,\"221\":2}}],[\"wmt20\",{\"1\":{\"218\":1}}],[\"wmt2014\",{\"1\":{\"22\":1}}],[\"wmt100k\",{\"1\":{\"252\":1,\"254\":1,\"257\":1}}],[\"wmt19\",{\"1\":{\"218\":1,\"221\":1}}],[\"wmt18\",{\"1\":{\"213\":1}}],[\"wmt16ro\",{\"1\":{\"187\":1}}],[\"wmt16en\",{\"1\":{\"186\":2,\"187\":1}}],[\"wmt14de\",{\"1\":{\"187\":1}}],[\"wmt14en\",{\"1\":{\"186\":2,\"187\":1}}],[\"wmt14en2de\",{\"1\":{\"160\":2}}],[\"wmt14+opensubtitles\",{\"1\":{\"98\":1}}],[\"wmt14\",{\"1\":{\"25\":1,\"160\":1,\"163\":1,\"256\":3,\"258\":1}}],[\"wmt\",{\"1\":{\"4\":1,\"5\":1,\"13\":1,\"18\":1,\"26\":2,\"97\":1,\"142\":1,\"146\":7,\"198\":1,\"217\":2,\"219\":1,\"244\":1,\"252\":1,\"269\":1}}],[\"wolfgang\",{\"1\":{\"221\":1}}],[\"woman\",{\"1\":{\"68\":3}}],[\"won\",{\"1\":{\"66\":1}}],[\"worry\",{\"1\":{\"231\":1}}],[\"worse\",{\"1\":{\"120\":2,\"216\":1,\"217\":1}}],[\"worlds\",{\"1\":{\"233\":1}}],[\"world\",{\"0\":{\"166\":1},\"1\":{\"30\":1,\"78\":1,\"93\":2,\"95\":2,\"101\":1,\"124\":1,\"218\":5}}],[\"worthy\",{\"1\":{\"95\":1}}],[\"worth\",{\"1\":{\"27\":1,\"72\":1,\"98\":1,\"219\":1}}],[\"worked\",{\"1\":{\"225\":1}}],[\"workflow\",{\"1\":{\"212\":1}}],[\"workflows\",{\"1\":{\"101\":1}}],[\"work\",{\"1\":{\"3\":1,\"22\":1,\"29\":1,\"44\":3,\"49\":1,\"71\":1,\"93\":1,\"95\":1,\"115\":1,\"122\":1,\"130\":3,\"142\":1,\"146\":2,\"170\":1,\"194\":1,\"225\":1,\"226\":1,\"238\":1,\"239\":1,\"250\":3,\"251\":1,\"252\":1,\"258\":1,\"259\":1,\"263\":1,\"264\":2,\"265\":2,\"266\":1,\"269\":2,\"270\":1}}],[\"workshop\",{\"1\":{\"221\":1}}],[\"works\",{\"1\":{\"1\":1,\"2\":2,\"95\":1,\"122\":1,\"124\":1,\"141\":1,\"194\":2,\"210\":1,\"212\":1,\"233\":1,\"244\":1,\"269\":1}}],[\"word2vec\",{\"1\":{\"105\":2}}],[\"word\",{\"0\":{\"34\":1,\"82\":1,\"123\":1},\"1\":{\"1\":15,\"2\":5,\"8\":2,\"24\":1,\"33\":1,\"34\":1,\"51\":1,\"81\":4,\"82\":3,\"84\":1,\"89\":1,\"96\":1,\"105\":1,\"122\":1,\"123\":2,\"124\":4,\"197\":1,\"201\":1,\"209\":2,\"211\":1,\"212\":5,\"216\":2,\"218\":1,\"225\":2,\"228\":5,\"231\":3,\"233\":2,\"264\":4,\"266\":1,\"269\":2,\"271\":1}}],[\"words\",{\"0\":{\"83\":1},\"1\":{\"1\":7,\"2\":4,\"8\":1,\"9\":1,\"24\":2,\"31\":1,\"72\":1,\"82\":2,\"83\":3,\"94\":2,\"119\":1,\"122\":4,\"124\":5,\"126\":3,\"197\":1,\"211\":4,\"212\":7,\"218\":1,\"227\":1,\"228\":4,\"229\":1,\"231\":1,\"233\":2,\"264\":3,\"266\":4}}],[\"would\",{\"1\":{\"1\":3,\"2\":3,\"3\":4,\"58\":1,\"113\":1,\"123\":1,\"125\":1,\"130\":1,\"132\":1,\"137\":1,\"224\":1,\"231\":2,\"232\":1,\"233\":2}}],[\"whose\",{\"1\":{\"68\":1}}],[\"who\",{\"1\":{\"27\":1,\"68\":1,\"93\":3,\"95\":1,\"101\":1,\"228\":2}}],[\"whole\",{\"1\":{\"23\":1,\"54\":1,\"97\":1,\"137\":1,\"219\":1,\"244\":1,\"246\":1,\"268\":1}}],[\"why\",{\"1\":{\"1\":3,\"2\":1,\"71\":2,\"79\":1,\"152\":1,\"226\":1}}],[\"whew\",{\"1\":{\"234\":1}}],[\"whether\",{\"1\":{\"8\":1,\"24\":1,\"27\":2,\"43\":1,\"123\":1,\"124\":1,\"172\":1,\"231\":1}}],[\"when\",{\"1\":{\"1\":1,\"8\":1,\"21\":2,\"22\":2,\"23\":1,\"25\":2,\"43\":1,\"44\":2,\"71\":1,\"87\":1,\"93\":2,\"95\":2,\"100\":1,\"110\":1,\"120\":1,\"121\":1,\"122\":2,\"125\":3,\"126\":3,\"130\":1,\"166\":1,\"171\":1,\"172\":1,\"181\":1,\"201\":1,\"211\":1,\"212\":1,\"231\":1,\"232\":2,\"244\":2,\"251\":1,\"253\":1,\"254\":2,\"256\":1,\"259\":1,\"263\":1,\"268\":2}}],[\"whereas\",{\"1\":{\"98\":1,\"120\":1,\"215\":1}}],[\"where\",{\"1\":{\"1\":1,\"3\":1,\"4\":2,\"25\":1,\"33\":1,\"42\":2,\"59\":1,\"69\":1,\"71\":1,\"78\":1,\"83\":1,\"95\":1,\"101\":1,\"111\":1,\"112\":3,\"124\":2,\"125\":1,\"146\":1,\"175\":1,\"196\":2,\"197\":1,\"216\":1,\"228\":1,\"240\":1,\"242\":1,\"244\":1,\"251\":1,\"252\":1,\"253\":1,\"265\":1,\"266\":1,\"267\":1}}],[\"while\",{\"1\":{\"1\":1,\"3\":1,\"23\":1,\"29\":1,\"31\":1,\"42\":1,\"43\":2,\"54\":2,\"64\":1,\"65\":2,\"82\":1,\"94\":1,\"100\":1,\"105\":1,\"113\":1,\"122\":1,\"124\":2,\"126\":1,\"130\":1,\"131\":1,\"146\":3,\"172\":1,\"174\":1,\"175\":1,\"196\":1,\"197\":1,\"201\":1,\"203\":1,\"211\":1,\"212\":1,\"213\":1,\"217\":1,\"218\":2,\"219\":1,\"233\":1,\"240\":1,\"241\":1,\"253\":1,\"254\":1,\"263\":1,\"268\":1,\"269\":1}}],[\"which\",{\"1\":{\"0\":1,\"1\":3,\"2\":1,\"3\":6,\"4\":1,\"7\":1,\"8\":1,\"22\":2,\"24\":1,\"25\":1,\"27\":1,\"33\":1,\"36\":2,\"41\":2,\"42\":3,\"44\":1,\"49\":1,\"51\":3,\"57\":1,\"58\":1,\"60\":1,\"66\":2,\"68\":1,\"69\":4,\"71\":4,\"72\":1,\"78\":1,\"80\":1,\"84\":3,\"88\":1,\"93\":3,\"95\":1,\"96\":1,\"97\":3,\"98\":1,\"105\":3,\"109\":6,\"110\":1,\"111\":2,\"112\":1,\"113\":2,\"114\":1,\"115\":1,\"119\":2,\"124\":3,\"130\":1,\"132\":1,\"133\":1,\"135\":1,\"137\":1,\"141\":1,\"146\":5,\"152\":1,\"153\":1,\"156\":1,\"171\":1,\"172\":1,\"173\":1,\"179\":1,\"187\":1,\"188\":1,\"190\":1,\"194\":1,\"198\":1,\"209\":1,\"210\":1,\"211\":1,\"212\":1,\"214\":1,\"218\":2,\"224\":1,\"225\":1,\"226\":1,\"233\":1,\"240\":2,\"242\":1,\"244\":1,\"250\":1,\"251\":2,\"252\":1,\"253\":1,\"254\":1,\"257\":1,\"259\":1,\"264\":1,\"266\":1,\"268\":3,\"269\":1}}],[\"what\",{\"0\":{\"21\":1,\"77\":1,\"150\":1,\"202\":1,\"225\":1},\"1\":{\"1\":2,\"115\":1,\"126\":1,\"170\":1,\"172\":1,\"208\":1,\"225\":1,\"226\":1,\"228\":1,\"230\":2,\"233\":1,\"251\":2}}],[\"wai\",{\"1\":{\"235\":1}}],[\"waiting\",{\"1\":{\"101\":1,\"230\":1}}],[\"walking\",{\"1\":{\"219\":1}}],[\"ward\",{\"1\":{\"105\":1,\"221\":1}}],[\"wav2vec\",{\"1\":{\"102\":1,\"175\":1}}],[\"wav2vec2\",{\"1\":{\"96\":1,\"97\":2}}],[\"wave\",{\"1\":{\"97\":1}}],[\"watching\",{\"1\":{\"95\":1}}],[\"water\",{\"1\":{\"42\":1}}],[\"watermarked\",{\"1\":{\"43\":3,\"44\":1}}],[\"watermarks\",{\"1\":{\"41\":1,\"43\":1,\"44\":1}}],[\"watermark\",{\"1\":{\"41\":1,\"42\":5,\"43\":11,\"44\":4,\"45\":2}}],[\"watermarking\",{\"1\":{\"41\":2,\"42\":2,\"46\":1}}],[\"wang\",{\"1\":{\"46\":1,\"81\":1,\"89\":4,\"102\":1,\"143\":1,\"146\":1,\"167\":1,\"175\":2,\"203\":1,\"235\":2}}],[\"wanted\",{\"1\":{\"124\":1}}],[\"wants\",{\"1\":{\"22\":1,\"232\":1}}],[\"want\",{\"1\":{\"3\":1,\"69\":1,\"125\":1,\"126\":1,\"135\":1,\"160\":1,\"172\":1,\"228\":2,\"233\":1}}],[\"ways\",{\"1\":{\"101\":1,\"124\":1,\"202\":2}}],[\"way\",{\"1\":{\"1\":3,\"2\":1,\"23\":1,\"25\":1,\"31\":1,\"35\":1,\"51\":2,\"84\":1,\"93\":1,\"111\":1,\"120\":1,\"126\":1,\"130\":2,\"146\":1,\"155\":1,\"170\":1,\"211\":1,\"216\":1,\"227\":1,\"233\":1,\"239\":1,\"264\":1,\"270\":1}}],[\"washington\",{\"1\":{\"65\":1,\"74\":1,\"221\":1}}],[\"wasted\",{\"1\":{\"3\":1}}],[\"was\",{\"1\":{\"0\":1,\"3\":2,\"5\":2,\"21\":3,\"43\":6,\"71\":3,\"93\":4,\"95\":3,\"100\":2,\"119\":3,\"120\":1,\"121\":1,\"122\":3,\"123\":8,\"124\":15,\"125\":2,\"175\":4,\"208\":4,\"209\":1,\"228\":1,\"233\":1,\"234\":1}}],[\"windows\",{\"1\":{\"245\":1}}],[\"winning\",{\"1\":{\"217\":1}}],[\"winograd\",{\"1\":{\"124\":1}}],[\"wise\",{\"1\":{\"216\":4,\"238\":1,\"240\":1,\"241\":1}}],[\"wider\",{\"1\":{\"227\":1}}],[\"wide\",{\"1\":{\"96\":1,\"228\":1}}],[\"widespread\",{\"1\":{\"65\":1}}],[\"widely\",{\"0\":{\"5\":1},\"1\":{\"1\":1,\"78\":1,\"84\":1,\"105\":1,\"215\":1,\"225\":1,\"250\":1}}],[\"wiki\",{\"1\":{\"102\":1}}],[\"wikidata\",{\"1\":{\"53\":1}}],[\"wikipedia\",{\"1\":{\"53\":1,\"68\":1,\"71\":1,\"72\":2,\"93\":1,\"102\":1,\"178\":1}}],[\"will\",{\"1\":{\"0\":1,\"1\":5,\"2\":2,\"3\":1,\"6\":3,\"22\":1,\"23\":1,\"24\":6,\"35\":1,\"36\":1,\"42\":1,\"45\":3,\"65\":1,\"66\":2,\"68\":4,\"70\":1,\"71\":2,\"93\":1,\"95\":2,\"96\":1,\"109\":2,\"110\":2,\"111\":4,\"112\":1,\"113\":1,\"121\":1,\"125\":2,\"126\":1,\"130\":1,\"146\":4,\"197\":2,\"211\":3,\"212\":2,\"213\":1,\"215\":2,\"216\":4,\"224\":1,\"227\":1,\"231\":2,\"233\":3,\"241\":1,\"250\":1,\"251\":1,\"263\":1,\"266\":1,\"269\":1}}],[\"within\",{\"1\":{\"41\":1,\"43\":1,\"57\":1,\"59\":1,\"71\":1,\"126\":1,\"170\":1,\"172\":1,\"175\":1}}],[\"without\",{\"1\":{\"2\":1,\"25\":1,\"36\":1,\"41\":1,\"58\":1,\"59\":2,\"71\":1,\"78\":1,\"79\":1,\"86\":1,\"105\":1,\"120\":1,\"142\":1,\"146\":3,\"171\":1,\"172\":1,\"189\":1,\"200\":1,\"201\":1,\"202\":1,\"212\":1,\"218\":1,\"229\":1,\"239\":1,\"242\":1,\"244\":2,\"246\":1,\"253\":2,\"254\":1,\"263\":2,\"264\":2,\"269\":1,\"271\":1}}],[\"with\",{\"0\":{\"0\":1,\"2\":1,\"77\":1,\"224\":1,\"241\":1,\"257\":1},\"1\":{\"1\":8,\"2\":3,\"3\":11,\"5\":2,\"6\":1,\"8\":1,\"9\":1,\"21\":2,\"22\":2,\"23\":2,\"24\":2,\"25\":3,\"26\":1,\"34\":1,\"36\":2,\"41\":1,\"42\":5,\"43\":6,\"51\":5,\"54\":6,\"57\":1,\"58\":1,\"59\":1,\"60\":2,\"68\":2,\"71\":5,\"73\":1,\"78\":2,\"81\":1,\"82\":1,\"84\":2,\"86\":1,\"87\":1,\"89\":1,\"93\":3,\"94\":2,\"95\":1,\"96\":3,\"97\":1,\"100\":3,\"101\":1,\"105\":6,\"111\":5,\"112\":3,\"113\":3,\"114\":1,\"119\":2,\"121\":1,\"122\":2,\"123\":3,\"124\":5,\"125\":4,\"130\":1,\"132\":2,\"134\":1,\"137\":1,\"139\":1,\"142\":1,\"146\":10,\"153\":1,\"156\":1,\"164\":1,\"167\":1,\"172\":2,\"179\":1,\"181\":1,\"183\":1,\"184\":1,\"187\":2,\"188\":1,\"194\":1,\"197\":1,\"199\":1,\"200\":2,\"201\":2,\"202\":1,\"203\":3,\"209\":1,\"212\":5,\"213\":1,\"214\":2,\"215\":2,\"216\":1,\"217\":5,\"218\":8,\"219\":2,\"221\":4,\"224\":1,\"225\":1,\"227\":2,\"228\":4,\"229\":1,\"231\":2,\"232\":2,\"233\":3,\"234\":1,\"235\":1,\"239\":3,\"240\":2,\"241\":1,\"242\":2,\"244\":1,\"250\":2,\"251\":2,\"252\":2,\"253\":1,\"254\":2,\"258\":1,\"263\":1,\"265\":1,\"266\":3,\"267\":1,\"269\":3,\"270\":1}}],[\"weak\",{\"1\":{\"256\":1}}],[\"weaker\",{\"1\":{\"29\":1}}],[\"went\",{\"1\":{\"123\":1,\"125\":2}}],[\"wenc​​\",{\"1\":{\"112\":1}}],[\"wenc​∈rpenc​×m\",{\"1\":{\"112\":2}}],[\"weiqiu\",{\"1\":{\"247\":1}}],[\"weighted\",{\"1\":{\"240\":1}}],[\"weightedness\",{\"1\":{\"209\":1}}],[\"weighting\",{\"1\":{\"212\":3,\"218\":1}}],[\"weight\",{\"1\":{\"212\":3,\"216\":1}}],[\"weights\",{\"1\":{\"120\":2,\"146\":3,\"212\":1,\"216\":1,\"233\":1,\"239\":1,\"242\":3,\"245\":2,\"247\":1}}],[\"weiss\",{\"1\":{\"175\":1}}],[\"weinberger\",{\"1\":{\"105\":1,\"221\":1}}],[\"wei\",{\"1\":{\"105\":1,\"221\":1}}],[\"weijing\",{\"1\":{\"105\":1}}],[\"weird\",{\"1\":{\"71\":1}}],[\"website\",{\"1\":{\"218\":4,\"269\":1}}],[\"webtext\",{\"1\":{\"119\":1}}],[\"web\",{\"1\":{\"36\":1,\"41\":1,\"45\":1,\"218\":2}}],[\"weekend\",{\"1\":{\"125\":2}}],[\"week\",{\"1\":{\"22\":1,\"25\":1,\"101\":1}}],[\"weeks\",{\"1\":{\"22\":1}}],[\"were\",{\"1\":{\"3\":2,\"22\":1,\"43\":2,\"94\":2,\"97\":1,\"114\":1,\"122\":1,\"172\":1,\"208\":1,\"216\":1,\"218\":4,\"228\":2}}],[\"well\",{\"1\":{\"1\":1,\"3\":1,\"5\":1,\"22\":1,\"29\":1,\"35\":1,\"41\":1,\"42\":2,\"43\":2,\"44\":2,\"50\":1,\"71\":2,\"73\":1,\"84\":1,\"93\":1,\"98\":2,\"110\":1,\"113\":1,\"115\":1,\"124\":1,\"130\":1,\"152\":2,\"172\":1,\"194\":1,\"203\":2,\"209\":1,\"212\":1,\"215\":1,\"218\":1,\"226\":1,\"228\":1,\"269\":1}}],[\"we\",{\"1\":{\"0\":1,\"1\":16,\"2\":5,\"3\":8,\"4\":2,\"5\":1,\"6\":3,\"7\":1,\"8\":1,\"22\":3,\"24\":2,\"25\":3,\"30\":1,\"31\":1,\"35\":2,\"36\":1,\"51\":7,\"53\":2,\"54\":3,\"55\":1,\"57\":1,\"58\":1,\"60\":1,\"65\":2,\"66\":1,\"67\":1,\"68\":2,\"69\":2,\"70\":1,\"71\":7,\"79\":2,\"80\":3,\"82\":2,\"83\":1,\"84\":1,\"86\":1,\"88\":2,\"92\":1,\"93\":1,\"96\":1,\"101\":2,\"109\":4,\"110\":5,\"111\":9,\"112\":5,\"113\":3,\"114\":1,\"115\":2,\"119\":1,\"125\":8,\"126\":2,\"130\":1,\"135\":2,\"137\":1,\"146\":2,\"156\":1,\"170\":1,\"171\":1,\"172\":6,\"175\":1,\"178\":1,\"179\":2,\"182\":1,\"196\":2,\"200\":1,\"201\":2,\"202\":1,\"203\":1,\"212\":3,\"213\":1,\"215\":1,\"218\":7,\"219\":1,\"225\":1,\"226\":4,\"227\":1,\"230\":2,\"232\":6,\"233\":3,\"240\":1,\"241\":1,\"244\":3,\"245\":1,\"251\":1,\"252\":2,\"258\":1,\"266\":1,\"267\":1,\"269\":2}}],[\"tweets\",{\"1\":{\"228\":1}}],[\"two\",{\"1\":{\"3\":3,\"23\":2,\"24\":3,\"33\":1,\"42\":1,\"43\":1,\"51\":5,\"59\":1,\"66\":1,\"68\":1,\"71\":3,\"79\":1,\"93\":3,\"95\":1,\"97\":1,\"99\":1,\"101\":2,\"105\":2,\"109\":1,\"111\":1,\"112\":1,\"113\":2,\"124\":2,\"125\":1,\"130\":1,\"139\":1,\"183\":1,\"194\":1,\"196\":2,\"198\":1,\"202\":1,\"203\":1,\"208\":2,\"211\":2,\"213\":1,\"216\":1,\"217\":4,\"218\":3,\"219\":1,\"228\":2,\"231\":1,\"232\":1,\"244\":2,\"251\":1,\"253\":1,\"254\":2,\"263\":1,\"264\":3,\"268\":1}}],[\"tm\",{\"1\":{\"181\":4}}],[\"tmcn\",{\"1\":{\"179\":3}}],[\"tmen\",{\"1\":{\"179\":5}}],[\"t4\",{\"0\":{\"165\":1},\"1\":{\"157\":1}}],[\"tvm\",{\"1\":{\"152\":1}}],[\"t​\",{\"1\":{\"112\":1}}],[\"t¨attar\",{\"1\":{\"105\":2}}],[\"tst\",{\"1\":{\"99\":2}}],[\"tuple\",{\"1\":{\"96\":1}}],[\"turbotransformers\",{\"1\":{\"152\":1,\"153\":1}}],[\"turkish\",{\"1\":{\"95\":1,\"239\":1}}],[\"turned\",{\"1\":{\"166\":1}}],[\"turn\",{\"1\":{\"93\":1,\"227\":1}}],[\"turns\",{\"1\":{\"93\":1}}],[\"tutorial\",{\"1\":{\"78\":1,\"167\":1}}],[\"tunning\",{\"1\":{\"146\":1}}],[\"tuned\",{\"1\":{\"120\":1,\"124\":3,\"126\":2,\"146\":1,\"199\":2,\"252\":1}}],[\"tune\",{\"1\":{\"22\":1,\"23\":2}}],[\"tuning\",{\"1\":{\"18\":3,\"22\":5,\"23\":4,\"24\":2,\"25\":2,\"27\":1,\"36\":1,\"78\":1,\"119\":1,\"120\":3,\"252\":2}}],[\"t5\",{\"1\":{\"68\":1,\"71\":1}}],[\"t\",{\"1\":{\"65\":1,\"93\":1,\"98\":1,\"110\":1,\"125\":1,\"146\":2,\"196\":1,\"203\":1,\"229\":1,\"231\":1}}],[\"typical\",{\"1\":{\"71\":1,\"109\":1}}],[\"typically\",{\"1\":{\"41\":1,\"120\":1}}],[\"types\",{\"1\":{\"42\":1,\"51\":1,\"53\":1,\"120\":1,\"121\":1,\"213\":1,\"217\":1}}],[\"type\",{\"1\":{\"1\":1,\"51\":1,\"109\":1,\"120\":1,\"126\":1,\"218\":2}}],[\"tiiiger\",{\"1\":{\"220\":1}}],[\"tight\",{\"1\":{\"170\":1}}],[\"tightly\",{\"1\":{\"101\":1}}],[\"ti\",{\"1\":{\"146\":1}}],[\"till\",{\"1\":{\"111\":1,\"209\":1}}],[\"tianyi\",{\"1\":{\"105\":1,\"221\":1}}],[\"tiananmen\",{\"1\":{\"24\":3}}],[\"tieyan\",{\"1\":{\"89\":1}}],[\"tips\",{\"1\":{\"65\":1,\"81\":1}}],[\"time\",{\"1\":{\"1\":3,\"21\":1,\"64\":1,\"65\":1,\"71\":1,\"92\":1,\"94\":2,\"101\":1,\"122\":2,\"123\":1,\"124\":2,\"125\":2,\"126\":2,\"132\":1,\"155\":1,\"157\":1,\"171\":1,\"206\":1,\"208\":1,\"225\":1,\"228\":2,\"232\":1,\"238\":1,\"239\":1,\"250\":1}}],[\"timespan\",{\"1\":{\"228\":1}}],[\"times\",{\"1\":{\"1\":1,\"8\":1,\"50\":1,\"212\":1,\"216\":1,\"217\":2}}],[\"tr⇒en\",{\"1\":{\"244\":1}}],[\"trivial\",{\"1\":{\"269\":1}}],[\"tried\",{\"1\":{\"225\":2,\"244\":1}}],[\"tries\",{\"1\":{\"178\":1,\"268\":1}}],[\"trillion\",{\"1\":{\"119\":1,\"126\":1}}],[\"trick\",{\"1\":{\"112\":1}}],[\"trial\",{\"1\":{\"97\":1,\"98\":1}}],[\"triple\",{\"1\":{\"171\":1,\"175\":1}}],[\"triplet\",{\"1\":{\"105\":3,\"216\":2}}],[\"triples\",{\"1\":{\"54\":1}}],[\"trip\",{\"1\":{\"21\":1}}],[\"tree\",{\"1\":{\"71\":2}}],[\"treats\",{\"1\":{\"8\":1,\"179\":1}}],[\"truthfulness\",{\"1\":{\"65\":1}}],[\"truth\",{\"1\":{\"65\":1,\"105\":1,\"263\":1}}],[\"truly\",{\"1\":{\"36\":1,\"126\":1}}],[\"true\",{\"1\":{\"24\":1,\"101\":1,\"109\":4,\"203\":1}}],[\"trouve\",{\"1\":{\"31\":3}}],[\"trouver\",{\"1\":{\"31\":2}}],[\"trying\",{\"1\":{\"131\":1,\"228\":1,\"231\":1}}],[\"try\",{\"1\":{\"22\":1,\"36\":1,\"130\":1,\"132\":1,\"133\":1,\"146\":1,\"172\":1,\"231\":1,\"251\":1}}],[\"trajectory\",{\"1\":{\"252\":1}}],[\"travel\",{\"1\":{\"170\":1}}],[\"tranlation\",{\"1\":{\"126\":1}}],[\"transition\",{\"1\":{\"242\":6,\"246\":1}}],[\"transltion\",{\"1\":{\"200\":1}}],[\"translators\",{\"1\":{\"208\":1}}],[\"translator\",{\"1\":{\"95\":1,\"218\":3,\"225\":1}}],[\"translates\",{\"1\":{\"29\":1,\"179\":1,\"267\":1}}],[\"translate\",{\"1\":{\"8\":1,\"21\":1,\"27\":1,\"30\":1,\"92\":1,\"95\":1,\"98\":1,\"113\":3,\"122\":1,\"125\":5,\"130\":2,\"135\":1,\"137\":1,\"146\":1,\"170\":1,\"171\":1,\"172\":4,\"175\":4,\"194\":1,\"218\":3,\"225\":2,\"228\":2,\"231\":1,\"254\":2,\"267\":1,\"269\":1}}],[\"translated\",{\"1\":{\"8\":1,\"125\":1,\"179\":1,\"184\":1,\"190\":1,\"208\":1,\"218\":1,\"225\":1,\"232\":1,\"267\":2}}],[\"translating\",{\"1\":{\"1\":1,\"21\":1,\"113\":1,\"122\":2,\"125\":1,\"126\":3,\"171\":1,\"179\":1}}],[\"translations\",{\"1\":{\"93\":1,\"97\":1,\"105\":1,\"122\":1,\"125\":3,\"211\":1,\"217\":1,\"225\":1,\"226\":1,\"227\":1,\"228\":2,\"231\":3,\"233\":3,\"263\":3,\"269\":2,\"270\":2}}],[\"translation\",{\"0\":{\"0\":1,\"21\":1,\"23\":1,\"92\":1,\"94\":1,\"105\":1,\"108\":1,\"122\":1,\"130\":1,\"146\":1,\"170\":1,\"178\":1,\"179\":1,\"194\":1,\"201\":1,\"206\":1,\"224\":2,\"225\":1,\"228\":1,\"230\":1,\"233\":1,\"238\":1,\"252\":1,\"256\":1,\"257\":1,\"263\":1},\"1\":{\"0\":2,\"1\":5,\"2\":1,\"5\":2,\"7\":2,\"8\":3,\"9\":4,\"21\":1,\"22\":16,\"23\":9,\"24\":5,\"25\":4,\"27\":1,\"29\":1,\"30\":2,\"32\":1,\"33\":1,\"36\":6,\"37\":6,\"41\":1,\"92\":2,\"93\":13,\"95\":4,\"96\":1,\"97\":2,\"101\":3,\"102\":1,\"105\":11,\"109\":11,\"110\":2,\"111\":3,\"112\":1,\"113\":1,\"115\":2,\"116\":1,\"119\":1,\"121\":1,\"122\":2,\"125\":2,\"126\":1,\"130\":7,\"131\":2,\"132\":2,\"134\":2,\"136\":2,\"137\":1,\"141\":1,\"142\":1,\"143\":1,\"146\":11,\"151\":1,\"153\":1,\"160\":1,\"163\":1,\"164\":1,\"170\":7,\"171\":1,\"172\":11,\"173\":1,\"174\":1,\"175\":9,\"178\":2,\"179\":4,\"181\":1,\"183\":2,\"184\":6,\"186\":3,\"187\":3,\"188\":2,\"189\":1,\"190\":1,\"191\":1,\"194\":4,\"195\":1,\"196\":1,\"197\":1,\"198\":1,\"200\":1,\"201\":3,\"202\":5,\"203\":7,\"206\":1,\"208\":2,\"209\":1,\"213\":2,\"214\":2,\"215\":4,\"216\":3,\"217\":1,\"218\":7,\"219\":1,\"221\":6,\"224\":3,\"225\":3,\"226\":2,\"227\":4,\"228\":9,\"230\":1,\"231\":3,\"232\":1,\"233\":4,\"234\":2,\"235\":3,\"238\":1,\"239\":3,\"244\":2,\"246\":2,\"247\":1,\"250\":1,\"251\":2,\"252\":1,\"254\":1,\"259\":2,\"263\":5,\"264\":2,\"265\":1,\"267\":3,\"269\":2,\"271\":3},\"2\":{\"39\":1,\"104\":1,\"145\":1,\"177\":1,\"205\":1,\"237\":1,\"273\":1}}],[\"transcription\",{\"1\":{\"175\":5}}],[\"transcripts\",{\"1\":{\"100\":2}}],[\"transcript\",{\"1\":{\"100\":3}}],[\"transactions\",{\"1\":{\"37\":1}}],[\"transf\",{\"1\":{\"244\":5,\"245\":1}}],[\"transfer\",{\"1\":{\"37\":1}}],[\"transferred\",{\"1\":{\"24\":1,\"42\":1}}],[\"transforming\",{\"1\":{\"216\":1}}],[\"transformed\",{\"1\":{\"215\":1,\"233\":1}}],[\"transformers\",{\"1\":{\"37\":1,\"81\":1,\"119\":1,\"140\":1,\"151\":2,\"154\":1,\"155\":1,\"159\":1,\"161\":1,\"167\":2,\"247\":1}}],[\"transformer\",{\"0\":{\"119\":1},\"1\":{\"23\":1,\"24\":1,\"96\":2,\"97\":4,\"111\":1,\"112\":1,\"119\":2,\"137\":2,\"139\":1,\"141\":1,\"146\":8,\"149\":1,\"152\":3,\"153\":2,\"155\":2,\"156\":1,\"157\":1,\"163\":1,\"164\":1,\"194\":1,\"195\":1,\"196\":1,\"199\":1,\"200\":3,\"201\":1,\"203\":1,\"212\":1,\"238\":1,\"239\":3,\"240\":1,\"244\":3,\"246\":1,\"247\":2,\"252\":1,\"263\":2},\"2\":{\"169\":1,\"249\":1}}],[\"transforms\",{\"1\":{\"112\":1,\"212\":1,\"264\":2}}],[\"transform\",{\"1\":{\"84\":1,\"266\":1}}],[\"transformation\",{\"1\":{\"23\":1,\"24\":2,\"86\":1,\"112\":1,\"212\":1}}],[\"transport\",{\"1\":{\"0\":1,\"3\":3,\"8\":2},\"2\":{\"11\":1}}],[\"track\",{\"1\":{\"9\":1}}],[\"traditional\",{\"1\":{\"24\":2,\"170\":1,\"263\":1}}],[\"traditionally\",{\"1\":{\"8\":1}}],[\"trades\",{\"1\":{\"228\":1}}],[\"trade\",{\"1\":{\"3\":1}}],[\"traiend\",{\"1\":{\"112\":1}}],[\"trains\",{\"1\":{\"227\":1,\"231\":2}}],[\"trainable\",{\"1\":{\"96\":1,\"146\":1,\"181\":1,\"216\":2}}],[\"trained\",{\"0\":{\"33\":1,\"119\":1},\"1\":{\"22\":4,\"23\":1,\"24\":1,\"26\":1,\"27\":1,\"31\":1,\"41\":1,\"43\":3,\"70\":1,\"77\":2,\"78\":2,\"89\":1,\"105\":4,\"110\":1,\"113\":1,\"119\":4,\"121\":1,\"123\":1,\"124\":1,\"126\":3,\"146\":2,\"171\":1,\"184\":1,\"186\":1,\"188\":1,\"195\":1,\"208\":1,\"216\":2,\"217\":5,\"218\":3,\"251\":2,\"252\":1}}],[\"train\",{\"1\":{\"2\":1,\"22\":1,\"23\":2,\"27\":1,\"42\":1,\"72\":1,\"95\":1,\"109\":1,\"113\":3,\"122\":1,\"126\":1,\"137\":2,\"139\":1,\"146\":3,\"172\":1,\"179\":1,\"182\":1,\"183\":1,\"194\":1,\"199\":1,\"226\":1,\"227\":3,\"232\":2,\"252\":3}}],[\"training\",{\"0\":{\"21\":1,\"23\":1,\"27\":1,\"160\":1,\"163\":1,\"170\":1,\"182\":1,\"183\":1,\"250\":1,\"253\":1,\"254\":1},\"1\":{\"1\":3,\"4\":1,\"8\":1,\"18\":1,\"21\":1,\"22\":5,\"23\":13,\"24\":8,\"25\":8,\"26\":3,\"27\":8,\"33\":2,\"35\":2,\"36\":1,\"37\":6,\"41\":3,\"43\":1,\"44\":1,\"53\":1,\"54\":1,\"70\":1,\"80\":1,\"81\":1,\"89\":1,\"93\":4,\"94\":2,\"95\":6,\"97\":1,\"101\":1,\"105\":1,\"111\":2,\"113\":4,\"114\":1,\"115\":1,\"130\":3,\"137\":1,\"146\":2,\"149\":1,\"151\":1,\"152\":2,\"153\":3,\"154\":1,\"155\":1,\"160\":4,\"161\":1,\"167\":2,\"171\":2,\"172\":2,\"175\":1,\"178\":1,\"179\":1,\"182\":1,\"183\":1,\"194\":1,\"197\":1,\"199\":1,\"210\":1,\"214\":2,\"216\":1,\"219\":1,\"227\":3,\"228\":1,\"233\":1,\"244\":3,\"250\":3,\"251\":9,\"252\":6,\"253\":3,\"254\":3,\"258\":1,\"259\":5,\"260\":1,\"263\":2,\"265\":1,\"268\":1},\"2\":{\"20\":1,\"39\":1,\"91\":1,\"107\":1,\"129\":1,\"262\":1}}],[\"trail\",{\"1\":{\"1\":2}}],[\"techinques\",{\"1\":{\"203\":1}}],[\"techinque\",{\"1\":{\"203\":1}}],[\"technology\",{\"1\":{\"22\":1,\"36\":1}}],[\"technique\",{\"0\":{\"154\":1,\"212\":1,\"216\":1},\"1\":{\"22\":1,\"41\":1,\"68\":1,\"179\":1,\"197\":1,\"212\":1}}],[\"techniques\",{\"0\":{\"3\":1,\"24\":1,\"95\":1},\"1\":{\"50\":1,\"101\":1,\"119\":1,\"126\":1,\"134\":1,\"172\":1,\"219\":1}}],[\"technically\",{\"1\":{\"136\":1}}],[\"technical\",{\"1\":{\"14\":1,\"105\":1,\"130\":1,\"228\":1,\"233\":1}}],[\"temperature\",{\"1\":{\"196\":1}}],[\"temporal\",{\"1\":{\"94\":1,\"172\":1}}],[\"teším\",{\"1\":{\"125\":1}}],[\"teacher\",{\"1\":{\"251\":1}}],[\"teaching\",{\"1\":{\"37\":1}}],[\"team\",{\"1\":{\"124\":1}}],[\"tesla\",{\"1\":{\"97\":1,\"157\":1}}],[\"test2017\",{\"1\":{\"141\":1}}],[\"test2016\",{\"1\":{\"141\":1}}],[\"testing\",{\"1\":{\"111\":1,\"120\":3,\"121\":1}}],[\"tested\",{\"1\":{\"22\":1,\"122\":1,\"123\":1,\"124\":4,\"146\":1,\"228\":1,\"254\":1}}],[\"test\",{\"0\":{\"166\":1},\"1\":{\"7\":1,\"22\":1,\"26\":2,\"35\":2,\"53\":1,\"54\":4,\"55\":1,\"70\":1,\"71\":1,\"94\":1,\"113\":1,\"122\":1,\"123\":1,\"124\":3,\"125\":5,\"161\":1,\"173\":2,\"174\":1,\"175\":1,\"203\":1,\"213\":1,\"217\":1,\"256\":1,\"257\":3}}],[\"tests\",{\"1\":{\"2\":1,\"43\":1}}],[\"term\",{\"1\":{\"82\":2}}],[\"terms\",{\"1\":{\"1\":1,\"3\":1,\"5\":1,\"78\":1,\"84\":1,\"86\":1,\"105\":2,\"125\":1}}],[\"territory\",{\"1\":{\"71\":3}}],[\"tento\",{\"1\":{\"125\":1}}],[\"tensorrt\",{\"1\":{\"152\":1,\"153\":1}}],[\"tensorflow\",{\"1\":{\"152\":2,\"155\":1,\"161\":1,\"164\":1}}],[\"tens\",{\"1\":{\"25\":1,\"93\":1,\"94\":1}}],[\"ten\",{\"1\":{\"25\":1,\"93\":1,\"125\":1,\"244\":1,\"246\":1}}],[\"tends\",{\"1\":{\"31\":1,\"146\":2,\"253\":1}}],[\"tend\",{\"1\":{\"2\":2,\"8\":1}}],[\"teden\",{\"1\":{\"187\":1}}],[\"tedde\",{\"1\":{\"187\":1}}],[\"ted\",{\"1\":{\"4\":2,\"35\":1,\"173\":1,\"186\":3,\"203\":2}}],[\"tell\",{\"1\":{\"1\":1}}],[\"textbook\",{\"1\":{\"228\":2}}],[\"textural\",{\"1\":{\"132\":1}}],[\"textual\",{\"1\":{\"78\":1,\"85\":1,\"86\":1,\"88\":2,\"132\":1,\"134\":1,\"135\":2,\"137\":1,\"142\":1}}],[\"texts\",{\"1\":{\"43\":1,\"132\":1}}],[\"text\",{\"0\":{\"92\":1,\"123\":1},\"1\":{\"1\":6,\"2\":2,\"8\":2,\"23\":1,\"29\":1,\"30\":2,\"31\":2,\"32\":1,\"36\":1,\"41\":1,\"42\":1,\"49\":2,\"92\":1,\"93\":15,\"94\":5,\"95\":7,\"96\":2,\"100\":4,\"101\":3,\"102\":1,\"105\":7,\"121\":1,\"122\":1,\"124\":1,\"125\":1,\"126\":2,\"130\":2,\"136\":1,\"137\":2,\"139\":1,\"141\":1,\"142\":1,\"151\":2,\"153\":1,\"170\":2,\"171\":3,\"172\":1,\"175\":3,\"178\":1,\"181\":1,\"197\":1,\"210\":1,\"212\":1,\"221\":1,\"227\":2,\"232\":1,\"233\":1,\"250\":1,\"259\":1}}],[\"tay\",{\"1\":{\"247\":1}}],[\"tales\",{\"1\":{\"228\":1}}],[\"talk\",{\"1\":{\"113\":1,\"130\":1,\"186\":1,\"230\":1}}],[\"tau\",{\"1\":{\"217\":1}}],[\"tam\",{\"1\":{\"125\":1}}],[\"table\",{\"1\":{\"99\":2,\"120\":1,\"122\":1,\"141\":1,\"146\":2,\"152\":1,\"153\":1,\"174\":2,\"199\":1,\"200\":1,\"201\":1,\"202\":1,\"213\":2,\"217\":3,\"218\":2,\"244\":1,\"253\":2,\"254\":1,\"256\":1}}],[\"tables\",{\"1\":{\"99\":1,\"153\":2}}],[\"tao\",{\"1\":{\"89\":1}}],[\"tanh\",{\"1\":{\"242\":1}}],[\"tanslation\",{\"1\":{\"146\":1}}],[\"tan\",{\"1\":{\"89\":1}}],[\"tagger\",{\"1\":{\"67\":2}}],[\"tagging\",{\"1\":{\"43\":2}}],[\"tail\",{\"1\":{\"54\":1}}],[\"tackling\",{\"1\":{\"211\":1}}],[\"tackle\",{\"1\":{\"51\":1}}],[\"tacl\",{\"1\":{\"37\":1}}],[\"targets\",{\"1\":{\"253\":2}}],[\"target\",{\"1\":{\"24\":1,\"27\":7,\"29\":1,\"30\":1,\"31\":2,\"32\":1,\"92\":1,\"109\":1,\"110\":3,\"111\":3,\"135\":1,\"146\":3,\"170\":1,\"171\":1,\"172\":1,\"175\":1,\"181\":4,\"183\":1,\"184\":2,\"195\":1,\"196\":2,\"197\":1,\"210\":1,\"217\":2,\"228\":1,\"232\":4,\"245\":1,\"251\":1,\"263\":3,\"266\":1,\"267\":2,\"269\":1,\"270\":1}}],[\"task1\",{\"1\":{\"269\":1}}],[\"tasked\",{\"1\":{\"124\":2}}],[\"task\",{\"1\":{\"22\":1,\"23\":1,\"41\":2,\"43\":5,\"49\":1,\"51\":1,\"70\":1,\"80\":1,\"93\":1,\"95\":1,\"105\":1,\"109\":1,\"120\":8,\"121\":1,\"123\":5,\"124\":7,\"125\":1,\"126\":3,\"131\":2,\"132\":2,\"134\":1,\"135\":1,\"141\":1,\"160\":1,\"170\":1,\"171\":1,\"172\":1,\"174\":2,\"175\":1,\"197\":1,\"213\":1,\"217\":1,\"219\":2,\"227\":1,\"244\":1,\"252\":1,\"253\":1,\"254\":1,\"259\":1,\"265\":1}}],[\"tasks\",{\"0\":{\"121\":1},\"1\":{\"0\":1,\"3\":1,\"7\":2,\"8\":1,\"22\":3,\"23\":5,\"33\":2,\"41\":3,\"43\":5,\"78\":1,\"85\":1,\"87\":1,\"88\":1,\"93\":2,\"94\":1,\"96\":1,\"97\":1,\"98\":2,\"101\":2,\"111\":1,\"113\":1,\"115\":1,\"120\":2,\"121\":3,\"122\":1,\"124\":1,\"126\":2,\"132\":1,\"142\":1,\"151\":3,\"152\":1,\"153\":1,\"163\":1,\"171\":1,\"226\":1,\"232\":1,\"238\":2,\"239\":3,\"244\":1,\"246\":1,\"250\":2,\"251\":2,\"259\":1,\"263\":1,\"270\":1}}],[\"takens\",{\"1\":{\"212\":1}}],[\"taken\",{\"1\":{\"42\":1,\"233\":1}}],[\"takes\",{\"1\":{\"2\":1,\"24\":1,\"96\":1,\"97\":1,\"131\":1,\"228\":1,\"241\":1,\"242\":1,\"246\":1}}],[\"take\",{\"1\":{\"1\":1,\"2\":1,\"3\":1,\"24\":4,\"41\":1,\"92\":1,\"120\":1,\"124\":1,\"126\":1,\"141\":1,\"172\":1,\"184\":1,\"211\":1,\"216\":1,\"218\":2,\"263\":1,\"264\":1,\"269\":2}}],[\"taking\",{\"1\":{\"1\":1,\"2\":1,\"93\":1,\"175\":1,\"219\":1,\"233\":1}}],[\"toy\",{\"1\":{\"253\":1}}],[\"tong\",{\"1\":{\"247\":1}}],[\"tolerant\",{\"1\":{\"175\":1}}],[\"told\",{\"1\":{\"120\":1,\"263\":1}}],[\"torch\",{\"1\":{\"161\":1}}],[\"tomorrow\",{\"1\":{\"125\":2}}],[\"tom\",{\"1\":{\"116\":1,\"167\":1}}],[\"todd\",{\"1\":{\"105\":1,\"221\":1}}],[\"today\",{\"1\":{\"1\":1,\"125\":2,\"130\":1,\"170\":1,\"209\":1,\"225\":1}}],[\"tourists\",{\"1\":{\"95\":1}}],[\"tourism\",{\"1\":{\"95\":1}}],[\"toward\",{\"1\":{\"72\":1,\"208\":1}}],[\"towardsml\",{\"1\":{\"78\":1}}],[\"towards\",{\"1\":{\"36\":1,\"37\":1,\"101\":1,\"239\":1,\"252\":1}}],[\"topics\",{\"1\":{\"228\":3,\"229\":1}}],[\"topic\",{\"1\":{\"130\":1}}],[\"top\",{\"1\":{\"35\":1,\"146\":2,\"153\":1,\"156\":1,\"213\":1,\"218\":3}}],[\"totally\",{\"1\":{\"54\":1}}],[\"total\",{\"1\":{\"25\":2,\"35\":1,\"53\":1,\"93\":1,\"110\":2,\"269\":1}}],[\"tools\",{\"1\":{\"153\":1,\"225\":1}}],[\"took\",{\"1\":{\"125\":1}}],[\"too\",{\"1\":{\"3\":1,\"79\":1,\"105\":1,\"124\":1,\"228\":1,\"266\":1}}],[\"together\",{\"1\":{\"2\":1,\"42\":1,\"93\":2,\"94\":2,\"95\":1,\"105\":2,\"122\":1,\"134\":1,\"254\":1}}],[\"tokenwise\",{\"1\":{\"244\":1}}],[\"tokenizes\",{\"1\":{\"212\":1}}],[\"tokenized\",{\"1\":{\"26\":2,\"212\":2}}],[\"tokenization\",{\"0\":{\"2\":1},\"1\":{\"1\":1,\"8\":2}}],[\"token\",{\"1\":{\"1\":11,\"2\":1,\"8\":4,\"24\":2,\"35\":1,\"195\":1,\"196\":1,\"211\":1,\"212\":10,\"216\":5,\"239\":2,\"240\":1,\"245\":1}}],[\"tokens\",{\"1\":{\"1\":9,\"2\":1,\"25\":1,\"51\":1,\"156\":1,\"172\":1,\"212\":1,\"244\":1,\"245\":1,\"254\":1}}],[\"to\",{\"0\":{\"27\":1,\"77\":1,\"92\":1,\"171\":1,\"194\":1},\"1\":{\"1\":19,\"2\":15,\"3\":21,\"4\":1,\"5\":1,\"6\":5,\"7\":4,\"8\":11,\"21\":4,\"22\":7,\"23\":20,\"24\":14,\"25\":9,\"27\":4,\"28\":1,\"31\":2,\"33\":1,\"36\":8,\"37\":2,\"40\":1,\"41\":14,\"42\":10,\"43\":7,\"44\":2,\"45\":2,\"49\":1,\"50\":2,\"51\":14,\"54\":1,\"57\":1,\"59\":1,\"60\":3,\"64\":2,\"65\":8,\"66\":4,\"67\":4,\"68\":5,\"69\":3,\"70\":1,\"71\":14,\"72\":5,\"73\":2,\"74\":2,\"77\":1,\"78\":2,\"79\":3,\"81\":1,\"82\":5,\"83\":2,\"84\":4,\"86\":2,\"87\":1,\"92\":3,\"93\":22,\"94\":7,\"95\":14,\"96\":4,\"97\":4,\"98\":2,\"100\":7,\"101\":9,\"102\":1,\"105\":8,\"109\":21,\"110\":4,\"111\":10,\"112\":5,\"113\":7,\"114\":4,\"115\":5,\"119\":4,\"120\":11,\"121\":5,\"122\":9,\"123\":5,\"124\":20,\"125\":17,\"126\":12,\"130\":8,\"131\":2,\"132\":4,\"133\":1,\"135\":2,\"136\":2,\"137\":12,\"139\":2,\"140\":1,\"142\":3,\"146\":38,\"151\":1,\"152\":4,\"153\":1,\"154\":2,\"155\":2,\"156\":1,\"157\":3,\"159\":1,\"160\":1,\"163\":3,\"166\":2,\"170\":7,\"171\":17,\"172\":22,\"173\":2,\"174\":1,\"175\":12,\"178\":2,\"179\":3,\"181\":1,\"182\":1,\"183\":2,\"184\":6,\"188\":2,\"189\":2,\"190\":2,\"194\":7,\"195\":3,\"196\":8,\"197\":2,\"199\":1,\"200\":1,\"202\":3,\"203\":5,\"206\":1,\"208\":4,\"209\":3,\"210\":3,\"211\":7,\"212\":16,\"213\":5,\"214\":2,\"215\":4,\"216\":13,\"217\":4,\"218\":12,\"219\":9,\"224\":1,\"225\":9,\"226\":11,\"227\":8,\"228\":12,\"229\":3,\"231\":10,\"232\":9,\"233\":11,\"234\":2,\"238\":3,\"239\":4,\"240\":4,\"241\":2,\"242\":1,\"244\":4,\"245\":5,\"246\":1,\"250\":1,\"251\":8,\"252\":2,\"253\":8,\"254\":6,\"257\":3,\"258\":3,\"259\":3,\"263\":9,\"264\":11,\"265\":3,\"266\":7,\"267\":4,\"268\":6,\"269\":5,\"270\":2}}],[\"th\",{\"1\":{\"240\":4,\"242\":3}}],[\"thursday\",{\"1\":{\"30\":2}}],[\"thus\",{\"1\":{\"23\":1,\"72\":1,\"93\":1,\"94\":1,\"95\":1,\"111\":1,\"112\":1,\"133\":1,\"152\":1,\"172\":1,\"259\":1}}],[\"thousands\",{\"1\":{\"94\":1,\"226\":1}}],[\"thought\",{\"1\":{\"93\":1,\"125\":1}}],[\"though\",{\"1\":{\"1\":1,\"65\":1,\"71\":3,\"98\":1,\"123\":1,\"126\":1,\"209\":1,\"211\":1,\"218\":1,\"227\":1,\"231\":1}}],[\"thomas\",{\"1\":{\"37\":1}}],[\"those\",{\"1\":{\"6\":1,\"7\":1,\"8\":1,\"57\":2,\"59\":1,\"93\":2,\"95\":2,\"97\":1,\"146\":1,\"151\":1,\"152\":1,\"228\":1,\"263\":1}}],[\"thrust\",{\"1\":{\"153\":1}}],[\"three\",{\"1\":{\"4\":1,\"22\":2,\"24\":3,\"51\":1,\"65\":1,\"66\":1,\"69\":1,\"71\":1,\"93\":1,\"95\":2,\"100\":2,\"113\":1,\"134\":1,\"146\":1,\"152\":1,\"154\":1,\"165\":1,\"172\":1,\"203\":1,\"216\":3,\"240\":1,\"252\":1,\"254\":1,\"258\":1}}],[\"throughout\",{\"1\":{\"125\":1}}],[\"through\",{\"1\":{\"1\":1,\"2\":1,\"8\":1,\"22\":1,\"41\":1,\"42\":1,\"54\":1,\"78\":1,\"82\":1,\"84\":1,\"101\":1,\"125\":1,\"130\":1,\"182\":1,\"200\":1,\"203\":1,\"209\":1,\"218\":1,\"219\":1,\"229\":1,\"231\":1,\"232\":1,\"233\":1,\"259\":1}}],[\"thibault\",{\"1\":{\"105\":1}}],[\"thing\",{\"1\":{\"71\":1}}],[\"things\",{\"1\":{\"3\":1,\"125\":1,\"228\":1,\"238\":1}}],[\"third\",{\"1\":{\"24\":1,\"66\":1,\"71\":2,\"95\":1,\"119\":1,\"245\":1}}],[\"thirds\",{\"1\":{\"3\":2}}],[\"this\",{\"1\":{\"0\":1,\"1\":8,\"2\":3,\"3\":4,\"6\":1,\"8\":2,\"22\":2,\"23\":1,\"24\":1,\"36\":2,\"41\":2,\"42\":3,\"43\":1,\"44\":1,\"45\":3,\"49\":1,\"51\":2,\"60\":1,\"65\":2,\"66\":1,\"68\":1,\"71\":10,\"72\":2,\"73\":1,\"77\":1,\"79\":1,\"81\":1,\"82\":1,\"84\":2,\"93\":2,\"94\":4,\"95\":2,\"96\":3,\"98\":1,\"100\":1,\"105\":1,\"109\":4,\"110\":1,\"111\":6,\"112\":3,\"113\":4,\"115\":2,\"119\":2,\"120\":3,\"121\":1,\"122\":2,\"123\":2,\"124\":10,\"125\":5,\"126\":3,\"130\":7,\"132\":1,\"133\":1,\"142\":1,\"146\":6,\"151\":1,\"155\":1,\"156\":1,\"166\":1,\"172\":2,\"174\":1,\"178\":1,\"189\":1,\"190\":1,\"194\":2,\"195\":1,\"197\":2,\"200\":4,\"201\":1,\"203\":1,\"208\":1,\"211\":1,\"212\":1,\"213\":1,\"215\":1,\"216\":1,\"218\":7,\"224\":1,\"225\":4,\"226\":3,\"227\":4,\"228\":5,\"231\":5,\"232\":6,\"233\":7,\"234\":2,\"239\":4,\"240\":4,\"241\":1,\"245\":1,\"250\":1,\"251\":3,\"253\":3,\"256\":1,\"259\":1,\"263\":2,\"264\":3,\"265\":3,\"266\":2,\"268\":1,\"269\":5,\"270\":3}}],[\"tha\",{\"1\":{\"95\":1}}],[\"that\",{\"1\":{\"1\":9,\"2\":2,\"3\":6,\"4\":1,\"5\":3,\"6\":1,\"7\":1,\"21\":2,\"22\":2,\"23\":1,\"24\":5,\"25\":1,\"26\":2,\"27\":2,\"30\":1,\"31\":2,\"33\":2,\"34\":1,\"35\":6,\"41\":2,\"42\":2,\"43\":3,\"44\":1,\"45\":3,\"51\":2,\"54\":1,\"65\":3,\"66\":4,\"68\":1,\"69\":3,\"70\":1,\"71\":13,\"72\":2,\"79\":1,\"80\":2,\"81\":1,\"82\":2,\"83\":1,\"84\":1,\"85\":1,\"86\":1,\"92\":1,\"93\":3,\"94\":1,\"95\":4,\"98\":2,\"100\":1,\"101\":1,\"105\":3,\"109\":2,\"110\":4,\"111\":3,\"112\":3,\"113\":6,\"114\":4,\"120\":1,\"121\":3,\"124\":3,\"125\":1,\"126\":5,\"130\":5,\"132\":1,\"141\":1,\"146\":8,\"151\":1,\"152\":1,\"153\":1,\"154\":1,\"155\":1,\"170\":3,\"172\":4,\"174\":2,\"175\":1,\"179\":2,\"181\":1,\"183\":1,\"187\":1,\"188\":1,\"189\":1,\"190\":1,\"194\":1,\"195\":1,\"197\":1,\"200\":3,\"201\":2,\"202\":1,\"203\":2,\"208\":1,\"209\":1,\"211\":2,\"212\":2,\"214\":1,\"215\":2,\"216\":1,\"217\":1,\"218\":4,\"219\":2,\"225\":1,\"228\":6,\"231\":3,\"232\":6,\"233\":10,\"234\":1,\"238\":2,\"239\":3,\"241\":3,\"242\":1,\"244\":4,\"245\":2,\"251\":1,\"252\":3,\"253\":4,\"254\":2,\"257\":1,\"258\":4,\"259\":2,\"263\":3,\"264\":2,\"265\":1,\"266\":3,\"269\":6}}],[\"thanks\",{\"1\":{\"263\":1}}],[\"thank\",{\"1\":{\"229\":1,\"234\":1}}],[\"than\",{\"0\":{\"5\":1},\"1\":{\"1\":7,\"5\":1,\"6\":1,\"7\":1,\"25\":1,\"29\":1,\"35\":1,\"43\":1,\"53\":1,\"57\":1,\"71\":2,\"93\":4,\"95\":1,\"105\":2,\"109\":1,\"112\":1,\"120\":2,\"126\":1,\"146\":1,\"156\":1,\"187\":1,\"194\":1,\"200\":1,\"212\":1,\"216\":1,\"218\":1,\"225\":1,\"228\":1,\"231\":1,\"253\":2,\"257\":1}}],[\"theta\",{\"1\":{\"146\":4,\"266\":2}}],[\"theart\",{\"1\":{\"87\":1}}],[\"theoretically\",{\"1\":{\"80\":1}}],[\"theoretical\",{\"1\":{\"42\":1,\"80\":1,\"94\":1}}],[\"theory\",{\"1\":{\"37\":1,\"78\":1,\"96\":1,\"226\":1,\"232\":1}}],[\"theft\",{\"1\":{\"41\":1,\"42\":2,\"45\":3}}],[\"theirs\",{\"1\":{\"54\":1}}],[\"their\",{\"1\":{\"22\":1,\"30\":1,\"41\":1,\"45\":1,\"51\":1,\"78\":1,\"81\":1,\"83\":1,\"93\":1,\"95\":2,\"97\":1,\"98\":1,\"100\":1,\"111\":2,\"120\":1,\"122\":1,\"125\":1,\"130\":1,\"131\":1,\"181\":1,\"183\":1,\"190\":1,\"194\":1,\"197\":1,\"198\":1,\"199\":1,\"202\":1,\"203\":1,\"211\":1,\"212\":1,\"218\":2,\"225\":2,\"228\":1,\"232\":3,\"233\":2,\"239\":1,\"244\":1,\"264\":1,\"269\":3}}],[\"themes\",{\"1\":{\"170\":1}}],[\"themselves\",{\"1\":{\"41\":2}}],[\"them\",{\"0\":{\"77\":1},\"1\":{\"2\":1,\"3\":1,\"5\":1,\"23\":1,\"27\":2,\"41\":1,\"42\":1,\"51\":1,\"93\":1,\"94\":1,\"105\":1,\"114\":1,\"122\":1,\"125\":3,\"130\":1,\"156\":2,\"171\":1,\"196\":1,\"216\":1,\"231\":1,\"232\":1,\"233\":1,\"244\":1,\"263\":1}}],[\"then\",{\"1\":{\"1\":2,\"2\":2,\"3\":1,\"23\":2,\"24\":3,\"27\":1,\"35\":1,\"51\":3,\"66\":1,\"68\":1,\"71\":2,\"80\":1,\"93\":1,\"95\":2,\"105\":1,\"110\":1,\"111\":1,\"112\":1,\"113\":2,\"130\":2,\"134\":1,\"135\":1,\"137\":1,\"170\":1,\"171\":1,\"203\":1,\"226\":1,\"227\":2,\"228\":1,\"232\":2,\"233\":2,\"240\":2,\"251\":2,\"252\":1}}],[\"therefore\",{\"1\":{\"2\":1,\"23\":2,\"24\":2,\"51\":1,\"94\":1,\"146\":2,\"171\":1,\"194\":1,\"196\":1,\"200\":1,\"212\":1,\"263\":1,\"265\":2,\"269\":1,\"270\":1}}],[\"there\",{\"1\":{\"1\":3,\"2\":1,\"3\":2,\"22\":1,\"23\":2,\"24\":1,\"41\":1,\"45\":1,\"50\":1,\"69\":1,\"71\":1,\"72\":2,\"82\":1,\"84\":1,\"93\":2,\"95\":1,\"101\":1,\"105\":2,\"114\":1,\"119\":1,\"120\":1,\"124\":1,\"125\":2,\"126\":2,\"136\":1,\"154\":1,\"211\":1,\"212\":1,\"218\":1,\"225\":1,\"226\":1,\"241\":1,\"245\":1,\"251\":1,\"253\":1,\"263\":2,\"269\":1}}],[\"these\",{\"1\":{\"1\":3,\"2\":1,\"3\":2,\"5\":1,\"6\":1,\"8\":1,\"41\":5,\"42\":1,\"44\":1,\"51\":1,\"65\":2,\"66\":1,\"67\":1,\"69\":1,\"71\":2,\"79\":1,\"84\":1,\"93\":1,\"97\":1,\"101\":1,\"114\":2,\"120\":1,\"121\":1,\"123\":1,\"126\":2,\"130\":1,\"151\":1,\"171\":1,\"172\":1,\"194\":2,\"203\":1,\"208\":1,\"225\":1,\"226\":1,\"228\":2,\"229\":1,\"231\":1,\"232\":1,\"233\":1,\"250\":1}}],[\"they\",{\"1\":{\"1\":2,\"3\":1,\"22\":1,\"23\":2,\"27\":1,\"41\":1,\"43\":1,\"49\":1,\"51\":2,\"54\":1,\"68\":1,\"70\":1,\"78\":1,\"79\":1,\"93\":1,\"94\":2,\"95\":2,\"97\":1,\"98\":1,\"105\":5,\"113\":1,\"114\":1,\"120\":1,\"123\":1,\"124\":1,\"130\":6,\"131\":2,\"137\":4,\"139\":2,\"142\":1,\"146\":9,\"151\":1,\"152\":3,\"170\":1,\"183\":1,\"194\":3,\"195\":1,\"196\":1,\"198\":2,\"203\":4,\"227\":1,\"231\":1,\"232\":5,\"233\":1,\"244\":1,\"252\":3,\"253\":1,\"254\":3,\"259\":1,\"264\":2,\"266\":2}}],[\"the\",{\"0\":{\"27\":1,\"67\":1,\"71\":2,\"77\":1,\"81\":1,\"82\":1,\"112\":1,\"149\":1,\"170\":1,\"173\":1,\"202\":1,\"203\":1,\"241\":1,\"243\":1,\"253\":1,\"254\":1},\"1\":{\"0\":3,\"1\":39,\"2\":22,\"3\":59,\"4\":7,\"5\":5,\"6\":6,\"7\":3,\"8\":12,\"9\":3,\"21\":5,\"22\":19,\"23\":28,\"24\":41,\"25\":12,\"26\":2,\"27\":22,\"28\":3,\"29\":4,\"30\":10,\"31\":9,\"32\":4,\"33\":11,\"34\":7,\"35\":22,\"36\":19,\"37\":3,\"41\":22,\"42\":36,\"43\":22,\"44\":11,\"45\":5,\"49\":2,\"50\":6,\"51\":30,\"53\":2,\"54\":13,\"55\":4,\"57\":1,\"58\":2,\"59\":7,\"60\":5,\"65\":20,\"66\":17,\"67\":9,\"68\":24,\"69\":15,\"70\":5,\"71\":87,\"72\":13,\"73\":9,\"74\":1,\"77\":3,\"78\":2,\"79\":3,\"80\":6,\"81\":6,\"82\":9,\"83\":5,\"84\":9,\"85\":2,\"86\":1,\"87\":1,\"88\":4,\"89\":2,\"92\":1,\"93\":30,\"94\":19,\"95\":21,\"96\":19,\"97\":13,\"98\":6,\"99\":2,\"100\":18,\"101\":10,\"102\":1,\"105\":39,\"109\":25,\"110\":13,\"111\":30,\"112\":36,\"113\":26,\"114\":13,\"115\":7,\"119\":16,\"120\":18,\"121\":4,\"122\":15,\"123\":18,\"124\":28,\"125\":24,\"126\":13,\"130\":17,\"131\":6,\"132\":5,\"133\":5,\"134\":6,\"135\":5,\"136\":4,\"137\":20,\"139\":4,\"140\":5,\"141\":11,\"142\":1,\"146\":79,\"152\":6,\"153\":9,\"154\":3,\"155\":3,\"156\":5,\"157\":3,\"160\":3,\"163\":5,\"164\":3,\"165\":4,\"166\":4,\"167\":1,\"170\":8,\"171\":15,\"172\":20,\"173\":4,\"174\":17,\"175\":16,\"178\":3,\"179\":3,\"181\":5,\"182\":2,\"183\":8,\"184\":10,\"186\":1,\"187\":5,\"188\":5,\"189\":2,\"190\":2,\"194\":1,\"195\":4,\"196\":22,\"197\":10,\"198\":1,\"199\":4,\"200\":4,\"201\":6,\"202\":6,\"203\":15,\"206\":1,\"208\":16,\"209\":10,\"210\":5,\"211\":26,\"212\":34,\"213\":21,\"214\":5,\"215\":8,\"216\":44,\"217\":26,\"218\":62,\"219\":12,\"221\":3,\"224\":3,\"225\":10,\"226\":10,\"227\":12,\"228\":21,\"229\":1,\"230\":1,\"231\":13,\"232\":17,\"233\":30,\"234\":2,\"238\":5,\"239\":14,\"240\":35,\"241\":2,\"242\":28,\"244\":26,\"245\":21,\"246\":4,\"250\":4,\"251\":12,\"252\":23,\"253\":22,\"254\":12,\"256\":7,\"257\":3,\"258\":14,\"259\":1,\"263\":26,\"264\":26,\"265\":9,\"266\":32,\"267\":20,\"268\":17,\"269\":34,\"270\":3}}],[\"ft\",{\"1\":{\"252\":2}}],[\"f\",{\"1\":{\"226\":1,\"233\":2}}],[\"fbert\",{\"1\":{\"213\":2}}],[\"fdec​\",{\"1\":{\"110\":1,\"111\":2}}],[\"fly\",{\"1\":{\"242\":1}}],[\"fluent\",{\"1\":{\"174\":1}}],[\"fluently\",{\"1\":{\"95\":1}}],[\"flexible\",{\"1\":{\"152\":1,\"241\":1}}],[\"flexiblity\",{\"1\":{\"126\":1}}],[\"flexibility\",{\"1\":{\"41\":1}}],[\"flores\",{\"1\":{\"256\":4,\"257\":1}}],[\"florence\",{\"1\":{\"105\":1}}],[\"flows\",{\"1\":{\"84\":1}}],[\"flow\",{\"0\":{\"84\":1},\"1\":{\"77\":1,\"85\":1,\"86\":1,\"88\":2}}],[\"flattened\",{\"1\":{\"84\":1}}],[\"f1\",{\"1\":{\"54\":8,\"55\":1,\"57\":6,\"58\":3,\"212\":4,\"213\":1,\"218\":4}}],[\"futbal\",{\"1\":{\"125\":1}}],[\"future\",{\"0\":{\"72\":1},\"1\":{\"8\":1,\"72\":1,\"101\":2,\"142\":1,\"190\":1,\"218\":1,\"219\":1}}],[\"fusing\",{\"1\":{\"153\":1}}],[\"fusion\",{\"0\":{\"155\":1},\"1\":{\"94\":2,\"188\":1}}],[\"fused\",{\"1\":{\"134\":1}}],[\"fuse\",{\"1\":{\"93\":1,\"137\":1}}],[\"funny\",{\"1\":{\"71\":1}}],[\"functions\",{\"1\":{\"155\":4,\"232\":1,\"269\":1}}],[\"functional\",{\"1\":{\"94\":1}}],[\"function\",{\"1\":{\"42\":2,\"51\":1,\"172\":1,\"195\":1,\"226\":1,\"242\":1,\"254\":1,\"266\":1,\"267\":1,\"268\":1}}],[\"fund\",{\"1\":{\"29\":2,\"65\":2,\"74\":1}}],[\"fully\",{\"1\":{\"51\":1,\"80\":1,\"93\":1,\"101\":1,\"146\":1,\"190\":1,\"251\":1,\"253\":1}}],[\"full\",{\"1\":{\"27\":3,\"30\":1,\"98\":1,\"113\":2,\"152\":1,\"153\":1,\"233\":1}}],[\"fuzhou\",{\"1\":{\"21\":1,\"36\":1}}],[\"further\",{\"0\":{\"56\":1},\"1\":{\"3\":1,\"25\":1,\"34\":1,\"35\":2,\"67\":1,\"69\":1,\"73\":1,\"101\":1,\"135\":1,\"146\":2,\"179\":1,\"181\":1,\"184\":1,\"187\":1,\"212\":1,\"213\":1,\"219\":2,\"239\":1,\"252\":1,\"254\":1,\"263\":1,\"269\":1}}],[\"furthermore\",{\"1\":{\"2\":1,\"42\":1,\"119\":1,\"231\":1}}],[\"fake\",{\"1\":{\"227\":1}}],[\"facial\",{\"1\":{\"232\":1}}],[\"facebookresearch\",{\"1\":{\"269\":1}}],[\"facebook\",{\"1\":{\"263\":1,\"269\":1}}],[\"face\",{\"1\":{\"209\":1,\"211\":1}}],[\"factors\",{\"1\":{\"252\":1,\"258\":1}}],[\"factor\",{\"1\":{\"97\":1}}],[\"facts\",{\"1\":{\"53\":2,\"124\":1}}],[\"fact\",{\"1\":{\"2\":1,\"23\":1,\"24\":1,\"29\":1,\"64\":1,\"65\":3,\"68\":1,\"72\":1,\"74\":1,\"96\":1,\"121\":1,\"122\":1,\"197\":1,\"202\":1},\"2\":{\"76\":1}}],[\"fault\",{\"1\":{\"175\":1}}],[\"fair\",{\"1\":{\"263\":1}}],[\"fairseq+lightseq\",{\"1\":{\"163\":1}}],[\"fairseq\",{\"1\":{\"159\":1,\"160\":5}}],[\"failed\",{\"1\":{\"71\":1}}],[\"fails\",{\"1\":{\"71\":4,\"200\":1}}],[\"fail\",{\"1\":{\"49\":1,\"105\":1,\"211\":1,\"263\":1}}],[\"fall\",{\"1\":{\"244\":1}}],[\"fallen\",{\"1\":{\"219\":1}}],[\"falls\",{\"1\":{\"124\":1,\"141\":1}}],[\"false\",{\"1\":{\"71\":2,\"109\":2}}],[\"fascinating\",{\"1\":{\"232\":2}}],[\"fast\",{\"1\":{\"232\":1,\"247\":1}}],[\"fastness\",{\"1\":{\"209\":1}}],[\"fastertransformer\",{\"1\":{\"153\":1,\"164\":1}}],[\"faster\",{\"1\":{\"1\":1,\"8\":1,\"24\":1,\"152\":1,\"173\":1,\"247\":1}}],[\"fashion\",{\"1\":{\"96\":1}}],[\"fantastic\",{\"1\":{\"96\":1}}],[\"families\",{\"1\":{\"114\":1}}],[\"familiar\",{\"1\":{\"105\":1}}],[\"family\",{\"1\":{\"95\":1,\"146\":3,\"153\":1}}],[\"famous\",{\"1\":{\"95\":2}}],[\"fazah\",{\"1\":{\"93\":1}}],[\"favorable\",{\"1\":{\"84\":1,\"194\":1}}],[\"farinha\",{\"1\":{\"221\":1}}],[\"farabi\",{\"1\":{\"93\":1}}],[\"far\",{\"1\":{\"82\":1,\"196\":1,\"211\":1,\"228\":1,\"234\":1}}],[\"fr<\",{\"1\":{\"201\":1}}],[\"friend\",{\"1\":{\"123\":1}}],[\"friends\",{\"1\":{\"123\":1,\"125\":2}}],[\"fruitful\",{\"1\":{\"93\":1}}],[\"fruit\",{\"1\":{\"71\":1}}],[\"fragments\",{\"1\":{\"269\":1}}],[\"fragile\",{\"1\":{\"41\":1}}],[\"fraction\",{\"1\":{\"251\":1}}],[\"frames\",{\"1\":{\"94\":1}}],[\"framework\",{\"1\":{\"24\":1,\"95\":1,\"96\":2,\"102\":1,\"111\":1,\"137\":1,\"146\":1,\"175\":2,\"181\":1,\"188\":1,\"200\":1,\"202\":1,\"214\":1,\"215\":1,\"221\":1}}],[\"frameworks\",{\"1\":{\"23\":1,\"152\":4,\"155\":1}}],[\"france\",{\"1\":{\"36\":1,\"114\":1}}],[\"free\",{\"1\":{\"65\":1,\"74\":1,\"111\":1,\"218\":2,\"234\":1}}],[\"french\",{\"0\":{\"29\":1,\"31\":1},\"1\":{\"22\":1,\"23\":1,\"24\":5,\"25\":2,\"37\":1,\"97\":2,\"99\":2,\"113\":3,\"114\":1,\"173\":1,\"197\":1}}],[\"frequency\",{\"0\":{\"82\":1,\"83\":1},\"1\":{\"8\":1,\"42\":2,\"81\":1,\"82\":5,\"83\":3,\"84\":1,\"212\":2}}],[\"frequently\",{\"1\":{\"8\":1,\"25\":1}}],[\"frequent\",{\"1\":{\"2\":2}}],[\"fr\",{\"0\":{\"26\":1,\"29\":1,\"31\":1},\"1\":{\"13\":1,\"18\":1,\"26\":1,\"27\":1,\"97\":2,\"98\":1,\"114\":1,\"175\":1,\"199\":1,\"200\":1}}],[\"from\",{\"0\":{\"33\":1},\"1\":{\"0\":1,\"1\":5,\"2\":1,\"3\":1,\"4\":1,\"21\":2,\"22\":1,\"24\":1,\"25\":2,\"33\":2,\"35\":1,\"36\":4,\"37\":1,\"40\":1,\"41\":1,\"42\":2,\"43\":4,\"49\":2,\"53\":2,\"54\":1,\"66\":1,\"67\":2,\"71\":1,\"72\":1,\"77\":1,\"78\":1,\"82\":1,\"87\":1,\"89\":1,\"92\":1,\"93\":9,\"94\":2,\"95\":6,\"96\":3,\"97\":2,\"98\":1,\"100\":2,\"101\":1,\"113\":2,\"120\":2,\"122\":6,\"123\":2,\"124\":2,\"125\":4,\"126\":3,\"130\":2,\"131\":2,\"132\":2,\"134\":1,\"135\":1,\"137\":1,\"141\":2,\"146\":13,\"153\":1,\"159\":2,\"163\":1,\"164\":1,\"165\":1,\"166\":2,\"171\":1,\"178\":1,\"181\":1,\"183\":3,\"184\":3,\"186\":2,\"188\":1,\"194\":1,\"196\":2,\"197\":1,\"198\":1,\"200\":1,\"201\":1,\"203\":1,\"208\":2,\"210\":1,\"211\":1,\"212\":4,\"213\":1,\"214\":1,\"215\":2,\"216\":4,\"217\":1,\"218\":7,\"219\":1,\"224\":1,\"225\":1,\"226\":1,\"227\":2,\"228\":3,\"231\":1,\"232\":1,\"233\":2,\"235\":2,\"242\":1,\"244\":3,\"245\":1,\"252\":4,\"253\":3,\"254\":1,\"257\":1,\"264\":3,\"265\":1,\"266\":5,\"267\":1,\"268\":3,\"269\":2}}],[\"feng\",{\"1\":{\"235\":1}}],[\"fenc​\",{\"1\":{\"110\":1,\"111\":2}}],[\"feel\",{\"1\":{\"234\":1}}],[\"feedback\",{\"1\":{\"229\":1}}],[\"feedbacks\",{\"1\":{\"219\":1}}],[\"feed\",{\"1\":{\"51\":1,\"105\":1,\"216\":1,\"240\":1,\"242\":1}}],[\"fellow\",{\"1\":{\"224\":1}}],[\"felix\",{\"1\":{\"105\":1,\"221\":1}}],[\"fei\",{\"1\":{\"105\":1}}],[\"feira\",{\"1\":{\"30\":1}}],[\"fev\",{\"1\":{\"71\":2}}],[\"fever\",{\"1\":{\"70\":1,\"71\":2}}],[\"feb\",{\"1\":{\"65\":1,\"235\":1}}],[\"fed\",{\"1\":{\"51\":1,\"96\":1,\"125\":1,\"216\":1,\"218\":1,\"233\":1,\"240\":1}}],[\"features\",{\"1\":{\"2\":2,\"60\":2,\"93\":1,\"96\":3,\"134\":1,\"146\":2,\"152\":1,\"153\":1,\"171\":2,\"172\":2,\"174\":2}}],[\"feature\",{\"1\":{\"2\":1,\"98\":1,\"137\":3,\"140\":2,\"172\":1,\"216\":1}}],[\"fewer\",{\"1\":{\"112\":1,\"142\":1,\"173\":1,\"239\":1}}],[\"few\",{\"1\":{\"1\":2,\"3\":1,\"27\":1,\"36\":1,\"44\":1,\"120\":4,\"122\":1,\"123\":1,\"124\":3,\"125\":2,\"126\":3,\"127\":1,\"156\":1,\"167\":1,\"225\":1,\"231\":1,\"270\":1}}],[\"fool\",{\"1\":{\"268\":1}}],[\"football\",{\"1\":{\"125\":2}}],[\"fo\",{\"1\":{\"101\":1}}],[\"fonts\",{\"1\":{\"100\":1}}],[\"folk\",{\"1\":{\"95\":1,\"228\":1}}],[\"follow\",{\"1\":{\"53\":1,\"124\":1,\"137\":1}}],[\"followed\",{\"1\":{\"51\":1,\"240\":1,\"242\":1}}],[\"follows\",{\"1\":{\"24\":2,\"95\":1,\"96\":1,\"111\":1,\"245\":1}}],[\"following\",{\"1\":{\"1\":1,\"3\":1,\"4\":1,\"6\":1,\"25\":1,\"26\":1,\"30\":1,\"42\":1,\"51\":1,\"54\":1,\"69\":1,\"97\":1,\"98\":1,\"112\":1,\"121\":1,\"136\":1,\"146\":2,\"156\":1,\"160\":2,\"196\":1,\"202\":1,\"203\":1,\"239\":1,\"258\":1,\"266\":1,\"269\":4}}],[\"foi\",{\"1\":{\"30\":1}}],[\"fourth\",{\"1\":{\"105\":1,\"221\":1}}],[\"fourier\",{\"1\":{\"42\":1}}],[\"four\",{\"1\":{\"24\":2,\"27\":1,\"41\":1,\"43\":2,\"51\":1,\"209\":2,\"211\":1}}],[\"found\",{\"1\":{\"5\":1,\"31\":1,\"71\":1,\"146\":1,\"175\":1,\"187\":1,\"232\":1,\"233\":1,\"245\":1}}],[\"foundation\",{\"1\":{\"1\":1,\"94\":2}}],[\"focusing\",{\"1\":{\"213\":1}}],[\"focused\",{\"1\":{\"72\":1,\"194\":1}}],[\"focuses\",{\"1\":{\"2\":1,\"174\":1,\"245\":1}}],[\"focus\",{\"1\":{\"8\":1,\"24\":1,\"49\":1,\"68\":1,\"174\":1,\"194\":1,\"213\":1,\"239\":1,\"240\":1}}],[\"forget\",{\"1\":{\"228\":3}}],[\"forgetting\",{\"1\":{\"146\":1},\"2\":{\"20\":1}}],[\"forum\",{\"1\":{\"221\":1}}],[\"forced\",{\"1\":{\"146\":1,\"244\":1}}],[\"forcused\",{\"1\":{\"146\":1}}],[\"form\",{\"1\":{\"120\":1,\"226\":1}}],[\"formular\",{\"1\":{\"111\":1,\"212\":1}}],[\"formulation\",{\"1\":{\"82\":1,\"217\":1}}],[\"formulate\",{\"1\":{\"51\":1,\"253\":1}}],[\"formisano\",{\"1\":{\"102\":1}}],[\"formally\",{\"1\":{\"95\":1,\"196\":1,\"241\":1,\"267\":1}}],[\"formed\",{\"1\":{\"83\":1}}],[\"former\",{\"1\":{\"71\":1,\"211\":1,\"218\":1}}],[\"forward\",{\"1\":{\"36\":1,\"51\":1,\"101\":1,\"105\":1,\"125\":1,\"210\":1,\"216\":1,\"240\":1,\"242\":1}}],[\"foreign\",{\"1\":{\"36\":1,\"122\":3,\"126\":1,\"175\":1,\"211\":1,\"221\":2}}],[\"foram\",{\"1\":{\"30\":1}}],[\"for\",{\"0\":{\"0\":1,\"21\":1,\"58\":1,\"71\":1,\"92\":1,\"108\":1,\"146\":1,\"149\":1,\"170\":1,\"194\":1,\"206\":1,\"238\":1,\"250\":1},\"1\":{\"0\":3,\"1\":4,\"2\":4,\"3\":8,\"5\":1,\"7\":2,\"8\":1,\"9\":4,\"22\":9,\"23\":5,\"24\":7,\"25\":6,\"26\":1,\"27\":1,\"29\":1,\"30\":1,\"32\":3,\"33\":1,\"37\":6,\"41\":3,\"42\":9,\"43\":7,\"44\":1,\"45\":1,\"46\":1,\"49\":1,\"51\":3,\"53\":4,\"55\":1,\"58\":1,\"61\":1,\"65\":7,\"66\":3,\"67\":1,\"68\":4,\"69\":1,\"71\":14,\"72\":2,\"74\":1,\"78\":1,\"81\":1,\"84\":1,\"93\":13,\"94\":7,\"95\":2,\"96\":2,\"97\":3,\"98\":1,\"100\":1,\"101\":1,\"102\":2,\"105\":14,\"109\":4,\"110\":2,\"111\":3,\"112\":4,\"113\":6,\"114\":2,\"116\":2,\"119\":3,\"120\":10,\"121\":2,\"122\":2,\"123\":3,\"124\":1,\"125\":10,\"126\":6,\"130\":2,\"131\":2,\"134\":1,\"136\":2,\"137\":3,\"140\":2,\"141\":1,\"142\":2,\"146\":28,\"149\":1,\"151\":1,\"152\":5,\"153\":2,\"155\":3,\"156\":1,\"157\":1,\"159\":1,\"161\":1,\"167\":2,\"170\":2,\"171\":1,\"172\":4,\"174\":2,\"175\":4,\"178\":2,\"181\":1,\"182\":1,\"183\":1,\"186\":3,\"187\":1,\"190\":1,\"194\":2,\"196\":1,\"198\":3,\"200\":1,\"202\":1,\"203\":2,\"206\":1,\"208\":3,\"209\":1,\"210\":2,\"211\":3,\"212\":5,\"213\":4,\"214\":1,\"215\":1,\"216\":7,\"217\":3,\"218\":17,\"221\":3,\"225\":1,\"226\":9,\"227\":1,\"228\":4,\"229\":1,\"230\":1,\"231\":4,\"232\":7,\"233\":1,\"234\":1,\"239\":1,\"240\":1,\"245\":1,\"246\":1,\"247\":3,\"251\":1,\"252\":1,\"253\":4,\"254\":1,\"256\":1,\"258\":1,\"259\":1,\"260\":1,\"263\":3,\"264\":1,\"266\":1,\"269\":1,\"271\":1}}],[\"fidelity\",{\"1\":{\"208\":2}}],[\"fishel\",{\"1\":{\"105\":2}}],[\"fisrt\",{\"1\":{\"0\":1}}],[\"fixed\",{\"1\":{\"96\":2,\"146\":1}}],[\"fix\",{\"0\":{\"77\":1},\"1\":{\"77\":1}}],[\"fill\",{\"1\":{\"94\":1,\"227\":1}}],[\"film\",{\"1\":{\"71\":3}}],[\"filtered\",{\"1\":{\"35\":1}}],[\"fire\",{\"1\":{\"31\":1}}],[\"first\",{\"1\":{\"1\":1,\"3\":1,\"6\":1,\"22\":1,\"24\":2,\"51\":1,\"59\":1,\"66\":1,\"71\":5,\"72\":1,\"73\":1,\"80\":1,\"84\":1,\"93\":2,\"95\":2,\"105\":1,\"110\":1,\"111\":1,\"113\":2,\"141\":1,\"172\":1,\"174\":1,\"208\":1,\"216\":1,\"217\":1,\"226\":1,\"228\":1,\"231\":1,\"232\":1,\"240\":1,\"245\":2,\"252\":3,\"254\":1,\"264\":1,\"266\":1,\"269\":2}}],[\"firstly\",{\"1\":{\"1\":1,\"3\":1,\"187\":1,\"211\":1}}],[\"fields\",{\"1\":{\"109\":1,\"208\":1,\"263\":1}}],[\"field\",{\"1\":{\"22\":1,\"23\":1,\"93\":1,\"224\":1,\"269\":1}}],[\"final\",{\"1\":{\"43\":1,\"96\":1,\"146\":1,\"228\":1,\"233\":1,\"240\":1,\"251\":1}}],[\"finally\",{\"1\":{\"22\":1,\"31\":1,\"44\":1,\"66\":1,\"93\":1,\"130\":1,\"137\":1,\"219\":1,\"230\":2,\"240\":1,\"267\":1,\"268\":1,\"269\":1}}],[\"finetuning\",{\"1\":{\"78\":1}}],[\"fine\",{\"1\":{\"18\":3,\"22\":6,\"23\":6,\"24\":2,\"25\":2,\"27\":1,\"36\":1,\"67\":2,\"78\":1,\"119\":1,\"120\":4,\"124\":3,\"126\":2,\"146\":2,\"155\":1,\"199\":2,\"252\":3}}],[\"findings\",{\"0\":{\"33\":1,\"80\":1},\"1\":{\"46\":1,\"98\":1}}],[\"finding\",{\"1\":{\"31\":1,\"94\":1}}],[\"finds\",{\"1\":{\"3\":1,\"174\":1}}],[\"find\",{\"1\":{\"1\":5,\"2\":2,\"3\":5,\"8\":1,\"30\":1,\"31\":1,\"51\":1,\"80\":1,\"109\":1,\"112\":1,\"113\":1,\"114\":1,\"146\":3,\"218\":1,\"232\":2,\"245\":1}}],[\"figure\",{\"1\":{\"3\":2,\"6\":1,\"7\":1,\"23\":1,\"26\":1,\"35\":3,\"42\":2,\"50\":1,\"59\":1,\"66\":1,\"67\":1,\"71\":1,\"94\":1,\"95\":2,\"100\":2,\"114\":1,\"126\":1,\"146\":2,\"171\":1,\"172\":2,\"174\":2,\"203\":1,\"233\":1,\"240\":2,\"242\":1,\"244\":1,\"245\":2,\"251\":1,\"252\":1,\"254\":1,\"258\":1,\"265\":1,\"266\":2,\"267\":1,\"268\":1}}],[\"figures\",{\"1\":{\"3\":2,\"269\":1}}],[\"fitting\",{\"1\":{\"84\":1}}],[\"fit\",{\"1\":{\"3\":1}}],[\"a0\",{\"1\":{\"242\":1}}],[\"aa\",{\"1\":{\"194\":1,\"197\":3,\"201\":1,\"202\":2}}],[\"aaai\",{\"1\":{\"37\":1,\"74\":1,\"175\":1}}],[\"axes\",{\"1\":{\"165\":2}}],[\"axis\",{\"1\":{\"3\":4}}],[\"ako\",{\"1\":{\"125\":1}}],[\"away\",{\"1\":{\"82\":1,\"196\":2}}],[\"awards\",{\"1\":{\"224\":1}}],[\"awarded\",{\"1\":{\"0\":1}}],[\"aware\",{\"1\":{\"51\":1,\"54\":1,\"60\":1,\"137\":1,\"146\":2}}],[\"agnostic\",{\"1\":{\"194\":1,\"201\":2,\"203\":1,\"242\":1,\"254\":1}}],[\"agree\",{\"1\":{\"114\":1}}],[\"age\",{\"1\":{\"95\":2}}],[\"agenda\",{\"1\":{\"29\":3}}],[\"against\",{\"1\":{\"244\":2}}],[\"again\",{\"1\":{\"71\":1,\"124\":2}}],[\"ago\",{\"1\":{\"71\":1}}],[\"aggcn\",{\"1\":{\"54\":1}}],[\"aggregated\",{\"1\":{\"245\":1}}],[\"aggregates\",{\"1\":{\"73\":1}}],[\"aggregate\",{\"1\":{\"51\":1,\"66\":1,\"105\":1,\"265\":1}}],[\"aggregationand\",{\"1\":{\"60\":1}}],[\"aggregation\",{\"1\":{\"51\":2,\"69\":2,\"136\":1,\"137\":1}}],[\"avoid\",{\"1\":{\"109\":1,\"133\":1,\"157\":1,\"209\":1}}],[\"avoided\",{\"1\":{\"1\":1}}],[\"available\",{\"1\":{\"105\":1,\"133\":1,\"218\":1,\"225\":1,\"269\":2}}],[\"average\",{\"1\":{\"35\":1,\"53\":1,\"86\":1,\"124\":1,\"125\":1,\"126\":1,\"146\":2,\"196\":1,\"200\":1,\"201\":1,\"216\":1,\"244\":1}}],[\"averaged\",{\"1\":{\"35\":1}}],[\"apart\",{\"1\":{\"146\":1,\"213\":1}}],[\"api\",{\"1\":{\"41\":1}}],[\"apis\",{\"1\":{\"41\":1}}],[\"après\",{\"1\":{\"31\":2}}],[\"appealing\",{\"1\":{\"218\":1}}],[\"appear\",{\"1\":{\"35\":1,\"50\":1}}],[\"appeared\",{\"1\":{\"22\":1,\"27\":2,\"35\":1,\"71\":1,\"200\":1,\"210\":1,\"239\":1}}],[\"approximate\",{\"1\":{\"182\":1,\"226\":2}}],[\"appropriate\",{\"1\":{\"105\":1,\"225\":1}}],[\"approach\",{\"1\":{\"24\":1,\"120\":1,\"146\":1,\"209\":1,\"214\":1}}],[\"appreciate\",{\"1\":{\"95\":1}}],[\"applcation\",{\"1\":{\"131\":1}}],[\"apple\",{\"1\":{\"72\":1}}],[\"applicant\",{\"1\":{\"124\":1}}],[\"applicable\",{\"1\":{\"25\":1,\"142\":1}}],[\"applications\",{\"1\":{\"49\":1,\"93\":1,\"151\":1,\"153\":1,\"170\":2}}],[\"application\",{\"1\":{\"23\":1,\"119\":1,\"130\":1}}],[\"applied\",{\"1\":{\"25\":1,\"36\":1,\"115\":1,\"126\":1,\"195\":1,\"240\":1}}],[\"applies\",{\"1\":{\"8\":1,\"266\":1}}],[\"applying\",{\"1\":{\"23\":1,\"78\":1,\"212\":2,\"216\":1,\"239\":1,\"252\":1,\"267\":1}}],[\"apply\",{\"1\":{\"3\":1,\"41\":1,\"95\":2,\"105\":1,\"111\":1,\"146\":1,\"195\":1,\"203\":1,\"212\":1,\"244\":1,\"254\":2}}],[\"aid\",{\"1\":{\"187\":1}}],[\"aidan\",{\"1\":{\"102\":1}}],[\"aim\",{\"1\":{\"65\":1,\"79\":1,\"105\":1}}],[\"aime\",{\"1\":{\"24\":4,\"196\":1}}],[\"aims\",{\"1\":{\"1\":2,\"22\":1,\"41\":1,\"51\":1,\"93\":1,\"146\":1,\"183\":1,\"210\":1,\"215\":1,\"218\":1}}],[\"ai\",{\"1\":{\"23\":1,\"40\":1,\"93\":1,\"263\":1,\"269\":1}}],[\"auli\",{\"1\":{\"102\":1}}],[\"auxiliary\",{\"1\":{\"98\":1}}],[\"augment\",{\"1\":{\"250\":1,\"251\":1}}],[\"augmentation\",{\"0\":{\"197\":1},\"1\":{\"137\":1,\"194\":1,\"197\":4,\"202\":1,\"203\":2}}],[\"augmented\",{\"1\":{\"97\":1,\"98\":1,\"101\":1,\"173\":1,\"228\":1,\"235\":1}}],[\"augmenting\",{\"1\":{\"93\":1,\"105\":1}}],[\"august\",{\"1\":{\"9\":2,\"218\":3}}],[\"auditory\",{\"1\":{\"94\":3,\"171\":1}}],[\"audio\",{\"1\":{\"93\":13,\"94\":3,\"95\":5,\"97\":1,\"100\":1,\"101\":1,\"171\":2,\"172\":4,\"175\":1}}],[\"audiences\",{\"1\":{\"65\":1}}],[\"auc\",{\"1\":{\"54\":2}}],[\"authros\",{\"1\":{\"211\":1}}],[\"author\",{\"1\":{\"33\":1,\"256\":1}}],[\"authors\",{\"1\":{\"22\":2,\"28\":1,\"93\":1,\"105\":1,\"110\":1,\"112\":2,\"113\":4,\"114\":1,\"146\":12,\"197\":1,\"202\":1,\"203\":1,\"211\":2,\"212\":1,\"215\":1,\"216\":1,\"217\":1,\"244\":1,\"252\":1,\"253\":1,\"254\":1,\"258\":1,\"270\":1}}],[\"automated\",{\"1\":{\"215\":2,\"219\":1}}],[\"automation\",{\"1\":{\"209\":1}}],[\"automatically\",{\"1\":{\"206\":1}}],[\"automatic\",{\"0\":{\"64\":1,\"105\":1,\"209\":1},\"1\":{\"105\":2,\"208\":1,\"210\":1,\"221\":3}}],[\"autoregressively\",{\"1\":{\"263\":1}}],[\"autoregressive\",{\"1\":{\"119\":1}}],[\"autocoding\",{\"1\":{\"23\":1}}],[\"auto\",{\"0\":{\"156\":1},\"1\":{\"23\":1,\"84\":1,\"113\":1,\"156\":1}}],[\"african\",{\"1\":{\"95\":1}}],[\"aforementioned\",{\"1\":{\"95\":1,\"141\":1}}],[\"afternoon\",{\"1\":{\"125\":1}}],[\"after\",{\"1\":{\"21\":1,\"23\":1,\"24\":2,\"27\":2,\"31\":1,\"33\":1,\"35\":2,\"42\":1,\"43\":1,\"95\":1,\"111\":1,\"131\":1,\"146\":1,\"153\":1,\"172\":1,\"215\":1,\"216\":2,\"233\":2,\"267\":1,\"269\":1}}],[\"affected\",{\"1\":{\"43\":1}}],[\"affects\",{\"1\":{\"8\":1,\"42\":1}}],[\"affect\",{\"1\":{\"3\":1,\"43\":1}}],[\"amplify\",{\"1\":{\"146\":1}}],[\"ambiguous\",{\"1\":{\"124\":1,\"139\":1}}],[\"amd\",{\"1\":{\"99\":1}}],[\"american\",{\"1\":{\"21\":1}}],[\"among\",{\"1\":{\"5\":1,\"24\":1,\"49\":1,\"51\":5,\"54\":3,\"57\":1,\"60\":1,\"96\":1,\"101\":1,\"109\":4,\"114\":1,\"189\":1,\"212\":1}}],[\"amounts\",{\"1\":{\"41\":1,\"227\":2,\"251\":1}}],[\"amount\",{\"1\":{\"1\":2,\"3\":2,\"21\":1,\"22\":2,\"23\":2,\"93\":1,\"94\":1,\"98\":1,\"120\":1,\"170\":2,\"171\":1,\"178\":1,\"203\":1,\"225\":1,\"269\":1}}],[\"academy\",{\"1\":{\"221\":2}}],[\"acoustics\",{\"1\":{\"175\":1}}],[\"acoustic\",{\"1\":{\"170\":1,\"171\":3,\"172\":3,\"174\":6,\"175\":2}}],[\"acm\",{\"1\":{\"167\":1}}],[\"achiveved\",{\"1\":{\"113\":1}}],[\"achieves\",{\"1\":{\"25\":1,\"27\":1,\"146\":2,\"173\":1,\"194\":1,\"200\":1,\"201\":1,\"203\":1}}],[\"achieved\",{\"1\":{\"22\":1,\"23\":2,\"25\":1,\"81\":1,\"113\":1,\"124\":1,\"126\":2,\"244\":1,\"263\":1,\"269\":1}}],[\"achieve\",{\"1\":{\"2\":1,\"23\":1,\"27\":1,\"71\":1,\"124\":1,\"146\":1,\"170\":1,\"171\":1,\"201\":1,\"251\":1,\"263\":1,\"264\":1}}],[\"acquire\",{\"1\":{\"93\":1,\"98\":1,\"251\":1}}],[\"acts\",{\"1\":{\"251\":1}}],[\"act\",{\"1\":{\"137\":1}}],[\"action\",{\"1\":{\"115\":1}}],[\"activation\",{\"1\":{\"140\":1,\"242\":1}}],[\"activated\",{\"1\":{\"94\":1}}],[\"active\",{\"1\":{\"94\":1}}],[\"actively\",{\"1\":{\"71\":1}}],[\"activities\",{\"1\":{\"94\":1}}],[\"actor\",{\"1\":{\"71\":1}}],[\"acta\",{\"1\":{\"30\":1}}],[\"actual\",{\"1\":{\"22\":1,\"120\":1,\"215\":1}}],[\"actually\",{\"1\":{\"5\":1,\"96\":1,\"120\":1,\"215\":1,\"228\":1,\"264\":1}}],[\"accidentally\",{\"1\":{\"229\":1}}],[\"accross\",{\"1\":{\"109\":1}}],[\"accompany\",{\"1\":{\"146\":1}}],[\"accompanied\",{\"1\":{\"21\":2}}],[\"accounts\",{\"1\":{\"253\":1}}],[\"account\",{\"1\":{\"124\":1}}],[\"according\",{\"1\":{\"24\":1,\"81\":1,\"82\":1,\"93\":1,\"95\":1,\"97\":1,\"105\":1,\"109\":2,\"111\":1,\"227\":1,\"253\":1,\"257\":1}}],[\"accuracy\",{\"1\":{\"35\":10,\"42\":3,\"43\":5,\"67\":1,\"71\":3,\"119\":1,\"121\":1,\"123\":1,\"124\":4,\"174\":2}}],[\"accurately\",{\"1\":{\"93\":1,\"105\":1,\"122\":1,\"125\":1}}],[\"accurate\",{\"1\":{\"24\":1,\"124\":1,\"200\":1,\"206\":1,\"225\":1}}],[\"accumulated\",{\"1\":{\"23\":1,\"244\":1,\"251\":1}}],[\"acceptance\",{\"1\":{\"269\":1}}],[\"accepted\",{\"1\":{\"5\":1}}],[\"access\",{\"1\":{\"218\":1,\"233\":1}}],[\"acceleration\",{\"1\":{\"152\":1,\"165\":1},\"2\":{\"169\":1}}],[\"accelerating\",{\"0\":{\"149\":1}}],[\"accelerate\",{\"1\":{\"24\":1,\"153\":1}}],[\"accent\",{\"1\":{\"36\":1}}],[\"across\",{\"1\":{\"7\":1,\"24\":2,\"33\":2,\"34\":2,\"43\":1,\"49\":1,\"51\":1,\"59\":1,\"60\":1,\"65\":1,\"93\":1,\"98\":1,\"100\":1,\"101\":1,\"109\":1,\"196\":1,\"212\":1,\"213\":1,\"232\":1,\"242\":1}}],[\"aclanthology\",{\"1\":{\"224\":1,\"238\":1}}],[\"acl\",{\"1\":{\"0\":1,\"9\":1,\"37\":1,\"61\":1,\"102\":1,\"146\":2,\"203\":1,\"221\":2,\"224\":2,\"235\":1,\"247\":1}}],[\"adjusted\",{\"1\":{\"233\":1}}],[\"adjacent\",{\"1\":{\"196\":1,\"245\":2}}],[\"adjective\",{\"1\":{\"67\":2}}],[\"adapatation\",{\"1\":{\"109\":1}}],[\"adaptively\",{\"1\":{\"247\":1}}],[\"adapted\",{\"1\":{\"109\":1}}],[\"adapt\",{\"1\":{\"21\":1,\"146\":1,\"231\":2}}],[\"admin\",{\"1\":{\"65\":1,\"74\":1}}],[\"advertising\",{\"1\":{\"218\":3}}],[\"adversarial\",{\"1\":{\"137\":2,\"268\":1}}],[\"adversaries\",{\"1\":{\"42\":1}}],[\"adversary\",{\"1\":{\"42\":1,\"44\":1}}],[\"advisory\",{\"1\":{\"208\":1,\"221\":1}}],[\"advanced\",{\"1\":{\"101\":1,\"219\":2,\"233\":1}}],[\"advance\",{\"1\":{\"65\":1,\"74\":1,\"101\":1,\"105\":1,\"224\":1,\"227\":1,\"232\":1}}],[\"advances\",{\"1\":{\"37\":1,\"102\":2,\"167\":1,\"175\":1,\"234\":1,\"247\":1}}],[\"advantages\",{\"1\":{\"1\":1,\"4\":1,\"22\":1,\"25\":1,\"26\":1,\"31\":1,\"93\":2,\"98\":1,\"120\":2}}],[\"advantage\",{\"1\":{\"1\":1,\"93\":1,\"211\":1,\"216\":1,\"233\":1}}],[\"adoptes\",{\"1\":{\"196\":1}}],[\"adopted\",{\"1\":{\"24\":1,\"68\":1,\"188\":1,\"215\":1}}],[\"adopts\",{\"1\":{\"72\":1,\"181\":1,\"182\":1,\"190\":1}}],[\"adopt\",{\"1\":{\"24\":1,\"139\":1,\"146\":1}}],[\"adds\",{\"1\":{\"172\":1}}],[\"address\",{\"1\":{\"66\":1,\"68\":1,\"84\":1,\"98\":1,\"133\":1,\"188\":1}}],[\"added\",{\"1\":{\"43\":1,\"195\":1,\"233\":1,\"252\":1}}],[\"additionally\",{\"1\":{\"43\":1,\"171\":1}}],[\"additional\",{\"1\":{\"24\":1,\"93\":1,\"94\":1,\"98\":1,\"101\":1,\"120\":1,\"152\":1,\"172\":1,\"179\":1,\"210\":1,\"212\":1,\"214\":1,\"219\":1}}],[\"addition\",{\"1\":{\"8\":1,\"71\":1,\"130\":1,\"181\":1,\"198\":1,\"200\":1,\"231\":1}}],[\"adding\",{\"1\":{\"1\":1}}],[\"add\",{\"1\":{\"1\":3,\"105\":1,\"155\":1,\"212\":1,\"266\":1}}],[\"abel\",{\"1\":{\"235\":1}}],[\"abroad\",{\"1\":{\"211\":1}}],[\"abdelrahman\",{\"1\":{\"102\":1}}],[\"ablation\",{\"0\":{\"55\":1,\"188\":1},\"1\":{\"55\":1,\"60\":1,\"98\":1,\"113\":1,\"202\":1,\"252\":1,\"254\":1}}],[\"able\",{\"1\":{\"21\":1,\"59\":1,\"72\":1,\"86\":1,\"121\":1,\"122\":1,\"125\":1,\"126\":1,\"146\":1,\"152\":1,\"157\":1,\"163\":1,\"172\":1,\"194\":1,\"211\":1,\"212\":1,\"226\":1,\"228\":2,\"231\":1,\"252\":1,\"257\":1,\"263\":1,\"266\":1,\"267\":1,\"269\":1}}],[\"about\",{\"1\":{\"27\":1,\"53\":1,\"64\":1,\"71\":1,\"92\":1,\"93\":1,\"113\":1,\"114\":1,\"124\":1,\"130\":2,\"206\":1,\"212\":1,\"228\":1,\"230\":1,\"233\":1,\"238\":1,\"239\":1,\"250\":1}}],[\"above\",{\"1\":{\"1\":1,\"2\":2,\"3\":1,\"6\":1,\"23\":1,\"24\":1,\"59\":1,\"66\":1,\"67\":2,\"69\":3,\"71\":3,\"94\":1,\"95\":2,\"96\":1,\"100\":2,\"111\":1,\"120\":1,\"123\":1,\"124\":1,\"133\":1,\"141\":1,\"153\":1,\"163\":1,\"164\":1,\"166\":1,\"199\":1,\"200\":1,\"201\":1,\"231\":1,\"233\":1,\"234\":1,\"240\":2,\"242\":1,\"245\":1,\"251\":1,\"252\":1,\"253\":2,\"256\":1,\"258\":1,\"268\":1}}],[\"abundant\",{\"1\":{\"24\":1}}],[\"absolute\",{\"1\":{\"216\":1}}],[\"abstract\",{\"1\":{\"24\":1,\"142\":1}}],[\"abs\",{\"1\":{\"12\":1,\"21\":1,\"41\":1,\"46\":1,\"49\":1,\"64\":1,\"77\":1,\"143\":1,\"146\":1,\"250\":1}}],[\"ability\",{\"1\":{\"3\":1,\"24\":3,\"71\":1,\"94\":1,\"95\":1,\"98\":1,\"120\":1,\"122\":1,\"123\":1,\"124\":3,\"126\":1,\"139\":1,\"266\":1}}],[\"abilities\",{\"1\":{\"1\":1,\"21\":1}}],[\"albeit\",{\"1\":{\"258\":1}}],[\"albert\",{\"1\":{\"112\":1,\"116\":1}}],[\"alpac\",{\"1\":{\"208\":2,\"221\":1}}],[\"alpha\",{\"1\":{\"146\":1}}],[\"alice\",{\"1\":{\"123\":2}}],[\"aligns\",{\"1\":{\"203\":1}}],[\"align\",{\"1\":{\"101\":1,\"203\":2,\"264\":1}}],[\"aligned\",{\"0\":{\"197\":1},\"1\":{\"97\":1,\"197\":2,\"203\":2,\"231\":1},\"2\":{\"39\":1,\"205\":1}}],[\"alignment\",{\"0\":{\"203\":1},\"1\":{\"24\":1,\"37\":1,\"194\":1,\"203\":1,\"232\":1,\"264\":1}}],[\"altogether\",{\"1\":{\"244\":1}}],[\"alternatvie\",{\"1\":{\"146\":1}}],[\"alternative\",{\"1\":{\"179\":1}}],[\"alternatively\",{\"1\":{\"137\":1,\"212\":1}}],[\"alternating\",{\"1\":{\"119\":1}}],[\"although\",{\"1\":{\"41\":1,\"45\":1,\"71\":1,\"93\":1,\"94\":1,\"112\":1,\"179\":1,\"244\":2,\"269\":2}}],[\"along\",{\"1\":{\"123\":2,\"137\":1,\"146\":1,\"233\":1}}],[\"alone\",{\"1\":{\"121\":1}}],[\"alon\",{\"1\":{\"105\":1,\"221\":2}}],[\"ale\",{\"1\":{\"125\":1}}],[\"alexis\",{\"1\":{\"271\":1}}],[\"alexandre\",{\"1\":{\"105\":1}}],[\"alexei\",{\"1\":{\"102\":1}}],[\"alec\",{\"1\":{\"37\":1}}],[\"always\",{\"1\":{\"71\":1,\"80\":1,\"93\":1,\"94\":2,\"133\":1,\"170\":1}}],[\"alaska\",{\"1\":{\"71\":4}}],[\"al\",{\"1\":{\"9\":2,\"37\":9,\"41\":1,\"49\":1,\"53\":2,\"77\":1,\"81\":2,\"82\":1,\"93\":1,\"105\":7,\"116\":1,\"167\":4,\"175\":5,\"209\":1,\"214\":1,\"221\":1,\"224\":1,\"228\":3,\"247\":6,\"260\":1,\"263\":1,\"271\":2}}],[\"almost\",{\"1\":{\"5\":1,\"101\":1,\"124\":1,\"199\":1,\"202\":1,\"253\":1,\"256\":1}}],[\"also\",{\"1\":{\"3\":1,\"5\":1,\"8\":1,\"22\":1,\"24\":2,\"25\":2,\"27\":1,\"28\":1,\"36\":1,\"43\":1,\"54\":1,\"57\":1,\"58\":1,\"60\":2,\"71\":7,\"72\":1,\"81\":1,\"83\":1,\"93\":4,\"95\":3,\"97\":1,\"98\":1,\"105\":2,\"109\":2,\"110\":1,\"111\":1,\"113\":1,\"114\":1,\"115\":1,\"130\":1,\"146\":4,\"157\":1,\"174\":1,\"175\":1,\"187\":1,\"188\":1,\"194\":1,\"195\":1,\"197\":1,\"199\":1,\"200\":1,\"201\":2,\"202\":2,\"203\":2,\"217\":1,\"218\":1,\"219\":1,\"225\":1,\"227\":2,\"231\":1,\"232\":3,\"242\":1,\"253\":1,\"254\":1,\"259\":1,\"263\":1,\"264\":1,\"265\":1,\"267\":1,\"269\":1}}],[\"already\",{\"1\":{\"1\":1,\"3\":1,\"21\":2,\"22\":2,\"54\":1,\"93\":1,\"232\":1,\"269\":1}}],[\"allocation\",{\"1\":{\"152\":2,\"157\":1}}],[\"allowed\",{\"1\":{\"120\":1,\"122\":1,\"266\":1}}],[\"allow\",{\"1\":{\"109\":1,\"233\":1}}],[\"allowing\",{\"1\":{\"41\":2,\"42\":2}}],[\"allows\",{\"1\":{\"2\":1,\"41\":1,\"112\":1,\"231\":1}}],[\"alleviated\",{\"1\":{\"119\":1}}],[\"alleviate\",{\"1\":{\"45\":1,\"146\":3,\"189\":1}}],[\"all\",{\"1\":{\"1\":3,\"2\":2,\"5\":1,\"8\":3,\"27\":3,\"29\":1,\"37\":1,\"43\":1,\"51\":5,\"54\":1,\"69\":1,\"72\":2,\"82\":1,\"93\":2,\"95\":2,\"98\":2,\"99\":2,\"102\":1,\"109\":4,\"111\":2,\"113\":2,\"119\":1,\"127\":1,\"146\":3,\"152\":1,\"156\":1,\"163\":1,\"167\":1,\"173\":1,\"175\":1,\"186\":1,\"187\":1,\"189\":1,\"199\":1,\"202\":1,\"203\":4,\"211\":1,\"212\":1,\"213\":1,\"215\":1,\"217\":1,\"225\":1,\"226\":1,\"227\":1,\"228\":3,\"230\":1,\"242\":2,\"244\":5,\"245\":1,\"247\":1,\"256\":1,\"269\":1}}],[\"algorithms\",{\"1\":{\"1\":3,\"3\":1,\"232\":1}}],[\"algorithm\",{\"1\":{\"0\":1,\"3\":1,\"6\":1,\"146\":1,\"228\":1}}],[\"arises\",{\"1\":{\"251\":1}}],[\"arrived\",{\"1\":{\"230\":1}}],[\"arrive\",{\"1\":{\"219\":1}}],[\"array\",{\"0\":{\"7\":1}}],[\"arbitrary\",{\"1\":{\"194\":1}}],[\"argue\",{\"1\":{\"80\":1}}],[\"argmaxy\",{\"1\":{\"184\":1}}],[\"argmax\",{\"1\":{\"44\":1}}],[\"around\",{\"1\":{\"44\":1,\"83\":1,\"97\":1,\"125\":1,\"130\":1,\"245\":1}}],[\"artzi\",{\"1\":{\"105\":1,\"221\":1}}],[\"art\",{\"1\":{\"43\":1,\"54\":1,\"85\":1,\"93\":1,\"98\":2,\"101\":1,\"105\":1,\"120\":1,\"121\":1,\"123\":2,\"124\":2,\"126\":1,\"130\":1,\"132\":1,\"137\":1,\"151\":1,\"208\":1,\"214\":1,\"226\":1}}],[\"artificial\",{\"1\":{\"41\":1,\"94\":1}}],[\"artificially\",{\"1\":{\"24\":1}}],[\"article\",{\"1\":{\"36\":1,\"65\":2,\"66\":1,\"68\":1,\"123\":3,\"233\":1,\"240\":1}}],[\"articles\",{\"1\":{\"31\":2,\"123\":3,\"178\":1,\"228\":1}}],[\"architecture+parameter\",{\"1\":{\"111\":1}}],[\"architectures\",{\"1\":{\"105\":1,\"119\":1,\"146\":1,\"226\":1}}],[\"architecture\",{\"0\":{\"66\":1},\"1\":{\"24\":1,\"65\":1,\"112\":1,\"119\":1,\"154\":1,\"172\":2,\"228\":1,\"240\":3,\"242\":1,\"246\":2,\"252\":1}}],[\"areas\",{\"1\":{\"84\":1,\"228\":1}}],[\"area\",{\"1\":{\"71\":1,\"94\":1,\"101\":1,\"130\":1}}],[\"are\",{\"1\":{\"1\":4,\"3\":3,\"4\":2,\"5\":1,\"6\":1,\"7\":1,\"22\":2,\"23\":5,\"24\":3,\"25\":2,\"27\":4,\"36\":1,\"41\":2,\"43\":1,\"44\":1,\"45\":1,\"50\":1,\"51\":6,\"54\":3,\"59\":1,\"60\":1,\"68\":1,\"69\":1,\"71\":3,\"72\":2,\"78\":2,\"79\":1,\"81\":1,\"82\":3,\"84\":4,\"89\":1,\"93\":3,\"94\":1,\"96\":5,\"97\":2,\"98\":3,\"100\":3,\"101\":3,\"105\":1,\"114\":3,\"115\":1,\"120\":3,\"124\":1,\"125\":3,\"126\":2,\"127\":1,\"130\":2,\"131\":1,\"132\":3,\"133\":1,\"134\":3,\"141\":1,\"142\":1,\"146\":6,\"151\":3,\"152\":4,\"153\":2,\"154\":1,\"155\":1,\"157\":1,\"163\":2,\"164\":1,\"165\":3,\"167\":1,\"170\":3,\"172\":2,\"175\":1,\"179\":2,\"186\":2,\"194\":2,\"195\":1,\"196\":2,\"197\":1,\"198\":2,\"200\":1,\"211\":6,\"212\":1,\"215\":1,\"216\":2,\"217\":1,\"218\":3,\"219\":1,\"226\":3,\"228\":2,\"230\":1,\"231\":1,\"232\":3,\"239\":1,\"240\":1,\"242\":4,\"244\":3,\"245\":3,\"251\":1,\"253\":1,\"254\":3,\"256\":1,\"263\":3,\"264\":1,\"266\":2,\"269\":1}}],[\"arxiv\",{\"1\":{\"0\":1,\"12\":1,\"21\":1,\"41\":1,\"46\":1,\"49\":1,\"64\":1,\"77\":1,\"92\":1,\"116\":2,\"143\":1,\"146\":1,\"167\":6,\"175\":7,\"247\":4,\"250\":1,\"271\":4}}],[\"asr\",{\"1\":{\"172\":3,\"175\":1}}],[\"astoundingly\",{\"1\":{\"123\":1}}],[\"aside\",{\"1\":{\"120\":1}}],[\"assessment\",{\"1\":{\"215\":1,\"216\":1}}],[\"assign\",{\"1\":{\"212\":1}}],[\"assigned\",{\"1\":{\"208\":1}}],[\"assistant\",{\"1\":{\"170\":1}}],[\"associate\",{\"1\":{\"231\":1}}],[\"associates\",{\"1\":{\"102\":1}}],[\"associated\",{\"0\":{\"241\":1},\"1\":{\"81\":1,\"82\":1,\"239\":1}}],[\"association\",{\"1\":{\"9\":3,\"37\":1,\"105\":6,\"175\":1}}],[\"assuming\",{\"1\":{\"179\":1}}],[\"assumption\",{\"1\":{\"71\":1,\"200\":1}}],[\"assume\",{\"1\":{\"68\":1,\"109\":1,\"110\":2,\"112\":1}}],[\"aspect\",{\"1\":{\"43\":1,\"124\":1}}],[\"aspects\",{\"1\":{\"22\":1,\"33\":1,\"65\":1,\"93\":1}}],[\"ashish\",{\"1\":{\"37\":1,\"102\":1,\"167\":1,\"247\":1}}],[\"asked\",{\"1\":{\"1\":1,\"122\":1,\"123\":1,\"228\":2}}],[\"as\",{\"1\":{\"1\":14,\"2\":2,\"3\":6,\"5\":2,\"6\":1,\"7\":3,\"8\":3,\"22\":2,\"23\":7,\"24\":6,\"27\":3,\"30\":1,\"31\":1,\"33\":1,\"35\":3,\"41\":5,\"42\":5,\"43\":3,\"50\":2,\"51\":5,\"53\":1,\"59\":2,\"65\":1,\"67\":1,\"68\":2,\"71\":11,\"72\":1,\"78\":1,\"82\":1,\"92\":1,\"93\":3,\"94\":3,\"95\":2,\"96\":4,\"97\":1,\"98\":5,\"100\":1,\"101\":1,\"109\":2,\"110\":3,\"111\":5,\"112\":4,\"115\":2,\"119\":1,\"120\":1,\"122\":1,\"123\":4,\"124\":1,\"125\":1,\"130\":4,\"131\":3,\"133\":1,\"135\":1,\"141\":3,\"142\":2,\"146\":3,\"156\":5,\"157\":1,\"171\":6,\"172\":2,\"179\":1,\"182\":1,\"183\":3,\"184\":1,\"186\":1,\"187\":1,\"195\":1,\"196\":4,\"197\":3,\"198\":1,\"200\":2,\"201\":1,\"202\":1,\"203\":1,\"209\":3,\"210\":1,\"211\":1,\"212\":1,\"215\":1,\"216\":1,\"217\":5,\"218\":5,\"219\":2,\"228\":2,\"231\":2,\"232\":1,\"238\":1,\"239\":1,\"240\":1,\"242\":4,\"245\":2,\"246\":1,\"251\":2,\"252\":2,\"253\":3,\"254\":2,\"257\":1,\"258\":2,\"264\":2,\"265\":1,\"269\":1}}],[\"attribute\",{\"1\":{\"228\":1}}],[\"attributes\",{\"1\":{\"94\":1}}],[\"attracted\",{\"1\":{\"170\":1}}],[\"attack\",{\"1\":{\"42\":1}}],[\"attacks\",{\"1\":{\"41\":1}}],[\"attacker\",{\"1\":{\"41\":1,\"44\":1}}],[\"attached\",{\"1\":{\"36\":1}}],[\"attains\",{\"1\":{\"3\":1}}],[\"atteveldt\",{\"1\":{\"102\":1}}],[\"attends\",{\"1\":{\"245\":1}}],[\"attending\",{\"1\":{\"245\":1}}],[\"attend\",{\"1\":{\"51\":1}}],[\"attention\",{\"0\":{\"238\":1,\"240\":1,\"241\":1,\"242\":1},\"1\":{\"18\":1,\"37\":1,\"51\":1,\"96\":3,\"97\":1,\"102\":1,\"113\":1,\"119\":2,\"127\":1,\"137\":1,\"167\":1,\"170\":1,\"174\":3,\"175\":1,\"212\":1,\"216\":1,\"233\":4,\"238\":1,\"239\":7,\"240\":6,\"241\":2,\"242\":10,\"244\":5,\"245\":7,\"246\":2,\"247\":4},\"2\":{\"249\":1}}],[\"attempts\",{\"1\":{\"41\":1}}],[\"attempt\",{\"1\":{\"3\":1,\"120\":1,\"189\":1,\"234\":1}}],[\"at\",{\"0\":{\"234\":1},\"1\":{\"0\":1,\"1\":3,\"3\":6,\"21\":1,\"22\":1,\"23\":1,\"27\":3,\"29\":1,\"35\":2,\"36\":1,\"41\":1,\"42\":1,\"43\":1,\"49\":1,\"50\":1,\"51\":1,\"69\":1,\"71\":1,\"93\":1,\"94\":2,\"95\":7,\"97\":1,\"100\":1,\"123\":1,\"124\":3,\"125\":4,\"146\":1,\"166\":1,\"171\":1,\"172\":1,\"174\":2,\"175\":1,\"183\":1,\"195\":1,\"208\":1,\"214\":1,\"215\":1,\"216\":1,\"218\":1,\"219\":1,\"226\":2,\"227\":1,\"228\":1,\"229\":1,\"232\":1,\"234\":1,\"239\":1,\"252\":2,\"254\":1,\"263\":1,\"264\":1,\"269\":3}}],[\"ana\",{\"1\":{\"221\":1}}],[\"analogy\",{\"1\":{\"124\":1}}],[\"analogies\",{\"1\":{\"124\":1}}],[\"analysized\",{\"1\":{\"146\":1}}],[\"analysis\",{\"0\":{\"56\":1,\"174\":1,\"243\":1,\"245\":1,\"258\":1},\"1\":{\"2\":2,\"22\":1,\"93\":1,\"130\":1,\"146\":1,\"153\":1,\"239\":1,\"252\":1}}],[\"analyzing\",{\"1\":{\"139\":1,\"175\":1,\"239\":1}}],[\"analyzed\",{\"1\":{\"100\":1}}],[\"analyzes\",{\"1\":{\"23\":1}}],[\"analyze\",{\"1\":{\"22\":1,\"65\":1,\"70\":1,\"80\":1,\"93\":1,\"252\":1,\"258\":1}}],[\"anchors\",{\"1\":{\"216\":2}}],[\"anchor\",{\"1\":{\"196\":1}}],[\"ancient\",{\"1\":{\"95\":1}}],[\"anootated\",{\"1\":{\"142\":1}}],[\"another\",{\"1\":{\"1\":1,\"8\":2,\"26\":1,\"43\":1,\"68\":1,\"71\":2,\"97\":1,\"105\":1,\"109\":2,\"113\":1,\"123\":2,\"124\":1,\"126\":1,\"130\":1,\"170\":1,\"179\":1,\"196\":1,\"217\":1,\"218\":2,\"231\":1,\"254\":1,\"267\":1}}],[\"antonios\",{\"1\":{\"116\":1}}],[\"ankur\",{\"1\":{\"105\":1}}],[\"anisotropy\",{\"1\":{\"82\":1}}],[\"anisotropic\",{\"0\":{\"81\":1},\"1\":{\"80\":1,\"81\":2,\"83\":1,\"84\":1}}],[\"answer\",{\"1\":{\"79\":1,\"124\":1,\"172\":1,\"228\":1,\"251\":1}}],[\"answering\",{\"1\":{\"68\":1,\"124\":2}}],[\"answers\",{\"1\":{\"68\":2,\"250\":1}}],[\"angle\",{\"1\":{\"34\":1}}],[\"annotated\",{\"1\":{\"53\":1,\"60\":1,\"86\":1,\"100\":1,\"133\":1,\"142\":1}}],[\"annotation\",{\"1\":{\"23\":2,\"133\":1}}],[\"annual\",{\"1\":{\"9\":1,\"105\":2,\"175\":1}}],[\"andi\",{\"1\":{\"235\":1}}],[\"andrew\",{\"1\":{\"235\":1}}],[\"andre\",{\"1\":{\"105\":1}}],[\"and\",{\"0\":{\"24\":1,\"26\":1,\"68\":1,\"77\":1,\"95\":1,\"97\":1,\"113\":1,\"123\":1,\"142\":1,\"165\":1,\"243\":1,\"264\":1,\"268\":1,\"269\":1},\"1\":{\"1\":14,\"2\":8,\"3\":15,\"6\":5,\"7\":1,\"8\":6,\"21\":3,\"22\":9,\"23\":13,\"24\":11,\"25\":4,\"26\":2,\"27\":6,\"31\":2,\"32\":2,\"33\":1,\"35\":2,\"36\":4,\"37\":3,\"41\":7,\"42\":4,\"43\":13,\"44\":1,\"45\":1,\"50\":4,\"51\":10,\"53\":4,\"54\":9,\"55\":1,\"57\":1,\"58\":1,\"59\":3,\"60\":3,\"65\":2,\"66\":6,\"67\":4,\"68\":6,\"69\":1,\"70\":3,\"71\":21,\"72\":2,\"73\":2,\"74\":1,\"78\":4,\"80\":2,\"81\":1,\"82\":1,\"83\":1,\"84\":1,\"86\":1,\"87\":1,\"89\":4,\"92\":2,\"93\":23,\"94\":16,\"95\":15,\"96\":7,\"97\":4,\"98\":4,\"100\":7,\"101\":10,\"102\":5,\"105\":26,\"109\":6,\"110\":3,\"111\":12,\"112\":8,\"113\":10,\"114\":4,\"115\":2,\"119\":9,\"120\":8,\"121\":4,\"122\":8,\"123\":3,\"124\":6,\"125\":11,\"126\":10,\"130\":7,\"131\":2,\"132\":1,\"133\":1,\"134\":3,\"136\":2,\"137\":4,\"139\":2,\"140\":3,\"141\":3,\"142\":3,\"146\":27,\"149\":1,\"151\":3,\"152\":8,\"153\":8,\"154\":1,\"155\":4,\"156\":2,\"157\":1,\"161\":1,\"164\":1,\"165\":2,\"167\":1,\"170\":4,\"171\":5,\"172\":7,\"173\":1,\"174\":6,\"175\":7,\"178\":1,\"179\":2,\"181\":5,\"182\":1,\"183\":2,\"184\":4,\"186\":3,\"187\":6,\"188\":1,\"190\":1,\"191\":1,\"194\":5,\"195\":4,\"196\":4,\"197\":3,\"198\":2,\"199\":2,\"200\":6,\"201\":3,\"202\":4,\"203\":4,\"208\":3,\"209\":3,\"210\":3,\"211\":9,\"212\":12,\"213\":2,\"214\":2,\"215\":3,\"216\":24,\"217\":5,\"218\":27,\"219\":4,\"221\":11,\"225\":4,\"226\":5,\"227\":2,\"228\":3,\"230\":1,\"232\":4,\"233\":5,\"239\":6,\"240\":11,\"241\":1,\"242\":6,\"244\":11,\"245\":1,\"246\":1,\"247\":1,\"250\":1,\"251\":2,\"252\":4,\"253\":1,\"254\":6,\"256\":2,\"257\":1,\"258\":1,\"259\":2,\"263\":8,\"264\":1,\"265\":6,\"266\":11,\"267\":3,\"268\":2,\"269\":7,\"270\":2}}],[\"an\",{\"1\":{\"0\":1,\"1\":4,\"2\":2,\"3\":4,\"8\":2,\"21\":1,\"23\":1,\"24\":1,\"31\":1,\"42\":3,\"44\":1,\"45\":1,\"49\":1,\"50\":1,\"51\":3,\"54\":1,\"58\":1,\"60\":1,\"65\":2,\"66\":1,\"67\":1,\"68\":5,\"71\":3,\"72\":1,\"77\":1,\"81\":1,\"84\":2,\"86\":1,\"93\":1,\"96\":2,\"97\":1,\"101\":1,\"110\":1,\"112\":1,\"115\":1,\"120\":1,\"123\":1,\"124\":1,\"125\":3,\"126\":1,\"130\":3,\"131\":1,\"136\":1,\"137\":1,\"146\":5,\"151\":1,\"156\":1,\"170\":1,\"172\":3,\"175\":1,\"182\":1,\"183\":1,\"184\":2,\"188\":1,\"189\":1,\"197\":1,\"200\":1,\"201\":1,\"202\":1,\"210\":1,\"212\":3,\"214\":1,\"216\":2,\"219\":1,\"221\":1,\"226\":1,\"227\":2,\"228\":1,\"231\":1,\"232\":2,\"233\":2,\"240\":2,\"241\":1,\"252\":1,\"254\":1,\"259\":1,\"264\":1}}],[\"anyway\",{\"1\":{\"234\":1}}],[\"anywhere\",{\"1\":{\"120\":1}}],[\"anything\",{\"1\":{\"126\":1}}],[\"any\",{\"1\":{\"0\":1,\"1\":1,\"2\":1,\"22\":4,\"24\":1,\"25\":1,\"33\":1,\"82\":1,\"86\":1,\"109\":1,\"110\":1,\"111\":1,\"142\":1,\"194\":2,\"226\":1,\"229\":1,\"234\":1,\"239\":1,\"269\":1}}],[\"a\",{\"0\":{\"7\":1,\"170\":1,\"207\":1},\"1\":{\"0\":2,\"1\":26,\"2\":8,\"3\":15,\"4\":1,\"5\":4,\"6\":3,\"8\":3,\"9\":1,\"21\":5,\"22\":14,\"23\":12,\"24\":14,\"25\":7,\"26\":1,\"27\":3,\"28\":1,\"30\":1,\"33\":2,\"35\":2,\"36\":5,\"41\":7,\"42\":18,\"43\":10,\"44\":3,\"45\":3,\"49\":5,\"50\":1,\"51\":10,\"53\":1,\"54\":2,\"57\":2,\"60\":2,\"61\":1,\"64\":2,\"65\":1,\"66\":4,\"67\":2,\"68\":2,\"69\":7,\"71\":16,\"72\":1,\"73\":2,\"78\":2,\"80\":1,\"81\":1,\"82\":1,\"84\":3,\"85\":1,\"88\":2,\"92\":1,\"93\":10,\"94\":7,\"95\":6,\"96\":5,\"97\":3,\"98\":4,\"100\":8,\"101\":4,\"102\":1,\"105\":7,\"109\":14,\"110\":7,\"111\":4,\"112\":4,\"113\":6,\"116\":1,\"119\":2,\"120\":6,\"121\":3,\"122\":2,\"123\":11,\"124\":16,\"125\":13,\"126\":7,\"130\":11,\"131\":1,\"132\":1,\"135\":2,\"137\":1,\"142\":1,\"146\":19,\"149\":1,\"151\":2,\"153\":1,\"154\":1,\"155\":1,\"156\":4,\"157\":1,\"160\":1,\"161\":1,\"166\":1,\"167\":1,\"170\":3,\"171\":4,\"172\":5,\"173\":1,\"174\":1,\"175\":6,\"178\":1,\"179\":1,\"181\":2,\"182\":1,\"183\":3,\"184\":1,\"187\":1,\"188\":2,\"190\":2,\"194\":8,\"195\":2,\"196\":6,\"197\":5,\"198\":2,\"200\":2,\"201\":4,\"202\":2,\"203\":8,\"206\":1,\"208\":3,\"209\":1,\"210\":1,\"211\":6,\"212\":9,\"213\":2,\"214\":3,\"215\":4,\"216\":18,\"217\":3,\"218\":12,\"219\":2,\"221\":3,\"224\":1,\"225\":4,\"226\":5,\"227\":4,\"228\":15,\"231\":12,\"232\":7,\"233\":9,\"234\":1,\"239\":4,\"240\":7,\"241\":1,\"242\":5,\"245\":1,\"246\":2,\"247\":1,\"250\":2,\"251\":6,\"252\":4,\"253\":3,\"254\":2,\"256\":3,\"258\":2,\"259\":1,\"263\":6,\"264\":6,\"265\":2,\"266\":2,\"267\":1,\"268\":1,\"269\":5,\"270\":2}}],[\"csv\",{\"1\":{\"221\":1}}],[\"cs\",{\"1\":{\"221\":1}}],[\"cn\",{\"1\":{\"179\":6,\"221\":1}}],[\"cnn\",{\"1\":{\"54\":1}}],[\"ctl\",{\"1\":{\"202\":2}}],[\"ctc\",{\"1\":{\"172\":1}}],[\"ctnmt\",{\"1\":{\"12\":1,\"14\":1,\"16\":1,\"18\":3,\"26\":1}}],[\"cdot\",{\"1\":{\"266\":1}}],[\"cd\",{\"1\":{\"161\":1}}],[\"c≤∣s∣∗∣t∣\",{\"1\":{\"110\":1}}],[\"cpg∗\",{\"1\":{\"113\":1}}],[\"cpg\",{\"0\":{\"112\":1},\"1\":{\"109\":2,\"112\":3,\"113\":7,\"114\":1,\"115\":1}}],[\"cpu\",{\"0\":{\"0\":1},\"1\":{\"6\":1}}],[\"cited\",{\"1\":{\"266\":1}}],[\"city\",{\"1\":{\"95\":1}}],[\"circles\",{\"1\":{\"100\":1}}],[\"circled\",{\"1\":{\"100\":2}}],[\"circulated\",{\"1\":{\"30\":2}}],[\"circumstances\",{\"1\":{\"27\":1}}],[\"cultural\",{\"1\":{\"271\":2}}],[\"culprit\",{\"1\":{\"71\":2}}],[\"custom\",{\"1\":{\"155\":2}}],[\"customers\",{\"1\":{\"41\":1}}],[\"cub\",{\"1\":{\"153\":1}}],[\"cublas\",{\"1\":{\"153\":1}}],[\"cuda\",{\"1\":{\"153\":1},\"2\":{\"169\":1}}],[\"curran\",{\"1\":{\"102\":1}}],[\"currently\",{\"1\":{\"172\":1}}],[\"current\",{\"0\":{\"2\":1},\"1\":{\"1\":3,\"2\":1,\"71\":1,\"94\":1,\"105\":1,\"115\":1,\"123\":1,\"132\":1,\"152\":1,\"226\":1,\"245\":1,\"252\":1,\"267\":1}}],[\"critical\",{\"1\":{\"211\":1,\"238\":1,\"259\":1}}],[\"crazy\",{\"1\":{\"263\":1}}],[\"craig\",{\"1\":{\"221\":1}}],[\"crawl\",{\"1\":{\"119\":1,\"122\":1}}],[\"crack\",{\"1\":{\"65\":2,\"74\":1}}],[\"crego\",{\"1\":{\"221\":1}}],[\"credit\",{\"1\":{\"78\":1}}],[\"creatively\",{\"1\":{\"227\":1}}],[\"creators\",{\"1\":{\"41\":1}}],[\"creates\",{\"1\":{\"215\":1}}],[\"created\",{\"1\":{\"24\":1,\"96\":1,\"119\":1}}],[\"create\",{\"1\":{\"21\":1,\"24\":1,\"42\":1,\"93\":1,\"126\":1,\"146\":1,\"233\":1}}],[\"crucial\",{\"1\":{\"49\":1,\"197\":1,\"226\":1,\"228\":1}}],[\"cross\",{\"0\":{\"57\":1,\"267\":1},\"1\":{\"24\":1,\"26\":1,\"36\":1,\"42\":1,\"105\":1,\"186\":2,\"216\":1,\"265\":1,\"267\":5,\"271\":2}}],[\"c\",{\"1\":{\"24\":1,\"93\":1,\"97\":1,\"98\":2,\"99\":2,\"101\":1,\"175\":9,\"221\":2,\"258\":1,\"266\":1,\"267\":1}}],[\"cells\",{\"1\":{\"146\":1}}],[\"centric\",{\"1\":{\"146\":1,\"194\":2,\"198\":1,\"199\":2,\"201\":1}}],[\"centra\",{\"1\":{\"125\":1}}],[\"central\",{\"1\":{\"22\":1}}],[\"centuries\",{\"1\":{\"114\":1}}],[\"century\",{\"1\":{\"71\":1,\"93\":1}}],[\"cet\",{\"1\":{\"31\":1}}],[\"certain\",{\"1\":{\"1\":1,\"3\":1,\"24\":1,\"26\":1,\"51\":2,\"71\":1,\"94\":1,\"120\":1,\"202\":1,\"211\":1,\"218\":1,\"239\":1}}],[\"clever\",{\"1\":{\"231\":1}}],[\"clement\",{\"1\":{\"221\":1}}],[\"clearly\",{\"1\":{\"218\":3,\"264\":1}}],[\"clearer\",{\"1\":{\"110\":1}}],[\"clear\",{\"1\":{\"3\":1,\"124\":1}}],[\"clustered\",{\"1\":{\"100\":1}}],[\"cluster\",{\"1\":{\"100\":2}}],[\"closing\",{\"1\":{\"215\":1}}],[\"closest\",{\"1\":{\"232\":1}}],[\"closely\",{\"1\":{\"35\":1,\"120\":1}}],[\"closer\",{\"0\":{\"34\":1,\"35\":1},\"1\":{\"34\":2,\"35\":1,\"213\":1,\"218\":1,\"225\":1}}],[\"closed\",{\"1\":{\"29\":3}}],[\"close\",{\"1\":{\"23\":1,\"24\":3,\"25\":1,\"71\":2,\"82\":1,\"100\":2,\"196\":1,\"197\":1}}],[\"cloud\",{\"0\":{\"166\":1},\"1\":{\"166\":1}}],[\"clock\",{\"1\":{\"125\":1}}],[\"clothes\",{\"1\":{\"125\":2}}],[\"cloze\",{\"1\":{\"68\":3}}],[\"clients\",{\"1\":{\"41\":1}}],[\"clarification\",{\"1\":{\"234\":1}}],[\"clarify\",{\"1\":{\"3\":1}}],[\"clauses\",{\"1\":{\"211\":1}}],[\"claim\",{\"0\":{\"67\":1},\"1\":{\"65\":1,\"66\":3,\"67\":3,\"68\":4,\"69\":6,\"71\":17,\"72\":1,\"73\":4,\"114\":1}}],[\"claimed\",{\"1\":{\"65\":1,\"93\":1}}],[\"claims\",{\"0\":{\"64\":1},\"1\":{\"65\":1,\"71\":1,\"72\":1}}],[\"classifying\",{\"1\":{\"268\":1}}],[\"classification\",{\"1\":{\"41\":1,\"51\":2,\"172\":1,\"174\":1,\"250\":1,\"251\":1}}],[\"classrooms\",{\"1\":{\"37\":1}}],[\"class\",{\"1\":{\"32\":4,\"42\":1}}],[\"chromosome\",{\"1\":{\"228\":1}}],[\"christian\",{\"1\":{\"105\":1}}],[\"christophe\",{\"1\":{\"105\":1}}],[\"chladničku\",{\"1\":{\"125\":1}}],[\"chicken\",{\"1\":{\"125\":2}}],[\"chi\",{\"1\":{\"102\":1,\"105\":1}}],[\"children\",{\"1\":{\"95\":3}}],[\"child\",{\"1\":{\"95\":1}}],[\"chimera\",{\"0\":{\"95\":1,\"98\":1},\"1\":{\"92\":1,\"93\":11,\"94\":1,\"95\":2,\"96\":2,\"97\":2,\"98\":3,\"101\":2},\"2\":{\"104\":1}}],[\"chinese\",{\"0\":{\"29\":1,\"32\":1},\"1\":{\"21\":1,\"24\":4,\"111\":1,\"172\":1,\"173\":1,\"179\":2,\"197\":1,\"218\":4,\"221\":1}}],[\"china\",{\"1\":{\"21\":1,\"36\":1}}],[\"chen\",{\"1\":{\"74\":2,\"116\":1,\"191\":1,\"221\":1}}],[\"check\",{\"1\":{\"72\":1,\"269\":1}}],[\"checking\",{\"1\":{\"64\":1}}],[\"cheaper\",{\"1\":{\"247\":1}}],[\"cheap\",{\"1\":{\"23\":1}}],[\"ch\",{\"1\":{\"6\":1,\"179\":1}}],[\"chouteau\",{\"1\":{\"221\":1}}],[\"chorowski\",{\"1\":{\"175\":1}}],[\"chosen\",{\"1\":{\"120\":1}}],[\"chose\",{\"1\":{\"4\":2}}],[\"choosing\",{\"1\":{\"3\":1}}],[\"choose\",{\"1\":{\"1\":1}}],[\"choices\",{\"1\":{\"124\":1}}],[\"choice\",{\"1\":{\"3\":2,\"9\":1,\"146\":1,\"218\":2}}],[\"chart\",{\"1\":{\"71\":1}}],[\"characteristics\",{\"1\":{\"24\":1}}],[\"character\",{\"1\":{\"1\":6,\"2\":4,\"3\":1,\"8\":1}}],[\"characters\",{\"1\":{\"1\":4,\"2\":1,\"8\":1,\"212\":1}}],[\"challenging\",{\"1\":{\"60\":1,\"120\":1,\"132\":1,\"170\":1}}],[\"challenge\",{\"0\":{\"132\":1},\"1\":{\"23\":1,\"93\":2,\"94\":1,\"109\":2,\"130\":1,\"146\":1,\"151\":1}}],[\"challenges\",{\"0\":{\"23\":1,\"50\":1,\"94\":1},\"1\":{\"22\":1,\"41\":1,\"50\":1,\"51\":1,\"93\":2,\"171\":1,\"225\":1}}],[\"chains\",{\"1\":{\"58\":1}}],[\"chain\",{\"1\":{\"51\":2}}],[\"chanter\",{\"1\":{\"197\":1}}],[\"changzhi\",{\"1\":{\"74\":1}}],[\"changed\",{\"1\":{\"253\":1,\"266\":1}}],[\"changes\",{\"1\":{\"120\":1,\"122\":1,\"211\":1}}],[\"change\",{\"1\":{\"71\":2,\"211\":1,\"231\":1,\"252\":1,\"266\":1}}],[\"chang\",{\"1\":{\"61\":1}}],[\"changsha\",{\"1\":{\"21\":4}}],[\"chance\",{\"1\":{\"1\":1,\"123\":1}}],[\"chao\",{\"1\":{\"21\":4,\"22\":1,\"36\":3}}],[\"cai\",{\"1\":{\"224\":1,\"235\":1}}],[\"cao\",{\"1\":{\"221\":1}}],[\"came\",{\"1\":{\"124\":1,\"125\":1,\"228\":1}}],[\"cascade\",{\"1\":{\"172\":1}}],[\"cascaded\",{\"0\":{\"175\":1},\"1\":{\"171\":3,\"173\":1,\"175\":3}}],[\"cascades\",{\"1\":{\"170\":1}}],[\"caspar\",{\"1\":{\"93\":1}}],[\"case\",{\"0\":{\"28\":1,\"59\":1,\"125\":1,\"218\":1,\"252\":1,\"269\":1},\"1\":{\"28\":1,\"42\":3,\"45\":1,\"59\":1,\"71\":3,\"72\":1,\"112\":1,\"125\":1,\"126\":1,\"146\":2,\"218\":1,\"226\":1,\"233\":1,\"251\":1,\"268\":2,\"269\":1}}],[\"cases\",{\"1\":{\"22\":1,\"121\":1,\"124\":1,\"171\":1,\"212\":1,\"233\":1,\"256\":1}}],[\"cars\",{\"1\":{\"211\":2}}],[\"carbon\",{\"1\":{\"115\":1}}],[\"cardinal\",{\"1\":{\"93\":1}}],[\"carry\",{\"1\":{\"79\":1}}],[\"carefully\",{\"1\":{\"41\":1}}],[\"causing\",{\"1\":{\"71\":1,\"228\":1}}],[\"causes\",{\"1\":{\"146\":2,\"218\":1}}],[\"caused\",{\"1\":{\"114\":1,\"172\":1,\"208\":1}}],[\"cause\",{\"1\":{\"6\":1,\"31\":4,\"43\":1,\"45\":1,\"71\":1,\"112\":1,\"211\":2}}],[\"captioning\",{\"1\":{\"136\":1,\"137\":1}}],[\"caption\",{\"1\":{\"130\":1}}],[\"capturing\",{\"1\":{\"58\":1}}],[\"captures\",{\"1\":{\"114\":1}}],[\"capture\",{\"1\":{\"51\":1,\"60\":1,\"79\":1,\"105\":1,\"174\":1,\"178\":1,\"211\":3,\"225\":1,\"244\":1}}],[\"captured\",{\"1\":{\"51\":1,\"174\":1}}],[\"capacity\",{\"0\":{\"146\":1},\"1\":{\"100\":1,\"146\":5,\"195\":1},\"2\":{\"148\":1}}],[\"capabilty\",{\"1\":{\"146\":1}}],[\"capabilities\",{\"1\":{\"22\":1,\"27\":1}}],[\"capability\",{\"1\":{\"22\":1,\"228\":1}}],[\"capable\",{\"1\":{\"93\":1}}],[\"categorical\",{\"1\":{\"69\":1}}],[\"categories\",{\"1\":{\"43\":2,\"96\":1,\"100\":1}}],[\"category\",{\"1\":{\"27\":1,\"43\":1,\"105\":1,\"141\":2}}],[\"catastrophic\",{\"1\":{\"146\":1},\"2\":{\"20\":1}}],[\"california\",{\"1\":{\"218\":3}}],[\"calibration\",{\"1\":{\"88\":1}}],[\"calculation\",{\"1\":{\"212\":1,\"241\":1}}],[\"calculations\",{\"1\":{\"156\":2}}],[\"calculating\",{\"1\":{\"42\":1,\"211\":1}}],[\"calculates\",{\"1\":{\"66\":1,\"71\":1}}],[\"calculate\",{\"1\":{\"35\":1,\"156\":2,\"210\":1}}],[\"calculated\",{\"1\":{\"24\":1,\"212\":3,\"216\":1,\"240\":1,\"263\":1}}],[\"callie\",{\"1\":{\"37\":1}}],[\"call\",{\"1\":{\"9\":1,\"130\":1}}],[\"called\",{\"1\":{\"1\":1,\"97\":1,\"105\":1,\"109\":2,\"111\":1,\"194\":2,\"197\":1,\"198\":1,\"203\":2,\"226\":1,\"227\":1,\"228\":1,\"231\":1,\"232\":1,\"242\":1}}],[\"cand\",{\"1\":{\"212\":1}}],[\"candidates\",{\"1\":{\"209\":2,\"211\":1}}],[\"candidate\",{\"1\":{\"125\":1,\"211\":2,\"212\":3,\"213\":1}}],[\"cannot\",{\"1\":{\"1\":1,\"105\":1,\"120\":1,\"124\":1,\"125\":1,\"200\":1,\"203\":1,\"211\":1,\"218\":2,\"231\":1}}],[\"can\",{\"0\":{\"130\":1},\"1\":{\"0\":1,\"1\":6,\"2\":2,\"3\":1,\"21\":1,\"22\":6,\"23\":1,\"24\":3,\"25\":2,\"26\":1,\"27\":1,\"30\":2,\"33\":2,\"34\":1,\"35\":3,\"36\":3,\"41\":3,\"42\":3,\"44\":1,\"51\":5,\"53\":1,\"54\":1,\"58\":1,\"59\":2,\"65\":2,\"66\":1,\"71\":8,\"79\":1,\"82\":1,\"83\":1,\"84\":3,\"88\":1,\"92\":2,\"93\":7,\"94\":1,\"95\":2,\"96\":1,\"100\":1,\"109\":3,\"110\":2,\"111\":6,\"112\":5,\"113\":3,\"114\":2,\"115\":3,\"120\":2,\"124\":1,\"125\":6,\"126\":2,\"130\":1,\"131\":1,\"137\":1,\"141\":1,\"146\":5,\"153\":1,\"156\":1,\"170\":2,\"171\":2,\"172\":5,\"173\":1,\"174\":2,\"175\":5,\"178\":1,\"179\":1,\"181\":1,\"182\":2,\"183\":1,\"187\":1,\"188\":1,\"195\":1,\"196\":1,\"197\":1,\"201\":2,\"202\":2,\"203\":2,\"208\":1,\"212\":6,\"213\":1,\"216\":1,\"218\":3,\"219\":1,\"225\":2,\"226\":3,\"227\":2,\"228\":2,\"230\":1,\"232\":6,\"233\":3,\"240\":1,\"242\":1,\"244\":6,\"251\":2,\"253\":1,\"257\":1,\"259\":1,\"263\":1,\"265\":1,\"268\":1,\"269\":3}}],[\"coefficient\",{\"1\":{\"216\":1}}],[\"copyisallyouneed\",{\"1\":{\"224\":1}}],[\"copora\",{\"1\":{\"194\":1}}],[\"copenhagen\",{\"1\":{\"105\":1}}],[\"cope\",{\"1\":{\"60\":1}}],[\"coco\",{\"1\":{\"139\":2}}],[\"cover\",{\"1\":{\"130\":1}}],[\"covered\",{\"1\":{\"98\":1}}],[\"coherent\",{\"1\":{\"126\":1}}],[\"coding\",{\"1\":{\"94\":1}}],[\"coded\",{\"1\":{\"244\":1,\"247\":1}}],[\"codes\",{\"1\":{\"22\":1,\"93\":1}}],[\"code\",{\"0\":{\"220\":1},\"1\":{\"0\":1,\"41\":1,\"49\":1,\"64\":1,\"77\":1,\"125\":1,\"146\":1,\"175\":1,\"178\":1,\"224\":1,\"269\":3}}],[\"columns\",{\"1\":{\"212\":1}}],[\"column\",{\"1\":{\"212\":1}}],[\"collect\",{\"1\":{\"146\":1,\"178\":1}}],[\"collects\",{\"1\":{\"141\":1}}],[\"collecting\",{\"1\":{\"78\":1}}],[\"collection\",{\"1\":{\"2\":1,\"68\":1,\"94\":1}}],[\"college\",{\"1\":{\"124\":1}}],[\"coling\",{\"1\":{\"105\":2}}],[\"color\",{\"1\":{\"94\":1,\"100\":1}}],[\"colored\",{\"1\":{\"81\":1,\"100\":1}}],[\"colonize\",{\"1\":{\"71\":1}}],[\"co\",{\"1\":{\"51\":2,\"64\":1}}],[\"cosine\",{\"1\":{\"35\":1,\"86\":1,\"211\":1,\"212\":4}}],[\"costly\",{\"1\":{\"241\":1,\"246\":1,\"251\":1}}],[\"costs\",{\"1\":{\"109\":1,\"155\":1,\"170\":1}}],[\"cost\",{\"1\":{\"3\":2,\"94\":1,\"112\":1,\"115\":1,\"133\":1}}],[\"coupling\",{\"1\":{\"170\":1}}],[\"coupled\",{\"1\":{\"170\":1}}],[\"couple\",{\"1\":{\"22\":1,\"119\":1}}],[\"counterparts\",{\"1\":{\"239\":1}}],[\"country\",{\"1\":{\"71\":2}}],[\"countries\",{\"1\":{\"36\":1,\"101\":1}}],[\"council\",{\"1\":{\"29\":3,\"221\":2}}],[\"cours\",{\"1\":{\"31\":3}}],[\"course\",{\"1\":{\"27\":1,\"221\":1}}],[\"could\",{\"1\":{\"1\":2,\"8\":1,\"21\":2,\"24\":1,\"43\":2,\"51\":2,\"83\":1,\"93\":1,\"95\":2,\"123\":1,\"124\":1,\"125\":1,\"126\":1,\"227\":1,\"228\":3,\"233\":3}}],[\"conjecture\",{\"1\":{\"244\":1}}],[\"conditional\",{\"1\":{\"181\":1}}],[\"conditioning\",{\"1\":{\"120\":1,\"123\":1,\"137\":2}}],[\"conducting\",{\"1\":{\"60\":1,\"97\":1}}],[\"conducted\",{\"1\":{\"3\":1,\"4\":1,\"146\":2,\"208\":1}}],[\"conduct\",{\"1\":{\"2\":1,\"7\":1,\"51\":1,\"54\":1,\"55\":1,\"111\":2,\"113\":1,\"126\":1,\"253\":1}}],[\"conbination\",{\"1\":{\"110\":1}}],[\"conneau\",{\"1\":{\"105\":2,\"271\":1}}],[\"connectionist\",{\"1\":{\"172\":1}}],[\"connection\",{\"1\":{\"80\":1,\"94\":1,\"195\":1,\"228\":1,\"242\":1}}],[\"connections\",{\"1\":{\"51\":1}}],[\"connected\",{\"1\":{\"51\":3,\"146\":1}}],[\"connect\",{\"1\":{\"51\":1}}],[\"conon\",{\"1\":{\"93\":1}}],[\"cone\",{\"1\":{\"81\":1}}],[\"confused\",{\"1\":{\"231\":1}}],[\"confusing\",{\"1\":{\"71\":1,\"234\":1}}],[\"confidences\",{\"1\":{\"233\":1}}],[\"confidence\",{\"1\":{\"228\":1}}],[\"confirming\",{\"1\":{\"146\":1}}],[\"confirms\",{\"1\":{\"60\":1}}],[\"configuration\",{\"0\":{\"140\":1},\"1\":{\"97\":1}}],[\"conference\",{\"1\":{\"5\":1,\"22\":1,\"37\":1,\"105\":6,\"167\":1,\"170\":1,\"175\":1,\"210\":1,\"214\":1,\"239\":1,\"247\":1,\"260\":1}}],[\"converts\",{\"1\":{\"232\":1,\"233\":1,\"240\":1}}],[\"converted\",{\"1\":{\"232\":1}}],[\"convert\",{\"1\":{\"226\":2}}],[\"convergence\",{\"1\":{\"146\":1}}],[\"converged\",{\"1\":{\"94\":1}}],[\"convenient\",{\"1\":{\"120\":1}}],[\"conventional\",{\"1\":{\"1\":1,\"139\":1}}],[\"convey\",{\"1\":{\"101\":1,\"269\":1}}],[\"conveyed\",{\"1\":{\"93\":1}}],[\"convinces\",{\"1\":{\"94\":1}}],[\"convince\",{\"1\":{\"65\":1}}],[\"convolution\",{\"1\":{\"51\":1,\"140\":1}}],[\"concordant\",{\"1\":{\"217\":1}}],[\"conclusions\",{\"1\":{\"245\":1}}],[\"conclusion\",{\"0\":{\"60\":1,\"73\":1,\"88\":1,\"126\":1,\"142\":1,\"190\":1,\"219\":1,\"270\":1},\"1\":{\"203\":1}}],[\"concatenated\",{\"1\":{\"216\":1}}],[\"concatenate\",{\"1\":{\"51\":1}}],[\"concatenation\",{\"1\":{\"51\":2,\"240\":1}}],[\"concretely\",{\"1\":{\"51\":2,\"244\":1}}],[\"concurrently\",{\"1\":{\"26\":1}}],[\"concurrent\",{\"1\":{\"26\":1}}],[\"concentrated\",{\"1\":{\"245\":2}}],[\"concentrates\",{\"1\":{\"83\":1}}],[\"concert\",{\"1\":{\"125\":2}}],[\"concerns\",{\"1\":{\"45\":1}}],[\"concern\",{\"1\":{\"2\":1}}],[\"concept\",{\"1\":{\"1\":1,\"3\":3,\"228\":1,\"232\":1}}],[\"contaimination\",{\"1\":{\"119\":1}}],[\"containing\",{\"1\":{\"93\":2,\"142\":1,\"198\":1,\"213\":1}}],[\"contained\",{\"1\":{\"54\":1,\"122\":1,\"126\":1}}],[\"contain\",{\"1\":{\"51\":1,\"53\":1}}],[\"contains\",{\"1\":{\"51\":1,\"93\":1,\"97\":2,\"98\":1,\"110\":1,\"124\":1,\"135\":1,\"146\":2,\"198\":1}}],[\"contemporarily\",{\"1\":{\"65\":1}}],[\"contexts\",{\"1\":{\"212\":1,\"225\":2,\"228\":1}}],[\"contextual\",{\"0\":{\"108\":1,\"111\":1},\"1\":{\"89\":1,\"96\":4,\"109\":1,\"116\":1,\"126\":1,\"210\":1,\"212\":3,\"219\":2,\"240\":1}}],[\"contextualized\",{\"1\":{\"51\":1,\"78\":1,\"89\":1,\"105\":1,\"211\":1,\"245\":1}}],[\"context\",{\"1\":{\"24\":2,\"34\":2,\"51\":1,\"54\":1,\"71\":1,\"82\":1,\"119\":1,\"122\":1,\"124\":1,\"215\":1,\"218\":1,\"231\":1,\"233\":1,\"240\":1}}],[\"contributing\",{\"1\":{\"252\":1}}],[\"contribution\",{\"0\":{\"202\":1},\"1\":{\"94\":2,\"212\":1}}],[\"contributor\",{\"1\":{\"202\":1}}],[\"contributes\",{\"1\":{\"251\":1,\"253\":1}}],[\"contribute\",{\"1\":{\"194\":1,\"253\":1}}],[\"contradictory\",{\"1\":{\"126\":1}}],[\"contradicting\",{\"1\":{\"71\":1}}],[\"contrastive\",{\"0\":{\"194\":1,\"196\":1},\"1\":{\"95\":1,\"194\":1,\"196\":2,\"201\":1,\"202\":2,\"203\":3},\"2\":{\"205\":1}}],[\"contrast\",{\"1\":{\"22\":1,\"23\":1,\"25\":1,\"188\":1,\"244\":1,\"257\":1}}],[\"controls\",{\"1\":{\"266\":1}}],[\"control\",{\"1\":{\"42\":1,\"89\":1,\"196\":1}}],[\"continue\",{\"1\":{\"175\":1}}],[\"continues\",{\"1\":{\"14\":1}}],[\"continuous\",{\"1\":{\"36\":1,\"105\":1}}],[\"constituency\",{\"1\":{\"67\":1}}],[\"constuct\",{\"1\":{\"51\":1}}],[\"constraints\",{\"1\":{\"8\":1,\"69\":1}}],[\"construction\",{\"0\":{\"68\":1,\"69\":1},\"1\":{\"54\":1,\"71\":2}}],[\"constructing\",{\"1\":{\"0\":1}}],[\"constructed\",{\"1\":{\"51\":1,\"53\":1}}],[\"constructable\",{\"1\":{\"1\":1}}],[\"construct\",{\"1\":{\"1\":5,\"68\":1}}],[\"conseil\",{\"1\":{\"29\":1}}],[\"considing\",{\"1\":{\"113\":1}}],[\"considered\",{\"1\":{\"196\":1,\"198\":1}}],[\"considering\",{\"1\":{\"93\":1,\"100\":1,\"105\":1,\"218\":1}}],[\"considerably\",{\"1\":{\"213\":1}}],[\"considerable\",{\"1\":{\"57\":1}}],[\"consideration\",{\"1\":{\"93\":1,\"210\":1,\"219\":1}}],[\"considerations\",{\"1\":{\"24\":1,\"95\":1}}],[\"considers\",{\"1\":{\"8\":1,\"71\":2,\"179\":1,\"181\":1,\"184\":1,\"186\":1,\"190\":1,\"254\":1}}],[\"consider\",{\"1\":{\"2\":1,\"8\":1,\"54\":1,\"71\":2,\"93\":1,\"146\":1,\"159\":1,\"218\":1}}],[\"consisting\",{\"1\":{\"93\":1,\"97\":1,\"126\":1}}],[\"consist\",{\"1\":{\"68\":1,\"140\":1}}],[\"consists\",{\"1\":{\"51\":1,\"97\":1,\"119\":1,\"172\":1,\"228\":1,\"242\":1}}],[\"consistency\",{\"1\":{\"31\":1,\"105\":1,\"137\":1}}],[\"consistent\",{\"1\":{\"25\":1,\"82\":1,\"132\":1,\"142\":1,\"146\":2,\"239\":1}}],[\"consistently\",{\"1\":{\"22\":1,\"54\":1,\"86\":1,\"93\":2,\"113\":1,\"146\":1,\"244\":1}}],[\"consuming\",{\"1\":{\"3\":1}}],[\"consumers\",{\"1\":{\"211\":1}}],[\"consumer\",{\"1\":{\"3\":1}}],[\"consumption\",{\"0\":{\"6\":1},\"1\":{\"1\":1,\"6\":1}}],[\"corroborate\",{\"1\":{\"98\":1}}],[\"correia\",{\"1\":{\"247\":1}}],[\"correlated\",{\"1\":{\"105\":1,\"146\":1}}],[\"correlates\",{\"1\":{\"94\":1,\"214\":1,\"218\":1,\"219\":1}}],[\"correlations\",{\"1\":{\"213\":3}}],[\"correlation\",{\"1\":{\"3\":4,\"86\":1,\"105\":1,\"209\":1,\"213\":2,\"214\":1,\"221\":1}}],[\"correctly\",{\"1\":{\"123\":1,\"124\":1,\"175\":1,\"265\":1}}],[\"correctness\",{\"1\":{\"72\":1,\"73\":2}}],[\"correct\",{\"1\":{\"71\":5,\"124\":2,\"175\":1,\"211\":1,\"226\":1,\"228\":1,\"251\":1,\"268\":1}}],[\"corresponds\",{\"1\":{\"100\":1,\"216\":1,\"268\":1}}],[\"correspondence\",{\"1\":{\"24\":1,\"135\":1,\"197\":1,\"200\":1,\"209\":1}}],[\"correspond\",{\"1\":{\"3\":1,\"23\":1}}],[\"corresponding\",{\"1\":{\"3\":1,\"22\":1,\"68\":1,\"73\":1,\"146\":2,\"172\":1,\"197\":1,\"212\":2,\"216\":2,\"217\":1,\"218\":1,\"263\":2}}],[\"cortex\",{\"1\":{\"94\":3}}],[\"corpora\",{\"0\":{\"263\":1},\"1\":{\"27\":1,\"94\":1,\"95\":1,\"97\":1,\"110\":2,\"113\":4,\"133\":1,\"200\":2,\"271\":1}}],[\"corpus\",{\"1\":{\"1\":1,\"22\":3,\"23\":1,\"24\":1,\"25\":4,\"27\":1,\"93\":3,\"97\":1,\"170\":3,\"171\":1,\"181\":3,\"182\":2,\"183\":2,\"187\":2,\"190\":1,\"201\":1,\"213\":1,\"217\":6,\"218\":1,\"221\":3,\"227\":1,\"231\":1,\"232\":1,\"244\":1,\"263\":6,\"269\":1}}],[\"corefrobertarelarge\",{\"1\":{\"54\":1}}],[\"corefroberta\",{\"1\":{\"54\":1}}],[\"corefbert\",{\"1\":{\"54\":1}}],[\"core\",{\"0\":{\"111\":1},\"1\":{\"1\":1,\"111\":1}}],[\"coming\",{\"1\":{\"114\":1}}],[\"combines\",{\"1\":{\"227\":1,\"233\":1}}],[\"combine\",{\"1\":{\"155\":1,\"183\":1}}],[\"combined\",{\"1\":{\"87\":1,\"95\":1,\"111\":1,\"212\":1,\"216\":1,\"228\":1,\"254\":1}}],[\"combination\",{\"1\":{\"95\":1,\"130\":1,\"268\":1}}],[\"combining\",{\"1\":{\"94\":1,\"95\":1,\"142\":1,\"203\":1,\"212\":1}}],[\"commands\",{\"1\":{\"174\":1}}],[\"command\",{\"1\":{\"160\":2}}],[\"commercial\",{\"1\":{\"153\":1}}],[\"commercially\",{\"1\":{\"45\":1}}],[\"communication\",{\"1\":{\"183\":1}}],[\"communicated\",{\"1\":{\"120\":1}}],[\"communicate\",{\"1\":{\"36\":1}}],[\"community\",{\"1\":{\"130\":1,\"170\":2,\"215\":1}}],[\"committee\",{\"1\":{\"105\":1,\"208\":1,\"221\":1}}],[\"commonly\",{\"1\":{\"209\":1,\"210\":1,\"212\":1,\"263\":1}}],[\"commoncrawl\",{\"1\":{\"126\":1}}],[\"commonsense\",{\"1\":{\"71\":1,\"72\":1}}],[\"commonalities\",{\"1\":{\"24\":3}}],[\"common\",{\"1\":{\"5\":1,\"24\":1,\"68\":1,\"72\":1,\"93\":3,\"99\":2,\"101\":1,\"119\":1,\"122\":1,\"124\":1,\"134\":1,\"137\":1,\"196\":1,\"212\":1,\"218\":1}}],[\"comet\",{\"0\":{\"105\":1,\"214\":1},\"1\":{\"105\":3,\"214\":2,\"215\":2,\"216\":1,\"217\":6,\"218\":15,\"219\":3,\"220\":2,\"221\":1},\"2\":{\"223\":1}}],[\"come\",{\"1\":{\"8\":1,\"33\":1,\"100\":1,\"130\":1,\"203\":1,\"231\":1,\"253\":1,\"268\":1}}],[\"comes\",{\"1\":{\"1\":2,\"8\":1,\"33\":1,\"93\":2,\"95\":1,\"101\":1,\"137\":1,\"183\":1,\"228\":2,\"244\":1,\"253\":1,\"268\":1}}],[\"compliant\",{\"1\":{\"215\":1}}],[\"complementary\",{\"1\":{\"254\":1}}],[\"completion\",{\"1\":{\"125\":1}}],[\"completed\",{\"1\":{\"170\":1,\"213\":1}}],[\"completely\",{\"1\":{\"71\":1,\"200\":1,\"233\":1,\"242\":1}}],[\"complete\",{\"1\":{\"25\":1,\"78\":1,\"120\":1,\"171\":1,\"196\":1}}],[\"complexity\",{\"1\":{\"152\":1}}],[\"complex\",{\"1\":{\"23\":1,\"142\":1}}],[\"competitive\",{\"1\":{\"187\":1,\"239\":1,\"244\":1}}],[\"compiling\",{\"1\":{\"159\":1}}],[\"component\",{\"1\":{\"228\":4,\"240\":1}}],[\"components\",{\"0\":{\"137\":1},\"1\":{\"134\":1,\"146\":2,\"152\":1,\"153\":1,\"203\":1}}],[\"composed\",{\"1\":{\"66\":1,\"97\":1,\"134\":1,\"136\":1}}],[\"comprehend\",{\"1\":{\"124\":1}}],[\"comprehension\",{\"0\":{\"124\":1},\"1\":{\"37\":1,\"68\":1,\"121\":1,\"124\":2,\"126\":2}}],[\"comprehensive\",{\"1\":{\"22\":1,\"203\":1,\"259\":1}}],[\"companies\",{\"1\":{\"45\":1}}],[\"comparing\",{\"1\":{\"89\":1,\"202\":1,\"219\":1,\"232\":1}}],[\"comparisons\",{\"1\":{\"152\":1}}],[\"comparison\",{\"0\":{\"257\":1},\"1\":{\"43\":1,\"54\":1,\"59\":1,\"109\":1,\"113\":1,\"122\":1,\"153\":1,\"200\":1,\"218\":1}}],[\"comparable\",{\"1\":{\"43\":1,\"71\":2,\"172\":1,\"254\":1,\"269\":1,\"270\":1}}],[\"compare\",{\"1\":{\"5\":1,\"6\":1,\"7\":1,\"54\":1,\"202\":1,\"218\":1,\"244\":1}}],[\"compares\",{\"1\":{\"2\":1,\"23\":1,\"26\":1,\"174\":2}}],[\"compared\",{\"1\":{\"1\":1,\"25\":2,\"54\":1,\"58\":1,\"93\":2,\"94\":1,\"109\":1,\"112\":1,\"122\":2,\"124\":1,\"130\":1,\"146\":2,\"152\":1,\"170\":1,\"172\":1,\"173\":1,\"199\":1,\"208\":1,\"212\":1,\"213\":2,\"218\":2,\"233\":1,\"244\":1}}],[\"computation\",{\"0\":{\"149\":1},\"1\":{\"212\":1,\"216\":1,\"240\":1,\"242\":1}}],[\"computationally\",{\"1\":{\"72\":1,\"151\":1}}],[\"computational\",{\"1\":{\"1\":3,\"9\":1,\"37\":1,\"105\":7,\"112\":1,\"175\":1}}],[\"computed\",{\"1\":{\"212\":3,\"216\":1}}],[\"compute\",{\"1\":{\"96\":1,\"212\":2,\"219\":1,\"240\":1}}],[\"computes\",{\"1\":{\"73\":1,\"212\":1}}],[\"computers\",{\"1\":{\"41\":2,\"221\":1,\"225\":1,\"228\":1}}],[\"computer\",{\"1\":{\"9\":1,\"130\":1,\"131\":1,\"134\":1,\"151\":1,\"231\":1}}],[\"computing\",{\"0\":{\"166\":1},\"1\":{\"1\":1,\"2\":1,\"6\":1,\"8\":1,\"156\":1,\"166\":1,\"242\":1}}],[\"com\",{\"1\":{\"0\":1,\"21\":1,\"41\":1,\"49\":1,\"64\":1,\"77\":1,\"78\":1,\"92\":1,\"146\":1,\"165\":1,\"166\":1,\"175\":1,\"203\":1,\"220\":2,\"221\":1,\"224\":1,\"235\":1,\"238\":1,\"250\":1,\"269\":1,\"271\":1}}],[\"okay\",{\"1\":{\"227\":1}}],[\"oluqhubekayo\",{\"1\":{\"225\":1}}],[\"olatunji\",{\"1\":{\"167\":1}}],[\"old\",{\"1\":{\"95\":4}}],[\"odkiaľ\",{\"1\":{\"125\":1}}],[\"occasionaly\",{\"1\":{\"126\":1}}],[\"occipital\",{\"1\":{\"94\":1}}],[\"occupancy\",{\"1\":{\"157\":1}}],[\"occupation\",{\"1\":{\"114\":1}}],[\"occupy\",{\"1\":{\"81\":1}}],[\"occurrences\",{\"1\":{\"51\":1}}],[\"occurring\",{\"1\":{\"1\":1}}],[\"occur\",{\"1\":{\"1\":1,\"51\":1}}],[\"occurs\",{\"1\":{\"1\":2,\"2\":1,\"8\":1}}],[\"o\",{\"0\":{\"86\":1},\"1\":{\"34\":1,\"35\":1,\"125\":2,\"155\":1,\"252\":4}}],[\"owners\",{\"1\":{\"45\":1}}],[\"ownership\",{\"1\":{\"41\":1}}],[\"owner\",{\"1\":{\"41\":1}}],[\"own\",{\"1\":{\"30\":1,\"120\":2,\"215\":1,\"228\":1,\"252\":1}}],[\"osaka\",{\"1\":{\"105\":1}}],[\"os\",{\"1\":{\"30\":2}}],[\"overlap\",{\"1\":{\"203\":1}}],[\"overlook\",{\"1\":{\"100\":1}}],[\"overhead\",{\"1\":{\"152\":1}}],[\"overfitting\",{\"1\":{\"119\":1}}],[\"oversimplification\",{\"1\":{\"109\":1}}],[\"oversimplified\",{\"1\":{\"109\":1}}],[\"overparameterization\",{\"1\":{\"109\":3}}],[\"overview\",{\"0\":{\"42\":1,\"136\":1,\"181\":1,\"264\":1},\"1\":{\"96\":1,\"240\":1}}],[\"over\",{\"1\":{\"31\":1,\"51\":2,\"69\":1,\"84\":1,\"85\":1,\"88\":1,\"95\":1,\"125\":1,\"126\":1,\"134\":1,\"146\":2,\"167\":1,\"170\":1,\"188\":1,\"202\":1,\"203\":1,\"225\":2,\"229\":1,\"232\":1,\"241\":1,\"244\":1,\"245\":1,\"253\":1,\"254\":1}}],[\"overcome\",{\"1\":{\"23\":1}}],[\"overall\",{\"0\":{\"5\":1},\"1\":{\"1\":1,\"2\":1,\"51\":1,\"66\":2,\"71\":1,\"111\":1,\"146\":1,\"202\":1,\"217\":1,\"244\":1,\"256\":2}}],[\"obtaiend\",{\"1\":{\"146\":1}}],[\"obtains\",{\"1\":{\"85\":1,\"88\":1,\"98\":1,\"146\":2,\"200\":1,\"214\":1,\"242\":1}}],[\"obtained\",{\"1\":{\"22\":1,\"30\":1,\"146\":1,\"184\":1,\"265\":1}}],[\"obtain\",{\"1\":{\"22\":1,\"42\":1,\"51\":1,\"182\":1,\"184\":1,\"203\":1,\"226\":1,\"254\":1,\"259\":1,\"267\":2}}],[\"obed\",{\"1\":{\"125\":1}}],[\"oblečenie\",{\"1\":{\"125\":1}}],[\"observation\",{\"1\":{\"93\":1}}],[\"observations\",{\"1\":{\"54\":1,\"146\":1}}],[\"observe\",{\"1\":{\"82\":1,\"83\":1,\"200\":1,\"202\":1,\"269\":3}}],[\"observed\",{\"1\":{\"81\":1,\"84\":1,\"146\":4,\"212\":1}}],[\"objects\",{\"1\":{\"71\":1,\"142\":1}}],[\"object\",{\"1\":{\"50\":1,\"130\":5}}],[\"objectives\",{\"1\":{\"23\":2,\"265\":1}}],[\"objective\",{\"1\":{\"1\":1,\"23\":1,\"24\":1,\"80\":1,\"84\":1,\"95\":1,\"268\":1,\"269\":1}}],[\"obvious\",{\"1\":{\"35\":1,\"100\":1,\"189\":1}}],[\"obviously\",{\"1\":{\"1\":1}}],[\"others\",{\"1\":{\"93\":1,\"105\":1,\"109\":1,\"213\":2,\"225\":1}}],[\"other\",{\"1\":{\"1\":6,\"6\":1,\"22\":1,\"24\":1,\"25\":1,\"35\":2,\"57\":1,\"59\":1,\"71\":4,\"72\":2,\"95\":2,\"100\":1,\"105\":1,\"109\":1,\"111\":2,\"115\":2,\"122\":1,\"130\":1,\"146\":4,\"153\":2,\"159\":1,\"178\":1,\"187\":1,\"196\":2,\"197\":2,\"199\":1,\"200\":2,\"201\":1,\"202\":1,\"203\":1,\"211\":1,\"212\":1,\"216\":1,\"217\":2,\"226\":1,\"228\":1,\"231\":2,\"233\":1,\"242\":2,\"244\":1,\"263\":1,\"264\":3}}],[\"otherwise\",{\"1\":{\"1\":1,\"234\":1,\"251\":1}}],[\"opus\",{\"1\":{\"198\":2}}],[\"opus100\",{\"1\":{\"97\":1,\"98\":2}}],[\"opinion\",{\"1\":{\"126\":1,\"208\":1}}],[\"opposed\",{\"1\":{\"122\":1}}],[\"opposite\",{\"1\":{\"1\":1,\"65\":1}}],[\"opennmt\",{\"1\":{\"221\":1}}],[\"openreview\",{\"1\":{\"221\":1}}],[\"open\",{\"1\":{\"149\":1,\"153\":1}}],[\"openai\",{\"1\":{\"119\":2,\"122\":1,\"124\":1}}],[\"opensubtitles\",{\"1\":{\"97\":1}}],[\"operation\",{\"0\":{\"155\":1},\"1\":{\"44\":1,\"240\":1}}],[\"operations\",{\"1\":{\"9\":1,\"240\":1}}],[\"optional\",{\"1\":{\"212\":1}}],[\"optionally\",{\"1\":{\"212\":1}}],[\"option\",{\"1\":{\"6\":1,\"212\":1}}],[\"options\",{\"1\":{\"3\":1}}],[\"optimum\",{\"1\":{\"252\":1}}],[\"optimizations\",{\"1\":{\"167\":1,\"182\":1}}],[\"optimization\",{\"1\":{\"152\":2}}],[\"optimized\",{\"1\":{\"226\":1,\"242\":1}}],[\"optimizes\",{\"1\":{\"156\":1}}],[\"optimize\",{\"1\":{\"3\":1,\"69\":1,\"105\":1,\"154\":1,\"172\":1,\"196\":1,\"212\":1,\"216\":1}}],[\"optimizing\",{\"1\":{\"1\":1,\"153\":2}}],[\"optimal\",{\"0\":{\"0\":1},\"1\":{\"0\":2,\"1\":2,\"2\":1,\"3\":7,\"8\":3,\"109\":1,\"244\":1},\"2\":{\"11\":1}}],[\"oov\",{\"1\":{\"1\":1}}],[\"outside\",{\"1\":{\"231\":1,\"232\":1}}],[\"outstanding\",{\"1\":{\"201\":1}}],[\"outdatedness\",{\"1\":{\"218\":1}}],[\"outdated\",{\"1\":{\"215\":1}}],[\"outcome\",{\"1\":{\"71\":1,\"212\":1}}],[\"outlined\",{\"1\":{\"42\":1}}],[\"outputs\",{\"1\":{\"44\":1,\"96\":1,\"172\":2}}],[\"output\",{\"1\":{\"35\":2,\"42\":4,\"43\":1,\"45\":1,\"71\":1,\"96\":3,\"111\":1,\"125\":1,\"156\":1,\"172\":1,\"196\":1,\"197\":1,\"218\":1,\"225\":1,\"232\":1,\"233\":1,\"240\":3,\"251\":1}}],[\"outperformance\",{\"1\":{\"213\":1}}],[\"outperform\",{\"1\":{\"121\":1,\"122\":1,\"124\":1,\"239\":1}}],[\"outperforming\",{\"1\":{\"71\":1}}],[\"outperformed\",{\"1\":{\"5\":1,\"123\":2}}],[\"outperforms\",{\"1\":{\"5\":1,\"54\":1,\"57\":1,\"60\":1,\"71\":1,\"87\":1,\"93\":1,\"113\":2,\"146\":1,\"187\":1,\"194\":1,\"199\":1,\"201\":1,\"217\":1,\"238\":1,\"244\":3,\"254\":1,\"256\":1,\"269\":1,\"270\":1}}],[\"out\",{\"1\":{\"1\":1,\"5\":1,\"6\":1,\"51\":1,\"68\":1,\"81\":1,\"93\":3,\"100\":1,\"126\":1,\"130\":1,\"139\":1,\"146\":2,\"188\":1,\"215\":1,\"229\":1,\"234\":1}}],[\"our\",{\"0\":{\"51\":1,\"80\":1},\"1\":{\"1\":5,\"2\":1,\"3\":1,\"21\":1,\"51\":2,\"53\":1,\"54\":3,\"57\":1,\"59\":1,\"60\":1,\"68\":1,\"84\":1,\"85\":1,\"86\":1,\"87\":1,\"110\":1,\"115\":1,\"125\":1,\"141\":1,\"170\":2,\"172\":1,\"179\":1,\"215\":1,\"218\":10,\"232\":1,\"268\":1}}],[\"originated\",{\"1\":{\"95\":1}}],[\"originally\",{\"1\":{\"233\":1,\"251\":1}}],[\"original\",{\"1\":{\"1\":1,\"24\":1,\"29\":1,\"30\":2,\"32\":1,\"45\":1,\"66\":1,\"67\":1,\"68\":2,\"71\":1,\"98\":1,\"119\":1,\"175\":1,\"211\":1,\"213\":1,\"216\":1,\"228\":1,\"231\":2,\"232\":1,\"233\":2,\"240\":1,\"242\":1,\"244\":1,\"250\":1,\"251\":1,\"266\":6,\"267\":1,\"269\":2}}],[\"origin\",{\"1\":{\"71\":1,\"82\":2,\"256\":2,\"257\":3}}],[\"ordre\",{\"1\":{\"29\":1}}],[\"ordering\",{\"1\":{\"211\":1}}],[\"order\",{\"1\":{\"24\":2,\"28\":1,\"41\":1,\"42\":2,\"65\":1,\"72\":1,\"125\":1,\"211\":2,\"218\":1,\"225\":1,\"226\":1,\"233\":1,\"266\":2}}],[\"or\",{\"1\":{\"1\":8,\"8\":1,\"24\":2,\"27\":1,\"40\":1,\"41\":1,\"42\":1,\"43\":1,\"51\":1,\"54\":4,\"65\":1,\"66\":1,\"71\":1,\"72\":1,\"78\":1,\"79\":1,\"100\":1,\"105\":2,\"111\":1,\"119\":1,\"120\":1,\"121\":1,\"123\":2,\"124\":1,\"126\":2,\"132\":1,\"134\":1,\"146\":1,\"151\":2,\"152\":1,\"153\":1,\"155\":1,\"158\":1,\"178\":1,\"211\":2,\"216\":1,\"217\":1,\"226\":1,\"229\":1,\"233\":1,\"244\":2,\"253\":1,\"264\":1,\"266\":1,\"270\":1}}],[\"organized\",{\"1\":{\"239\":1}}],[\"organizing\",{\"1\":{\"105\":1}}],[\"organization\",{\"1\":{\"29\":2,\"170\":1}}],[\"org\",{\"1\":{\"0\":1,\"12\":1,\"21\":1,\"41\":1,\"46\":1,\"49\":1,\"64\":1,\"77\":1,\"92\":1,\"102\":1,\"143\":1,\"146\":1,\"175\":1,\"221\":1,\"224\":1,\"238\":1,\"250\":1}}],[\"ongoing\",{\"1\":{\"225\":1}}],[\"online\",{\"1\":{\"105\":1,\"152\":1,\"218\":2}}],[\"only\",{\"0\":{\"0\":1,\"263\":1},\"1\":{\"1\":3,\"5\":1,\"22\":2,\"23\":1,\"24\":2,\"25\":4,\"27\":3,\"44\":2,\"53\":1,\"54\":1,\"57\":1,\"59\":2,\"65\":1,\"71\":1,\"93\":2,\"94\":1,\"95\":1,\"100\":1,\"109\":2,\"111\":1,\"113\":1,\"115\":1,\"124\":2,\"131\":1,\"139\":1,\"141\":1,\"142\":1,\"146\":6,\"153\":2,\"155\":1,\"156\":1,\"159\":1,\"174\":1,\"175\":1,\"187\":1,\"188\":1,\"200\":2,\"201\":1,\"216\":1,\"219\":1,\"239\":1,\"240\":1,\"251\":1,\"252\":2,\"253\":1,\"263\":1,\"271\":1}}],[\"onto\",{\"1\":{\"42\":1}}],[\"once\",{\"1\":{\"1\":1}}],[\"ones\",{\"1\":{\"21\":1,\"84\":1,\"146\":1,\"266\":4}}],[\"one\",{\"1\":{\"1\":3,\"2\":3,\"3\":2,\"4\":1,\"6\":1,\"8\":2,\"24\":5,\"27\":2,\"31\":1,\"36\":1,\"42\":1,\"43\":1,\"51\":1,\"68\":1,\"69\":1,\"71\":3,\"93\":2,\"95\":1,\"97\":3,\"100\":3,\"101\":1,\"105\":1,\"109\":2,\"111\":1,\"112\":1,\"113\":3,\"120\":5,\"121\":1,\"122\":2,\"123\":2,\"124\":1,\"125\":1,\"126\":3,\"130\":1,\"146\":2,\"155\":1,\"158\":1,\"188\":1,\"190\":1,\"200\":1,\"208\":2,\"209\":1,\"210\":1,\"216\":1,\"217\":2,\"218\":1,\"224\":1,\"225\":1,\"226\":1,\"227\":2,\"228\":3,\"234\":1,\"238\":1,\"256\":1,\"263\":2,\"264\":3,\"267\":2}}],[\"on\",{\"0\":{\"7\":1,\"121\":1,\"149\":1,\"165\":1,\"166\":1,\"252\":1},\"1\":{\"1\":5,\"2\":5,\"3\":5,\"4\":1,\"5\":1,\"7\":2,\"8\":3,\"21\":2,\"22\":8,\"23\":6,\"24\":3,\"25\":1,\"26\":4,\"27\":2,\"30\":2,\"35\":2,\"37\":1,\"41\":1,\"42\":1,\"43\":4,\"49\":2,\"53\":2,\"54\":5,\"55\":1,\"57\":1,\"58\":1,\"60\":1,\"65\":3,\"68\":2,\"69\":1,\"70\":2,\"71\":4,\"72\":5,\"77\":2,\"78\":1,\"85\":1,\"86\":1,\"88\":2,\"89\":1,\"93\":3,\"94\":3,\"95\":2,\"96\":2,\"97\":1,\"98\":4,\"99\":6,\"101\":1,\"105\":9,\"111\":1,\"112\":1,\"113\":6,\"114\":2,\"115\":1,\"119\":2,\"120\":4,\"121\":2,\"122\":2,\"123\":3,\"124\":5,\"126\":3,\"130\":2,\"139\":1,\"142\":1,\"146\":19,\"151\":2,\"153\":2,\"157\":1,\"159\":1,\"160\":1,\"161\":1,\"163\":1,\"164\":1,\"165\":1,\"166\":2,\"167\":1,\"172\":1,\"174\":5,\"175\":2,\"178\":1,\"187\":8,\"194\":3,\"195\":1,\"196\":1,\"199\":1,\"200\":4,\"201\":4,\"202\":2,\"203\":2,\"208\":5,\"209\":2,\"210\":2,\"211\":1,\"212\":2,\"213\":3,\"214\":1,\"215\":1,\"216\":1,\"217\":2,\"218\":7,\"219\":1,\"221\":1,\"225\":1,\"226\":1,\"227\":3,\"228\":2,\"231\":1,\"232\":1,\"233\":1,\"238\":1,\"239\":4,\"240\":2,\"242\":2,\"244\":4,\"245\":2,\"246\":1,\"247\":1,\"250\":1,\"251\":1,\"252\":2,\"253\":1,\"256\":1,\"257\":3,\"258\":3,\"259\":1,\"260\":1,\"263\":3,\"269\":5,\"270\":1}}],[\"ofthe\",{\"1\":{\"105\":2}}],[\"often\",{\"1\":{\"1\":2,\"2\":1,\"24\":1,\"126\":1,\"146\":1,\"156\":1,\"251\":1}}],[\"official\",{\"1\":{\"153\":2,\"163\":1,\"164\":1,\"217\":1}}],[\"offered\",{\"1\":{\"120\":1}}],[\"off\",{\"1\":{\"1\":1,\"3\":1,\"68\":2}}],[\"of\",{\"0\":{\"3\":1,\"4\":1,\"7\":1,\"24\":1,\"25\":1,\"34\":1,\"35\":1,\"40\":1,\"64\":1,\"67\":1,\"71\":1,\"81\":1,\"95\":1,\"98\":1,\"112\":1,\"170\":1,\"173\":1,\"202\":1,\"203\":1,\"207\":1,\"229\":1,\"243\":1},\"1\":{\"1\":24,\"2\":9,\"3\":14,\"4\":3,\"5\":6,\"6\":3,\"7\":1,\"8\":4,\"9\":5,\"21\":1,\"22\":12,\"23\":17,\"24\":13,\"25\":11,\"26\":1,\"27\":4,\"28\":1,\"29\":1,\"30\":6,\"31\":4,\"33\":6,\"34\":1,\"35\":13,\"36\":10,\"37\":4,\"41\":12,\"42\":8,\"43\":10,\"44\":3,\"45\":7,\"49\":3,\"50\":2,\"51\":11,\"53\":1,\"54\":2,\"57\":1,\"59\":4,\"60\":1,\"61\":1,\"65\":9,\"66\":6,\"67\":2,\"68\":6,\"69\":7,\"71\":25,\"72\":2,\"73\":5,\"78\":2,\"80\":2,\"82\":3,\"84\":5,\"85\":2,\"86\":2,\"87\":1,\"88\":2,\"89\":5,\"93\":17,\"94\":19,\"95\":11,\"96\":10,\"97\":12,\"98\":5,\"100\":9,\"101\":4,\"102\":2,\"105\":18,\"109\":5,\"110\":11,\"111\":4,\"112\":16,\"113\":6,\"114\":1,\"115\":4,\"116\":1,\"119\":6,\"120\":10,\"121\":4,\"122\":5,\"123\":7,\"124\":10,\"125\":7,\"126\":11,\"130\":12,\"131\":1,\"132\":5,\"133\":2,\"134\":2,\"135\":1,\"136\":1,\"137\":6,\"139\":1,\"140\":1,\"142\":1,\"146\":13,\"151\":2,\"152\":2,\"153\":2,\"154\":1,\"155\":2,\"156\":6,\"157\":1,\"166\":1,\"167\":2,\"170\":6,\"171\":5,\"172\":9,\"173\":1,\"174\":4,\"175\":7,\"178\":3,\"179\":1,\"181\":2,\"182\":1,\"183\":2,\"184\":1,\"186\":1,\"187\":1,\"188\":3,\"194\":2,\"195\":2,\"196\":5,\"197\":2,\"198\":1,\"199\":1,\"200\":1,\"201\":3,\"202\":1,\"203\":6,\"206\":1,\"208\":8,\"209\":4,\"210\":1,\"211\":12,\"212\":15,\"213\":6,\"214\":4,\"215\":2,\"216\":4,\"217\":5,\"218\":17,\"219\":4,\"221\":5,\"224\":2,\"225\":6,\"226\":11,\"227\":4,\"228\":9,\"231\":5,\"232\":2,\"233\":4,\"234\":1,\"238\":1,\"239\":8,\"240\":11,\"242\":8,\"244\":2,\"245\":7,\"246\":1,\"247\":3,\"251\":2,\"252\":3,\"253\":6,\"254\":1,\"257\":1,\"258\":3,\"259\":1,\"263\":4,\"264\":5,\"266\":2,\"267\":2,\"268\":3,\"269\":5,\"271\":1}}]],\"serializationVersion\":2}}")).map(([e,t])=>[e,zt(t,{fields:["h","t","c"],storeFields:["h","t","c"]})]));self.onmessage=({data:{type:e="all",query:t,locale:s,options:n}})=>{e==="suggest"?self.postMessage(st(t,v[s],n)):e==="search"?self.postMessage(et(t,v[s],n)):self.postMessage({suggestions:st(t,v[s],n),results:et(t,v[s],n)})};
//# sourceMappingURL=index.js.map
